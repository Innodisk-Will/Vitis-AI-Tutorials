##
##* Â© Copyright (C) 2021 Xilinx, Inc
##*
##* Licensed under the Apache License, Version 2.0 (the "License"). You may
##* not use this file except in compliance with the License. A copy of the
##* License is located at
##*
##*     http://www.apache.org/licenses/LICENSE-2.0
##*
##* Unless required by applicable law or agreed to in writing, software
##* distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
##* WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
##* License for the specific language governing permissions and limitations
##* under the License.
##
## *******************************************************************************



Collecting lmdb==0.98
  Downloading lmdb-0.98.tar.gz (869 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Building wheels for collected packages: lmdb
  Building wheel for lmdb (setup.py): started
  Building wheel for lmdb (setup.py): finished with status 'done'
  Created wheel for lmdb: filename=lmdb-0.98-cp36-cp36m-linux_x86_64.whl size=297440 sha256=d181dde5b08a6c4357eb5e2cd741b35c6d20e4534103e9251a804aff41a4ddf7
  Stored in directory: /home/vitis-ai-user/.cache/pip/wheels/6e/53/3d/5a93174b38712013b3a3b3df15ea2a5144bd11b22edb84a14b
Successfully built lmdb
Installing collected packages: lmdb
Successfully installed lmdb-0.98

project ML_DIR is /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files
CAFFE_TOOLS_DIR is /workspace/VAI2.0/tutorials/caffe-xilinx
rm: cannot remove '/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/test': No such file or directory
 END

DATABASE: training and validation in LMDB, test in JPG and MEAN values
BUILD THE VALIDATION SET with 4000 images: 2000 per each class
BUILD THE TEST SET with 1000 images of size 227 x 277
Test       set contains  1000  images
BUILD THE TRAIN IMAGES SET with 20000 images
BUILD THE CALIBRATION IMAGES SET with 200 images
Train      set contains  20000  images
Validation set contains  4000  images
Calibrationset contains  200  images
END

 mean value channel 0:  106.3889
 mean value channel 1:  116.175804
 mean value channel 2:  124.65352

Creating train_lmdb


Creating valid_lmdb

Finished processing all images

 Number of images in LMDB training   dataset  20000

 Number of images in LMDB validation dataset  4000
Now testing VALIDATION LMDB
Now testing TRAINING LMDB
number of images in the VALID database = 4000
number of images in the TRAIN database = 20000

I0614 09:42:22.375000   290 gpu_memory.cpp:53] GPUMemory::Manager initialized with Caching (CUB) GPU Allocator
I0614 09:42:22.375203   290 gpu_memory.cpp:55] Total memory: 25635127296, Free: 24783683584, dev_info[0]: total=25635127296 free=24783683584
I0614 09:42:22.375347   290 caffe.cpp:213] Using GPUs 0
I0614 09:42:22.375452   290 caffe.cpp:218] GPU 0: Quadro P6000
I0614 09:42:23.038311   290 solver.cpp:51] Initializing solver from parameters: 
test_iter: 80
test_interval: 1000
base_lr: 0.001
display: 50
max_iter: 20000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 2500
snapshot: 5000
snapshot_prefix: "caffe/models/alexnetBNnoLRN/m2/snapshot_2_alexnetBNnoLRN_"
solver_mode: GPU
device_id: 0
random_seed: 1201
net: "caffe/models/alexnetBNnoLRN/m2/train_val_2_alexnetBNnoLRN.prototxt"
type: "Adam"
I0614 09:42:23.039595   290 solver.cpp:99] Creating training net from net file: caffe/models/alexnetBNnoLRN/m2/train_val_2_alexnetBNnoLRN.prototxt
I0614 09:42:23.058048   290 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0614 09:42:23.058128   290 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0614 09:42:23.058143   290 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy-top1
I0614 09:42:23.058157   290 net.cpp:52] Initializing net from parameters: 
name: "alexnetBNnoLRN m2 (as m3 but less DROP and less BN)"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_value: 106
    mean_value: 116
    mean_value: 124
  }
  data_param {
    source: "input/lmdb/train_lmdb"
    batch_size: 256
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 0
    kernel_size: 8
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "bn1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "bn2"
  top: "relu2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "relu6"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "drop6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn7"
  type: "BatchNorm"
  bottom: "fc7"
  top: "bn7"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "bn7"
  top: "relu7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "relu7"
  top: "drop7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "drop7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0614 09:42:23.058853   290 layer_factory.hpp:77] Creating layer data
I0614 09:42:23.059751   290 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0614 09:42:23.062798   290 net.cpp:94] Creating Layer data
I0614 09:42:23.062830   290 net.cpp:409] data -> data
I0614 09:42:23.062860   290 net.cpp:409] data -> label
I0614 09:42:23.064149   322 db_lmdb.cpp:35] Opened lmdb input/lmdb/train_lmdb
I0614 09:42:23.064180   322 db_lmdb.cpp:38] Items count: 20000
I0614 09:42:23.064220   322 data_reader.cpp:124] TRAIN: reading data using 1 channel(s)
I0614 09:42:23.065183   290 data_layer.cpp:78] ReshapePrefetch 256, 3, 227, 227
I0614 09:42:23.065392   290 data_layer.cpp:83] output data size: 256,3,227,227
I0614 09:42:23.595611   290 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0614 09:42:23.595762   290 net.cpp:144] Setting up data
I0614 09:42:23.595767   290 net.cpp:151] Top shape: 256 3 227 227 (39574272)
I0614 09:42:23.595777   290 net.cpp:151] Top shape: 256 (256)
I0614 09:42:23.595780   290 net.cpp:159] Memory required for data: 158298112
I0614 09:42:23.595785   290 layer_factory.hpp:77] Creating layer conv1
I0614 09:42:23.595804   290 net.cpp:94] Creating Layer conv1
I0614 09:42:23.595808   290 net.cpp:435] conv1 <- data
I0614 09:42:23.595815   290 net.cpp:409] conv1 -> conv1
I0614 09:42:23.598014   290 net.cpp:144] Setting up conv1
I0614 09:42:23.598023   290 net.cpp:151] Top shape: 256 96 55 55 (74342400)
I0614 09:42:23.598029   290 net.cpp:159] Memory required for data: 455667712
I0614 09:42:23.598038   290 layer_factory.hpp:77] Creating layer bn1
I0614 09:42:23.598062   290 net.cpp:94] Creating Layer bn1
I0614 09:42:23.598065   290 net.cpp:435] bn1 <- conv1
I0614 09:42:23.598070   290 net.cpp:409] bn1 -> bn1
I0614 09:42:23.598767   290 net.cpp:144] Setting up bn1
I0614 09:42:23.598774   290 net.cpp:151] Top shape: 256 96 55 55 (74342400)
I0614 09:42:23.598780   290 net.cpp:159] Memory required for data: 753037312
I0614 09:42:23.598790   290 layer_factory.hpp:77] Creating layer relu1
I0614 09:42:23.598796   290 net.cpp:94] Creating Layer relu1
I0614 09:42:23.598799   290 net.cpp:435] relu1 <- bn1
I0614 09:42:23.598804   290 net.cpp:409] relu1 -> relu1
I0614 09:42:23.599009   290 net.cpp:144] Setting up relu1
I0614 09:42:23.599014   290 net.cpp:151] Top shape: 256 96 55 55 (74342400)
I0614 09:42:23.599020   290 net.cpp:159] Memory required for data: 1050406912
I0614 09:42:23.599023   290 layer_factory.hpp:77] Creating layer pool1
I0614 09:42:23.599030   290 net.cpp:94] Creating Layer pool1
I0614 09:42:23.599033   290 net.cpp:435] pool1 <- relu1
I0614 09:42:23.599037   290 net.cpp:409] pool1 -> pool1
I0614 09:42:23.599053   290 net.cpp:144] Setting up pool1
I0614 09:42:23.599057   290 net.cpp:151] Top shape: 256 96 27 27 (17915904)
I0614 09:42:23.599061   290 net.cpp:159] Memory required for data: 1122070528
I0614 09:42:23.599066   290 layer_factory.hpp:77] Creating layer conv2
I0614 09:42:23.599072   290 net.cpp:94] Creating Layer conv2
I0614 09:42:23.599076   290 net.cpp:435] conv2 <- pool1
I0614 09:42:23.599081   290 net.cpp:409] conv2 -> conv2
I0614 09:42:23.613579   290 net.cpp:144] Setting up conv2
I0614 09:42:23.613596   290 net.cpp:151] Top shape: 256 256 27 27 (47775744)
I0614 09:42:23.613605   290 net.cpp:159] Memory required for data: 1313173504
I0614 09:42:23.613615   290 layer_factory.hpp:77] Creating layer bn2
I0614 09:42:23.613626   290 net.cpp:94] Creating Layer bn2
I0614 09:42:23.613631   290 net.cpp:435] bn2 <- conv2
I0614 09:42:23.613637   290 net.cpp:409] bn2 -> bn2
I0614 09:42:23.613916   290 net.cpp:144] Setting up bn2
I0614 09:42:23.613922   290 net.cpp:151] Top shape: 256 256 27 27 (47775744)
I0614 09:42:23.613929   290 net.cpp:159] Memory required for data: 1504276480
I0614 09:42:23.613937   290 layer_factory.hpp:77] Creating layer relu2
I0614 09:42:23.613942   290 net.cpp:94] Creating Layer relu2
I0614 09:42:23.613946   290 net.cpp:435] relu2 <- bn2
I0614 09:42:23.613951   290 net.cpp:409] relu2 -> relu2
I0614 09:42:23.613965   290 net.cpp:144] Setting up relu2
I0614 09:42:23.613968   290 net.cpp:151] Top shape: 256 256 27 27 (47775744)
I0614 09:42:23.613973   290 net.cpp:159] Memory required for data: 1695379456
I0614 09:42:23.613977   290 layer_factory.hpp:77] Creating layer pool2
I0614 09:42:23.613983   290 net.cpp:94] Creating Layer pool2
I0614 09:42:23.613987   290 net.cpp:435] pool2 <- relu2
I0614 09:42:23.613992   290 net.cpp:409] pool2 -> pool2
I0614 09:42:23.614007   290 net.cpp:144] Setting up pool2
I0614 09:42:23.614012   290 net.cpp:151] Top shape: 256 256 13 13 (11075584)
I0614 09:42:23.614017   290 net.cpp:159] Memory required for data: 1739681792
I0614 09:42:23.614020   290 layer_factory.hpp:77] Creating layer conv3
I0614 09:42:23.614027   290 net.cpp:94] Creating Layer conv3
I0614 09:42:23.614032   290 net.cpp:435] conv3 <- pool2
I0614 09:42:23.614037   290 net.cpp:409] conv3 -> conv3
I0614 09:42:23.627271   290 net.cpp:144] Setting up conv3
I0614 09:42:23.627298   290 net.cpp:151] Top shape: 256 384 13 13 (16613376)
I0614 09:42:23.627310   290 net.cpp:159] Memory required for data: 1806135296
I0614 09:42:23.627324   290 layer_factory.hpp:77] Creating layer relu3
I0614 09:42:23.627336   290 net.cpp:94] Creating Layer relu3
I0614 09:42:23.627341   290 net.cpp:435] relu3 <- conv3
I0614 09:42:23.627349   290 net.cpp:409] relu3 -> relu3
I0614 09:42:23.627372   290 net.cpp:144] Setting up relu3
I0614 09:42:23.627377   290 net.cpp:151] Top shape: 256 384 13 13 (16613376)
I0614 09:42:23.627382   290 net.cpp:159] Memory required for data: 1872588800
I0614 09:42:23.627384   290 layer_factory.hpp:77] Creating layer conv4
I0614 09:42:23.627416   290 net.cpp:94] Creating Layer conv4
I0614 09:42:23.627420   290 net.cpp:435] conv4 <- relu3
I0614 09:42:23.627425   290 net.cpp:409] conv4 -> conv4
I0614 09:42:23.655006   290 net.cpp:144] Setting up conv4
I0614 09:42:23.655084   290 net.cpp:151] Top shape: 256 384 13 13 (16613376)
I0614 09:42:23.655102   290 net.cpp:159] Memory required for data: 1939042304
I0614 09:42:23.655124   290 layer_factory.hpp:77] Creating layer relu4
I0614 09:42:23.655139   290 net.cpp:94] Creating Layer relu4
I0614 09:42:23.655149   290 net.cpp:435] relu4 <- conv4
I0614 09:42:23.655164   290 net.cpp:409] relu4 -> relu4
I0614 09:42:23.655220   290 net.cpp:144] Setting up relu4
I0614 09:42:23.655227   290 net.cpp:151] Top shape: 256 384 13 13 (16613376)
I0614 09:42:23.655237   290 net.cpp:159] Memory required for data: 2005495808
I0614 09:42:23.655244   290 layer_factory.hpp:77] Creating layer conv5
I0614 09:42:23.655261   290 net.cpp:94] Creating Layer conv5
I0614 09:42:23.655267   290 net.cpp:435] conv5 <- relu4
I0614 09:42:23.655277   290 net.cpp:409] conv5 -> conv5
I0614 09:42:23.692849   290 net.cpp:144] Setting up conv5
I0614 09:42:23.692881   290 net.cpp:151] Top shape: 256 256 13 13 (11075584)
I0614 09:42:23.692895   290 net.cpp:159] Memory required for data: 2049798144
I0614 09:42:23.692910   290 layer_factory.hpp:77] Creating layer relu5
I0614 09:42:23.692922   290 net.cpp:94] Creating Layer relu5
I0614 09:42:23.692931   290 net.cpp:435] relu5 <- conv5
I0614 09:42:23.692941   290 net.cpp:409] relu5 -> relu5
I0614 09:42:23.692973   290 net.cpp:144] Setting up relu5
I0614 09:42:23.692981   290 net.cpp:151] Top shape: 256 256 13 13 (11075584)
I0614 09:42:23.692987   290 net.cpp:159] Memory required for data: 2094100480
I0614 09:42:23.692993   290 layer_factory.hpp:77] Creating layer pool5
I0614 09:42:23.693002   290 net.cpp:94] Creating Layer pool5
I0614 09:42:23.693008   290 net.cpp:435] pool5 <- relu5
I0614 09:42:23.693015   290 net.cpp:409] pool5 -> pool5
I0614 09:42:23.693059   290 net.cpp:144] Setting up pool5
I0614 09:42:23.693073   290 net.cpp:151] Top shape: 256 256 6 6 (2359296)
I0614 09:42:23.693087   290 net.cpp:159] Memory required for data: 2103537664
I0614 09:42:23.693096   290 layer_factory.hpp:77] Creating layer fc6
I0614 09:42:23.694622   290 net.cpp:94] Creating Layer fc6
I0614 09:42:23.694679   290 net.cpp:435] fc6 <- pool5
I0614 09:42:23.694711   290 net.cpp:409] fc6 -> fc6
I0614 09:42:24.061004   290 net.cpp:144] Setting up fc6
I0614 09:42:24.061028   290 net.cpp:151] Top shape: 256 4096 (1048576)
I0614 09:42:24.061036   290 net.cpp:159] Memory required for data: 2107731968
I0614 09:42:24.061048   290 layer_factory.hpp:77] Creating layer relu6
I0614 09:42:24.061055   290 net.cpp:94] Creating Layer relu6
I0614 09:42:24.061059   290 net.cpp:435] relu6 <- fc6
I0614 09:42:24.061066   290 net.cpp:409] relu6 -> relu6
I0614 09:42:24.061082   290 net.cpp:144] Setting up relu6
I0614 09:42:24.061085   290 net.cpp:151] Top shape: 256 4096 (1048576)
I0614 09:42:24.061089   290 net.cpp:159] Memory required for data: 2111926272
I0614 09:42:24.061092   290 layer_factory.hpp:77] Creating layer drop6
I0614 09:42:24.061162   290 net.cpp:94] Creating Layer drop6
I0614 09:42:24.061167   290 net.cpp:435] drop6 <- relu6
I0614 09:42:24.061170   290 net.cpp:409] drop6 -> drop6
I0614 09:42:24.061185   290 net.cpp:144] Setting up drop6
I0614 09:42:24.061189   290 net.cpp:151] Top shape: 256 4096 (1048576)
I0614 09:42:24.061192   290 net.cpp:159] Memory required for data: 2116120576
I0614 09:42:24.061195   290 layer_factory.hpp:77] Creating layer fc7
I0614 09:42:24.061203   290 net.cpp:94] Creating Layer fc7
I0614 09:42:24.061205   290 net.cpp:435] fc7 <- drop6
I0614 09:42:24.061209   290 net.cpp:409] fc7 -> fc7
I0614 09:42:24.203449   290 net.cpp:144] Setting up fc7
I0614 09:42:24.203471   290 net.cpp:151] Top shape: 256 4096 (1048576)
I0614 09:42:24.203480   290 net.cpp:159] Memory required for data: 2120314880
I0614 09:42:24.203490   290 layer_factory.hpp:77] Creating layer bn7
I0614 09:42:24.203526   290 net.cpp:94] Creating Layer bn7
I0614 09:42:24.203531   290 net.cpp:435] bn7 <- fc7
I0614 09:42:24.203537   290 net.cpp:409] bn7 -> bn7
I0614 09:42:24.203799   290 net.cpp:144] Setting up bn7
I0614 09:42:24.203802   290 net.cpp:151] Top shape: 256 4096 (1048576)
I0614 09:42:24.203806   290 net.cpp:159] Memory required for data: 2124509184
I0614 09:42:24.203814   290 layer_factory.hpp:77] Creating layer relu7
I0614 09:42:24.203819   290 net.cpp:94] Creating Layer relu7
I0614 09:42:24.203822   290 net.cpp:435] relu7 <- bn7
I0614 09:42:24.203826   290 net.cpp:409] relu7 -> relu7
I0614 09:42:24.203837   290 net.cpp:144] Setting up relu7
I0614 09:42:24.203856   290 net.cpp:151] Top shape: 256 4096 (1048576)
I0614 09:42:24.203860   290 net.cpp:159] Memory required for data: 2128703488
I0614 09:42:24.203864   290 layer_factory.hpp:77] Creating layer drop7
I0614 09:42:24.203869   290 net.cpp:94] Creating Layer drop7
I0614 09:42:24.203872   290 net.cpp:435] drop7 <- relu7
I0614 09:42:24.203877   290 net.cpp:409] drop7 -> drop7
I0614 09:42:24.203891   290 net.cpp:144] Setting up drop7
I0614 09:42:24.203895   290 net.cpp:151] Top shape: 256 4096 (1048576)
I0614 09:42:24.203899   290 net.cpp:159] Memory required for data: 2132897792
I0614 09:42:24.203902   290 layer_factory.hpp:77] Creating layer fc8
I0614 09:42:24.203908   290 net.cpp:94] Creating Layer fc8
I0614 09:42:24.203912   290 net.cpp:435] fc8 <- drop7
I0614 09:42:24.203917   290 net.cpp:409] fc8 -> fc8
I0614 09:42:24.204032   290 net.cpp:144] Setting up fc8
I0614 09:42:24.204036   290 net.cpp:151] Top shape: 256 2 (512)
I0614 09:42:24.204041   290 net.cpp:159] Memory required for data: 2132899840
I0614 09:42:24.204046   290 layer_factory.hpp:77] Creating layer loss
I0614 09:42:24.205945   290 net.cpp:94] Creating Layer loss
I0614 09:42:24.205986   290 net.cpp:435] loss <- fc8
I0614 09:42:24.206003   290 net.cpp:435] loss <- label
I0614 09:42:24.206019   290 net.cpp:409] loss -> loss
I0614 09:42:24.206053   290 layer_factory.hpp:77] Creating layer loss
I0614 09:42:24.206212   290 net.cpp:144] Setting up loss
I0614 09:42:24.206228   290 net.cpp:151] Top shape: (1)
I0614 09:42:24.206243   290 net.cpp:154]     with loss weight 1
I0614 09:42:24.206292   290 net.cpp:159] Memory required for data: 2132899844
I0614 09:42:24.206305   290 net.cpp:220] loss needs backward computation.
I0614 09:42:24.206317   290 net.cpp:220] fc8 needs backward computation.
I0614 09:42:24.206329   290 net.cpp:220] drop7 needs backward computation.
I0614 09:42:24.206341   290 net.cpp:220] relu7 needs backward computation.
I0614 09:42:24.206352   290 net.cpp:220] bn7 needs backward computation.
I0614 09:42:24.206364   290 net.cpp:220] fc7 needs backward computation.
I0614 09:42:24.206377   290 net.cpp:220] drop6 needs backward computation.
I0614 09:42:24.206388   290 net.cpp:220] relu6 needs backward computation.
I0614 09:42:24.206400   290 net.cpp:220] fc6 needs backward computation.
I0614 09:42:24.206413   290 net.cpp:220] pool5 needs backward computation.
I0614 09:42:24.206423   290 net.cpp:220] relu5 needs backward computation.
I0614 09:42:24.206435   290 net.cpp:220] conv5 needs backward computation.
I0614 09:42:24.206447   290 net.cpp:220] relu4 needs backward computation.
I0614 09:42:24.206459   290 net.cpp:220] conv4 needs backward computation.
I0614 09:42:24.206470   290 net.cpp:220] relu3 needs backward computation.
I0614 09:42:24.206482   290 net.cpp:220] conv3 needs backward computation.
I0614 09:42:24.206493   290 net.cpp:220] pool2 needs backward computation.
I0614 09:42:24.206506   290 net.cpp:220] relu2 needs backward computation.
I0614 09:42:24.206517   290 net.cpp:220] bn2 needs backward computation.
I0614 09:42:24.206528   290 net.cpp:220] conv2 needs backward computation.
I0614 09:42:24.206540   290 net.cpp:220] pool1 needs backward computation.
I0614 09:42:24.206552   290 net.cpp:220] relu1 needs backward computation.
I0614 09:42:24.206563   290 net.cpp:220] bn1 needs backward computation.
I0614 09:42:24.206575   290 net.cpp:220] conv1 needs backward computation.
I0614 09:42:24.206619   290 net.cpp:222] data does not need backward computation.
I0614 09:42:24.206630   290 net.cpp:264] This network produces output loss
I0614 09:42:24.206679   290 net.cpp:284] Network initialization done.
I0614 09:42:24.208117   290 solver.cpp:189] Creating test net (#0) specified by net file: caffe/models/alexnetBNnoLRN/m2/train_val_2_alexnetBNnoLRN.prototxt
I0614 09:42:24.208214   290 net.cpp:323] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0614 09:42:24.208258   290 net.cpp:52] Initializing net from parameters: 
name: "alexnetBNnoLRN m2 (as m3 but less DROP and less BN)"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_value: 106
    mean_value: 116
    mean_value: 124
  }
  data_param {
    source: "input/lmdb/valid_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 0
    kernel_size: 8
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "bn1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "bn2"
  top: "relu2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "relu6"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "drop6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn7"
  type: "BatchNorm"
  bottom: "fc7"
  top: "bn7"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "bn7"
  top: "relu7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "relu7"
  top: "drop7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "drop7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy-top1"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "top-1"
  include {
    phase: TEST
  }
}
I0614 09:42:24.208881   290 layer_factory.hpp:77] Creating layer data
I0614 09:42:24.209030   290 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0614 09:42:24.211669   290 net.cpp:94] Creating Layer data
I0614 09:42:24.211704   290 net.cpp:409] data -> data
I0614 09:42:24.211730   290 net.cpp:409] data -> label
I0614 09:42:24.213414   352 db_lmdb.cpp:35] Opened lmdb input/lmdb/valid_lmdb
I0614 09:42:24.213447   352 db_lmdb.cpp:38] Items count: 4000
I0614 09:42:24.213486   352 data_reader.cpp:124] TEST: reading data using 1 channel(s)
I0614 09:42:24.213897   290 data_layer.cpp:78] ReshapePrefetch 50, 3, 227, 227
I0614 09:42:24.214063   290 data_layer.cpp:83] output data size: 50,3,227,227
I0614 09:42:24.336346   290 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0614 09:42:24.336573   290 net.cpp:144] Setting up data
I0614 09:42:24.336582   290 net.cpp:151] Top shape: 50 3 227 227 (7729350)
I0614 09:42:24.336608   290 net.cpp:151] Top shape: 50 (50)
I0614 09:42:24.336612   290 net.cpp:159] Memory required for data: 30917600
I0614 09:42:24.336618   290 layer_factory.hpp:77] Creating layer label_data_1_split
I0614 09:42:24.336630   290 net.cpp:94] Creating Layer label_data_1_split
I0614 09:42:24.336635   290 net.cpp:435] label_data_1_split <- label
I0614 09:42:24.336642   290 net.cpp:409] label_data_1_split -> label_data_1_split_0
I0614 09:42:24.336652   290 net.cpp:409] label_data_1_split -> label_data_1_split_1
I0614 09:42:24.336658   290 net.cpp:409] label_data_1_split -> label_data_1_split_2
I0614 09:42:24.336700   290 net.cpp:144] Setting up label_data_1_split
I0614 09:42:24.336704   290 net.cpp:151] Top shape: 50 (50)
I0614 09:42:24.336709   290 net.cpp:151] Top shape: 50 (50)
I0614 09:42:24.336711   290 net.cpp:151] Top shape: 50 (50)
I0614 09:42:24.336715   290 net.cpp:159] Memory required for data: 30918200
I0614 09:42:24.336719   290 layer_factory.hpp:77] Creating layer conv1
I0614 09:42:24.336730   290 net.cpp:94] Creating Layer conv1
I0614 09:42:24.336761   290 net.cpp:435] conv1 <- data
I0614 09:42:24.336768   290 net.cpp:409] conv1 -> conv1
I0614 09:42:24.337412   290 net.cpp:144] Setting up conv1
I0614 09:42:24.337432   290 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0614 09:42:24.337443   290 net.cpp:159] Memory required for data: 88998200
I0614 09:42:24.337460   290 layer_factory.hpp:77] Creating layer bn1
I0614 09:42:24.337472   290 net.cpp:94] Creating Layer bn1
I0614 09:42:24.337478   290 net.cpp:435] bn1 <- conv1
I0614 09:42:24.337487   290 net.cpp:409] bn1 -> bn1
I0614 09:42:24.338073   290 net.cpp:144] Setting up bn1
I0614 09:42:24.338089   290 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0614 09:42:24.338101   290 net.cpp:159] Memory required for data: 147078200
I0614 09:42:24.338120   290 layer_factory.hpp:77] Creating layer relu1
I0614 09:42:24.338133   290 net.cpp:94] Creating Layer relu1
I0614 09:42:24.338141   290 net.cpp:435] relu1 <- bn1
I0614 09:42:24.338151   290 net.cpp:409] relu1 -> relu1
I0614 09:42:24.338176   290 net.cpp:144] Setting up relu1
I0614 09:42:24.338184   290 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0614 09:42:24.338194   290 net.cpp:159] Memory required for data: 205158200
I0614 09:42:24.338202   290 layer_factory.hpp:77] Creating layer pool1
I0614 09:42:24.338213   290 net.cpp:94] Creating Layer pool1
I0614 09:42:24.338223   290 net.cpp:435] pool1 <- relu1
I0614 09:42:24.338238   290 net.cpp:409] pool1 -> pool1
I0614 09:42:24.338276   290 net.cpp:144] Setting up pool1
I0614 09:42:24.338286   290 net.cpp:151] Top shape: 50 96 27 27 (3499200)
I0614 09:42:24.338296   290 net.cpp:159] Memory required for data: 219155000
I0614 09:42:24.338306   290 layer_factory.hpp:77] Creating layer conv2
I0614 09:42:24.338325   290 net.cpp:94] Creating Layer conv2
I0614 09:42:24.338332   290 net.cpp:435] conv2 <- pool1
I0614 09:42:24.338343   290 net.cpp:409] conv2 -> conv2
I0614 09:42:24.355237   290 net.cpp:144] Setting up conv2
I0614 09:42:24.355295   290 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0614 09:42:24.355325   290 net.cpp:159] Memory required for data: 256479800
I0614 09:42:24.355362   290 layer_factory.hpp:77] Creating layer bn2
I0614 09:42:24.355396   290 net.cpp:94] Creating Layer bn2
I0614 09:42:24.355417   290 net.cpp:435] bn2 <- conv2
I0614 09:42:24.355441   290 net.cpp:409] bn2 -> bn2
I0614 09:42:24.356727   290 net.cpp:144] Setting up bn2
I0614 09:42:24.356766   290 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0614 09:42:24.356793   290 net.cpp:159] Memory required for data: 293804600
I0614 09:42:24.356833   290 layer_factory.hpp:77] Creating layer relu2
I0614 09:42:24.356860   290 net.cpp:94] Creating Layer relu2
I0614 09:42:24.356878   290 net.cpp:435] relu2 <- bn2
I0614 09:42:24.356900   290 net.cpp:409] relu2 -> relu2
I0614 09:42:24.356951   290 net.cpp:144] Setting up relu2
I0614 09:42:24.356968   290 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0614 09:42:24.356990   290 net.cpp:159] Memory required for data: 331129400
I0614 09:42:24.357007   290 layer_factory.hpp:77] Creating layer pool2
I0614 09:42:24.357028   290 net.cpp:94] Creating Layer pool2
I0614 09:42:24.357045   290 net.cpp:435] pool2 <- relu2
I0614 09:42:24.357065   290 net.cpp:409] pool2 -> pool2
I0614 09:42:24.357133   290 net.cpp:144] Setting up pool2
I0614 09:42:24.357149   290 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0614 09:42:24.357172   290 net.cpp:159] Memory required for data: 339782200
I0614 09:42:24.357188   290 layer_factory.hpp:77] Creating layer conv3
I0614 09:42:24.357220   290 net.cpp:94] Creating Layer conv3
I0614 09:42:24.357234   290 net.cpp:435] conv3 <- pool2
I0614 09:42:24.357254   290 net.cpp:409] conv3 -> conv3
I0614 09:42:24.382601   290 net.cpp:144] Setting up conv3
I0614 09:42:24.382637   290 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0614 09:42:24.382653   290 net.cpp:159] Memory required for data: 352761400
I0614 09:42:24.382670   290 layer_factory.hpp:77] Creating layer relu3
I0614 09:42:24.382683   290 net.cpp:94] Creating Layer relu3
I0614 09:42:24.382694   290 net.cpp:435] relu3 <- conv3
I0614 09:42:24.382741   290 net.cpp:409] relu3 -> relu3
I0614 09:42:24.382787   290 net.cpp:144] Setting up relu3
I0614 09:42:24.382794   290 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0614 09:42:24.382805   290 net.cpp:159] Memory required for data: 365740600
I0614 09:42:24.382812   290 layer_factory.hpp:77] Creating layer conv4
I0614 09:42:24.382828   290 net.cpp:94] Creating Layer conv4
I0614 09:42:24.382835   290 net.cpp:435] conv4 <- relu3
I0614 09:42:24.382844   290 net.cpp:409] conv4 -> conv4
I0614 09:42:24.399967   290 net.cpp:144] Setting up conv4
I0614 09:42:24.399996   290 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0614 09:42:24.400007   290 net.cpp:159] Memory required for data: 378719800
I0614 09:42:24.400020   290 layer_factory.hpp:77] Creating layer relu4
I0614 09:42:24.400036   290 net.cpp:94] Creating Layer relu4
I0614 09:42:24.400045   290 net.cpp:435] relu4 <- conv4
I0614 09:42:24.400058   290 net.cpp:409] relu4 -> relu4
I0614 09:42:24.400099   290 net.cpp:144] Setting up relu4
I0614 09:42:24.400106   290 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0614 09:42:24.400113   290 net.cpp:159] Memory required for data: 391699000
I0614 09:42:24.400120   290 layer_factory.hpp:77] Creating layer conv5
I0614 09:42:24.400130   290 net.cpp:94] Creating Layer conv5
I0614 09:42:24.400139   290 net.cpp:435] conv5 <- relu4
I0614 09:42:24.400148   290 net.cpp:409] conv5 -> conv5
I0614 09:42:24.410166   290 net.cpp:144] Setting up conv5
I0614 09:42:24.410187   290 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0614 09:42:24.410197   290 net.cpp:159] Memory required for data: 400351800
I0614 09:42:24.410209   290 layer_factory.hpp:77] Creating layer relu5
I0614 09:42:24.410223   290 net.cpp:94] Creating Layer relu5
I0614 09:42:24.410231   290 net.cpp:435] relu5 <- conv5
I0614 09:42:24.410241   290 net.cpp:409] relu5 -> relu5
I0614 09:42:24.410264   290 net.cpp:144] Setting up relu5
I0614 09:42:24.410269   290 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0614 09:42:24.410276   290 net.cpp:159] Memory required for data: 409004600
I0614 09:42:24.410280   290 layer_factory.hpp:77] Creating layer pool5
I0614 09:42:24.410287   290 net.cpp:94] Creating Layer pool5
I0614 09:42:24.410291   290 net.cpp:435] pool5 <- relu5
I0614 09:42:24.410296   290 net.cpp:409] pool5 -> pool5
I0614 09:42:24.410315   290 net.cpp:144] Setting up pool5
I0614 09:42:24.410318   290 net.cpp:151] Top shape: 50 256 6 6 (460800)
I0614 09:42:24.410323   290 net.cpp:159] Memory required for data: 410847800
I0614 09:42:24.410327   290 layer_factory.hpp:77] Creating layer fc6
I0614 09:42:24.410334   290 net.cpp:94] Creating Layer fc6
I0614 09:42:24.410338   290 net.cpp:435] fc6 <- pool5
I0614 09:42:24.410343   290 net.cpp:409] fc6 -> fc6
I0614 09:42:24.733614   290 net.cpp:144] Setting up fc6
I0614 09:42:24.733639   290 net.cpp:151] Top shape: 50 4096 (204800)
I0614 09:42:24.733649   290 net.cpp:159] Memory required for data: 411667000
I0614 09:42:24.733659   290 layer_factory.hpp:77] Creating layer relu6
I0614 09:42:24.733667   290 net.cpp:94] Creating Layer relu6
I0614 09:42:24.733673   290 net.cpp:435] relu6 <- fc6
I0614 09:42:24.733680   290 net.cpp:409] relu6 -> relu6
I0614 09:42:24.733711   290 net.cpp:144] Setting up relu6
I0614 09:42:24.733716   290 net.cpp:151] Top shape: 50 4096 (204800)
I0614 09:42:24.733721   290 net.cpp:159] Memory required for data: 412486200
I0614 09:42:24.733723   290 layer_factory.hpp:77] Creating layer drop6
I0614 09:42:24.733729   290 net.cpp:94] Creating Layer drop6
I0614 09:42:24.733732   290 net.cpp:435] drop6 <- relu6
I0614 09:42:24.733736   290 net.cpp:409] drop6 -> drop6
I0614 09:42:24.733752   290 net.cpp:144] Setting up drop6
I0614 09:42:24.733754   290 net.cpp:151] Top shape: 50 4096 (204800)
I0614 09:42:24.733757   290 net.cpp:159] Memory required for data: 413305400
I0614 09:42:24.733760   290 layer_factory.hpp:77] Creating layer fc7
I0614 09:42:24.733768   290 net.cpp:94] Creating Layer fc7
I0614 09:42:24.733772   290 net.cpp:435] fc7 <- drop6
I0614 09:42:24.733778   290 net.cpp:409] fc7 -> fc7
I0614 09:42:24.875452   290 net.cpp:144] Setting up fc7
I0614 09:42:24.875478   290 net.cpp:151] Top shape: 50 4096 (204800)
I0614 09:42:24.875488   290 net.cpp:159] Memory required for data: 414124600
I0614 09:42:24.875500   290 layer_factory.hpp:77] Creating layer bn7
I0614 09:42:24.875516   290 net.cpp:94] Creating Layer bn7
I0614 09:42:24.875524   290 net.cpp:435] bn7 <- fc7
I0614 09:42:24.875531   290 net.cpp:409] bn7 -> bn7
I0614 09:42:24.875841   290 net.cpp:144] Setting up bn7
I0614 09:42:24.875846   290 net.cpp:151] Top shape: 50 4096 (204800)
I0614 09:42:24.875852   290 net.cpp:159] Memory required for data: 414943800
I0614 09:42:24.875860   290 layer_factory.hpp:77] Creating layer relu7
I0614 09:42:24.875866   290 net.cpp:94] Creating Layer relu7
I0614 09:42:24.875869   290 net.cpp:435] relu7 <- bn7
I0614 09:42:24.875874   290 net.cpp:409] relu7 -> relu7
I0614 09:42:24.875903   290 net.cpp:144] Setting up relu7
I0614 09:42:24.875910   290 net.cpp:151] Top shape: 50 4096 (204800)
I0614 09:42:24.875916   290 net.cpp:159] Memory required for data: 415763000
I0614 09:42:24.875921   290 layer_factory.hpp:77] Creating layer drop7
I0614 09:42:24.875927   290 net.cpp:94] Creating Layer drop7
I0614 09:42:24.875931   290 net.cpp:435] drop7 <- relu7
I0614 09:42:24.875936   290 net.cpp:409] drop7 -> drop7
I0614 09:42:24.875954   290 net.cpp:144] Setting up drop7
I0614 09:42:24.875958   290 net.cpp:151] Top shape: 50 4096 (204800)
I0614 09:42:24.875963   290 net.cpp:159] Memory required for data: 416582200
I0614 09:42:24.875967   290 layer_factory.hpp:77] Creating layer fc8
I0614 09:42:24.875973   290 net.cpp:94] Creating Layer fc8
I0614 09:42:24.875977   290 net.cpp:435] fc8 <- drop7
I0614 09:42:24.875982   290 net.cpp:409] fc8 -> fc8
I0614 09:42:24.876113   290 net.cpp:144] Setting up fc8
I0614 09:42:24.876118   290 net.cpp:151] Top shape: 50 2 (100)
I0614 09:42:24.876123   290 net.cpp:159] Memory required for data: 416582600
I0614 09:42:24.876129   290 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0614 09:42:24.876137   290 net.cpp:94] Creating Layer fc8_fc8_0_split
I0614 09:42:24.876140   290 net.cpp:435] fc8_fc8_0_split <- fc8
I0614 09:42:24.876145   290 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0614 09:42:24.876152   290 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0614 09:42:24.876156   290 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_2
I0614 09:42:24.876176   290 net.cpp:144] Setting up fc8_fc8_0_split
I0614 09:42:24.876179   290 net.cpp:151] Top shape: 50 2 (100)
I0614 09:42:24.876184   290 net.cpp:151] Top shape: 50 2 (100)
I0614 09:42:24.876189   290 net.cpp:151] Top shape: 50 2 (100)
I0614 09:42:24.876195   290 net.cpp:159] Memory required for data: 416583800
I0614 09:42:24.876200   290 layer_factory.hpp:77] Creating layer accuracy
I0614 09:42:24.876209   290 net.cpp:94] Creating Layer accuracy
I0614 09:42:24.876212   290 net.cpp:435] accuracy <- fc8_fc8_0_split_0
I0614 09:42:24.876216   290 net.cpp:435] accuracy <- label_data_1_split_0
I0614 09:42:24.876221   290 net.cpp:409] accuracy -> accuracy
I0614 09:42:24.876228   290 net.cpp:144] Setting up accuracy
I0614 09:42:24.876231   290 net.cpp:151] Top shape: (1)
I0614 09:42:24.876237   290 net.cpp:159] Memory required for data: 416583804
I0614 09:42:24.876242   290 layer_factory.hpp:77] Creating layer loss
I0614 09:42:24.876247   290 net.cpp:94] Creating Layer loss
I0614 09:42:24.876250   290 net.cpp:435] loss <- fc8_fc8_0_split_1
I0614 09:42:24.876255   290 net.cpp:435] loss <- label_data_1_split_1
I0614 09:42:24.876260   290 net.cpp:409] loss -> loss
I0614 09:42:24.876268   290 layer_factory.hpp:77] Creating layer loss
I0614 09:42:24.876312   290 net.cpp:144] Setting up loss
I0614 09:42:24.876315   290 net.cpp:151] Top shape: (1)
I0614 09:42:24.876319   290 net.cpp:154]     with loss weight 1
I0614 09:42:24.876331   290 net.cpp:159] Memory required for data: 416583808
I0614 09:42:24.876335   290 layer_factory.hpp:77] Creating layer accuracy-top1
I0614 09:42:24.876343   290 net.cpp:94] Creating Layer accuracy-top1
I0614 09:42:24.876348   290 net.cpp:435] accuracy-top1 <- fc8_fc8_0_split_2
I0614 09:42:24.876369   290 net.cpp:435] accuracy-top1 <- label_data_1_split_2
I0614 09:42:24.876374   290 net.cpp:409] accuracy-top1 -> top-1
I0614 09:42:24.876382   290 net.cpp:144] Setting up accuracy-top1
I0614 09:42:24.876387   290 net.cpp:151] Top shape: (1)
I0614 09:42:24.876391   290 net.cpp:159] Memory required for data: 416583812
I0614 09:42:24.876394   290 net.cpp:222] accuracy-top1 does not need backward computation.
I0614 09:42:24.876399   290 net.cpp:220] loss needs backward computation.
I0614 09:42:24.876403   290 net.cpp:222] accuracy does not need backward computation.
I0614 09:42:24.876407   290 net.cpp:220] fc8_fc8_0_split needs backward computation.
I0614 09:42:24.876411   290 net.cpp:220] fc8 needs backward computation.
I0614 09:42:24.876415   290 net.cpp:220] drop7 needs backward computation.
I0614 09:42:24.876418   290 net.cpp:220] relu7 needs backward computation.
I0614 09:42:24.876422   290 net.cpp:220] bn7 needs backward computation.
I0614 09:42:24.876425   290 net.cpp:220] fc7 needs backward computation.
I0614 09:42:24.876430   290 net.cpp:220] drop6 needs backward computation.
I0614 09:42:24.876433   290 net.cpp:220] relu6 needs backward computation.
I0614 09:42:24.876437   290 net.cpp:220] fc6 needs backward computation.
I0614 09:42:24.876441   290 net.cpp:220] pool5 needs backward computation.
I0614 09:42:24.876444   290 net.cpp:220] relu5 needs backward computation.
I0614 09:42:24.876448   290 net.cpp:220] conv5 needs backward computation.
I0614 09:42:24.876452   290 net.cpp:220] relu4 needs backward computation.
I0614 09:42:24.876456   290 net.cpp:220] conv4 needs backward computation.
I0614 09:42:24.876461   290 net.cpp:220] relu3 needs backward computation.
I0614 09:42:24.876464   290 net.cpp:220] conv3 needs backward computation.
I0614 09:42:24.876467   290 net.cpp:220] pool2 needs backward computation.
I0614 09:42:24.876471   290 net.cpp:220] relu2 needs backward computation.
I0614 09:42:24.876475   290 net.cpp:220] bn2 needs backward computation.
I0614 09:42:24.876479   290 net.cpp:220] conv2 needs backward computation.
I0614 09:42:24.876485   290 net.cpp:220] pool1 needs backward computation.
I0614 09:42:24.876489   290 net.cpp:220] relu1 needs backward computation.
I0614 09:42:24.876493   290 net.cpp:220] bn1 needs backward computation.
I0614 09:42:24.876497   290 net.cpp:220] conv1 needs backward computation.
I0614 09:42:24.876502   290 net.cpp:222] label_data_1_split does not need backward computation.
I0614 09:42:24.876507   290 net.cpp:222] data does not need backward computation.
I0614 09:42:24.876509   290 net.cpp:264] This network produces output accuracy
I0614 09:42:24.876513   290 net.cpp:264] This network produces output loss
I0614 09:42:24.876516   290 net.cpp:264] This network produces output top-1
I0614 09:42:24.876535   290 net.cpp:284] Network initialization done.
I0614 09:42:24.876597   290 solver.cpp:63] Solver scaffolding done.
I0614 09:42:24.877162   290 caffe.cpp:247] Starting Optimization
I0614 09:42:24.877171   290 solver.cpp:341] Solving alexnetBNnoLRN m2 (as m3 but less DROP and less BN)
I0614 09:42:24.877174   290 solver.cpp:342] Learning Rate Policy: step
I0614 09:42:24.878487   290 solver.cpp:424] Iteration 0, Testing net (#0)
I0614 09:42:26.360193   290 solver.cpp:523]     Test net output #0: accuracy = 0.492
I0614 09:42:26.360229   290 solver.cpp:523]     Test net output #1: loss = 44.367 (* 1 = 44.367 loss)
I0614 09:42:26.360236   290 solver.cpp:523]     Test net output #2: top-1 = 0.492
I0614 09:42:26.622099   290 solver.cpp:270] Iteration 0 (0 iter/s, 1.74483s/50 iter), loss = 0.793226, remaining 554999 hours and 59 minutes
I0614 09:42:26.622129   290 solver.cpp:291]     Train net output #0: loss = 0.793226 (* 1 = 0.793226 loss)
I0614 09:42:26.622138   290 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0614 09:42:38.750556   290 solver.cpp:270] Iteration 50 (4.12269 iter/s, 12.128s/50 iter), loss = 0.694899, remaining 1 hours and 20 minutes
I0614 09:42:38.750587   290 solver.cpp:291]     Train net output #0: loss = 0.694899 (* 1 = 0.694899 loss)
I0614 09:42:38.750617   290 sgd_solver.cpp:106] Iteration 50, lr = 0.001
I0614 09:42:51.003051   290 solver.cpp:270] Iteration 100 (4.08096 iter/s, 12.252s/50 iter), loss = 0.747979, remaining 1 hours and 21 minutes
I0614 09:42:51.003085   290 solver.cpp:291]     Train net output #0: loss = 0.747979 (* 1 = 0.747979 loss)
I0614 09:42:51.003094   290 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I0614 09:43:03.337962   290 solver.cpp:270] Iteration 150 (4.0537 iter/s, 12.3344s/50 iter), loss = 0.7183, remaining 1 hours and 21 minutes
I0614 09:43:03.338011   290 solver.cpp:291]     Train net output #0: loss = 0.7183 (* 1 = 0.7183 loss)
I0614 09:43:03.338035   290 sgd_solver.cpp:106] Iteration 150, lr = 0.001
I0614 09:43:15.751245   290 solver.cpp:270] Iteration 200 (4.02811 iter/s, 12.4128s/50 iter), loss = 0.634697, remaining 1 hours and 21 minutes
I0614 09:43:15.751276   290 solver.cpp:291]     Train net output #0: loss = 0.634697 (* 1 = 0.634697 loss)
I0614 09:43:15.751286   290 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I0614 09:43:28.210376   290 solver.cpp:270] Iteration 250 (4.01328 iter/s, 12.4586s/50 iter), loss = 0.653876, remaining 1 hours and 21 minutes
I0614 09:43:28.210408   290 solver.cpp:291]     Train net output #0: loss = 0.653876 (* 1 = 0.653876 loss)
I0614 09:43:28.210433   290 sgd_solver.cpp:106] Iteration 250, lr = 0.001
I0614 09:43:40.719033   290 solver.cpp:270] Iteration 300 (3.99739 iter/s, 12.5081s/50 iter), loss = 0.734511, remaining 1 hours and 22 minutes
I0614 09:43:40.719080   290 solver.cpp:291]     Train net output #0: loss = 0.734511 (* 1 = 0.734511 loss)
I0614 09:43:40.719089   290 sgd_solver.cpp:106] Iteration 300, lr = 0.001
I0614 09:43:53.339177   290 solver.cpp:270] Iteration 350 (3.96209 iter/s, 12.6196s/50 iter), loss = 0.668219, remaining 1 hours and 22 minutes
I0614 09:43:53.339210   290 solver.cpp:291]     Train net output #0: loss = 0.668219 (* 1 = 0.668219 loss)
I0614 09:43:53.339236   290 sgd_solver.cpp:106] Iteration 350, lr = 0.001
I0614 09:44:06.003804   290 solver.cpp:270] Iteration 400 (3.94817 iter/s, 12.6641s/50 iter), loss = 0.629273, remaining 1 hours and 22 minutes
I0614 09:44:06.003836   290 solver.cpp:291]     Train net output #0: loss = 0.629273 (* 1 = 0.629273 loss)
I0614 09:44:06.003860   290 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I0614 09:44:18.652004   290 solver.cpp:270] Iteration 450 (3.9533 iter/s, 12.6477s/50 iter), loss = 0.588952, remaining 1 hours and 22 minutes
I0614 09:44:18.652053   290 solver.cpp:291]     Train net output #0: loss = 0.588952 (* 1 = 0.588952 loss)
I0614 09:44:18.652062   290 sgd_solver.cpp:106] Iteration 450, lr = 0.001
I0614 09:44:31.321157   290 solver.cpp:270] Iteration 500 (3.94676 iter/s, 12.6686s/50 iter), loss = 0.638191, remaining 1 hours and 22 minutes
I0614 09:44:31.321199   290 solver.cpp:291]     Train net output #0: loss = 0.638191 (* 1 = 0.638191 loss)
I0614 09:44:31.321223   290 sgd_solver.cpp:106] Iteration 500, lr = 0.001
I0614 09:44:44.027681   290 solver.cpp:270] Iteration 550 (3.93515 iter/s, 12.706s/50 iter), loss = 0.649281, remaining 1 hours and 22 minutes
I0614 09:44:44.027714   290 solver.cpp:291]     Train net output #0: loss = 0.649281 (* 1 = 0.649281 loss)
I0614 09:44:44.027722   290 sgd_solver.cpp:106] Iteration 550, lr = 0.001
I0614 09:44:56.706262   290 solver.cpp:270] Iteration 600 (3.94381 iter/s, 12.6781s/50 iter), loss = 0.657944, remaining 1 hours and 21 minutes
I0614 09:44:56.706312   290 solver.cpp:291]     Train net output #0: loss = 0.657944 (* 1 = 0.657944 loss)
I0614 09:44:56.706321   290 sgd_solver.cpp:106] Iteration 600, lr = 0.001
I0614 09:45:09.384302   290 solver.cpp:270] Iteration 650 (3.94397 iter/s, 12.6776s/50 iter), loss = 0.603799, remaining 1 hours and 21 minutes
I0614 09:45:09.384333   290 solver.cpp:291]     Train net output #0: loss = 0.603799 (* 1 = 0.603799 loss)
I0614 09:45:09.384357   290 sgd_solver.cpp:106] Iteration 650, lr = 0.001
I0614 09:45:22.092037   290 solver.cpp:270] Iteration 700 (3.93475 iter/s, 12.7073s/50 iter), loss = 0.564011, remaining 1 hours and 21 minutes
I0614 09:45:22.092070   290 solver.cpp:291]     Train net output #0: loss = 0.564011 (* 1 = 0.564011 loss)
I0614 09:45:22.092094   290 sgd_solver.cpp:106] Iteration 700, lr = 0.001
I0614 09:45:34.787089   290 solver.cpp:270] Iteration 750 (3.93868 iter/s, 12.6946s/50 iter), loss = 0.509252, remaining 1 hours and 21 minutes
I0614 09:45:34.787144   290 solver.cpp:291]     Train net output #0: loss = 0.509252 (* 1 = 0.509252 loss)
I0614 09:45:34.787168   290 sgd_solver.cpp:106] Iteration 750, lr = 0.001
I0614 09:45:47.484184   290 solver.cpp:270] Iteration 800 (3.93806 iter/s, 12.6966s/50 iter), loss = 0.603626, remaining 1 hours and 21 minutes
I0614 09:45:47.484216   290 solver.cpp:291]     Train net output #0: loss = 0.603626 (* 1 = 0.603626 loss)
I0614 09:45:47.484239   290 sgd_solver.cpp:106] Iteration 800, lr = 0.001
I0614 09:46:00.163211   290 solver.cpp:270] Iteration 850 (3.94366 iter/s, 12.6786s/50 iter), loss = 0.418162, remaining 1 hours and 20 minutes
I0614 09:46:00.163244   290 solver.cpp:291]     Train net output #0: loss = 0.418162 (* 1 = 0.418162 loss)
I0614 09:46:00.163251   290 sgd_solver.cpp:106] Iteration 850, lr = 0.001
I0614 09:46:12.863721   290 solver.cpp:270] Iteration 900 (3.93699 iter/s, 12.7001s/50 iter), loss = 0.516228, remaining 1 hours and 20 minutes
I0614 09:46:12.863766   290 solver.cpp:291]     Train net output #0: loss = 0.516228 (* 1 = 0.516228 loss)
I0614 09:46:12.863790   290 sgd_solver.cpp:106] Iteration 900, lr = 0.001
I0614 09:46:25.569634   290 solver.cpp:270] Iteration 950 (3.93532 iter/s, 12.7054s/50 iter), loss = 0.396665, remaining 1 hours and 20 minutes
I0614 09:46:25.569665   290 solver.cpp:291]     Train net output #0: loss = 0.396665 (* 1 = 0.396665 loss)
I0614 09:46:25.569674   290 sgd_solver.cpp:106] Iteration 950, lr = 0.001
I0614 09:46:38.022231   290 solver.cpp:424] Iteration 1000, Testing net (#0)
I0614 09:46:39.530318   290 solver.cpp:523]     Test net output #0: accuracy = 0.72725
I0614 09:46:39.530349   290 solver.cpp:523]     Test net output #1: loss = 0.658473 (* 1 = 0.658473 loss)
I0614 09:46:39.530352   290 solver.cpp:523]     Test net output #2: top-1 = 0.72725
I0614 09:46:39.781486   290 solver.cpp:270] Iteration 1000 (3.51831 iter/s, 14.2114s/50 iter), loss = 0.374149, remaining 1 hours and 29 minutes
I0614 09:46:39.781518   290 solver.cpp:291]     Train net output #0: loss = 0.374149 (* 1 = 0.374149 loss)
I0614 09:46:39.781543   290 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I0614 09:46:52.480194   290 solver.cpp:270] Iteration 1050 (3.93755 iter/s, 12.6983s/50 iter), loss = 0.308096, remaining 1 hours and 19 minutes
I0614 09:46:52.480242   290 solver.cpp:291]     Train net output #0: loss = 0.308096 (* 1 = 0.308096 loss)
I0614 09:46:52.480252   290 sgd_solver.cpp:106] Iteration 1050, lr = 0.001
I0614 09:47:05.223709   290 solver.cpp:270] Iteration 1100 (3.92371 iter/s, 12.743s/50 iter), loss = 0.377567, remaining 1 hours and 20 minutes
I0614 09:47:05.223742   290 solver.cpp:291]     Train net output #0: loss = 0.377567 (* 1 = 0.377567 loss)
I0614 09:47:05.223765   290 sgd_solver.cpp:106] Iteration 1100, lr = 0.001
I0614 09:47:17.928298   290 solver.cpp:270] Iteration 1150 (3.93573 iter/s, 12.7041s/50 iter), loss = 0.302448, remaining 1 hours and 19 minutes
I0614 09:47:17.928331   290 solver.cpp:291]     Train net output #0: loss = 0.302448 (* 1 = 0.302448 loss)
I0614 09:47:17.928339   290 sgd_solver.cpp:106] Iteration 1150, lr = 0.001
I0614 09:47:30.645246   290 solver.cpp:270] Iteration 1200 (3.9319 iter/s, 12.7165s/50 iter), loss = 0.301592, remaining 1 hours and 19 minutes
I0614 09:47:30.645295   290 solver.cpp:291]     Train net output #0: loss = 0.301592 (* 1 = 0.301592 loss)
I0614 09:47:30.645304   290 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I0614 09:47:43.359865   290 solver.cpp:270] Iteration 1250 (3.93263 iter/s, 12.7142s/50 iter), loss = 0.341578, remaining 1 hours and 19 minutes
I0614 09:47:43.359900   290 solver.cpp:291]     Train net output #0: loss = 0.341578 (* 1 = 0.341578 loss)
I0614 09:47:43.359908   290 sgd_solver.cpp:106] Iteration 1250, lr = 0.001
I0614 09:47:56.071334   290 solver.cpp:270] Iteration 1300 (3.9336 iter/s, 12.711s/50 iter), loss = 0.302015, remaining 1 hours and 19 minutes
I0614 09:47:56.071367   290 solver.cpp:291]     Train net output #0: loss = 0.302015 (* 1 = 0.302015 loss)
I0614 09:47:56.071390   290 sgd_solver.cpp:106] Iteration 1300, lr = 0.001
I0614 09:48:08.792522   290 solver.cpp:270] Iteration 1350 (3.93059 iter/s, 12.7207s/50 iter), loss = 0.303031, remaining 1 hours and 18 minutes
I0614 09:48:08.792582   290 solver.cpp:291]     Train net output #0: loss = 0.303031 (* 1 = 0.303031 loss)
I0614 09:48:08.792589   290 sgd_solver.cpp:106] Iteration 1350, lr = 0.001
I0614 09:48:21.499682   290 solver.cpp:270] Iteration 1400 (3.93494 iter/s, 12.7067s/50 iter), loss = 0.260317, remaining 1 hours and 18 minutes
I0614 09:48:21.499714   290 solver.cpp:291]     Train net output #0: loss = 0.260317 (* 1 = 0.260317 loss)
I0614 09:48:21.499738   290 sgd_solver.cpp:106] Iteration 1400, lr = 0.001
I0614 09:48:34.190021   290 solver.cpp:270] Iteration 1450 (3.94014 iter/s, 12.6899s/50 iter), loss = 0.202262, remaining 1 hours and 18 minutes
I0614 09:48:34.190054   290 solver.cpp:291]     Train net output #0: loss = 0.202262 (* 1 = 0.202262 loss)
I0614 09:48:34.190064   290 sgd_solver.cpp:106] Iteration 1450, lr = 0.001
I0614 09:48:46.867964   290 solver.cpp:270] Iteration 1500 (3.944 iter/s, 12.6775s/50 iter), loss = 0.29382, remaining 1 hours and 18 minutes
I0614 09:48:46.868010   290 solver.cpp:291]     Train net output #0: loss = 0.29382 (* 1 = 0.29382 loss)
I0614 09:48:46.868034   290 sgd_solver.cpp:106] Iteration 1500, lr = 0.001
I0614 09:48:59.553534   290 solver.cpp:270] Iteration 1550 (3.94163 iter/s, 12.6851s/50 iter), loss = 0.220422, remaining 1 hours and 17 minutes
I0614 09:48:59.553568   290 solver.cpp:291]     Train net output #0: loss = 0.220422 (* 1 = 0.220422 loss)
I0614 09:48:59.553577   290 sgd_solver.cpp:106] Iteration 1550, lr = 0.001
I0614 09:49:12.265412   290 solver.cpp:270] Iteration 1600 (3.93347 iter/s, 12.7114s/50 iter), loss = 0.196371, remaining 1 hours and 17 minutes
I0614 09:49:12.265446   290 solver.cpp:291]     Train net output #0: loss = 0.196371 (* 1 = 0.196371 loss)
I0614 09:49:12.265455   290 sgd_solver.cpp:106] Iteration 1600, lr = 0.001
I0614 09:49:24.951429   290 solver.cpp:270] Iteration 1650 (3.94149 iter/s, 12.6856s/50 iter), loss = 0.227844, remaining 1 hours and 17 minutes
I0614 09:49:24.951478   290 solver.cpp:291]     Train net output #0: loss = 0.227844 (* 1 = 0.227844 loss)
I0614 09:49:24.951488   290 sgd_solver.cpp:106] Iteration 1650, lr = 0.001
I0614 09:49:37.613775   290 solver.cpp:270] Iteration 1700 (3.94886 iter/s, 12.6619s/50 iter), loss = 0.210297, remaining 1 hours and 17 minutes
I0614 09:49:37.613809   290 solver.cpp:291]     Train net output #0: loss = 0.210297 (* 1 = 0.210297 loss)
I0614 09:49:37.613818   290 sgd_solver.cpp:106] Iteration 1700, lr = 0.001
I0614 09:49:50.312263   290 solver.cpp:270] Iteration 1750 (3.93762 iter/s, 12.698s/50 iter), loss = 0.239455, remaining 1 hours and 17 minutes
I0614 09:49:50.312294   290 solver.cpp:291]     Train net output #0: loss = 0.239455 (* 1 = 0.239455 loss)
I0614 09:49:50.312319   290 sgd_solver.cpp:106] Iteration 1750, lr = 0.001
I0614 09:50:02.982347   290 solver.cpp:270] Iteration 1800 (3.94644 iter/s, 12.6696s/50 iter), loss = 0.261242, remaining 1 hours and 16 minutes
I0614 09:50:02.982400   290 solver.cpp:291]     Train net output #0: loss = 0.261242 (* 1 = 0.261242 loss)
I0614 09:50:02.982410   290 sgd_solver.cpp:106] Iteration 1800, lr = 0.001
I0614 09:50:15.693737   290 solver.cpp:270] Iteration 1850 (3.93362 iter/s, 12.7109s/50 iter), loss = 0.236233, remaining 1 hours and 16 minutes
I0614 09:50:15.693771   290 solver.cpp:291]     Train net output #0: loss = 0.236233 (* 1 = 0.236233 loss)
I0614 09:50:15.693795   290 sgd_solver.cpp:106] Iteration 1850, lr = 0.001
I0614 09:50:28.364125   290 solver.cpp:270] Iteration 1900 (3.94635 iter/s, 12.6699s/50 iter), loss = 0.220857, remaining 1 hours and 16 minutes
I0614 09:50:28.364158   290 solver.cpp:291]     Train net output #0: loss = 0.220857 (* 1 = 0.220857 loss)
I0614 09:50:28.364167   290 sgd_solver.cpp:106] Iteration 1900, lr = 0.001
I0614 09:50:41.041066   290 solver.cpp:270] Iteration 1950 (3.94431 iter/s, 12.6765s/50 iter), loss = 0.218746, remaining 1 hours and 16 minutes
I0614 09:50:41.041141   290 solver.cpp:291]     Train net output #0: loss = 0.218746 (* 1 = 0.218746 loss)
I0614 09:50:41.041150   290 sgd_solver.cpp:106] Iteration 1950, lr = 0.001
I0614 09:50:53.454792   290 solver.cpp:424] Iteration 2000, Testing net (#0)
I0614 09:50:54.960598   290 solver.cpp:523]     Test net output #0: accuracy = 0.54275
I0614 09:50:54.960630   290 solver.cpp:523]     Test net output #1: loss = 0.643111 (* 1 = 0.643111 loss)
I0614 09:50:54.960634   290 solver.cpp:523]     Test net output #2: top-1 = 0.54275
I0614 09:50:55.214910   290 solver.cpp:270] Iteration 2000 (3.52776 iter/s, 14.1733s/50 iter), loss = 0.19163, remaining 1 hours and 25 minutes
I0614 09:50:55.214942   290 solver.cpp:291]     Train net output #0: loss = 0.19163 (* 1 = 0.19163 loss)
I0614 09:50:55.214952   290 sgd_solver.cpp:106] Iteration 2000, lr = 0.001
I0614 09:51:07.904855   290 solver.cpp:270] Iteration 2050 (3.94027 iter/s, 12.6895s/50 iter), loss = 0.252677, remaining 1 hours and 15 minutes
I0614 09:51:07.904886   290 solver.cpp:291]     Train net output #0: loss = 0.252677 (* 1 = 0.252677 loss)
I0614 09:51:07.904911   290 sgd_solver.cpp:106] Iteration 2050, lr = 0.001
I0614 09:51:20.617377   290 solver.cpp:270] Iteration 2100 (3.93327 iter/s, 12.7121s/50 iter), loss = 0.153939, remaining 1 hours and 15 minutes
I0614 09:51:20.617425   290 solver.cpp:291]     Train net output #0: loss = 0.153939 (* 1 = 0.153939 loss)
I0614 09:51:20.617434   290 sgd_solver.cpp:106] Iteration 2100, lr = 0.001
I0614 09:51:33.283155   290 solver.cpp:270] Iteration 2150 (3.94779 iter/s, 12.6653s/50 iter), loss = 0.235712, remaining 1 hours and 15 minutes
I0614 09:51:33.283188   290 solver.cpp:291]     Train net output #0: loss = 0.235712 (* 1 = 0.235712 loss)
I0614 09:51:33.283197   290 sgd_solver.cpp:106] Iteration 2150, lr = 0.001
I0614 09:51:46.001016   290 solver.cpp:270] Iteration 2200 (3.93162 iter/s, 12.7174s/50 iter), loss = 0.247884, remaining 1 hours and 15 minutes
I0614 09:51:46.001049   290 solver.cpp:291]     Train net output #0: loss = 0.247884 (* 1 = 0.247884 loss)
I0614 09:51:46.001056   290 sgd_solver.cpp:106] Iteration 2200, lr = 0.001
I0614 09:51:58.683563   290 solver.cpp:270] Iteration 2250 (3.94256 iter/s, 12.6821s/50 iter), loss = 0.218858, remaining 1 hours and 14 minutes
I0614 09:51:58.683612   290 solver.cpp:291]     Train net output #0: loss = 0.218858 (* 1 = 0.218858 loss)
I0614 09:51:58.683621   290 sgd_solver.cpp:106] Iteration 2250, lr = 0.001
I0614 09:52:11.359076   290 solver.cpp:270] Iteration 2300 (3.94476 iter/s, 12.675s/50 iter), loss = 0.147073, remaining 1 hours and 14 minutes
I0614 09:52:11.359107   290 solver.cpp:291]     Train net output #0: loss = 0.147073 (* 1 = 0.147073 loss)
I0614 09:52:11.359131   290 sgd_solver.cpp:106] Iteration 2300, lr = 0.001
I0614 09:52:24.029651   290 solver.cpp:270] Iteration 2350 (3.94629 iter/s, 12.6701s/50 iter), loss = 0.220944, remaining 1 hours and 14 minutes
I0614 09:52:24.029683   290 solver.cpp:291]     Train net output #0: loss = 0.220944 (* 1 = 0.220944 loss)
I0614 09:52:24.029692   290 sgd_solver.cpp:106] Iteration 2350, lr = 0.001
I0614 09:52:36.714589   290 solver.cpp:270] Iteration 2400 (3.94182 iter/s, 12.6845s/50 iter), loss = 0.189836, remaining 1 hours and 14 minutes
I0614 09:52:36.714635   290 solver.cpp:291]     Train net output #0: loss = 0.189836 (* 1 = 0.189836 loss)
I0614 09:52:36.714644   290 sgd_solver.cpp:106] Iteration 2400, lr = 0.001
I0614 09:52:49.354218   290 solver.cpp:270] Iteration 2450 (3.95596 iter/s, 12.6392s/50 iter), loss = 0.139855, remaining 1 hours and 13 minutes
I0614 09:52:49.354249   290 solver.cpp:291]     Train net output #0: loss = 0.139855 (* 1 = 0.139855 loss)
I0614 09:52:49.354274   290 sgd_solver.cpp:106] Iteration 2450, lr = 0.001
I0614 09:53:02.043644   290 solver.cpp:270] Iteration 2500 (3.94043 iter/s, 12.689s/50 iter), loss = 0.265514, remaining 1 hours and 13 minutes
I0614 09:53:02.043676   290 solver.cpp:291]     Train net output #0: loss = 0.265514 (* 1 = 0.265514 loss)
I0614 09:53:02.043684   290 sgd_solver.cpp:106] Iteration 2500, lr = 0.0001
I0614 09:53:14.712235   290 solver.cpp:270] Iteration 2550 (3.94691 iter/s, 12.6681s/50 iter), loss = 0.172199, remaining 1 hours and 13 minutes
I0614 09:53:14.712316   290 solver.cpp:291]     Train net output #0: loss = 0.172199 (* 1 = 0.172199 loss)
I0614 09:53:14.712330   290 sgd_solver.cpp:106] Iteration 2550, lr = 0.0001
I0614 09:53:27.725538   290 solver.cpp:270] Iteration 2600 (3.84237 iter/s, 13.0128s/50 iter), loss = 0.146201, remaining 1 hours and 15 minutes
I0614 09:53:27.725579   290 solver.cpp:291]     Train net output #0: loss = 0.146201 (* 1 = 0.146201 loss)
I0614 09:53:27.725590   290 sgd_solver.cpp:106] Iteration 2600, lr = 0.0001
I0614 09:53:40.501047   290 solver.cpp:270] Iteration 2650 (3.91388 iter/s, 12.7751s/50 iter), loss = 0.129549, remaining 1 hours and 13 minutes
I0614 09:53:40.501087   290 solver.cpp:291]     Train net output #0: loss = 0.129549 (* 1 = 0.129549 loss)
I0614 09:53:40.501101   290 sgd_solver.cpp:106] Iteration 2650, lr = 0.0001
I0614 09:53:53.124235   290 solver.cpp:270] Iteration 2700 (3.9611 iter/s, 12.6227s/50 iter), loss = 0.0818322, remaining 1 hours and 12 minutes
I0614 09:53:53.124289   290 solver.cpp:291]     Train net output #0: loss = 0.0818322 (* 1 = 0.0818322 loss)
I0614 09:53:53.124302   290 sgd_solver.cpp:106] Iteration 2700, lr = 0.0001
I0614 09:54:05.798971   290 solver.cpp:270] Iteration 2750 (3.945 iter/s, 12.6743s/50 iter), loss = 0.132566, remaining 1 hours and 12 minutes
I0614 09:54:05.799010   290 solver.cpp:291]     Train net output #0: loss = 0.132566 (* 1 = 0.132566 loss)
I0614 09:54:05.799021   290 sgd_solver.cpp:106] Iteration 2750, lr = 0.0001
I0614 09:54:18.412196   290 solver.cpp:270] Iteration 2800 (3.96423 iter/s, 12.6128s/50 iter), loss = 0.100255, remaining 1 hours and 12 minutes
I0614 09:54:18.412235   290 solver.cpp:291]     Train net output #0: loss = 0.100255 (* 1 = 0.100255 loss)
I0614 09:54:18.412248   290 sgd_solver.cpp:106] Iteration 2800, lr = 0.0001
I0614 09:54:31.015447   290 solver.cpp:270] Iteration 2850 (3.96737 iter/s, 12.6028s/50 iter), loss = 0.125615, remaining 1 hours and 11 minutes
I0614 09:54:31.015497   290 solver.cpp:291]     Train net output #0: loss = 0.125615 (* 1 = 0.125615 loss)
I0614 09:54:31.015522   290 sgd_solver.cpp:106] Iteration 2850, lr = 0.0001
I0614 09:54:43.639657   290 solver.cpp:270] Iteration 2900 (3.96079 iter/s, 12.6238s/50 iter), loss = 0.121969, remaining 1 hours and 11 minutes
I0614 09:54:43.639691   290 solver.cpp:291]     Train net output #0: loss = 0.121969 (* 1 = 0.121969 loss)
I0614 09:54:43.639701   290 sgd_solver.cpp:106] Iteration 2900, lr = 0.0001
I0614 09:54:56.245126   290 solver.cpp:270] Iteration 2950 (3.96667 iter/s, 12.605s/50 iter), loss = 0.152729, remaining 1 hours and 11 minutes
I0614 09:54:56.245159   290 solver.cpp:291]     Train net output #0: loss = 0.152729 (* 1 = 0.152729 loss)
I0614 09:54:56.245168   290 sgd_solver.cpp:106] Iteration 2950, lr = 0.0001
I0614 09:55:08.612864   290 solver.cpp:424] Iteration 3000, Testing net (#0)
I0614 09:55:10.104482   290 solver.cpp:523]     Test net output #0: accuracy = 0.9115
I0614 09:55:10.104513   290 solver.cpp:523]     Test net output #1: loss = 0.627532 (* 1 = 0.627532 loss)
I0614 09:55:10.104518   290 solver.cpp:523]     Test net output #2: top-1 = 0.9115
I0614 09:55:10.350883   290 solver.cpp:270] Iteration 3000 (3.54478 iter/s, 14.1053s/50 iter), loss = 0.107426, remaining 1 hours and 19 minutes
I0614 09:55:10.350916   290 solver.cpp:291]     Train net output #0: loss = 0.107426 (* 1 = 0.107426 loss)
I0614 09:55:10.350925   290 sgd_solver.cpp:106] Iteration 3000, lr = 0.0001
I0614 09:55:22.970806   290 solver.cpp:270] Iteration 3050 (3.96213 iter/s, 12.6195s/50 iter), loss = 0.152532, remaining 1 hours and 11 minutes
I0614 09:55:22.970840   290 solver.cpp:291]     Train net output #0: loss = 0.152532 (* 1 = 0.152532 loss)
I0614 09:55:22.970849   290 sgd_solver.cpp:106] Iteration 3050, lr = 0.0001
I0614 09:55:35.598306   290 solver.cpp:270] Iteration 3100 (3.95975 iter/s, 12.6271s/50 iter), loss = 0.106048, remaining 1 hours and 10 minutes
I0614 09:55:35.598338   290 solver.cpp:291]     Train net output #0: loss = 0.106048 (* 1 = 0.106048 loss)
I0614 09:55:35.598362   290 sgd_solver.cpp:106] Iteration 3100, lr = 0.0001
I0614 09:55:48.207232   290 solver.cpp:270] Iteration 3150 (3.96558 iter/s, 12.6085s/50 iter), loss = 0.110889, remaining 1 hours and 10 minutes
I0614 09:55:48.207291   290 solver.cpp:291]     Train net output #0: loss = 0.110889 (* 1 = 0.110889 loss)
I0614 09:55:48.207316   290 sgd_solver.cpp:106] Iteration 3150, lr = 0.0001
I0614 09:56:00.835611   290 solver.cpp:270] Iteration 3200 (3.95948 iter/s, 12.6279s/50 iter), loss = 0.074072, remaining 1 hours and 10 minutes
I0614 09:56:00.835644   290 solver.cpp:291]     Train net output #0: loss = 0.074072 (* 1 = 0.074072 loss)
I0614 09:56:00.835667   290 sgd_solver.cpp:106] Iteration 3200, lr = 0.0001
I0614 09:56:13.428825   290 solver.cpp:270] Iteration 3250 (3.97053 iter/s, 12.5928s/50 iter), loss = 0.124069, remaining 1 hours and 10 minutes
I0614 09:56:13.428859   290 solver.cpp:291]     Train net output #0: loss = 0.124069 (* 1 = 0.124069 loss)
I0614 09:56:13.428869   290 sgd_solver.cpp:106] Iteration 3250, lr = 0.0001
I0614 09:56:26.041587   290 solver.cpp:270] Iteration 3300 (3.96438 iter/s, 12.6123s/50 iter), loss = 0.106658, remaining 1 hours and 10 minutes
I0614 09:56:26.041635   290 solver.cpp:291]     Train net output #0: loss = 0.106658 (* 1 = 0.106658 loss)
I0614 09:56:26.041643   290 sgd_solver.cpp:106] Iteration 3300, lr = 0.0001
I0614 09:56:38.667830   290 solver.cpp:270] Iteration 3350 (3.96015 iter/s, 12.6258s/50 iter), loss = 0.0654053, remaining 1 hours and 9 minutes
I0614 09:56:38.667865   290 solver.cpp:291]     Train net output #0: loss = 0.0654053 (* 1 = 0.0654053 loss)
I0614 09:56:38.667873   290 sgd_solver.cpp:106] Iteration 3350, lr = 0.0001
I0614 09:56:51.288210   290 solver.cpp:270] Iteration 3400 (3.96198 iter/s, 12.6199s/50 iter), loss = 0.0954787, remaining 1 hours and 9 minutes
I0614 09:56:51.288244   290 solver.cpp:291]     Train net output #0: loss = 0.0954787 (* 1 = 0.0954787 loss)
I0614 09:56:51.288252   290 sgd_solver.cpp:106] Iteration 3400, lr = 0.0001
I0614 09:57:03.905227   290 solver.cpp:270] Iteration 3450 (3.96304 iter/s, 12.6166s/50 iter), loss = 0.123461, remaining 1 hours and 9 minutes
I0614 09:57:03.905273   290 solver.cpp:291]     Train net output #0: loss = 0.123461 (* 1 = 0.123461 loss)
I0614 09:57:03.905282   290 sgd_solver.cpp:106] Iteration 3450, lr = 0.0001
I0614 09:57:16.508983   290 solver.cpp:270] Iteration 3500 (3.96721 iter/s, 12.6033s/50 iter), loss = 0.0944724, remaining 1 hours and 9 minutes
I0614 09:57:16.509016   290 solver.cpp:291]     Train net output #0: loss = 0.0944724 (* 1 = 0.0944724 loss)
I0614 09:57:16.509024   290 sgd_solver.cpp:106] Iteration 3500, lr = 0.0001
I0614 09:57:29.133621   290 solver.cpp:270] Iteration 3550 (3.96065 iter/s, 12.6242s/50 iter), loss = 0.053056, remaining 1 hours and 9 minutes
I0614 09:57:29.133653   290 solver.cpp:291]     Train net output #0: loss = 0.053056 (* 1 = 0.053056 loss)
I0614 09:57:29.133677   290 sgd_solver.cpp:106] Iteration 3550, lr = 0.0001
I0614 09:57:41.748669   290 solver.cpp:270] Iteration 3600 (3.96366 iter/s, 12.6146s/50 iter), loss = 0.0729185, remaining 1 hours and 8 minutes
I0614 09:57:41.748720   290 solver.cpp:291]     Train net output #0: loss = 0.0729185 (* 1 = 0.0729185 loss)
I0614 09:57:41.748728   290 sgd_solver.cpp:106] Iteration 3600, lr = 0.0001
I0614 09:57:54.366533   290 solver.cpp:270] Iteration 3650 (3.96278 iter/s, 12.6174s/50 iter), loss = 0.0959032, remaining 1 hours and 8 minutes
I0614 09:57:54.366567   290 solver.cpp:291]     Train net output #0: loss = 0.0959032 (* 1 = 0.0959032 loss)
I0614 09:57:54.366575   290 sgd_solver.cpp:106] Iteration 3650, lr = 0.0001
I0614 09:58:06.991384   290 solver.cpp:270] Iteration 3700 (3.96058 iter/s, 12.6244s/50 iter), loss = 0.0683807, remaining 1 hours and 8 minutes
I0614 09:58:06.991418   290 solver.cpp:291]     Train net output #0: loss = 0.0683807 (* 1 = 0.0683807 loss)
I0614 09:58:06.991427   290 sgd_solver.cpp:106] Iteration 3700, lr = 0.0001
I0614 09:58:19.593009   290 solver.cpp:270] Iteration 3750 (3.96788 iter/s, 12.6012s/50 iter), loss = 0.105041, remaining 1 hours and 8 minutes
I0614 09:58:19.593063   290 solver.cpp:291]     Train net output #0: loss = 0.105041 (* 1 = 0.105041 loss)
I0614 09:58:19.593072   290 sgd_solver.cpp:106] Iteration 3750, lr = 0.0001
I0614 09:58:32.209861   290 solver.cpp:270] Iteration 3800 (3.9631 iter/s, 12.6164s/50 iter), loss = 0.116934, remaining 1 hours and 8 minutes
I0614 09:58:32.209892   290 solver.cpp:291]     Train net output #0: loss = 0.116934 (* 1 = 0.116934 loss)
I0614 09:58:32.209900   290 sgd_solver.cpp:106] Iteration 3800, lr = 0.0001
I0614 09:58:44.822021   290 solver.cpp:270] Iteration 3850 (3.96457 iter/s, 12.6117s/50 iter), loss = 0.122998, remaining 1 hours and 7 minutes
I0614 09:58:44.822053   290 solver.cpp:291]     Train net output #0: loss = 0.122998 (* 1 = 0.122998 loss)
I0614 09:58:44.822062   290 sgd_solver.cpp:106] Iteration 3850, lr = 0.0001
I0614 09:58:57.462324   290 solver.cpp:270] Iteration 3900 (3.95574 iter/s, 12.6399s/50 iter), loss = 0.0947435, remaining 1 hours and 7 minutes
I0614 09:58:57.462373   290 solver.cpp:291]     Train net output #0: loss = 0.0947435 (* 1 = 0.0947435 loss)
I0614 09:58:57.462397   290 sgd_solver.cpp:106] Iteration 3900, lr = 0.0001
I0614 09:59:10.073158   290 solver.cpp:270] Iteration 3950 (3.96499 iter/s, 12.6104s/50 iter), loss = 0.0393411, remaining 1 hours and 7 minutes
I0614 09:59:10.073190   290 solver.cpp:291]     Train net output #0: loss = 0.0393411 (* 1 = 0.0393411 loss)
I0614 09:59:10.073215   290 sgd_solver.cpp:106] Iteration 3950, lr = 0.0001
I0614 09:59:22.421332   290 solver.cpp:424] Iteration 4000, Testing net (#0)
I0614 09:59:23.914321   290 solver.cpp:523]     Test net output #0: accuracy = 0.59975
I0614 09:59:23.914350   290 solver.cpp:523]     Test net output #1: loss = 0.643847 (* 1 = 0.643847 loss)
I0614 09:59:23.914355   290 solver.cpp:523]     Test net output #2: top-1 = 0.59975
I0614 09:59:24.160584   290 solver.cpp:270] Iteration 4000 (3.54939 iter/s, 14.0869s/50 iter), loss = 0.08408, remaining 1 hours and 14 minutes
I0614 09:59:24.160616   290 solver.cpp:291]     Train net output #0: loss = 0.08408 (* 1 = 0.08408 loss)
I0614 09:59:24.160624   290 sgd_solver.cpp:106] Iteration 4000, lr = 0.0001
I0614 09:59:36.786269   290 solver.cpp:270] Iteration 4050 (3.96032 iter/s, 12.6252s/50 iter), loss = 0.0646876, remaining 1 hours and 6 minutes
I0614 09:59:36.786317   290 solver.cpp:291]     Train net output #0: loss = 0.0646876 (* 1 = 0.0646876 loss)
I0614 09:59:36.786326   290 sgd_solver.cpp:106] Iteration 4050, lr = 0.0001
I0614 09:59:49.408927   290 solver.cpp:270] Iteration 4100 (3.96127 iter/s, 12.6222s/50 iter), loss = 0.0795154, remaining 1 hours and 6 minutes
I0614 09:59:49.408977   290 solver.cpp:291]     Train net output #0: loss = 0.0795154 (* 1 = 0.0795154 loss)
I0614 09:59:49.408985   290 sgd_solver.cpp:106] Iteration 4100, lr = 0.0001
I0614 10:00:02.037885   290 solver.cpp:270] Iteration 4150 (3.95929 iter/s, 12.6285s/50 iter), loss = 0.0764593, remaining 1 hours and 6 minutes
I0614 10:00:02.037918   290 solver.cpp:291]     Train net output #0: loss = 0.0764593 (* 1 = 0.0764593 loss)
I0614 10:00:02.037927   290 sgd_solver.cpp:106] Iteration 4150, lr = 0.0001
I0614 10:00:14.648777   290 solver.cpp:270] Iteration 4200 (3.96497 iter/s, 12.6104s/50 iter), loss = 0.0767224, remaining 1 hours and 6 minutes
I0614 10:00:14.648840   290 solver.cpp:291]     Train net output #0: loss = 0.0767224 (* 1 = 0.0767224 loss)
I0614 10:00:14.648864   290 sgd_solver.cpp:106] Iteration 4200, lr = 0.0001
I0614 10:00:27.268150   290 solver.cpp:270] Iteration 4250 (3.96231 iter/s, 12.6189s/50 iter), loss = 0.107298, remaining 1 hours and 6 minutes
I0614 10:00:27.268182   290 solver.cpp:291]     Train net output #0: loss = 0.107298 (* 1 = 0.107298 loss)
I0614 10:00:27.268190   290 sgd_solver.cpp:106] Iteration 4250, lr = 0.0001
I0614 10:00:39.896101   290 solver.cpp:270] Iteration 4300 (3.95961 iter/s, 12.6275s/50 iter), loss = 0.0751663, remaining 1 hours and 5 minutes
I0614 10:00:39.896135   290 solver.cpp:291]     Train net output #0: loss = 0.0751663 (* 1 = 0.0751663 loss)
I0614 10:00:39.896160   290 sgd_solver.cpp:106] Iteration 4300, lr = 0.0001
I0614 10:00:52.517755   290 solver.cpp:270] Iteration 4350 (3.96159 iter/s, 12.6212s/50 iter), loss = 0.0791081, remaining 1 hours and 5 minutes
I0614 10:00:52.517804   290 solver.cpp:291]     Train net output #0: loss = 0.0791081 (* 1 = 0.0791081 loss)
I0614 10:00:52.517812   290 sgd_solver.cpp:106] Iteration 4350, lr = 0.0001
I0614 10:01:05.144647   290 solver.cpp:270] Iteration 4400 (3.95995 iter/s, 12.6264s/50 iter), loss = 0.0695461, remaining 1 hours and 5 minutes
I0614 10:01:05.144680   290 solver.cpp:291]     Train net output #0: loss = 0.0695461 (* 1 = 0.0695461 loss)
I0614 10:01:05.144688   290 sgd_solver.cpp:106] Iteration 4400, lr = 0.0001
I0614 10:01:17.756561   290 solver.cpp:270] Iteration 4450 (3.96464 iter/s, 12.6115s/50 iter), loss = 0.0880108, remaining 1 hours and 5 minutes
I0614 10:01:17.756595   290 solver.cpp:291]     Train net output #0: loss = 0.0880108 (* 1 = 0.0880108 loss)
I0614 10:01:17.756604   290 sgd_solver.cpp:106] Iteration 4450, lr = 0.0001
I0614 10:01:30.376835   290 solver.cpp:270] Iteration 4500 (3.96202 iter/s, 12.6198s/50 iter), loss = 0.0776492, remaining 1 hours and 5 minutes
I0614 10:01:30.376883   290 solver.cpp:291]     Train net output #0: loss = 0.0776491 (* 1 = 0.0776491 loss)
I0614 10:01:30.376907   290 sgd_solver.cpp:106] Iteration 4500, lr = 0.0001
I0614 10:01:42.971603   290 solver.cpp:270] Iteration 4550 (3.97005 iter/s, 12.5943s/50 iter), loss = 0.0835778, remaining 1 hours and 4 minutes
I0614 10:01:42.971637   290 solver.cpp:291]     Train net output #0: loss = 0.0835777 (* 1 = 0.0835777 loss)
I0614 10:01:42.971647   290 sgd_solver.cpp:106] Iteration 4550, lr = 0.0001
I0614 10:01:55.591444   290 solver.cpp:270] Iteration 4600 (3.96215 iter/s, 12.6194s/50 iter), loss = 0.0585811, remaining 1 hours and 4 minutes
I0614 10:01:55.591477   290 solver.cpp:291]     Train net output #0: loss = 0.0585811 (* 1 = 0.0585811 loss)
I0614 10:01:55.591486   290 sgd_solver.cpp:106] Iteration 4600, lr = 0.0001
I0614 10:02:08.205142   290 solver.cpp:270] Iteration 4650 (3.96408 iter/s, 12.6133s/50 iter), loss = 0.104364, remaining 1 hours and 4 minutes
I0614 10:02:08.205190   290 solver.cpp:291]     Train net output #0: loss = 0.104364 (* 1 = 0.104364 loss)
I0614 10:02:08.205214   290 sgd_solver.cpp:106] Iteration 4650, lr = 0.0001
I0614 10:02:20.803558   290 solver.cpp:270] Iteration 4700 (3.9689 iter/s, 12.598s/50 iter), loss = 0.0947205, remaining 1 hours and 4 minutes
I0614 10:02:20.803592   290 solver.cpp:291]     Train net output #0: loss = 0.0947205 (* 1 = 0.0947205 loss)
I0614 10:02:20.803615   290 sgd_solver.cpp:106] Iteration 4700, lr = 0.0001
I0614 10:02:33.431145   290 solver.cpp:270] Iteration 4750 (3.95972 iter/s, 12.6271s/50 iter), loss = 0.0499405, remaining 1 hours and 4 minutes
I0614 10:02:33.431180   290 solver.cpp:291]     Train net output #0: loss = 0.0499405 (* 1 = 0.0499405 loss)
I0614 10:02:33.431203   290 sgd_solver.cpp:106] Iteration 4750, lr = 0.0001
I0614 10:02:46.045614   290 solver.cpp:270] Iteration 4800 (3.96384 iter/s, 12.614s/50 iter), loss = 0.0381451, remaining 1 hours and 3 minutes
I0614 10:02:46.045662   290 solver.cpp:291]     Train net output #0: loss = 0.0381451 (* 1 = 0.0381451 loss)
I0614 10:02:46.045686   290 sgd_solver.cpp:106] Iteration 4800, lr = 0.0001
I0614 10:02:58.658766   290 solver.cpp:270] Iteration 4850 (3.96426 iter/s, 12.6127s/50 iter), loss = 0.0660781, remaining 1 hours and 3 minutes
I0614 10:02:58.658799   290 solver.cpp:291]     Train net output #0: loss = 0.0660781 (* 1 = 0.0660781 loss)
I0614 10:02:58.658808   290 sgd_solver.cpp:106] Iteration 4850, lr = 0.0001
I0614 10:03:11.273918   290 solver.cpp:270] Iteration 4900 (3.96363 iter/s, 12.6147s/50 iter), loss = 0.0691337, remaining 1 hours and 3 minutes
I0614 10:03:11.273952   290 solver.cpp:291]     Train net output #0: loss = 0.0691337 (* 1 = 0.0691337 loss)
I0614 10:03:11.273959   290 sgd_solver.cpp:106] Iteration 4900, lr = 0.0001
I0614 10:03:23.887077   290 solver.cpp:270] Iteration 4950 (3.96425 iter/s, 12.6127s/50 iter), loss = 0.0552061, remaining 1 hours and 3 minutes
I0614 10:03:23.887136   290 solver.cpp:291]     Train net output #0: loss = 0.0552061 (* 1 = 0.0552061 loss)
I0614 10:03:23.887161   290 sgd_solver.cpp:106] Iteration 4950, lr = 0.0001
I0614 10:03:36.251410   290 solver.cpp:935] Snapshotting to binary proto file caffe/models/alexnetBNnoLRN/m2/snapshot_2_alexnetBNnoLRN__iter_5000.caffemodel
I0614 10:03:41.348758   290 sgd_solver.cpp:273] Snapshotting solver state to binary proto file caffe/models/alexnetBNnoLRN/m2/snapshot_2_alexnetBNnoLRN__iter_5000.solverstate
I0614 10:03:45.027487   290 solver.cpp:424] Iteration 5000, Testing net (#0)
I0614 10:03:46.454547   290 solver.cpp:523]     Test net output #0: accuracy = 0.73525
I0614 10:03:46.454579   290 solver.cpp:523]     Test net output #1: loss = 0.623404 (* 1 = 0.623404 loss)
I0614 10:03:46.454583   290 solver.cpp:523]     Test net output #2: top-1 = 0.73525
I0614 10:03:46.694943   290 solver.cpp:270] Iteration 5000 (2.1923 iter/s, 22.8071s/50 iter), loss = 0.0997797, remaining 1 hours and 54 minutes
I0614 10:03:46.694976   290 solver.cpp:291]     Train net output #0: loss = 0.0997797 (* 1 = 0.0997797 loss)
I0614 10:03:46.694985   290 sgd_solver.cpp:106] Iteration 5000, lr = 1e-05
I0614 10:03:59.241430   290 solver.cpp:270] Iteration 5050 (3.98532 iter/s, 12.546s/50 iter), loss = 0.0596434, remaining 1 hours and 2 minutes
I0614 10:03:59.241477   290 solver.cpp:291]     Train net output #0: loss = 0.0596434 (* 1 = 0.0596434 loss)
I0614 10:03:59.241485   290 sgd_solver.cpp:106] Iteration 5050, lr = 1e-05
I0614 10:04:11.831877   290 solver.cpp:270] Iteration 5100 (3.97141 iter/s, 12.59s/50 iter), loss = 0.0359207, remaining 1 hours and 2 minutes
I0614 10:04:11.831910   290 solver.cpp:291]     Train net output #0: loss = 0.0359206 (* 1 = 0.0359206 loss)
I0614 10:04:11.831919   290 sgd_solver.cpp:106] Iteration 5100, lr = 1e-05
I0614 10:04:24.445971   290 solver.cpp:270] Iteration 5150 (3.96396 iter/s, 12.6137s/50 iter), loss = 0.0429243, remaining 1 hours and 2 minutes
I0614 10:04:24.446005   290 solver.cpp:291]     Train net output #0: loss = 0.0429243 (* 1 = 0.0429243 loss)
I0614 10:04:24.446014   290 sgd_solver.cpp:106] Iteration 5150, lr = 1e-05
I0614 10:04:37.066581   290 solver.cpp:270] Iteration 5200 (3.96191 iter/s, 12.6202s/50 iter), loss = 0.0255555, remaining 1 hours and 2 minutes
I0614 10:04:37.066632   290 solver.cpp:291]     Train net output #0: loss = 0.0255555 (* 1 = 0.0255555 loss)
I0614 10:04:37.066656   290 sgd_solver.cpp:106] Iteration 5200, lr = 1e-05
I0614 10:04:49.675837   290 solver.cpp:270] Iteration 5250 (3.96549 iter/s, 12.6088s/50 iter), loss = 0.0583046, remaining 1 hours and 1 minutes
I0614 10:04:49.675870   290 solver.cpp:291]     Train net output #0: loss = 0.0583046 (* 1 = 0.0583046 loss)
I0614 10:04:49.675879   290 sgd_solver.cpp:106] Iteration 5250, lr = 1e-05
I0614 10:05:02.281345   290 solver.cpp:270] Iteration 5300 (3.96666 iter/s, 12.6051s/50 iter), loss = 0.0482128, remaining 1 hours and 1 minutes
I0614 10:05:02.281399   290 solver.cpp:291]     Train net output #0: loss = 0.0482127 (* 1 = 0.0482127 loss)
I0614 10:05:02.281411   290 sgd_solver.cpp:106] Iteration 5300, lr = 1e-05
I0614 10:05:14.889621   290 solver.cpp:270] Iteration 5350 (3.96579 iter/s, 12.6078s/50 iter), loss = 0.0536075, remaining 1 hours and 1 minutes
I0614 10:05:14.889678   290 solver.cpp:291]     Train net output #0: loss = 0.0536075 (* 1 = 0.0536075 loss)
I0614 10:05:14.889686   290 sgd_solver.cpp:106] Iteration 5350, lr = 1e-05
I0614 10:05:27.504220   290 solver.cpp:270] Iteration 5400 (3.96381 iter/s, 12.6141s/50 iter), loss = 0.0601142, remaining 1 hours and 1 minutes
I0614 10:05:27.504256   290 solver.cpp:291]     Train net output #0: loss = 0.0601142 (* 1 = 0.0601142 loss)
I0614 10:05:27.504279   290 sgd_solver.cpp:106] Iteration 5400, lr = 1e-05
I0614 10:05:40.156921   290 solver.cpp:270] Iteration 5450 (3.95186 iter/s, 12.6523s/50 iter), loss = 0.0611146, remaining 1 hours and 1 minutes
I0614 10:05:40.156953   290 solver.cpp:291]     Train net output #0: loss = 0.0611146 (* 1 = 0.0611146 loss)
I0614 10:05:40.156961   290 sgd_solver.cpp:106] Iteration 5450, lr = 1e-05
I0614 10:05:52.796437   290 solver.cpp:270] Iteration 5500 (3.95599 iter/s, 12.6391s/50 iter), loss = 0.0644402, remaining 1 hours and 0 minutes
I0614 10:05:52.796487   290 solver.cpp:291]     Train net output #0: loss = 0.0644402 (* 1 = 0.0644402 loss)
I0614 10:05:52.796495   290 sgd_solver.cpp:106] Iteration 5500, lr = 1e-05
I0614 10:06:05.439960   290 solver.cpp:270] Iteration 5550 (3.95474 iter/s, 12.6431s/50 iter), loss = 0.060252, remaining 1 hours and 0 minutes
I0614 10:06:05.439994   290 solver.cpp:291]     Train net output #0: loss = 0.0602519 (* 1 = 0.0602519 loss)
I0614 10:06:05.440003   290 sgd_solver.cpp:106] Iteration 5550, lr = 1e-05
I0614 10:06:18.072190   290 solver.cpp:270] Iteration 5600 (3.95827 iter/s, 12.6318s/50 iter), loss = 0.0495237, remaining 1 hours and 0 minutes
I0614 10:06:18.072222   290 solver.cpp:291]     Train net output #0: loss = 0.0495237 (* 1 = 0.0495237 loss)
I0614 10:06:18.072247   290 sgd_solver.cpp:106] Iteration 5600, lr = 1e-05
I0614 10:06:30.686635   290 solver.cpp:270] Iteration 5650 (3.96385 iter/s, 12.614s/50 iter), loss = 0.0383163, remaining 1 hours and 0 minutes
I0614 10:06:30.686686   290 solver.cpp:291]     Train net output #0: loss = 0.0383163 (* 1 = 0.0383163 loss)
I0614 10:06:30.686697   290 sgd_solver.cpp:106] Iteration 5650, lr = 1e-05
I0614 10:06:43.313984   290 solver.cpp:270] Iteration 5700 (3.9598 iter/s, 12.6269s/50 iter), loss = 0.0461755, remaining 1 hours and 0 minutes
I0614 10:06:43.314018   290 solver.cpp:291]     Train net output #0: loss = 0.0461754 (* 1 = 0.0461754 loss)
I0614 10:06:43.314026   290 sgd_solver.cpp:106] Iteration 5700, lr = 1e-05
I0614 10:06:55.918180   290 solver.cpp:270] Iteration 5750 (3.96707 iter/s, 12.6038s/50 iter), loss = 0.0683635, remaining 0 hours and 59 minutes
I0614 10:06:55.918212   290 solver.cpp:291]     Train net output #0: loss = 0.0683635 (* 1 = 0.0683635 loss)
I0614 10:06:55.918223   290 sgd_solver.cpp:106] Iteration 5750, lr = 1e-05
I0614 10:07:08.544415   290 solver.cpp:270] Iteration 5800 (3.96015 iter/s, 12.6258s/50 iter), loss = 0.0519003, remaining 0 hours and 59 minutes
I0614 10:07:08.544466   290 solver.cpp:291]     Train net output #0: loss = 0.0519003 (* 1 = 0.0519003 loss)
I0614 10:07:08.544476   290 sgd_solver.cpp:106] Iteration 5800, lr = 1e-05
I0614 10:07:21.169365   290 solver.cpp:270] Iteration 5850 (3.96056 iter/s, 12.6245s/50 iter), loss = 0.0437181, remaining 0 hours and 59 minutes
I0614 10:07:21.169405   290 solver.cpp:291]     Train net output #0: loss = 0.0437181 (* 1 = 0.0437181 loss)
I0614 10:07:21.169414   290 sgd_solver.cpp:106] Iteration 5850, lr = 1e-05
I0614 10:07:33.793623   290 solver.cpp:270] Iteration 5900 (3.96077 iter/s, 12.6238s/50 iter), loss = 0.0491781, remaining 0 hours and 59 minutes
I0614 10:07:33.793656   290 solver.cpp:291]     Train net output #0: loss = 0.0491781 (* 1 = 0.0491781 loss)
I0614 10:07:33.793664   290 sgd_solver.cpp:106] Iteration 5900, lr = 1e-05
I0614 10:07:46.414963   290 solver.cpp:270] Iteration 5950 (3.96168 iter/s, 12.6209s/50 iter), loss = 0.0544583, remaining 0 hours and 59 minutes
I0614 10:07:46.415011   290 solver.cpp:291]     Train net output #0: loss = 0.0544583 (* 1 = 0.0544583 loss)
I0614 10:07:46.415020   290 sgd_solver.cpp:106] Iteration 5950, lr = 1e-05
I0614 10:07:58.783360   290 solver.cpp:424] Iteration 6000, Testing net (#0)
I0614 10:08:00.298689   290 solver.cpp:523]     Test net output #0: accuracy = 0.7575
I0614 10:08:00.298719   290 solver.cpp:523]     Test net output #1: loss = 0.598659 (* 1 = 0.598659 loss)
I0614 10:08:00.298724   290 solver.cpp:523]     Test net output #2: top-1 = 0.7575
I0614 10:08:00.545785   290 solver.cpp:270] Iteration 6000 (3.53849 iter/s, 14.1303s/50 iter), loss = 0.0350641, remaining 1 hours and 5 minutes
I0614 10:08:00.545819   290 solver.cpp:291]     Train net output #0: loss = 0.0350641 (* 1 = 0.0350641 loss)
I0614 10:08:00.545843   290 sgd_solver.cpp:106] Iteration 6000, lr = 1e-05
I0614 10:08:13.163441   290 solver.cpp:270] Iteration 6050 (3.96284 iter/s, 12.6172s/50 iter), loss = 0.0417504, remaining 0 hours and 58 minutes
I0614 10:08:13.163475   290 solver.cpp:291]     Train net output #0: loss = 0.0417503 (* 1 = 0.0417503 loss)
I0614 10:08:13.163498   290 sgd_solver.cpp:106] Iteration 6050, lr = 1e-05
I0614 10:08:25.778558   290 solver.cpp:270] Iteration 6100 (3.96364 iter/s, 12.6147s/50 iter), loss = 0.0361467, remaining 0 hours and 58 minutes
I0614 10:08:25.778616   290 solver.cpp:291]     Train net output #0: loss = 0.0361467 (* 1 = 0.0361467 loss)
I0614 10:08:25.778625   290 sgd_solver.cpp:106] Iteration 6100, lr = 1e-05
I0614 10:08:38.398453   290 solver.cpp:270] Iteration 6150 (3.96214 iter/s, 12.6194s/50 iter), loss = 0.0558813, remaining 0 hours and 58 minutes
I0614 10:08:38.398488   290 solver.cpp:291]     Train net output #0: loss = 0.0558813 (* 1 = 0.0558813 loss)
I0614 10:08:38.398499   290 sgd_solver.cpp:106] Iteration 6150, lr = 1e-05
I0614 10:08:51.011039   290 solver.cpp:270] Iteration 6200 (3.96443 iter/s, 12.6121s/50 iter), loss = 0.0403608, remaining 0 hours and 58 minutes
I0614 10:08:51.011072   290 solver.cpp:291]     Train net output #0: loss = 0.0403608 (* 1 = 0.0403608 loss)
I0614 10:08:51.011096   290 sgd_solver.cpp:106] Iteration 6200, lr = 1e-05
I0614 10:09:03.633203   290 solver.cpp:270] Iteration 6250 (3.96142 iter/s, 12.6217s/50 iter), loss = 0.0496401, remaining 0 hours and 57 minutes
I0614 10:09:03.633250   290 solver.cpp:291]     Train net output #0: loss = 0.0496401 (* 1 = 0.0496401 loss)
I0614 10:09:03.633260   290 sgd_solver.cpp:106] Iteration 6250, lr = 1e-05
I0614 10:09:16.252735   290 solver.cpp:270] Iteration 6300 (3.96225 iter/s, 12.6191s/50 iter), loss = 0.0374842, remaining 0 hours and 57 minutes
I0614 10:09:16.252768   290 solver.cpp:291]     Train net output #0: loss = 0.0374842 (* 1 = 0.0374842 loss)
I0614 10:09:16.252792   290 sgd_solver.cpp:106] Iteration 6300, lr = 1e-05
I0614 10:09:28.869393   290 solver.cpp:270] Iteration 6350 (3.96315 iter/s, 12.6162s/50 iter), loss = 0.0302949, remaining 0 hours and 57 minutes
I0614 10:09:28.869426   290 solver.cpp:291]     Train net output #0: loss = 0.0302949 (* 1 = 0.0302949 loss)
I0614 10:09:28.869450   290 sgd_solver.cpp:106] Iteration 6350, lr = 1e-05
I0614 10:09:41.485842   290 solver.cpp:270] Iteration 6400 (3.96322 iter/s, 12.616s/50 iter), loss = 0.0237501, remaining 0 hours and 57 minutes
I0614 10:09:41.485890   290 solver.cpp:291]     Train net output #0: loss = 0.0237501 (* 1 = 0.0237501 loss)
I0614 10:09:41.485914   290 sgd_solver.cpp:106] Iteration 6400, lr = 1e-05
I0614 10:09:54.086616   290 solver.cpp:270] Iteration 6450 (3.96815 iter/s, 12.6003s/50 iter), loss = 0.016175, remaining 0 hours and 56 minutes
I0614 10:09:54.086650   290 solver.cpp:291]     Train net output #0: loss = 0.016175 (* 1 = 0.016175 loss)
I0614 10:09:54.086674   290 sgd_solver.cpp:106] Iteration 6450, lr = 1e-05
I0614 10:10:06.702893   290 solver.cpp:270] Iteration 6500 (3.96327 iter/s, 12.6158s/50 iter), loss = 0.0414805, remaining 0 hours and 56 minutes
I0614 10:10:06.702926   290 solver.cpp:291]     Train net output #0: loss = 0.0414805 (* 1 = 0.0414805 loss)
I0614 10:10:06.702934   290 sgd_solver.cpp:106] Iteration 6500, lr = 1e-05
I0614 10:10:19.312335   290 solver.cpp:270] Iteration 6550 (3.96542 iter/s, 12.609s/50 iter), loss = 0.0530873, remaining 0 hours and 56 minutes
I0614 10:10:19.312393   290 solver.cpp:291]     Train net output #0: loss = 0.0530873 (* 1 = 0.0530873 loss)
I0614 10:10:19.312402   290 sgd_solver.cpp:106] Iteration 6550, lr = 1e-05
I0614 10:10:31.927400   290 solver.cpp:270] Iteration 6600 (3.96366 iter/s, 12.6146s/50 iter), loss = 0.0720534, remaining 0 hours and 56 minutes
I0614 10:10:31.927434   290 solver.cpp:291]     Train net output #0: loss = 0.0720534 (* 1 = 0.0720534 loss)
I0614 10:10:31.927459   290 sgd_solver.cpp:106] Iteration 6600, lr = 1e-05
I0614 10:10:44.547994   290 solver.cpp:270] Iteration 6650 (3.96192 iter/s, 12.6202s/50 iter), loss = 0.0539958, remaining 0 hours and 56 minutes
I0614 10:10:44.548027   290 solver.cpp:291]     Train net output #0: loss = 0.0539958 (* 1 = 0.0539958 loss)
I0614 10:10:44.548035   290 sgd_solver.cpp:106] Iteration 6650, lr = 1e-05
I0614 10:10:57.165608   290 solver.cpp:270] Iteration 6700 (3.96285 iter/s, 12.6172s/50 iter), loss = 0.0656995, remaining 0 hours and 55 minutes
I0614 10:10:57.165657   290 solver.cpp:291]     Train net output #0: loss = 0.0656995 (* 1 = 0.0656995 loss)
I0614 10:10:57.165666   290 sgd_solver.cpp:106] Iteration 6700, lr = 1e-05
I0614 10:11:09.786573   290 solver.cpp:270] Iteration 6750 (3.96181 iter/s, 12.6205s/50 iter), loss = 0.0483491, remaining 0 hours and 55 minutes
I0614 10:11:09.786607   290 solver.cpp:291]     Train net output #0: loss = 0.0483491 (* 1 = 0.0483491 loss)
I0614 10:11:09.786617   290 sgd_solver.cpp:106] Iteration 6750, lr = 1e-05
I0614 10:11:22.412046   290 solver.cpp:270] Iteration 6800 (3.96039 iter/s, 12.625s/50 iter), loss = 0.0624493, remaining 0 hours and 55 minutes
I0614 10:11:22.412081   290 solver.cpp:291]     Train net output #0: loss = 0.0624493 (* 1 = 0.0624493 loss)
I0614 10:11:22.412091   290 sgd_solver.cpp:106] Iteration 6800, lr = 1e-05
I0614 10:11:35.028964   290 solver.cpp:270] Iteration 6850 (3.96307 iter/s, 12.6165s/50 iter), loss = 0.0318296, remaining 0 hours and 55 minutes
I0614 10:11:35.029011   290 solver.cpp:291]     Train net output #0: loss = 0.0318296 (* 1 = 0.0318296 loss)
I0614 10:11:35.029021   290 sgd_solver.cpp:106] Iteration 6850, lr = 1e-05
I0614 10:11:47.647735   290 solver.cpp:270] Iteration 6900 (3.96249 iter/s, 12.6183s/50 iter), loss = 0.0448327, remaining 0 hours and 55 minutes
I0614 10:11:47.647770   290 solver.cpp:291]     Train net output #0: loss = 0.0448327 (* 1 = 0.0448327 loss)
I0614 10:11:47.647778   290 sgd_solver.cpp:106] Iteration 6900, lr = 1e-05
I0614 10:12:00.258618   290 solver.cpp:270] Iteration 6950 (3.96497 iter/s, 12.6104s/50 iter), loss = 0.0304985, remaining 0 hours and 54 minutes
I0614 10:12:00.258652   290 solver.cpp:291]     Train net output #0: loss = 0.0304985 (* 1 = 0.0304985 loss)
I0614 10:12:00.258661   290 sgd_solver.cpp:106] Iteration 6950, lr = 1e-05
I0614 10:12:12.633617   290 solver.cpp:424] Iteration 7000, Testing net (#0)
I0614 10:12:14.121120   290 solver.cpp:523]     Test net output #0: accuracy = 0.80775
I0614 10:12:14.121153   290 solver.cpp:523]     Test net output #1: loss = 0.574834 (* 1 = 0.574834 loss)
I0614 10:12:14.121158   290 solver.cpp:523]     Test net output #2: top-1 = 0.80775
I0614 10:12:14.368305   290 solver.cpp:270] Iteration 7000 (3.54379 iter/s, 14.1092s/50 iter), loss = 0.0333306, remaining 1 hours and 0 minutes
I0614 10:12:14.368340   290 solver.cpp:291]     Train net output #0: loss = 0.0333306 (* 1 = 0.0333306 loss)
I0614 10:12:14.368348   290 sgd_solver.cpp:106] Iteration 7000, lr = 1e-05
I0614 10:12:26.984995   290 solver.cpp:270] Iteration 7050 (3.96314 iter/s, 12.6162s/50 iter), loss = 0.0533536, remaining 0 hours and 54 minutes
I0614 10:12:26.985028   290 solver.cpp:291]     Train net output #0: loss = 0.0533536 (* 1 = 0.0533536 loss)
I0614 10:12:26.985036   290 sgd_solver.cpp:106] Iteration 7050, lr = 1e-05
I0614 10:12:39.590167   290 solver.cpp:270] Iteration 7100 (3.96676 iter/s, 12.6047s/50 iter), loss = 0.0179374, remaining 0 hours and 54 minutes
I0614 10:12:39.590198   290 solver.cpp:291]     Train net output #0: loss = 0.0179374 (* 1 = 0.0179374 loss)
I0614 10:12:39.590222   290 sgd_solver.cpp:106] Iteration 7100, lr = 1e-05
I0614 10:12:52.196835   290 solver.cpp:270] Iteration 7150 (3.96629 iter/s, 12.6062s/50 iter), loss = 0.0670131, remaining 0 hours and 53 minutes
I0614 10:12:52.196893   290 solver.cpp:291]     Train net output #0: loss = 0.0670131 (* 1 = 0.0670131 loss)
I0614 10:12:52.196902   290 sgd_solver.cpp:106] Iteration 7150, lr = 1e-05
I0614 10:13:04.817204   290 solver.cpp:270] Iteration 7200 (3.962 iter/s, 12.6199s/50 iter), loss = 0.049958, remaining 0 hours and 53 minutes
I0614 10:13:04.817237   290 solver.cpp:291]     Train net output #0: loss = 0.049958 (* 1 = 0.049958 loss)
I0614 10:13:04.817245   290 sgd_solver.cpp:106] Iteration 7200, lr = 1e-05
I0614 10:13:17.438901   290 solver.cpp:270] Iteration 7250 (3.96157 iter/s, 12.6213s/50 iter), loss = 0.016341, remaining 0 hours and 53 minutes
I0614 10:13:17.438935   290 solver.cpp:291]     Train net output #0: loss = 0.016341 (* 1 = 0.016341 loss)
I0614 10:13:17.438946   290 sgd_solver.cpp:106] Iteration 7250, lr = 1e-05
I0614 10:13:30.043706   290 solver.cpp:270] Iteration 7300 (3.96688 iter/s, 12.6044s/50 iter), loss = 0.0217379, remaining 0 hours and 53 minutes
I0614 10:13:30.043756   290 solver.cpp:291]     Train net output #0: loss = 0.0217379 (* 1 = 0.0217379 loss)
I0614 10:13:30.043766   290 sgd_solver.cpp:106] Iteration 7300, lr = 1e-05
I0614 10:13:42.652465   290 solver.cpp:270] Iteration 7350 (3.96564 iter/s, 12.6083s/50 iter), loss = 0.0365559, remaining 0 hours and 52 minutes
I0614 10:13:42.652499   290 solver.cpp:291]     Train net output #0: loss = 0.0365559 (* 1 = 0.0365559 loss)
I0614 10:13:42.652508   290 sgd_solver.cpp:106] Iteration 7350, lr = 1e-05
I0614 10:13:55.264902   290 solver.cpp:270] Iteration 7400 (3.96448 iter/s, 12.612s/50 iter), loss = 0.0306156, remaining 0 hours and 52 minutes
I0614 10:13:55.264936   290 solver.cpp:291]     Train net output #0: loss = 0.0306156 (* 1 = 0.0306156 loss)
I0614 10:13:55.264945   290 sgd_solver.cpp:106] Iteration 7400, lr = 1e-05
I0614 10:14:07.877712   290 solver.cpp:270] Iteration 7450 (3.96436 iter/s, 12.6124s/50 iter), loss = 0.0238295, remaining 0 hours and 52 minutes
I0614 10:14:07.877761   290 solver.cpp:291]     Train net output #0: loss = 0.0238295 (* 1 = 0.0238295 loss)
I0614 10:14:07.877770   290 sgd_solver.cpp:106] Iteration 7450, lr = 1e-05
I0614 10:14:20.501806   290 solver.cpp:270] Iteration 7500 (3.96082 iter/s, 12.6236s/50 iter), loss = 0.0692794, remaining 0 hours and 52 minutes
I0614 10:14:20.501840   290 solver.cpp:291]     Train net output #0: loss = 0.0692794 (* 1 = 0.0692794 loss)
I0614 10:14:20.501849   290 sgd_solver.cpp:106] Iteration 7500, lr = 1e-06
I0614 10:14:33.117910   290 solver.cpp:270] Iteration 7550 (3.96333 iter/s, 12.6157s/50 iter), loss = 0.0388028, remaining 0 hours and 52 minutes
I0614 10:14:33.117944   290 solver.cpp:291]     Train net output #0: loss = 0.0388028 (* 1 = 0.0388028 loss)
I0614 10:14:33.117954   290 sgd_solver.cpp:106] Iteration 7550, lr = 1e-06
I0614 10:14:45.729315   290 solver.cpp:270] Iteration 7600 (3.9648 iter/s, 12.611s/50 iter), loss = 0.0371399, remaining 0 hours and 51 minutes
I0614 10:14:45.729364   290 solver.cpp:291]     Train net output #0: loss = 0.0371399 (* 1 = 0.0371399 loss)
I0614 10:14:45.729390   290 sgd_solver.cpp:106] Iteration 7600, lr = 1e-06
I0614 10:14:58.336549   290 solver.cpp:270] Iteration 7650 (3.96612 iter/s, 12.6068s/50 iter), loss = 0.0383949, remaining 0 hours and 51 minutes
I0614 10:14:58.336581   290 solver.cpp:291]     Train net output #0: loss = 0.0383949 (* 1 = 0.0383949 loss)
I0614 10:14:58.336591   290 sgd_solver.cpp:106] Iteration 7650, lr = 1e-06
I0614 10:15:10.948379   290 solver.cpp:270] Iteration 7700 (3.96467 iter/s, 12.6114s/50 iter), loss = 0.0068936, remaining 0 hours and 51 minutes
I0614 10:15:10.948412   290 solver.cpp:291]     Train net output #0: loss = 0.00689361 (* 1 = 0.00689361 loss)
I0614 10:15:10.948421   290 sgd_solver.cpp:106] Iteration 7700, lr = 1e-06
I0614 10:15:23.568873   290 solver.cpp:270] Iteration 7750 (3.96195 iter/s, 12.6201s/50 iter), loss = 0.0446702, remaining 0 hours and 51 minutes
I0614 10:15:23.568930   290 solver.cpp:291]     Train net output #0: loss = 0.0446702 (* 1 = 0.0446702 loss)
I0614 10:15:23.568940   290 sgd_solver.cpp:106] Iteration 7750, lr = 1e-06
I0614 10:15:36.181516   290 solver.cpp:270] Iteration 7800 (3.96442 iter/s, 12.6122s/50 iter), loss = 0.0230567, remaining 0 hours and 51 minutes
I0614 10:15:36.181550   290 solver.cpp:291]     Train net output #0: loss = 0.0230568 (* 1 = 0.0230568 loss)
I0614 10:15:36.181560   290 sgd_solver.cpp:106] Iteration 7800, lr = 1e-06
I0614 10:15:48.796001   290 solver.cpp:270] Iteration 7850 (3.96384 iter/s, 12.614s/50 iter), loss = 0.0343935, remaining 0 hours and 50 minutes
I0614 10:15:48.796033   290 solver.cpp:291]     Train net output #0: loss = 0.0343935 (* 1 = 0.0343935 loss)
I0614 10:15:48.796058   290 sgd_solver.cpp:106] Iteration 7850, lr = 1e-06
I0614 10:16:01.424137   290 solver.cpp:270] Iteration 7900 (3.95955 iter/s, 12.6277s/50 iter), loss = 0.0494707, remaining 0 hours and 50 minutes
I0614 10:16:01.424181   290 solver.cpp:291]     Train net output #0: loss = 0.0494707 (* 1 = 0.0494707 loss)
I0614 10:16:01.424206   290 sgd_solver.cpp:106] Iteration 7900, lr = 1e-06
I0614 10:16:14.023680   290 solver.cpp:270] Iteration 7950 (3.96854 iter/s, 12.5991s/50 iter), loss = 0.0896775, remaining 0 hours and 50 minutes
I0614 10:16:14.023712   290 solver.cpp:291]     Train net output #0: loss = 0.0896775 (* 1 = 0.0896775 loss)
I0614 10:16:14.023737   290 sgd_solver.cpp:106] Iteration 7950, lr = 1e-06
I0614 10:16:26.394974   290 solver.cpp:424] Iteration 8000, Testing net (#0)
I0614 10:16:27.882097   290 solver.cpp:523]     Test net output #0: accuracy = 0.8875
I0614 10:16:27.882129   290 solver.cpp:523]     Test net output #1: loss = 0.53429 (* 1 = 0.53429 loss)
I0614 10:16:27.882133   290 solver.cpp:523]     Test net output #2: top-1 = 0.8875
I0614 10:16:28.128823   290 solver.cpp:270] Iteration 8000 (3.54493 iter/s, 14.1047s/50 iter), loss = 0.0335851, remaining 0 hours and 56 minutes
I0614 10:16:28.128873   290 solver.cpp:291]     Train net output #0: loss = 0.0335851 (* 1 = 0.0335851 loss)
I0614 10:16:28.128883   290 sgd_solver.cpp:106] Iteration 8000, lr = 1e-06
I0614 10:16:40.758548   290 solver.cpp:270] Iteration 8050 (3.95905 iter/s, 12.6293s/50 iter), loss = 0.0649148, remaining 0 hours and 50 minutes
I0614 10:16:40.758599   290 solver.cpp:291]     Train net output #0: loss = 0.0649148 (* 1 = 0.0649148 loss)
I0614 10:16:40.758623   290 sgd_solver.cpp:106] Iteration 8050, lr = 1e-06
I0614 10:16:53.360841   290 solver.cpp:270] Iteration 8100 (3.96768 iter/s, 12.6018s/50 iter), loss = 0.0453782, remaining 0 hours and 49 minutes
I0614 10:16:53.360875   290 solver.cpp:291]     Train net output #0: loss = 0.0453782 (* 1 = 0.0453782 loss)
I0614 10:16:53.360900   290 sgd_solver.cpp:106] Iteration 8100, lr = 1e-06
I0614 10:17:05.974310   290 solver.cpp:270] Iteration 8150 (3.96416 iter/s, 12.613s/50 iter), loss = 0.0454443, remaining 0 hours and 49 minutes
I0614 10:17:05.974345   290 solver.cpp:291]     Train net output #0: loss = 0.0454443 (* 1 = 0.0454443 loss)
I0614 10:17:05.974354   290 sgd_solver.cpp:106] Iteration 8150, lr = 1e-06
I0614 10:17:18.580324   290 solver.cpp:270] Iteration 8200 (3.9665 iter/s, 12.6056s/50 iter), loss = 0.0234782, remaining 0 hours and 49 minutes
I0614 10:17:18.580389   290 solver.cpp:291]     Train net output #0: loss = 0.0234782 (* 1 = 0.0234782 loss)
I0614 10:17:18.580397   290 sgd_solver.cpp:106] Iteration 8200, lr = 1e-06
I0614 10:17:31.193543   290 solver.cpp:270] Iteration 8250 (3.96424 iter/s, 12.6127s/50 iter), loss = 0.0512955, remaining 0 hours and 49 minutes
I0614 10:17:31.193575   290 solver.cpp:291]     Train net output #0: loss = 0.0512955 (* 1 = 0.0512955 loss)
I0614 10:17:31.193599   290 sgd_solver.cpp:106] Iteration 8250, lr = 1e-06
I0614 10:17:43.818691   290 solver.cpp:270] Iteration 8300 (3.96049 iter/s, 12.6247s/50 iter), loss = 0.0278317, remaining 0 hours and 49 minutes
I0614 10:17:43.818725   290 solver.cpp:291]     Train net output #0: loss = 0.0278317 (* 1 = 0.0278317 loss)
I0614 10:17:43.818750   290 sgd_solver.cpp:106] Iteration 8300, lr = 1e-06
I0614 10:17:56.432444   290 solver.cpp:270] Iteration 8350 (3.96407 iter/s, 12.6133s/50 iter), loss = 0.0237697, remaining 0 hours and 48 minutes
I0614 10:17:56.432502   290 solver.cpp:291]     Train net output #0: loss = 0.0237697 (* 1 = 0.0237697 loss)
I0614 10:17:56.432511   290 sgd_solver.cpp:106] Iteration 8350, lr = 1e-06
I0614 10:18:09.047271   290 solver.cpp:270] Iteration 8400 (3.96374 iter/s, 12.6144s/50 iter), loss = 0.0501832, remaining 0 hours and 48 minutes
I0614 10:18:09.047307   290 solver.cpp:291]     Train net output #0: loss = 0.0501832 (* 1 = 0.0501832 loss)
I0614 10:18:09.047315   290 sgd_solver.cpp:106] Iteration 8400, lr = 1e-06
I0614 10:18:21.662281   290 solver.cpp:270] Iteration 8450 (3.96367 iter/s, 12.6146s/50 iter), loss = 0.0480381, remaining 0 hours and 48 minutes
I0614 10:18:21.662312   290 solver.cpp:291]     Train net output #0: loss = 0.048038 (* 1 = 0.048038 loss)
I0614 10:18:21.662336   290 sgd_solver.cpp:106] Iteration 8450, lr = 1e-06
I0614 10:18:34.269990   290 solver.cpp:270] Iteration 8500 (3.96597 iter/s, 12.6073s/50 iter), loss = 0.0241324, remaining 0 hours and 48 minutes
I0614 10:18:34.270042   290 solver.cpp:291]     Train net output #0: loss = 0.0241324 (* 1 = 0.0241324 loss)
I0614 10:18:34.270052   290 sgd_solver.cpp:106] Iteration 8500, lr = 1e-06
I0614 10:18:46.884689   290 solver.cpp:270] Iteration 8550 (3.96377 iter/s, 12.6142s/50 iter), loss = 0.0339071, remaining 0 hours and 47 minutes
I0614 10:18:46.884722   290 solver.cpp:291]     Train net output #0: loss = 0.0339071 (* 1 = 0.0339071 loss)
I0614 10:18:46.884732   290 sgd_solver.cpp:106] Iteration 8550, lr = 1e-06
I0614 10:18:59.492451   290 solver.cpp:270] Iteration 8600 (3.96595 iter/s, 12.6073s/50 iter), loss = 0.0335153, remaining 0 hours and 47 minutes
I0614 10:18:59.492486   290 solver.cpp:291]     Train net output #0: loss = 0.0335153 (* 1 = 0.0335153 loss)
I0614 10:18:59.492496   290 sgd_solver.cpp:106] Iteration 8600, lr = 1e-06
I0614 10:19:12.109453   290 solver.cpp:270] Iteration 8650 (3.96305 iter/s, 12.6166s/50 iter), loss = 0.0454969, remaining 0 hours and 47 minutes
I0614 10:19:12.109501   290 solver.cpp:291]     Train net output #0: loss = 0.0454968 (* 1 = 0.0454968 loss)
I0614 10:19:12.109510   290 sgd_solver.cpp:106] Iteration 8650, lr = 1e-06
I0614 10:19:24.723527   290 solver.cpp:270] Iteration 8700 (3.96397 iter/s, 12.6136s/50 iter), loss = 0.0191024, remaining 0 hours and 47 minutes
I0614 10:19:24.723559   290 solver.cpp:291]     Train net output #0: loss = 0.0191024 (* 1 = 0.0191024 loss)
I0614 10:19:24.723568   290 sgd_solver.cpp:106] Iteration 8700, lr = 1e-06
I0614 10:19:37.342473   290 solver.cpp:270] Iteration 8750 (3.96243 iter/s, 12.6185s/50 iter), loss = 0.0529555, remaining 0 hours and 47 minutes
I0614 10:19:37.342507   290 solver.cpp:291]     Train net output #0: loss = 0.0529555 (* 1 = 0.0529555 loss)
I0614 10:19:37.342532   290 sgd_solver.cpp:106] Iteration 8750, lr = 1e-06
I0614 10:19:49.957661   290 solver.cpp:270] Iteration 8800 (3.96361 iter/s, 12.6147s/50 iter), loss = 0.0305515, remaining 0 hours and 46 minutes
I0614 10:19:49.957708   290 solver.cpp:291]     Train net output #0: loss = 0.0305515 (* 1 = 0.0305515 loss)
I0614 10:19:49.957717   290 sgd_solver.cpp:106] Iteration 8800, lr = 1e-06
I0614 10:20:02.578651   290 solver.cpp:270] Iteration 8850 (3.9618 iter/s, 12.6205s/50 iter), loss = 0.0221193, remaining 0 hours and 46 minutes
I0614 10:20:02.578684   290 solver.cpp:291]     Train net output #0: loss = 0.0221193 (* 1 = 0.0221193 loss)
I0614 10:20:02.578693   290 sgd_solver.cpp:106] Iteration 8850, lr = 1e-06
I0614 10:20:15.188943   290 solver.cpp:270] Iteration 8900 (3.96515 iter/s, 12.6099s/50 iter), loss = 0.0293535, remaining 0 hours and 46 minutes
I0614 10:20:15.188977   290 solver.cpp:291]     Train net output #0: loss = 0.0293535 (* 1 = 0.0293535 loss)
I0614 10:20:15.189002   290 sgd_solver.cpp:106] Iteration 8900, lr = 1e-06
I0614 10:20:27.793553   290 solver.cpp:270] Iteration 8950 (3.96694 iter/s, 12.6042s/50 iter), loss = 0.0163493, remaining 0 hours and 46 minutes
I0614 10:20:27.793610   290 solver.cpp:291]     Train net output #0: loss = 0.0163493 (* 1 = 0.0163493 loss)
I0614 10:20:27.793634   290 sgd_solver.cpp:106] Iteration 8950, lr = 1e-06
I0614 10:20:40.157790   290 solver.cpp:424] Iteration 9000, Testing net (#0)
I0614 10:20:41.652591   290 solver.cpp:523]     Test net output #0: accuracy = 0.9305
I0614 10:20:41.652621   290 solver.cpp:523]     Test net output #1: loss = 0.463615 (* 1 = 0.463615 loss)
I0614 10:20:41.652626   290 solver.cpp:523]     Test net output #2: top-1 = 0.9305
I0614 10:20:41.898958   290 solver.cpp:270] Iteration 9000 (3.54487 iter/s, 14.1049s/50 iter), loss = 0.0408265, remaining 0 hours and 51 minutes
I0614 10:20:41.898989   290 solver.cpp:291]     Train net output #0: loss = 0.0408264 (* 1 = 0.0408264 loss)
I0614 10:20:41.898999   290 sgd_solver.cpp:106] Iteration 9000, lr = 1e-06
I0614 10:20:54.509378   290 solver.cpp:270] Iteration 9050 (3.96511 iter/s, 12.61s/50 iter), loss = 0.0254666, remaining 0 hours and 45 minutes
I0614 10:20:54.509415   290 solver.cpp:291]     Train net output #0: loss = 0.0254665 (* 1 = 0.0254665 loss)
I0614 10:20:54.509439   290 sgd_solver.cpp:106] Iteration 9050, lr = 1e-06
I0614 10:21:07.134081   290 solver.cpp:270] Iteration 9100 (3.96063 iter/s, 12.6243s/50 iter), loss = 0.029567, remaining 0 hours and 45 minutes
I0614 10:21:07.134131   290 solver.cpp:291]     Train net output #0: loss = 0.029567 (* 1 = 0.029567 loss)
I0614 10:21:07.134156   290 sgd_solver.cpp:106] Iteration 9100, lr = 1e-06
I0614 10:21:19.739611   290 solver.cpp:270] Iteration 9150 (3.96666 iter/s, 12.6051s/50 iter), loss = 0.0173261, remaining 0 hours and 45 minutes
I0614 10:21:19.739642   290 solver.cpp:291]     Train net output #0: loss = 0.017326 (* 1 = 0.017326 loss)
I0614 10:21:19.739667   290 sgd_solver.cpp:106] Iteration 9150, lr = 1e-06
I0614 10:21:32.353504   290 solver.cpp:270] Iteration 9200 (3.96402 iter/s, 12.6135s/50 iter), loss = 0.0889566, remaining 0 hours and 45 minutes
I0614 10:21:32.353538   290 solver.cpp:291]     Train net output #0: loss = 0.0889566 (* 1 = 0.0889566 loss)
I0614 10:21:32.353561   290 sgd_solver.cpp:106] Iteration 9200, lr = 1e-06
I0614 10:21:44.959496   290 solver.cpp:270] Iteration 9250 (3.96651 iter/s, 12.6056s/50 iter), loss = 0.0415817, remaining 0 hours and 45 minutes
I0614 10:21:44.959542   290 solver.cpp:291]     Train net output #0: loss = 0.0415817 (* 1 = 0.0415817 loss)
I0614 10:21:44.959568   290 sgd_solver.cpp:106] Iteration 9250, lr = 1e-06
I0614 10:21:57.579499   290 solver.cpp:270] Iteration 9300 (3.96211 iter/s, 12.6195s/50 iter), loss = 0.0541857, remaining 0 hours and 44 minutes
I0614 10:21:57.579532   290 solver.cpp:291]     Train net output #0: loss = 0.0541856 (* 1 = 0.0541856 loss)
I0614 10:21:57.579540   290 sgd_solver.cpp:106] Iteration 9300, lr = 1e-06
I0614 10:22:10.193923   290 solver.cpp:270] Iteration 9350 (3.96386 iter/s, 12.614s/50 iter), loss = 0.0443334, remaining 0 hours and 44 minutes
I0614 10:22:10.193955   290 solver.cpp:291]     Train net output #0: loss = 0.0443334 (* 1 = 0.0443334 loss)
I0614 10:22:10.193964   290 sgd_solver.cpp:106] Iteration 9350, lr = 1e-06
I0614 10:22:22.797578   290 solver.cpp:270] Iteration 9400 (3.96724 iter/s, 12.6032s/50 iter), loss = 0.0494349, remaining 0 hours and 44 minutes
I0614 10:22:22.797626   290 solver.cpp:291]     Train net output #0: loss = 0.0494349 (* 1 = 0.0494349 loss)
I0614 10:22:22.797650   290 sgd_solver.cpp:106] Iteration 9400, lr = 1e-06
I0614 10:22:35.403394   290 solver.cpp:270] Iteration 9450 (3.96657 iter/s, 12.6054s/50 iter), loss = 0.0245951, remaining 0 hours and 44 minutes
I0614 10:22:35.403429   290 solver.cpp:291]     Train net output #0: loss = 0.0245951 (* 1 = 0.0245951 loss)
I0614 10:22:35.403438   290 sgd_solver.cpp:106] Iteration 9450, lr = 1e-06
I0614 10:22:48.012722   290 solver.cpp:270] Iteration 9500 (3.96546 iter/s, 12.6089s/50 iter), loss = 0.0490821, remaining 0 hours and 44 minutes
I0614 10:22:48.012754   290 solver.cpp:291]     Train net output #0: loss = 0.0490821 (* 1 = 0.0490821 loss)
I0614 10:22:48.012779   290 sgd_solver.cpp:106] Iteration 9500, lr = 1e-06
I0614 10:23:00.626567   290 solver.cpp:270] Iteration 9550 (3.96404 iter/s, 12.6134s/50 iter), loss = 0.0204789, remaining 0 hours and 43 minutes
I0614 10:23:00.626624   290 solver.cpp:291]     Train net output #0: loss = 0.0204788 (* 1 = 0.0204788 loss)
I0614 10:23:00.626634   290 sgd_solver.cpp:106] Iteration 9550, lr = 1e-06
I0614 10:23:13.237627   290 solver.cpp:270] Iteration 9600 (3.96492 iter/s, 12.6106s/50 iter), loss = 0.0158569, remaining 0 hours and 43 minutes
I0614 10:23:13.237660   290 solver.cpp:291]     Train net output #0: loss = 0.0158569 (* 1 = 0.0158569 loss)
I0614 10:23:13.237669   290 sgd_solver.cpp:106] Iteration 9600, lr = 1e-06
I0614 10:23:25.855648   290 solver.cpp:270] Iteration 9650 (3.96272 iter/s, 12.6176s/50 iter), loss = 0.0731047, remaining 0 hours and 43 minutes
I0614 10:23:25.855682   290 solver.cpp:291]     Train net output #0: loss = 0.0731047 (* 1 = 0.0731047 loss)
I0614 10:23:25.855692   290 sgd_solver.cpp:106] Iteration 9650, lr = 1e-06
I0614 10:23:38.463673   290 solver.cpp:270] Iteration 9700 (3.96587 iter/s, 12.6076s/50 iter), loss = 0.0506441, remaining 0 hours and 43 minutes
I0614 10:23:38.463721   290 solver.cpp:291]     Train net output #0: loss = 0.0506441 (* 1 = 0.0506441 loss)
I0614 10:23:38.463730   290 sgd_solver.cpp:106] Iteration 9700, lr = 1e-06
I0614 10:23:51.073129   290 solver.cpp:270] Iteration 9750 (3.96542 iter/s, 12.609s/50 iter), loss = 0.0363153, remaining 0 hours and 42 minutes
I0614 10:23:51.073163   290 solver.cpp:291]     Train net output #0: loss = 0.0363153 (* 1 = 0.0363153 loss)
I0614 10:23:51.073174   290 sgd_solver.cpp:106] Iteration 9750, lr = 1e-06
I0614 10:24:03.683631   290 solver.cpp:270] Iteration 9800 (3.96509 iter/s, 12.6101s/50 iter), loss = 0.0280168, remaining 0 hours and 42 minutes
I0614 10:24:03.683665   290 solver.cpp:291]     Train net output #0: loss = 0.0280167 (* 1 = 0.0280167 loss)
I0614 10:24:03.683674   290 sgd_solver.cpp:106] Iteration 9800, lr = 1e-06
I0614 10:24:16.299868   290 solver.cpp:270] Iteration 9850 (3.96329 iter/s, 12.6158s/50 iter), loss = 0.0333203, remaining 0 hours and 42 minutes
I0614 10:24:16.299917   290 solver.cpp:291]     Train net output #0: loss = 0.0333203 (* 1 = 0.0333203 loss)
I0614 10:24:16.299928   290 sgd_solver.cpp:106] Iteration 9850, lr = 1e-06
I0614 10:24:28.911468   290 solver.cpp:270] Iteration 9900 (3.96475 iter/s, 12.6111s/50 iter), loss = 0.0392669, remaining 0 hours and 42 minutes
I0614 10:24:28.911502   290 solver.cpp:291]     Train net output #0: loss = 0.0392668 (* 1 = 0.0392668 loss)
I0614 10:24:28.911512   290 sgd_solver.cpp:106] Iteration 9900, lr = 1e-06
I0614 10:24:41.514407   290 solver.cpp:270] Iteration 9950 (3.96747 iter/s, 12.6025s/50 iter), loss = 0.0257077, remaining 0 hours and 42 minutes
I0614 10:24:41.514439   290 solver.cpp:291]     Train net output #0: loss = 0.0257076 (* 1 = 0.0257076 loss)
I0614 10:24:41.514464   290 sgd_solver.cpp:106] Iteration 9950, lr = 1e-06
I0614 10:24:53.873580   290 solver.cpp:935] Snapshotting to binary proto file caffe/models/alexnetBNnoLRN/m2/snapshot_2_alexnetBNnoLRN__iter_10000.caffemodel
I0614 10:24:58.801142   290 sgd_solver.cpp:273] Snapshotting solver state to binary proto file caffe/models/alexnetBNnoLRN/m2/snapshot_2_alexnetBNnoLRN__iter_10000.solverstate
I0614 10:25:02.239243   290 solver.cpp:424] Iteration 10000, Testing net (#0)
I0614 10:25:03.672335   290 solver.cpp:523]     Test net output #0: accuracy = 0.94425
I0614 10:25:03.672367   290 solver.cpp:523]     Test net output #1: loss = 0.366615 (* 1 = 0.366615 loss)
I0614 10:25:03.672371   290 solver.cpp:523]     Test net output #2: top-1 = 0.94425
I0614 10:25:03.908186   290 solver.cpp:270] Iteration 10000 (2.23284 iter/s, 22.393s/50 iter), loss = 0.0314566, remaining 1 hours and 14 minutes
I0614 10:25:03.908218   290 solver.cpp:291]     Train net output #0: loss = 0.0314566 (* 1 = 0.0314566 loss)
I0614 10:25:03.908228   290 sgd_solver.cpp:106] Iteration 10000, lr = 1e-07
I0614 10:25:16.448681   290 solver.cpp:270] Iteration 10050 (3.98722 iter/s, 12.5401s/50 iter), loss = 0.0444908, remaining 0 hours and 41 minutes
I0614 10:25:16.448714   290 solver.cpp:291]     Train net output #0: loss = 0.0444908 (* 1 = 0.0444908 loss)
I0614 10:25:16.448737   290 sgd_solver.cpp:106] Iteration 10050, lr = 1e-07
I0614 10:25:29.029309   290 solver.cpp:270] Iteration 10100 (3.9745 iter/s, 12.5802s/50 iter), loss = 0.0364447, remaining 0 hours and 41 minutes
I0614 10:25:29.029366   290 solver.cpp:291]     Train net output #0: loss = 0.0364447 (* 1 = 0.0364447 loss)
I0614 10:25:29.029376   290 sgd_solver.cpp:106] Iteration 10100, lr = 1e-07
I0614 10:25:41.646083   290 solver.cpp:270] Iteration 10150 (3.96312 iter/s, 12.6163s/50 iter), loss = 0.0310487, remaining 0 hours and 41 minutes
I0614 10:25:41.646116   290 solver.cpp:291]     Train net output #0: loss = 0.0310486 (* 1 = 0.0310486 loss)
I0614 10:25:41.646140   290 sgd_solver.cpp:106] Iteration 10150, lr = 1e-07
I0614 10:25:54.250557   290 solver.cpp:270] Iteration 10200 (3.96698 iter/s, 12.604s/50 iter), loss = 0.0153154, remaining 0 hours and 41 minutes
I0614 10:25:54.250593   290 solver.cpp:291]     Train net output #0: loss = 0.0153153 (* 1 = 0.0153153 loss)
I0614 10:25:54.250604   290 sgd_solver.cpp:106] Iteration 10200, lr = 1e-07
I0614 10:26:06.871064   290 solver.cpp:270] Iteration 10250 (3.96195 iter/s, 12.6201s/50 iter), loss = 0.054055, remaining 0 hours and 40 minutes
I0614 10:26:06.871116   290 solver.cpp:291]     Train net output #0: loss = 0.054055 (* 1 = 0.054055 loss)
I0614 10:26:06.871142   290 sgd_solver.cpp:106] Iteration 10250, lr = 1e-07
I0614 10:26:19.493456   290 solver.cpp:270] Iteration 10300 (3.96136 iter/s, 12.6219s/50 iter), loss = 0.0189027, remaining 0 hours and 40 minutes
I0614 10:26:19.493490   290 solver.cpp:291]     Train net output #0: loss = 0.0189027 (* 1 = 0.0189027 loss)
I0614 10:26:19.493501   290 sgd_solver.cpp:106] Iteration 10300, lr = 1e-07
I0614 10:26:32.108435   290 solver.cpp:270] Iteration 10350 (3.96368 iter/s, 12.6145s/50 iter), loss = 0.0273298, remaining 0 hours and 40 minutes
I0614 10:26:32.108470   290 solver.cpp:291]     Train net output #0: loss = 0.0273297 (* 1 = 0.0273297 loss)
I0614 10:26:32.108480   290 sgd_solver.cpp:106] Iteration 10350, lr = 1e-07
I0614 10:26:44.728902   290 solver.cpp:270] Iteration 10400 (3.96196 iter/s, 12.62s/50 iter), loss = 0.0431895, remaining 0 hours and 40 minutes
I0614 10:26:44.728950   290 solver.cpp:291]     Train net output #0: loss = 0.0431895 (* 1 = 0.0431895 loss)
I0614 10:26:44.728960   290 sgd_solver.cpp:106] Iteration 10400, lr = 1e-07
I0614 10:26:57.339558   290 solver.cpp:270] Iteration 10450 (3.96504 iter/s, 12.6102s/50 iter), loss = 0.0573529, remaining 0 hours and 40 minutes
I0614 10:26:57.339591   290 solver.cpp:291]     Train net output #0: loss = 0.0573529 (* 1 = 0.0573529 loss)
I0614 10:26:57.339601   290 sgd_solver.cpp:106] Iteration 10450, lr = 1e-07
I0614 10:27:09.975914   290 solver.cpp:270] Iteration 10500 (3.95697 iter/s, 12.6359s/50 iter), loss = 0.0385754, remaining 0 hours and 39 minutes
I0614 10:27:09.975946   290 solver.cpp:291]     Train net output #0: loss = 0.0385754 (* 1 = 0.0385754 loss)
I0614 10:27:09.975957   290 sgd_solver.cpp:106] Iteration 10500, lr = 1e-07
I0614 10:27:22.611462   290 solver.cpp:270] Iteration 10550 (3.95723 iter/s, 12.6351s/50 iter), loss = 0.0634091, remaining 0 hours and 39 minutes
I0614 10:27:22.611513   290 solver.cpp:291]     Train net output #0: loss = 0.0634091 (* 1 = 0.0634091 loss)
I0614 10:27:22.611523   290 sgd_solver.cpp:106] Iteration 10550, lr = 1e-07
I0614 10:27:35.238499   290 solver.cpp:270] Iteration 10600 (3.9599 iter/s, 12.6266s/50 iter), loss = 0.0253449, remaining 0 hours and 39 minutes
I0614 10:27:35.238531   290 solver.cpp:291]     Train net output #0: loss = 0.0253449 (* 1 = 0.0253449 loss)
I0614 10:27:35.238556   290 sgd_solver.cpp:106] Iteration 10600, lr = 1e-07
I0614 10:27:47.874998   290 solver.cpp:270] Iteration 10650 (3.95693 iter/s, 12.6361s/50 iter), loss = 0.043779, remaining 0 hours and 39 minutes
I0614 10:27:47.875032   290 solver.cpp:291]     Train net output #0: loss = 0.043779 (* 1 = 0.043779 loss)
I0614 10:27:47.875057   290 sgd_solver.cpp:106] Iteration 10650, lr = 1e-07
I0614 10:28:00.499678   290 solver.cpp:270] Iteration 10700 (3.96063 iter/s, 12.6242s/50 iter), loss = 0.0308948, remaining 0 hours and 39 minutes
I0614 10:28:00.499734   290 solver.cpp:291]     Train net output #0: loss = 0.0308947 (* 1 = 0.0308947 loss)
I0614 10:28:00.499744   290 sgd_solver.cpp:106] Iteration 10700, lr = 1e-07
I0614 10:28:13.126415   290 solver.cpp:270] Iteration 10750 (3.96 iter/s, 12.6263s/50 iter), loss = 0.0256815, remaining 0 hours and 38 minutes
I0614 10:28:13.126448   290 solver.cpp:291]     Train net output #0: loss = 0.0256815 (* 1 = 0.0256815 loss)
I0614 10:28:13.126457   290 sgd_solver.cpp:106] Iteration 10750, lr = 1e-07
I0614 10:28:25.739183   290 solver.cpp:270] Iteration 10800 (3.96437 iter/s, 12.6123s/50 iter), loss = 0.0627476, remaining 0 hours and 38 minutes
I0614 10:28:25.739217   290 solver.cpp:291]     Train net output #0: loss = 0.0627476 (* 1 = 0.0627476 loss)
I0614 10:28:25.739241   290 sgd_solver.cpp:106] Iteration 10800, lr = 1e-07
I0614 10:28:38.355338   290 solver.cpp:270] Iteration 10850 (3.96331 iter/s, 12.6157s/50 iter), loss = 0.0171163, remaining 0 hours and 38 minutes
I0614 10:28:38.355386   290 solver.cpp:291]     Train net output #0: loss = 0.0171162 (* 1 = 0.0171162 loss)
I0614 10:28:38.355410   290 sgd_solver.cpp:106] Iteration 10850, lr = 1e-07
I0614 10:28:50.966620   290 solver.cpp:270] Iteration 10900 (3.96485 iter/s, 12.6108s/50 iter), loss = 0.0845947, remaining 0 hours and 38 minutes
I0614 10:28:50.966663   290 solver.cpp:291]     Train net output #0: loss = 0.0845946 (* 1 = 0.0845946 loss)
I0614 10:28:50.966688   290 sgd_solver.cpp:106] Iteration 10900, lr = 1e-07
I0614 10:29:03.583829   290 solver.cpp:270] Iteration 10950 (3.96298 iter/s, 12.6168s/50 iter), loss = 0.0558348, remaining 0 hours and 37 minutes
I0614 10:29:03.583863   290 solver.cpp:291]     Train net output #0: loss = 0.0558348 (* 1 = 0.0558348 loss)
I0614 10:29:03.583873   290 sgd_solver.cpp:106] Iteration 10950, lr = 1e-07
I0614 10:29:15.965189   290 solver.cpp:424] Iteration 11000, Testing net (#0)
I0614 10:29:17.476147   290 solver.cpp:523]     Test net output #0: accuracy = 0.951
I0614 10:29:17.476179   290 solver.cpp:523]     Test net output #1: loss = 0.258503 (* 1 = 0.258503 loss)
I0614 10:29:17.476183   290 solver.cpp:523]     Test net output #2: top-1 = 0.951
I0614 10:29:17.722899   290 solver.cpp:270] Iteration 11000 (3.53642 iter/s, 14.1386s/50 iter), loss = 0.0262959, remaining 0 hours and 42 minutes
I0614 10:29:17.722930   290 solver.cpp:291]     Train net output #0: loss = 0.0262959 (* 1 = 0.0262959 loss)
I0614 10:29:17.722940   290 sgd_solver.cpp:106] Iteration 11000, lr = 1e-07
I0614 10:29:30.337131   290 solver.cpp:270] Iteration 11050 (3.96391 iter/s, 12.6138s/50 iter), loss = 0.0323451, remaining 0 hours and 37 minutes
I0614 10:29:30.337162   290 solver.cpp:291]     Train net output #0: loss = 0.0323451 (* 1 = 0.0323451 loss)
I0614 10:29:30.337188   290 sgd_solver.cpp:106] Iteration 11050, lr = 1e-07
I0614 10:29:42.963217   290 solver.cpp:270] Iteration 11100 (3.96019 iter/s, 12.6256s/50 iter), loss = 0.0256418, remaining 0 hours and 37 minutes
I0614 10:29:42.963249   290 solver.cpp:291]     Train net output #0: loss = 0.0256418 (* 1 = 0.0256418 loss)
I0614 10:29:42.963258   290 sgd_solver.cpp:106] Iteration 11100, lr = 1e-07
I0614 10:29:55.577711   290 solver.cpp:270] Iteration 11150 (3.96383 iter/s, 12.6141s/50 iter), loss = 0.0709662, remaining 0 hours and 37 minutes
I0614 10:29:55.577761   290 solver.cpp:291]     Train net output #0: loss = 0.0709662 (* 1 = 0.0709662 loss)
I0614 10:29:55.577773   290 sgd_solver.cpp:106] Iteration 11150, lr = 1e-07
I0614 10:30:08.195849   290 solver.cpp:270] Iteration 11200 (3.96269 iter/s, 12.6177s/50 iter), loss = 0.022735, remaining 0 hours and 36 minutes
I0614 10:30:08.195883   290 solver.cpp:291]     Train net output #0: loss = 0.022735 (* 1 = 0.022735 loss)
I0614 10:30:08.195894   290 sgd_solver.cpp:106] Iteration 11200, lr = 1e-07
I0614 10:30:20.808521   290 solver.cpp:270] Iteration 11250 (3.96441 iter/s, 12.6122s/50 iter), loss = 0.0483921, remaining 0 hours and 36 minutes
I0614 10:30:20.808553   290 solver.cpp:291]     Train net output #0: loss = 0.0483921 (* 1 = 0.0483921 loss)
I0614 10:30:20.808562   290 sgd_solver.cpp:106] Iteration 11250, lr = 1e-07
I0614 10:30:33.422956   290 solver.cpp:270] Iteration 11300 (3.96385 iter/s, 12.614s/50 iter), loss = 0.0530849, remaining 0 hours and 36 minutes
I0614 10:30:33.423012   290 solver.cpp:291]     Train net output #0: loss = 0.0530848 (* 1 = 0.0530848 loss)
I0614 10:30:33.423038   290 sgd_solver.cpp:106] Iteration 11300, lr = 1e-07
I0614 10:30:46.038161   290 solver.cpp:270] Iteration 11350 (3.96362 iter/s, 12.6147s/50 iter), loss = 0.0188848, remaining 0 hours and 36 minutes
I0614 10:30:46.038197   290 solver.cpp:291]     Train net output #0: loss = 0.0188848 (* 1 = 0.0188848 loss)
I0614 10:30:46.038223   290 sgd_solver.cpp:106] Iteration 11350, lr = 1e-07
I0614 10:30:58.659317   290 solver.cpp:270] Iteration 11400 (3.96174 iter/s, 12.6207s/50 iter), loss = 0.0244599, remaining 0 hours and 36 minutes
I0614 10:30:58.659349   290 solver.cpp:291]     Train net output #0: loss = 0.0244599 (* 1 = 0.0244599 loss)
I0614 10:30:58.659373   290 sgd_solver.cpp:106] Iteration 11400, lr = 1e-07
I0614 10:31:11.268275   290 solver.cpp:270] Iteration 11450 (3.96557 iter/s, 12.6085s/50 iter), loss = 0.0156604, remaining 0 hours and 35 minutes
I0614 10:31:11.268321   290 solver.cpp:291]     Train net output #0: loss = 0.0156603 (* 1 = 0.0156603 loss)
I0614 10:31:11.268330   290 sgd_solver.cpp:106] Iteration 11450, lr = 1e-07
I0614 10:31:23.890460   290 solver.cpp:270] Iteration 11500 (3.96143 iter/s, 12.6217s/50 iter), loss = 0.0464618, remaining 0 hours and 35 minutes
I0614 10:31:23.890493   290 solver.cpp:291]     Train net output #0: loss = 0.0464617 (* 1 = 0.0464617 loss)
I0614 10:31:23.890503   290 sgd_solver.cpp:106] Iteration 11500, lr = 1e-07
I0614 10:31:36.502293   290 solver.cpp:270] Iteration 11550 (3.96467 iter/s, 12.6114s/50 iter), loss = 0.0224596, remaining 0 hours and 35 minutes
I0614 10:31:36.502326   290 solver.cpp:291]     Train net output #0: loss = 0.0224596 (* 1 = 0.0224596 loss)
I0614 10:31:36.502336   290 sgd_solver.cpp:106] Iteration 11550, lr = 1e-07
I0614 10:31:49.118041   290 solver.cpp:270] Iteration 11600 (3.96344 iter/s, 12.6153s/50 iter), loss = 0.0306089, remaining 0 hours and 35 minutes
I0614 10:31:49.118093   290 solver.cpp:291]     Train net output #0: loss = 0.0306089 (* 1 = 0.0306089 loss)
I0614 10:31:49.118103   290 sgd_solver.cpp:106] Iteration 11600, lr = 1e-07
I0614 10:32:01.733314   290 solver.cpp:270] Iteration 11650 (3.96359 iter/s, 12.6148s/50 iter), loss = 0.0487241, remaining 0 hours and 35 minutes
I0614 10:32:01.733345   290 solver.cpp:291]     Train net output #0: loss = 0.0487241 (* 1 = 0.0487241 loss)
I0614 10:32:01.733354   290 sgd_solver.cpp:106] Iteration 11650, lr = 1e-07
I0614 10:32:14.343483   290 solver.cpp:270] Iteration 11700 (3.96519 iter/s, 12.6097s/50 iter), loss = 0.0436786, remaining 0 hours and 34 minutes
I0614 10:32:14.343518   290 solver.cpp:291]     Train net output #0: loss = 0.0436786 (* 1 = 0.0436786 loss)
I0614 10:32:14.343528   290 sgd_solver.cpp:106] Iteration 11700, lr = 1e-07
I0614 10:32:26.949873   290 solver.cpp:270] Iteration 11750 (3.96638 iter/s, 12.6059s/50 iter), loss = 0.0188561, remaining 0 hours and 34 minutes
I0614 10:32:26.949923   290 solver.cpp:291]     Train net output #0: loss = 0.018856 (* 1 = 0.018856 loss)
I0614 10:32:26.949931   290 sgd_solver.cpp:106] Iteration 11750, lr = 1e-07
I0614 10:32:39.561766   290 solver.cpp:270] Iteration 11800 (3.96466 iter/s, 12.6114s/50 iter), loss = 0.0399624, remaining 0 hours and 34 minutes
I0614 10:32:39.561798   290 solver.cpp:291]     Train net output #0: loss = 0.0399624 (* 1 = 0.0399624 loss)
I0614 10:32:39.561807   290 sgd_solver.cpp:106] Iteration 11800, lr = 1e-07
I0614 10:32:52.186754   290 solver.cpp:270] Iteration 11850 (3.96054 iter/s, 12.6245s/50 iter), loss = 0.0347476, remaining 0 hours and 34 minutes
I0614 10:32:52.186789   290 solver.cpp:291]     Train net output #0: loss = 0.0347476 (* 1 = 0.0347476 loss)
I0614 10:32:52.186797   290 sgd_solver.cpp:106] Iteration 11850, lr = 1e-07
I0614 10:33:04.792891   290 solver.cpp:270] Iteration 11900 (3.96646 iter/s, 12.6057s/50 iter), loss = 0.0338437, remaining 0 hours and 34 minutes
I0614 10:33:04.792948   290 solver.cpp:291]     Train net output #0: loss = 0.0338436 (* 1 = 0.0338436 loss)
I0614 10:33:04.792958   290 sgd_solver.cpp:106] Iteration 11900, lr = 1e-07
I0614 10:33:17.405261   290 solver.cpp:270] Iteration 11950 (3.96451 iter/s, 12.6119s/50 iter), loss = 0.0514619, remaining 0 hours and 33 minutes
I0614 10:33:17.405297   290 solver.cpp:291]     Train net output #0: loss = 0.0514618 (* 1 = 0.0514618 loss)
I0614 10:33:17.405305   290 sgd_solver.cpp:106] Iteration 11950, lr = 1e-07
I0614 10:33:29.763419   290 solver.cpp:424] Iteration 12000, Testing net (#0)
I0614 10:33:31.265784   290 solver.cpp:523]     Test net output #0: accuracy = 0.95275
I0614 10:33:31.265812   290 solver.cpp:523]     Test net output #1: loss = 0.17255 (* 1 = 0.17255 loss)
I0614 10:33:31.265817   290 solver.cpp:523]     Test net output #2: top-1 = 0.95275
I0614 10:33:31.513036   290 solver.cpp:270] Iteration 12000 (3.54427 iter/s, 14.1073s/50 iter), loss = 0.0532086, remaining 0 hours and 37 minutes
I0614 10:33:31.513065   290 solver.cpp:291]     Train net output #0: loss = 0.0532086 (* 1 = 0.0532086 loss)
I0614 10:33:31.513089   290 sgd_solver.cpp:106] Iteration 12000, lr = 1e-07
I0614 10:33:44.139240   290 solver.cpp:270] Iteration 12050 (3.96016 iter/s, 12.6258s/50 iter), loss = 0.0195288, remaining 0 hours and 33 minutes
I0614 10:33:44.139289   290 solver.cpp:291]     Train net output #0: loss = 0.0195288 (* 1 = 0.0195288 loss)
I0614 10:33:44.139299   290 sgd_solver.cpp:106] Iteration 12050, lr = 1e-07
I0614 10:33:56.752121   290 solver.cpp:270] Iteration 12100 (3.96434 iter/s, 12.6124s/50 iter), loss = 0.0387486, remaining 0 hours and 33 minutes
I0614 10:33:56.752156   290 solver.cpp:291]     Train net output #0: loss = 0.0387486 (* 1 = 0.0387486 loss)
I0614 10:33:56.752166   290 sgd_solver.cpp:106] Iteration 12100, lr = 1e-07
I0614 10:34:09.376710   290 solver.cpp:270] Iteration 12150 (3.96066 iter/s, 12.6241s/50 iter), loss = 0.043989, remaining 0 hours and 32 minutes
I0614 10:34:09.376744   290 solver.cpp:291]     Train net output #0: loss = 0.0439889 (* 1 = 0.0439889 loss)
I0614 10:34:09.376767   290 sgd_solver.cpp:106] Iteration 12150, lr = 1e-07
I0614 10:34:21.981350   290 solver.cpp:270] Iteration 12200 (3.96693 iter/s, 12.6042s/50 iter), loss = 0.0527552, remaining 0 hours and 32 minutes
I0614 10:34:21.981402   290 solver.cpp:291]     Train net output #0: loss = 0.0527551 (* 1 = 0.0527551 loss)
I0614 10:34:21.981412   290 sgd_solver.cpp:106] Iteration 12200, lr = 1e-07
I0614 10:34:34.588563   290 solver.cpp:270] Iteration 12250 (3.96613 iter/s, 12.6068s/50 iter), loss = 0.0226475, remaining 0 hours and 32 minutes
I0614 10:34:34.588596   290 solver.cpp:291]     Train net output #0: loss = 0.0226475 (* 1 = 0.0226475 loss)
I0614 10:34:34.588621   290 sgd_solver.cpp:106] Iteration 12250, lr = 1e-07
I0614 10:34:47.214550   290 solver.cpp:270] Iteration 12300 (3.96023 iter/s, 12.6255s/50 iter), loss = 0.036579, remaining 0 hours and 32 minutes
I0614 10:34:47.214581   290 solver.cpp:291]     Train net output #0: loss = 0.036579 (* 1 = 0.036579 loss)
I0614 10:34:47.214604   290 sgd_solver.cpp:106] Iteration 12300, lr = 1e-07
I0614 10:34:59.828431   290 solver.cpp:270] Iteration 12350 (3.96403 iter/s, 12.6134s/50 iter), loss = 0.0232578, remaining 0 hours and 32 minutes
I0614 10:34:59.828487   290 solver.cpp:291]     Train net output #0: loss = 0.0232577 (* 1 = 0.0232577 loss)
I0614 10:34:59.828497   290 sgd_solver.cpp:106] Iteration 12350, lr = 1e-07
I0614 10:35:12.437784   290 solver.cpp:270] Iteration 12400 (3.96546 iter/s, 12.6089s/50 iter), loss = 0.0527202, remaining 0 hours and 31 minutes
I0614 10:35:12.437816   290 solver.cpp:291]     Train net output #0: loss = 0.0527202 (* 1 = 0.0527202 loss)
I0614 10:35:12.437825   290 sgd_solver.cpp:106] Iteration 12400, lr = 1e-07
I0614 10:35:25.043041   290 solver.cpp:270] Iteration 12450 (3.96674 iter/s, 12.6048s/50 iter), loss = 0.0247821, remaining 0 hours and 31 minutes
I0614 10:35:25.043074   290 solver.cpp:291]     Train net output #0: loss = 0.0247821 (* 1 = 0.0247821 loss)
I0614 10:35:25.043099   290 sgd_solver.cpp:106] Iteration 12450, lr = 1e-07
I0614 10:35:37.649013   290 solver.cpp:270] Iteration 12500 (3.96651 iter/s, 12.6055s/50 iter), loss = 0.0378734, remaining 0 hours and 31 minutes
I0614 10:35:37.649058   290 solver.cpp:291]     Train net output #0: loss = 0.0378733 (* 1 = 0.0378733 loss)
I0614 10:35:37.649083   290 sgd_solver.cpp:106] Iteration 12500, lr = 1e-08
I0614 10:35:50.267798   290 solver.cpp:270] Iteration 12550 (3.96249 iter/s, 12.6183s/50 iter), loss = 0.0620707, remaining 0 hours and 31 minutes
I0614 10:35:50.267834   290 solver.cpp:291]     Train net output #0: loss = 0.0620707 (* 1 = 0.0620707 loss)
I0614 10:35:50.267843   290 sgd_solver.cpp:106] Iteration 12550, lr = 1e-08
I0614 10:36:02.880779   290 solver.cpp:270] Iteration 12600 (3.96431 iter/s, 12.6125s/50 iter), loss = 0.0247721, remaining 0 hours and 31 minutes
I0614 10:36:02.880815   290 solver.cpp:291]     Train net output #0: loss = 0.0247721 (* 1 = 0.0247721 loss)
I0614 10:36:02.880825   290 sgd_solver.cpp:106] Iteration 12600, lr = 1e-08
I0614 10:36:15.496124   290 solver.cpp:270] Iteration 12650 (3.96357 iter/s, 12.6149s/50 iter), loss = 0.0319538, remaining 0 hours and 30 minutes
I0614 10:36:15.496173   290 solver.cpp:291]     Train net output #0: loss = 0.0319538 (* 1 = 0.0319538 loss)
I0614 10:36:15.496198   290 sgd_solver.cpp:106] Iteration 12650, lr = 1e-08
I0614 10:36:28.116254   290 solver.cpp:270] Iteration 12700 (3.96207 iter/s, 12.6197s/50 iter), loss = 0.019537, remaining 0 hours and 30 minutes
I0614 10:36:28.116287   290 solver.cpp:291]     Train net output #0: loss = 0.019537 (* 1 = 0.019537 loss)
I0614 10:36:28.116295   290 sgd_solver.cpp:106] Iteration 12700, lr = 1e-08
I0614 10:36:40.728721   290 solver.cpp:270] Iteration 12750 (3.96447 iter/s, 12.612s/50 iter), loss = 0.0395586, remaining 0 hours and 30 minutes
I0614 10:36:40.728754   290 solver.cpp:291]     Train net output #0: loss = 0.0395585 (* 1 = 0.0395585 loss)
I0614 10:36:40.728780   290 sgd_solver.cpp:106] Iteration 12750, lr = 1e-08
I0614 10:36:53.339098   290 solver.cpp:270] Iteration 12800 (3.96513 iter/s, 12.6099s/50 iter), loss = 0.0203021, remaining 0 hours and 30 minutes
I0614 10:36:53.339145   290 solver.cpp:291]     Train net output #0: loss = 0.0203021 (* 1 = 0.0203021 loss)
I0614 10:36:53.339154   290 sgd_solver.cpp:106] Iteration 12800, lr = 1e-08
I0614 10:37:05.952126   290 solver.cpp:270] Iteration 12850 (3.9643 iter/s, 12.6126s/50 iter), loss = 0.0166319, remaining 0 hours and 30 minutes
I0614 10:37:05.952160   290 solver.cpp:291]     Train net output #0: loss = 0.0166319 (* 1 = 0.0166319 loss)
I0614 10:37:05.952185   290 sgd_solver.cpp:106] Iteration 12850, lr = 1e-08
I0614 10:37:18.562067   290 solver.cpp:270] Iteration 12900 (3.96526 iter/s, 12.6095s/50 iter), loss = 0.043477, remaining 0 hours and 29 minutes
I0614 10:37:18.562099   290 solver.cpp:291]     Train net output #0: loss = 0.043477 (* 1 = 0.043477 loss)
I0614 10:37:18.562124   290 sgd_solver.cpp:106] Iteration 12900, lr = 1e-08
I0614 10:37:31.169700   290 solver.cpp:270] Iteration 12950 (3.96599 iter/s, 12.6072s/50 iter), loss = 0.0599303, remaining 0 hours and 29 minutes
I0614 10:37:31.169747   290 solver.cpp:291]     Train net output #0: loss = 0.0599303 (* 1 = 0.0599303 loss)
I0614 10:37:31.169773   290 sgd_solver.cpp:106] Iteration 12950, lr = 1e-08
I0614 10:37:43.529301   290 solver.cpp:424] Iteration 13000, Testing net (#0)
I0614 10:37:45.037171   290 solver.cpp:523]     Test net output #0: accuracy = 0.95425
I0614 10:37:45.037202   290 solver.cpp:523]     Test net output #1: loss = 0.129707 (* 1 = 0.129707 loss)
I0614 10:37:45.037207   290 solver.cpp:523]     Test net output #2: top-1 = 0.95425
I0614 10:37:45.283993   290 solver.cpp:270] Iteration 13000 (3.54263 iter/s, 14.1138s/50 iter), loss = 0.0392155, remaining 0 hours and 32 minutes
I0614 10:37:45.284025   290 solver.cpp:291]     Train net output #0: loss = 0.0392155 (* 1 = 0.0392155 loss)
I0614 10:37:45.284050   290 sgd_solver.cpp:106] Iteration 13000, lr = 1e-08
I0614 10:37:57.891604   290 solver.cpp:270] Iteration 13050 (3.966 iter/s, 12.6072s/50 iter), loss = 0.0481768, remaining 0 hours and 28 minutes
I0614 10:37:57.891638   290 solver.cpp:291]     Train net output #0: loss = 0.0481768 (* 1 = 0.0481768 loss)
I0614 10:37:57.891649   290 sgd_solver.cpp:106] Iteration 13050, lr = 1e-08
I0614 10:38:10.498518   290 solver.cpp:270] Iteration 13100 (3.96622 iter/s, 12.6065s/50 iter), loss = 0.0187296, remaining 0 hours and 28 minutes
I0614 10:38:10.498577   290 solver.cpp:291]     Train net output #0: loss = 0.0187296 (* 1 = 0.0187296 loss)
I0614 10:38:10.498602   290 sgd_solver.cpp:106] Iteration 13100, lr = 1e-08
I0614 10:38:23.120733   290 solver.cpp:270] Iteration 13150 (3.96142 iter/s, 12.6217s/50 iter), loss = 0.050485, remaining 0 hours and 28 minutes
I0614 10:38:23.120767   290 solver.cpp:291]     Train net output #0: loss = 0.050485 (* 1 = 0.050485 loss)
I0614 10:38:23.120776   290 sgd_solver.cpp:106] Iteration 13150, lr = 1e-08
I0614 10:38:35.745000   290 solver.cpp:270] Iteration 13200 (3.96076 iter/s, 12.6238s/50 iter), loss = 0.0347848, remaining 0 hours and 28 minutes
I0614 10:38:35.745033   290 solver.cpp:291]     Train net output #0: loss = 0.0347848 (* 1 = 0.0347848 loss)
I0614 10:38:35.745059   290 sgd_solver.cpp:106] Iteration 13200, lr = 1e-08
I0614 10:38:48.359143   290 solver.cpp:270] Iteration 13250 (3.96394 iter/s, 12.6137s/50 iter), loss = 0.0243251, remaining 0 hours and 28 minutes
I0614 10:38:48.359189   290 solver.cpp:291]     Train net output #0: loss = 0.0243251 (* 1 = 0.0243251 loss)
I0614 10:38:48.359213   290 sgd_solver.cpp:106] Iteration 13250, lr = 1e-08
I0614 10:39:00.978273   290 solver.cpp:270] Iteration 13300 (3.96238 iter/s, 12.6187s/50 iter), loss = 0.0286295, remaining 0 hours and 28 minutes
I0614 10:39:00.978307   290 solver.cpp:291]     Train net output #0: loss = 0.0286295 (* 1 = 0.0286295 loss)
I0614 10:39:00.978317   290 sgd_solver.cpp:106] Iteration 13300, lr = 1e-08
I0614 10:39:13.575368   290 solver.cpp:270] Iteration 13350 (3.96931 iter/s, 12.5967s/50 iter), loss = 0.010687, remaining 0 hours and 27 minutes
I0614 10:39:13.575399   290 solver.cpp:291]     Train net output #0: loss = 0.010687 (* 1 = 0.010687 loss)
I0614 10:39:13.575408   290 sgd_solver.cpp:106] Iteration 13350, lr = 1e-08
I0614 10:39:26.188395   290 solver.cpp:270] Iteration 13400 (3.96429 iter/s, 12.6126s/50 iter), loss = 0.028626, remaining 0 hours and 27 minutes
I0614 10:39:26.188444   290 solver.cpp:291]     Train net output #0: loss = 0.028626 (* 1 = 0.028626 loss)
I0614 10:39:26.188469   290 sgd_solver.cpp:106] Iteration 13400, lr = 1e-08
I0614 10:39:38.801267   290 solver.cpp:270] Iteration 13450 (3.96435 iter/s, 12.6124s/50 iter), loss = 0.039758, remaining 0 hours and 27 minutes
I0614 10:39:38.801299   290 solver.cpp:291]     Train net output #0: loss = 0.039758 (* 1 = 0.039758 loss)
I0614 10:39:38.801311   290 sgd_solver.cpp:106] Iteration 13450, lr = 1e-08
I0614 10:39:51.413866   290 solver.cpp:270] Iteration 13500 (3.96443 iter/s, 12.6122s/50 iter), loss = 0.0298984, remaining 0 hours and 27 minutes
I0614 10:39:51.413900   290 solver.cpp:291]     Train net output #0: loss = 0.0298984 (* 1 = 0.0298984 loss)
I0614 10:39:51.413926   290 sgd_solver.cpp:106] Iteration 13500, lr = 1e-08
I0614 10:40:04.033421   290 solver.cpp:270] Iteration 13550 (3.96224 iter/s, 12.6191s/50 iter), loss = 0.0344466, remaining 0 hours and 27 minutes
I0614 10:40:04.033475   290 solver.cpp:291]     Train net output #0: loss = 0.0344466 (* 1 = 0.0344466 loss)
I0614 10:40:04.033500   290 sgd_solver.cpp:106] Iteration 13550, lr = 1e-08
I0614 10:40:16.652359   290 solver.cpp:270] Iteration 13600 (3.96244 iter/s, 12.6185s/50 iter), loss = 0.0476611, remaining 0 hours and 26 minutes
I0614 10:40:16.652391   290 solver.cpp:291]     Train net output #0: loss = 0.0476611 (* 1 = 0.0476611 loss)
I0614 10:40:16.652416   290 sgd_solver.cpp:106] Iteration 13600, lr = 1e-08
I0614 10:40:29.265285   290 solver.cpp:270] Iteration 13650 (3.96433 iter/s, 12.6125s/50 iter), loss = 0.0635228, remaining 0 hours and 26 minutes
I0614 10:40:29.265318   290 solver.cpp:291]     Train net output #0: loss = 0.0635228 (* 1 = 0.0635228 loss)
I0614 10:40:29.265328   290 sgd_solver.cpp:106] Iteration 13650, lr = 1e-08
I0614 10:40:41.879734   290 solver.cpp:270] Iteration 13700 (3.96385 iter/s, 12.614s/50 iter), loss = 0.0322789, remaining 0 hours and 26 minutes
I0614 10:40:41.879796   290 solver.cpp:291]     Train net output #0: loss = 0.0322789 (* 1 = 0.0322789 loss)
I0614 10:40:41.879806   290 sgd_solver.cpp:106] Iteration 13700, lr = 1e-08
I0614 10:40:54.497205   290 solver.cpp:270] Iteration 13750 (3.9629 iter/s, 12.617s/50 iter), loss = 0.0555496, remaining 0 hours and 26 minutes
I0614 10:40:54.497238   290 solver.cpp:291]     Train net output #0: loss = 0.0555496 (* 1 = 0.0555496 loss)
I0614 10:40:54.497249   290 sgd_solver.cpp:106] Iteration 13750, lr = 1e-08
I0614 10:41:07.118113   290 solver.cpp:270] Iteration 13800 (3.96182 iter/s, 12.6205s/50 iter), loss = 0.0521436, remaining 0 hours and 25 minutes
I0614 10:41:07.118145   290 solver.cpp:291]     Train net output #0: loss = 0.0521436 (* 1 = 0.0521436 loss)
I0614 10:41:07.118155   290 sgd_solver.cpp:106] Iteration 13800, lr = 1e-08
I0614 10:41:19.724408   290 solver.cpp:270] Iteration 13850 (3.96641 iter/s, 12.6059s/50 iter), loss = 0.0274764, remaining 0 hours and 25 minutes
I0614 10:41:19.724454   290 solver.cpp:291]     Train net output #0: loss = 0.0274764 (* 1 = 0.0274764 loss)
I0614 10:41:19.724479   290 sgd_solver.cpp:106] Iteration 13850, lr = 1e-08
I0614 10:41:32.342694   290 solver.cpp:270] Iteration 13900 (3.96265 iter/s, 12.6178s/50 iter), loss = 0.0134587, remaining 0 hours and 25 minutes
I0614 10:41:32.342726   290 solver.cpp:291]     Train net output #0: loss = 0.0134587 (* 1 = 0.0134587 loss)
I0614 10:41:32.342751   290 sgd_solver.cpp:106] Iteration 13900, lr = 1e-08
I0614 10:41:44.946601   290 solver.cpp:270] Iteration 13950 (3.96716 iter/s, 12.6035s/50 iter), loss = 0.0152533, remaining 0 hours and 25 minutes
I0614 10:41:44.946632   290 solver.cpp:291]     Train net output #0: loss = 0.0152533 (* 1 = 0.0152533 loss)
I0614 10:41:44.946657   290 sgd_solver.cpp:106] Iteration 13950, lr = 1e-08
I0614 10:41:57.313369   290 solver.cpp:424] Iteration 14000, Testing net (#0)
I0614 10:41:58.807958   290 solver.cpp:523]     Test net output #0: accuracy = 0.9535
I0614 10:41:58.807992   290 solver.cpp:523]     Test net output #1: loss = 0.122223 (* 1 = 0.122223 loss)
I0614 10:41:58.807997   290 solver.cpp:523]     Test net output #2: top-1 = 0.9535
I0614 10:41:59.055003   290 solver.cpp:270] Iteration 14000 (3.54411 iter/s, 14.1079s/50 iter), loss = 0.0453938, remaining 0 hours and 28 minutes
I0614 10:41:59.055034   290 solver.cpp:291]     Train net output #0: loss = 0.0453938 (* 1 = 0.0453938 loss)
I0614 10:41:59.055059   290 sgd_solver.cpp:106] Iteration 14000, lr = 1e-08
I0614 10:42:11.682971   290 solver.cpp:270] Iteration 14050 (3.9596 iter/s, 12.6275s/50 iter), loss = 0.0160909, remaining 0 hours and 25 minutes
I0614 10:42:11.683003   290 solver.cpp:291]     Train net output #0: loss = 0.016091 (* 1 = 0.016091 loss)
I0614 10:42:11.683028   290 sgd_solver.cpp:106] Iteration 14050, lr = 1e-08
I0614 10:42:24.293100   290 solver.cpp:270] Iteration 14100 (3.9652 iter/s, 12.6097s/50 iter), loss = 0.0384818, remaining 0 hours and 24 minutes
I0614 10:42:24.293134   290 solver.cpp:291]     Train net output #0: loss = 0.0384818 (* 1 = 0.0384818 loss)
I0614 10:42:24.293143   290 sgd_solver.cpp:106] Iteration 14100, lr = 1e-08
I0614 10:42:36.910277   290 solver.cpp:270] Iteration 14150 (3.96299 iter/s, 12.6167s/50 iter), loss = 0.0290638, remaining 0 hours and 24 minutes
I0614 10:42:36.910329   290 solver.cpp:291]     Train net output #0: loss = 0.0290638 (* 1 = 0.0290638 loss)
I0614 10:42:36.910354   290 sgd_solver.cpp:106] Iteration 14150, lr = 1e-08
I0614 10:42:49.528188   290 solver.cpp:270] Iteration 14200 (3.96276 iter/s, 12.6175s/50 iter), loss = 0.0569436, remaining 0 hours and 24 minutes
I0614 10:42:49.528220   290 solver.cpp:291]     Train net output #0: loss = 0.0569437 (* 1 = 0.0569437 loss)
I0614 10:42:49.528229   290 sgd_solver.cpp:106] Iteration 14200, lr = 1e-08
I0614 10:43:02.135674   290 solver.cpp:270] Iteration 14250 (3.96604 iter/s, 12.607s/50 iter), loss = 0.0441602, remaining 0 hours and 23 minutes
I0614 10:43:02.135707   290 solver.cpp:291]     Train net output #0: loss = 0.0441602 (* 1 = 0.0441602 loss)
I0614 10:43:02.135732   290 sgd_solver.cpp:106] Iteration 14250, lr = 1e-08
I0614 10:43:14.756675   290 solver.cpp:270] Iteration 14300 (3.96179 iter/s, 12.6206s/50 iter), loss = 0.0340637, remaining 0 hours and 23 minutes
I0614 10:43:14.756737   290 solver.cpp:291]     Train net output #0: loss = 0.0340637 (* 1 = 0.0340637 loss)
I0614 10:43:14.756747   290 sgd_solver.cpp:106] Iteration 14300, lr = 1e-08
I0614 10:43:27.370839   290 solver.cpp:270] Iteration 14350 (3.96394 iter/s, 12.6137s/50 iter), loss = 0.0355245, remaining 0 hours and 23 minutes
I0614 10:43:27.370872   290 solver.cpp:291]     Train net output #0: loss = 0.0355245 (* 1 = 0.0355245 loss)
I0614 10:43:27.370883   290 sgd_solver.cpp:106] Iteration 14350, lr = 1e-08
I0614 10:43:39.990005   290 solver.cpp:270] Iteration 14400 (3.96237 iter/s, 12.6187s/50 iter), loss = 0.0302619, remaining 0 hours and 23 minutes
I0614 10:43:39.990037   290 solver.cpp:291]     Train net output #0: loss = 0.0302619 (* 1 = 0.0302619 loss)
I0614 10:43:39.990048   290 sgd_solver.cpp:106] Iteration 14400, lr = 1e-08
I0614 10:43:52.597921   290 solver.cpp:270] Iteration 14450 (3.9659 iter/s, 12.6075s/50 iter), loss = 0.0399122, remaining 0 hours and 23 minutes
I0614 10:43:52.597970   290 solver.cpp:291]     Train net output #0: loss = 0.0399122 (* 1 = 0.0399122 loss)
I0614 10:43:52.597996   290 sgd_solver.cpp:106] Iteration 14450, lr = 1e-08
I0614 10:44:05.207223   290 solver.cpp:270] Iteration 14500 (3.96547 iter/s, 12.6088s/50 iter), loss = 0.0371053, remaining 0 hours and 22 minutes
I0614 10:44:05.207257   290 solver.cpp:291]     Train net output #0: loss = 0.0371053 (* 1 = 0.0371053 loss)
I0614 10:44:05.207265   290 sgd_solver.cpp:106] Iteration 14500, lr = 1e-08
I0614 10:44:17.826084   290 solver.cpp:270] Iteration 14550 (3.96246 iter/s, 12.6184s/50 iter), loss = 0.0509227, remaining 0 hours and 22 minutes
I0614 10:44:17.826115   290 solver.cpp:291]     Train net output #0: loss = 0.0509228 (* 1 = 0.0509228 loss)
I0614 10:44:17.826140   290 sgd_solver.cpp:106] Iteration 14550, lr = 1e-08
I0614 10:44:30.428459   290 solver.cpp:270] Iteration 14600 (3.96764 iter/s, 12.6019s/50 iter), loss = 0.0173096, remaining 0 hours and 22 minutes
I0614 10:44:30.428508   290 solver.cpp:291]     Train net output #0: loss = 0.0173096 (* 1 = 0.0173096 loss)
I0614 10:44:30.428517   290 sgd_solver.cpp:106] Iteration 14600, lr = 1e-08
I0614 10:44:43.033432   290 solver.cpp:270] Iteration 14650 (3.96683 iter/s, 12.6045s/50 iter), loss = 0.0363185, remaining 0 hours and 22 minutes
I0614 10:44:43.033463   290 solver.cpp:291]     Train net output #0: loss = 0.0363185 (* 1 = 0.0363185 loss)
I0614 10:44:43.033488   290 sgd_solver.cpp:106] Iteration 14650, lr = 1e-08
I0614 10:44:55.654675   290 solver.cpp:270] Iteration 14700 (3.96171 iter/s, 12.6208s/50 iter), loss = 0.0397545, remaining 0 hours and 22 minutes
I0614 10:44:55.654706   290 solver.cpp:291]     Train net output #0: loss = 0.0397545 (* 1 = 0.0397545 loss)
I0614 10:44:55.654731   290 sgd_solver.cpp:106] Iteration 14700, lr = 1e-08
I0614 10:45:08.284641   290 solver.cpp:270] Iteration 14750 (3.95898 iter/s, 12.6295s/50 iter), loss = 0.0290107, remaining 0 hours and 21 minutes
I0614 10:45:08.284695   290 solver.cpp:291]     Train net output #0: loss = 0.0290108 (* 1 = 0.0290108 loss)
I0614 10:45:08.284720   290 sgd_solver.cpp:106] Iteration 14750, lr = 1e-08
I0614 10:45:20.911828   290 solver.cpp:270] Iteration 14800 (3.95986 iter/s, 12.6267s/50 iter), loss = 0.0208533, remaining 0 hours and 21 minutes
I0614 10:45:20.911860   290 solver.cpp:291]     Train net output #0: loss = 0.0208533 (* 1 = 0.0208533 loss)
I0614 10:45:20.911870   290 sgd_solver.cpp:106] Iteration 14800, lr = 1e-08
I0614 10:45:33.529609   290 solver.cpp:270] Iteration 14850 (3.9628 iter/s, 12.6173s/50 iter), loss = 0.0317902, remaining 0 hours and 21 minutes
I0614 10:45:33.529642   290 solver.cpp:291]     Train net output #0: loss = 0.0317902 (* 1 = 0.0317902 loss)
I0614 10:45:33.529650   290 sgd_solver.cpp:106] Iteration 14850, lr = 1e-08
I0614 10:45:46.156780   290 solver.cpp:270] Iteration 14900 (3.95985 iter/s, 12.6267s/50 iter), loss = 0.0502471, remaining 0 hours and 21 minutes
I0614 10:45:46.156826   290 solver.cpp:291]     Train net output #0: loss = 0.0502471 (* 1 = 0.0502471 loss)
I0614 10:45:46.156836   290 sgd_solver.cpp:106] Iteration 14900, lr = 1e-08
I0614 10:45:58.769589   290 solver.cpp:270] Iteration 14950 (3.96437 iter/s, 12.6124s/50 iter), loss = 0.021341, remaining 0 hours and 21 minutes
I0614 10:45:58.769623   290 solver.cpp:291]     Train net output #0: loss = 0.0213411 (* 1 = 0.0213411 loss)
I0614 10:45:58.769632   290 sgd_solver.cpp:106] Iteration 14950, lr = 1e-08
I0614 10:46:11.125300   290 solver.cpp:935] Snapshotting to binary proto file caffe/models/alexnetBNnoLRN/m2/snapshot_2_alexnetBNnoLRN__iter_15000.caffemodel
I0614 10:46:15.595170   290 sgd_solver.cpp:273] Snapshotting solver state to binary proto file caffe/models/alexnetBNnoLRN/m2/snapshot_2_alexnetBNnoLRN__iter_15000.solverstate
I0614 10:46:19.289743   290 solver.cpp:424] Iteration 15000, Testing net (#0)
I0614 10:46:20.719224   290 solver.cpp:523]     Test net output #0: accuracy = 0.954
I0614 10:46:20.719255   290 solver.cpp:523]     Test net output #1: loss = 0.130263 (* 1 = 0.130263 loss)
I0614 10:46:20.719260   290 solver.cpp:523]     Test net output #2: top-1 = 0.954
I0614 10:46:20.954636   290 solver.cpp:270] Iteration 15000 (2.25385 iter/s, 22.1843s/50 iter), loss = 0.0584513, remaining 0 hours and 36 minutes
I0614 10:46:20.954669   290 solver.cpp:291]     Train net output #0: loss = 0.0584513 (* 1 = 0.0584513 loss)
I0614 10:46:20.954694   290 sgd_solver.cpp:106] Iteration 15000, lr = 1e-09
I0614 10:46:33.498989   290 solver.cpp:270] Iteration 15050 (3.986 iter/s, 12.5439s/50 iter), loss = 0.0397301, remaining 0 hours and 20 minutes
I0614 10:46:33.499022   290 solver.cpp:291]     Train net output #0: loss = 0.0397301 (* 1 = 0.0397301 loss)
I0614 10:46:33.499047   290 sgd_solver.cpp:106] Iteration 15050, lr = 1e-09
I0614 10:46:46.084287   290 solver.cpp:270] Iteration 15100 (3.97303 iter/s, 12.5849s/50 iter), loss = 0.0427798, remaining 0 hours and 20 minutes
I0614 10:46:46.084322   290 solver.cpp:291]     Train net output #0: loss = 0.0427799 (* 1 = 0.0427799 loss)
I0614 10:46:46.084347   290 sgd_solver.cpp:106] Iteration 15100, lr = 1e-09
I0614 10:46:58.682700   290 solver.cpp:270] Iteration 15150 (3.96889 iter/s, 12.598s/50 iter), loss = 0.0230493, remaining 0 hours and 20 minutes
I0614 10:46:58.682750   290 solver.cpp:291]     Train net output #0: loss = 0.0230494 (* 1 = 0.0230494 loss)
I0614 10:46:58.682760   290 sgd_solver.cpp:106] Iteration 15150, lr = 1e-09
I0614 10:47:11.307538   290 solver.cpp:270] Iteration 15200 (3.96059 iter/s, 12.6244s/50 iter), loss = 0.0112882, remaining 0 hours and 20 minutes
I0614 10:47:11.307571   290 solver.cpp:291]     Train net output #0: loss = 0.0112883 (* 1 = 0.0112883 loss)
I0614 10:47:11.307581   290 sgd_solver.cpp:106] Iteration 15200, lr = 1e-09
I0614 10:47:23.908733   290 solver.cpp:270] Iteration 15250 (3.96802 iter/s, 12.6008s/50 iter), loss = 0.028322, remaining 0 hours and 19 minutes
I0614 10:47:23.908767   290 solver.cpp:291]     Train net output #0: loss = 0.028322 (* 1 = 0.028322 loss)
I0614 10:47:23.908792   290 sgd_solver.cpp:106] Iteration 15250, lr = 1e-09
I0614 10:47:36.530800   290 solver.cpp:270] Iteration 15300 (3.96146 iter/s, 12.6216s/50 iter), loss = 0.0221405, remaining 0 hours and 19 minutes
I0614 10:47:36.530859   290 solver.cpp:291]     Train net output #0: loss = 0.0221405 (* 1 = 0.0221405 loss)
I0614 10:47:36.530869   290 sgd_solver.cpp:106] Iteration 15300, lr = 1e-09
I0614 10:47:49.137445   290 solver.cpp:270] Iteration 15350 (3.96631 iter/s, 12.6062s/50 iter), loss = 0.0182605, remaining 0 hours and 19 minutes
I0614 10:47:49.137480   290 solver.cpp:291]     Train net output #0: loss = 0.0182606 (* 1 = 0.0182606 loss)
I0614 10:47:49.137488   290 sgd_solver.cpp:106] Iteration 15350, lr = 1e-09
I0614 10:48:01.766589   290 solver.cpp:270] Iteration 15400 (3.95924 iter/s, 12.6287s/50 iter), loss = 0.0442019, remaining 0 hours and 19 minutes
I0614 10:48:01.766624   290 solver.cpp:291]     Train net output #0: loss = 0.044202 (* 1 = 0.044202 loss)
I0614 10:48:01.766633   290 sgd_solver.cpp:106] Iteration 15400, lr = 1e-09
I0614 10:48:14.398686   290 solver.cpp:270] Iteration 15450 (3.95831 iter/s, 12.6317s/50 iter), loss = 0.0671162, remaining 0 hours and 18 minutes
I0614 10:48:14.398737   290 solver.cpp:291]     Train net output #0: loss = 0.0671163 (* 1 = 0.0671163 loss)
I0614 10:48:14.398746   290 sgd_solver.cpp:106] Iteration 15450, lr = 1e-09
I0614 10:48:27.041568   290 solver.cpp:270] Iteration 15500 (3.95494 iter/s, 12.6424s/50 iter), loss = 0.0333611, remaining 0 hours and 18 minutes
I0614 10:48:27.041600   290 solver.cpp:291]     Train net output #0: loss = 0.0333611 (* 1 = 0.0333611 loss)
I0614 10:48:27.041610   290 sgd_solver.cpp:106] Iteration 15500, lr = 1e-09
I0614 10:48:39.672384   290 solver.cpp:270] Iteration 15550 (3.95871 iter/s, 12.6304s/50 iter), loss = 0.0394243, remaining 0 hours and 18 minutes
I0614 10:48:39.672420   290 solver.cpp:291]     Train net output #0: loss = 0.0394244 (* 1 = 0.0394244 loss)
I0614 10:48:39.672446   290 sgd_solver.cpp:106] Iteration 15550, lr = 1e-09
I0614 10:48:52.318323   290 solver.cpp:270] Iteration 15600 (3.95398 iter/s, 12.6455s/50 iter), loss = 0.0160394, remaining 0 hours and 18 minutes
I0614 10:48:52.318372   290 solver.cpp:291]     Train net output #0: loss = 0.0160394 (* 1 = 0.0160394 loss)
I0614 10:48:52.318382   290 sgd_solver.cpp:106] Iteration 15600, lr = 1e-09
I0614 10:49:04.933596   290 solver.cpp:270] Iteration 15650 (3.96359 iter/s, 12.6148s/50 iter), loss = 0.0273541, remaining 0 hours and 18 minutes
I0614 10:49:04.933630   290 solver.cpp:291]     Train net output #0: loss = 0.0273541 (* 1 = 0.0273541 loss)
I0614 10:49:04.933655   290 sgd_solver.cpp:106] Iteration 15650, lr = 1e-09
I0614 10:49:17.551688   290 solver.cpp:270] Iteration 15700 (3.9627 iter/s, 12.6177s/50 iter), loss = 0.0433011, remaining 0 hours and 17 minutes
I0614 10:49:17.551721   290 solver.cpp:291]     Train net output #0: loss = 0.0433011 (* 1 = 0.0433011 loss)
I0614 10:49:17.551745   290 sgd_solver.cpp:106] Iteration 15700, lr = 1e-09
I0614 10:49:30.163612   290 solver.cpp:270] Iteration 15750 (3.96464 iter/s, 12.6115s/50 iter), loss = 0.0458769, remaining 0 hours and 17 minutes
I0614 10:49:30.163664   290 solver.cpp:291]     Train net output #0: loss = 0.045877 (* 1 = 0.045877 loss)
I0614 10:49:30.163674   290 sgd_solver.cpp:106] Iteration 15750, lr = 1e-09
I0614 10:49:42.778373   290 solver.cpp:270] Iteration 15800 (3.96375 iter/s, 12.6143s/50 iter), loss = 0.0421461, remaining 0 hours and 17 minutes
I0614 10:49:42.778406   290 solver.cpp:291]     Train net output #0: loss = 0.0421461 (* 1 = 0.0421461 loss)
I0614 10:49:42.778417   290 sgd_solver.cpp:106] Iteration 15800, lr = 1e-09
I0614 10:49:55.388787   290 solver.cpp:270] Iteration 15850 (3.96512 iter/s, 12.61s/50 iter), loss = 0.0340776, remaining 0 hours and 17 minutes
I0614 10:49:55.388820   290 solver.cpp:291]     Train net output #0: loss = 0.0340777 (* 1 = 0.0340777 loss)
I0614 10:49:55.388829   290 sgd_solver.cpp:106] Iteration 15850, lr = 1e-09
I0614 10:50:08.006217   290 solver.cpp:270] Iteration 15900 (3.96291 iter/s, 12.617s/50 iter), loss = 0.0686604, remaining 0 hours and 17 minutes
I0614 10:50:08.006273   290 solver.cpp:291]     Train net output #0: loss = 0.0686604 (* 1 = 0.0686604 loss)
I0614 10:50:08.006299   290 sgd_solver.cpp:106] Iteration 15900, lr = 1e-09
I0614 10:50:20.622958   290 solver.cpp:270] Iteration 15950 (3.96313 iter/s, 12.6163s/50 iter), loss = 0.0519485, remaining 0 hours and 16 minutes
I0614 10:50:20.622992   290 solver.cpp:291]     Train net output #0: loss = 0.0519485 (* 1 = 0.0519485 loss)
I0614 10:50:20.623003   290 sgd_solver.cpp:106] Iteration 15950, lr = 1e-09
I0614 10:50:32.989063   290 solver.cpp:424] Iteration 16000, Testing net (#0)
I0614 10:50:34.468335   290 solver.cpp:523]     Test net output #0: accuracy = 0.95375
I0614 10:50:34.468369   290 solver.cpp:523]     Test net output #1: loss = 0.140785 (* 1 = 0.140785 loss)
I0614 10:50:34.468374   290 solver.cpp:523]     Test net output #2: top-1 = 0.95375
I0614 10:50:34.714802   290 solver.cpp:270] Iteration 16000 (3.54827 iter/s, 14.0914s/50 iter), loss = 0.0393008, remaining 0 hours and 18 minutes
I0614 10:50:34.714834   290 solver.cpp:291]     Train net output #0: loss = 0.0393008 (* 1 = 0.0393008 loss)
I0614 10:50:34.714845   290 sgd_solver.cpp:106] Iteration 16000, lr = 1e-09
I0614 10:50:47.336294   290 solver.cpp:270] Iteration 16050 (3.96163 iter/s, 12.6211s/50 iter), loss = 0.0229604, remaining 0 hours and 16 minutes
I0614 10:50:47.336344   290 solver.cpp:291]     Train net output #0: loss = 0.0229605 (* 1 = 0.0229605 loss)
I0614 10:50:47.336354   290 sgd_solver.cpp:106] Iteration 16050, lr = 1e-09
I0614 10:50:59.944576   290 solver.cpp:270] Iteration 16100 (3.96579 iter/s, 12.6078s/50 iter), loss = 0.0448191, remaining 0 hours and 16 minutes
I0614 10:50:59.944612   290 solver.cpp:291]     Train net output #0: loss = 0.0448191 (* 1 = 0.0448191 loss)
I0614 10:50:59.944620   290 sgd_solver.cpp:106] Iteration 16100, lr = 1e-09
I0614 10:51:12.571130   290 solver.cpp:270] Iteration 16150 (3.96005 iter/s, 12.6261s/50 iter), loss = 0.0409082, remaining 0 hours and 16 minutes
I0614 10:51:12.571164   290 solver.cpp:291]     Train net output #0: loss = 0.0409082 (* 1 = 0.0409082 loss)
I0614 10:51:12.571174   290 sgd_solver.cpp:106] Iteration 16150, lr = 1e-09
I0614 10:51:25.182261   290 solver.cpp:270] Iteration 16200 (3.96489 iter/s, 12.6107s/50 iter), loss = 0.0183035, remaining 0 hours and 15 minutes
I0614 10:51:25.182312   290 solver.cpp:291]     Train net output #0: loss = 0.0183035 (* 1 = 0.0183035 loss)
I0614 10:51:25.182337   290 sgd_solver.cpp:106] Iteration 16200, lr = 1e-09
I0614 10:51:37.796440   290 solver.cpp:270] Iteration 16250 (3.96394 iter/s, 12.6137s/50 iter), loss = 0.0533864, remaining 0 hours and 15 minutes
I0614 10:51:37.796474   290 solver.cpp:291]     Train net output #0: loss = 0.0533864 (* 1 = 0.0533864 loss)
I0614 10:51:37.796483   290 sgd_solver.cpp:106] Iteration 16250, lr = 1e-09
I0614 10:51:50.404958   290 solver.cpp:270] Iteration 16300 (3.96571 iter/s, 12.6081s/50 iter), loss = 0.0313985, remaining 0 hours and 15 minutes
I0614 10:51:50.404994   290 solver.cpp:291]     Train net output #0: loss = 0.0313986 (* 1 = 0.0313986 loss)
I0614 10:51:50.405004   290 sgd_solver.cpp:106] Iteration 16300, lr = 1e-09
I0614 10:52:03.024040   290 solver.cpp:270] Iteration 16350 (3.96239 iter/s, 12.6186s/50 iter), loss = 0.0396472, remaining 0 hours and 15 minutes
I0614 10:52:03.024108   290 solver.cpp:291]     Train net output #0: loss = 0.0396472 (* 1 = 0.0396472 loss)
I0614 10:52:03.024117   290 sgd_solver.cpp:106] Iteration 16350, lr = 1e-09
I0614 10:52:15.639012   290 solver.cpp:270] Iteration 16400 (3.96369 iter/s, 12.6145s/50 iter), loss = 0.0528617, remaining 0 hours and 15 minutes
I0614 10:52:15.639048   290 solver.cpp:291]     Train net output #0: loss = 0.0528617 (* 1 = 0.0528617 loss)
I0614 10:52:15.639057   290 sgd_solver.cpp:106] Iteration 16400, lr = 1e-09
I0614 10:52:28.258755   290 solver.cpp:270] Iteration 16450 (3.96218 iter/s, 12.6193s/50 iter), loss = 0.0239222, remaining 0 hours and 14 minutes
I0614 10:52:28.258790   290 solver.cpp:291]     Train net output #0: loss = 0.0239222 (* 1 = 0.0239222 loss)
I0614 10:52:28.258800   290 sgd_solver.cpp:106] Iteration 16450, lr = 1e-09
I0614 10:52:40.873013   290 solver.cpp:270] Iteration 16500 (3.96391 iter/s, 12.6138s/50 iter), loss = 0.040379, remaining 0 hours and 14 minutes
I0614 10:52:40.873067   290 solver.cpp:291]     Train net output #0: loss = 0.040379 (* 1 = 0.040379 loss)
I0614 10:52:40.873076   290 sgd_solver.cpp:106] Iteration 16500, lr = 1e-09
I0614 10:52:53.482839   290 solver.cpp:270] Iteration 16550 (3.96531 iter/s, 12.6094s/50 iter), loss = 0.02724, remaining 0 hours and 14 minutes
I0614 10:52:53.482875   290 solver.cpp:291]     Train net output #0: loss = 0.02724 (* 1 = 0.02724 loss)
I0614 10:52:53.482900   290 sgd_solver.cpp:106] Iteration 16550, lr = 1e-09
I0614 10:53:06.098157   290 solver.cpp:270] Iteration 16600 (3.96357 iter/s, 12.6149s/50 iter), loss = 0.0307488, remaining 0 hours and 14 minutes
I0614 10:53:06.098191   290 solver.cpp:291]     Train net output #0: loss = 0.0307488 (* 1 = 0.0307488 loss)
I0614 10:53:06.098201   290 sgd_solver.cpp:106] Iteration 16600, lr = 1e-09
I0614 10:53:18.708675   290 solver.cpp:270] Iteration 16650 (3.96508 iter/s, 12.6101s/50 iter), loss = 0.0257957, remaining 0 hours and 13 minutes
I0614 10:53:18.708725   290 solver.cpp:291]     Train net output #0: loss = 0.0257957 (* 1 = 0.0257957 loss)
I0614 10:53:18.708734   290 sgd_solver.cpp:106] Iteration 16650, lr = 1e-09
I0614 10:53:31.321468   290 solver.cpp:270] Iteration 16700 (3.96437 iter/s, 12.6123s/50 iter), loss = 0.0573327, remaining 0 hours and 13 minutes
I0614 10:53:31.321502   290 solver.cpp:291]     Train net output #0: loss = 0.0573328 (* 1 = 0.0573328 loss)
I0614 10:53:31.321527   290 sgd_solver.cpp:106] Iteration 16700, lr = 1e-09
I0614 10:53:43.930632   290 solver.cpp:270] Iteration 16750 (3.96551 iter/s, 12.6087s/50 iter), loss = 0.042775, remaining 0 hours and 13 minutes
I0614 10:53:43.930665   290 solver.cpp:291]     Train net output #0: loss = 0.042775 (* 1 = 0.042775 loss)
I0614 10:53:43.930675   290 sgd_solver.cpp:106] Iteration 16750, lr = 1e-09
I0614 10:53:56.533294   290 solver.cpp:270] Iteration 16800 (3.96755 iter/s, 12.6022s/50 iter), loss = 0.0753403, remaining 0 hours and 13 minutes
I0614 10:53:56.533344   290 solver.cpp:291]     Train net output #0: loss = 0.0753404 (* 1 = 0.0753404 loss)
I0614 10:53:56.533370   290 sgd_solver.cpp:106] Iteration 16800, lr = 1e-09
I0614 10:54:09.152861   290 solver.cpp:270] Iteration 16850 (3.96224 iter/s, 12.6191s/50 iter), loss = 0.0245394, remaining 0 hours and 13 minutes
I0614 10:54:09.152897   290 solver.cpp:291]     Train net output #0: loss = 0.0245395 (* 1 = 0.0245395 loss)
I0614 10:54:09.152906   290 sgd_solver.cpp:106] Iteration 16850, lr = 1e-09
I0614 10:54:21.752930   290 solver.cpp:270] Iteration 16900 (3.96837 iter/s, 12.5996s/50 iter), loss = 0.0365526, remaining 0 hours and 12 minutes
I0614 10:54:21.752965   290 solver.cpp:291]     Train net output #0: loss = 0.0365527 (* 1 = 0.0365527 loss)
I0614 10:54:21.752974   290 sgd_solver.cpp:106] Iteration 16900, lr = 1e-09
I0614 10:54:34.362955   290 solver.cpp:270] Iteration 16950 (3.96524 iter/s, 12.6096s/50 iter), loss = 0.0194078, remaining 0 hours and 12 minutes
I0614 10:54:34.363003   290 solver.cpp:291]     Train net output #0: loss = 0.0194079 (* 1 = 0.0194079 loss)
I0614 10:54:34.363013   290 sgd_solver.cpp:106] Iteration 16950, lr = 1e-09
I0614 10:54:46.704988   290 solver.cpp:424] Iteration 17000, Testing net (#0)
I0614 10:54:48.216192   290 solver.cpp:523]     Test net output #0: accuracy = 0.954
I0614 10:54:48.216223   290 solver.cpp:523]     Test net output #1: loss = 0.148926 (* 1 = 0.148926 loss)
I0614 10:54:48.216228   290 solver.cpp:523]     Test net output #2: top-1 = 0.954
I0614 10:54:48.463176   290 solver.cpp:270] Iteration 17000 (3.54617 iter/s, 14.0997s/50 iter), loss = 0.0374113, remaining 0 hours and 14 minutes
I0614 10:54:48.463207   290 solver.cpp:291]     Train net output #0: loss = 0.0374113 (* 1 = 0.0374113 loss)
I0614 10:54:48.463217   290 sgd_solver.cpp:106] Iteration 17000, lr = 1e-09
I0614 10:55:01.085763   290 solver.cpp:270] Iteration 17050 (3.96129 iter/s, 12.6221s/50 iter), loss = 0.0249127, remaining 0 hours and 12 minutes
I0614 10:55:01.085799   290 solver.cpp:291]     Train net output #0: loss = 0.0249127 (* 1 = 0.0249127 loss)
I0614 10:55:01.085808   290 sgd_solver.cpp:106] Iteration 17050, lr = 1e-09
I0614 10:55:13.701853   290 solver.cpp:270] Iteration 17100 (3.96333 iter/s, 12.6156s/50 iter), loss = 0.0336652, remaining 0 hours and 12 minutes
I0614 10:55:13.701910   290 solver.cpp:291]     Train net output #0: loss = 0.0336652 (* 1 = 0.0336652 loss)
I0614 10:55:13.701936   290 sgd_solver.cpp:106] Iteration 17100, lr = 1e-09
I0614 10:55:26.324669   290 solver.cpp:270] Iteration 17150 (3.96123 iter/s, 12.6224s/50 iter), loss = 0.0580533, remaining 0 hours and 11 minutes
I0614 10:55:26.324704   290 solver.cpp:291]     Train net output #0: loss = 0.0580533 (* 1 = 0.0580533 loss)
I0614 10:55:26.324713   290 sgd_solver.cpp:106] Iteration 17150, lr = 1e-09
I0614 10:55:38.929482   290 solver.cpp:270] Iteration 17200 (3.96688 iter/s, 12.6044s/50 iter), loss = 0.0457209, remaining 0 hours and 11 minutes
I0614 10:55:38.929515   290 solver.cpp:291]     Train net output #0: loss = 0.045721 (* 1 = 0.045721 loss)
I0614 10:55:38.929541   290 sgd_solver.cpp:106] Iteration 17200, lr = 1e-09
I0614 10:55:51.539619   290 solver.cpp:270] Iteration 17250 (3.9652 iter/s, 12.6097s/50 iter), loss = 0.0260482, remaining 0 hours and 11 minutes
I0614 10:55:51.539669   290 solver.cpp:291]     Train net output #0: loss = 0.0260482 (* 1 = 0.0260482 loss)
I0614 10:55:51.539678   290 sgd_solver.cpp:106] Iteration 17250, lr = 1e-09
I0614 10:56:04.145989   290 solver.cpp:270] Iteration 17300 (3.96639 iter/s, 12.6059s/50 iter), loss = 0.028587, remaining 0 hours and 11 minutes
I0614 10:56:04.146024   290 solver.cpp:291]     Train net output #0: loss = 0.028587 (* 1 = 0.028587 loss)
I0614 10:56:04.146049   290 sgd_solver.cpp:106] Iteration 17300, lr = 1e-09
I0614 10:56:16.746937   290 solver.cpp:270] Iteration 17350 (3.96809 iter/s, 12.6005s/50 iter), loss = 0.0303851, remaining 0 hours and 11 minutes
I0614 10:56:16.746970   290 solver.cpp:291]     Train net output #0: loss = 0.0303851 (* 1 = 0.0303851 loss)
I0614 10:56:16.746996   290 sgd_solver.cpp:106] Iteration 17350, lr = 1e-09
I0614 10:56:29.368808   290 solver.cpp:270] Iteration 17400 (3.96152 iter/s, 12.6214s/50 iter), loss = 0.039082, remaining 0 hours and 10 minutes
I0614 10:56:29.368858   290 solver.cpp:291]     Train net output #0: loss = 0.0390821 (* 1 = 0.0390821 loss)
I0614 10:56:29.368867   290 sgd_solver.cpp:106] Iteration 17400, lr = 1e-09
I0614 10:56:41.972975   290 solver.cpp:270] Iteration 17450 (3.96709 iter/s, 12.6037s/50 iter), loss = 0.0353514, remaining 0 hours and 10 minutes
I0614 10:56:41.973006   290 solver.cpp:291]     Train net output #0: loss = 0.0353514 (* 1 = 0.0353514 loss)
I0614 10:56:41.973031   290 sgd_solver.cpp:106] Iteration 17450, lr = 1e-09
I0614 10:56:54.586223   290 solver.cpp:270] Iteration 17500 (3.96422 iter/s, 12.6128s/50 iter), loss = 0.0524817, remaining 0 hours and 10 minutes
I0614 10:56:54.586256   290 solver.cpp:291]     Train net output #0: loss = 0.0524817 (* 1 = 0.0524817 loss)
I0614 10:56:54.586266   290 sgd_solver.cpp:106] Iteration 17500, lr = 1e-10
I0614 10:57:07.198746   290 solver.cpp:270] Iteration 17550 (3.96445 iter/s, 12.6121s/50 iter), loss = 0.0385717, remaining 0 hours and 10 minutes
I0614 10:57:07.198796   290 solver.cpp:291]     Train net output #0: loss = 0.0385718 (* 1 = 0.0385718 loss)
I0614 10:57:07.198822   290 sgd_solver.cpp:106] Iteration 17550, lr = 1e-10
I0614 10:57:19.809432   290 solver.cpp:270] Iteration 17600 (3.96503 iter/s, 12.6102s/50 iter), loss = 0.0165603, remaining 0 hours and 10 minutes
I0614 10:57:19.809465   290 solver.cpp:291]     Train net output #0: loss = 0.0165603 (* 1 = 0.0165603 loss)
I0614 10:57:19.809474   290 sgd_solver.cpp:106] Iteration 17600, lr = 1e-10
I0614 10:57:32.422636   290 solver.cpp:270] Iteration 17650 (3.96424 iter/s, 12.6128s/50 iter), loss = 0.0184683, remaining 0 hours and 9 minutes
I0614 10:57:32.422669   290 solver.cpp:291]     Train net output #0: loss = 0.0184684 (* 1 = 0.0184684 loss)
I0614 10:57:32.422678   290 sgd_solver.cpp:106] Iteration 17650, lr = 1e-10
I0614 10:57:45.029924   290 solver.cpp:270] Iteration 17700 (3.9661 iter/s, 12.6068s/50 iter), loss = 0.0178433, remaining 0 hours and 9 minutes
I0614 10:57:45.029980   290 solver.cpp:291]     Train net output #0: loss = 0.0178434 (* 1 = 0.0178434 loss)
I0614 10:57:45.030006   290 sgd_solver.cpp:106] Iteration 17700, lr = 1e-10
I0614 10:57:57.644425   290 solver.cpp:270] Iteration 17750 (3.96384 iter/s, 12.614s/50 iter), loss = 0.0634374, remaining 0 hours and 9 minutes
I0614 10:57:57.644457   290 solver.cpp:291]     Train net output #0: loss = 0.0634375 (* 1 = 0.0634375 loss)
I0614 10:57:57.644466   290 sgd_solver.cpp:106] Iteration 17750, lr = 1e-10
I0614 10:58:10.258239   290 solver.cpp:270] Iteration 17800 (3.96405 iter/s, 12.6134s/50 iter), loss = 0.0231827, remaining 0 hours and 9 minutes
I0614 10:58:10.258272   290 solver.cpp:291]     Train net output #0: loss = 0.0231828 (* 1 = 0.0231828 loss)
I0614 10:58:10.258281   290 sgd_solver.cpp:106] Iteration 17800, lr = 1e-10
I0614 10:58:22.878470   290 solver.cpp:270] Iteration 17850 (3.96203 iter/s, 12.6198s/50 iter), loss = 0.0246097, remaining 0 hours and 8 minutes
I0614 10:58:22.878520   290 solver.cpp:291]     Train net output #0: loss = 0.0246098 (* 1 = 0.0246098 loss)
I0614 10:58:22.878528   290 sgd_solver.cpp:106] Iteration 17850, lr = 1e-10
I0614 10:58:35.489212   290 solver.cpp:270] Iteration 17900 (3.96502 iter/s, 12.6103s/50 iter), loss = 0.0440732, remaining 0 hours and 8 minutes
I0614 10:58:35.489246   290 solver.cpp:291]     Train net output #0: loss = 0.0440733 (* 1 = 0.0440733 loss)
I0614 10:58:35.489255   290 sgd_solver.cpp:106] Iteration 17900, lr = 1e-10
I0614 10:58:48.117043   290 solver.cpp:270] Iteration 17950 (3.95965 iter/s, 12.6274s/50 iter), loss = 0.0538701, remaining 0 hours and 8 minutes
I0614 10:58:48.117075   290 solver.cpp:291]     Train net output #0: loss = 0.0538702 (* 1 = 0.0538702 loss)
I0614 10:58:48.117100   290 sgd_solver.cpp:106] Iteration 17950, lr = 1e-10
I0614 10:59:00.467630   290 solver.cpp:424] Iteration 18000, Testing net (#0)
I0614 10:59:01.971947   290 solver.cpp:523]     Test net output #0: accuracy = 0.95375
I0614 10:59:01.971977   290 solver.cpp:523]     Test net output #1: loss = 0.154146 (* 1 = 0.154146 loss)
I0614 10:59:01.971982   290 solver.cpp:523]     Test net output #2: top-1 = 0.95375
I0614 10:59:02.218590   290 solver.cpp:270] Iteration 18000 (3.54583 iter/s, 14.1011s/50 iter), loss = 0.020961, remaining 0 hours and 9 minutes
I0614 10:59:02.218622   290 solver.cpp:291]     Train net output #0: loss = 0.0209611 (* 1 = 0.0209611 loss)
I0614 10:59:02.218631   290 sgd_solver.cpp:106] Iteration 18000, lr = 1e-10
I0614 10:59:14.833201   290 solver.cpp:270] Iteration 18050 (3.9638 iter/s, 12.6142s/50 iter), loss = 0.0586522, remaining 0 hours and 8 minutes
I0614 10:59:14.833235   290 solver.cpp:291]     Train net output #0: loss = 0.0586523 (* 1 = 0.0586523 loss)
I0614 10:59:14.833243   290 sgd_solver.cpp:106] Iteration 18050, lr = 1e-10
I0614 10:59:27.437278   290 solver.cpp:270] Iteration 18100 (3.96711 iter/s, 12.6036s/50 iter), loss = 0.0514326, remaining 0 hours and 7 minutes
I0614 10:59:27.437310   290 solver.cpp:291]     Train net output #0: loss = 0.0514327 (* 1 = 0.0514327 loss)
I0614 10:59:27.437320   290 sgd_solver.cpp:106] Iteration 18100, lr = 1e-10
I0614 10:59:40.051407   290 solver.cpp:270] Iteration 18150 (3.96395 iter/s, 12.6137s/50 iter), loss = 0.0602924, remaining 0 hours and 7 minutes
I0614 10:59:40.051457   290 solver.cpp:291]     Train net output #0: loss = 0.0602925 (* 1 = 0.0602925 loss)
I0614 10:59:40.051467   290 sgd_solver.cpp:106] Iteration 18150, lr = 1e-10
I0614 10:59:52.662197   290 solver.cpp:270] Iteration 18200 (3.965 iter/s, 12.6103s/50 iter), loss = 0.0292826, remaining 0 hours and 7 minutes
I0614 10:59:52.662231   290 solver.cpp:291]     Train net output #0: loss = 0.0292826 (* 1 = 0.0292826 loss)
I0614 10:59:52.662240   290 sgd_solver.cpp:106] Iteration 18200, lr = 1e-10
I0614 11:00:05.264292   290 solver.cpp:270] Iteration 18250 (3.96773 iter/s, 12.6017s/50 iter), loss = 0.0690387, remaining 0 hours and 7 minutes
I0614 11:00:05.264325   290 solver.cpp:291]     Train net output #0: loss = 0.0690388 (* 1 = 0.0690388 loss)
I0614 11:00:05.264351   290 sgd_solver.cpp:106] Iteration 18250, lr = 1e-10
I0614 11:00:17.869343   290 solver.cpp:270] Iteration 18300 (3.9668 iter/s, 12.6046s/50 iter), loss = 0.0464413, remaining 0 hours and 7 minutes
I0614 11:00:17.869402   290 solver.cpp:291]     Train net output #0: loss = 0.0464414 (* 1 = 0.0464414 loss)
I0614 11:00:17.869412   290 sgd_solver.cpp:106] Iteration 18300, lr = 1e-10
I0614 11:00:30.487030   290 solver.cpp:270] Iteration 18350 (3.96284 iter/s, 12.6172s/50 iter), loss = 0.021752, remaining 0 hours and 6 minutes
I0614 11:00:30.487063   290 solver.cpp:291]     Train net output #0: loss = 0.0217521 (* 1 = 0.0217521 loss)
I0614 11:00:30.487072   290 sgd_solver.cpp:106] Iteration 18350, lr = 1e-10
I0614 11:00:43.099279   290 solver.cpp:270] Iteration 18400 (3.96454 iter/s, 12.6118s/50 iter), loss = 0.0356289, remaining 0 hours and 6 minutes
I0614 11:00:43.099313   290 solver.cpp:291]     Train net output #0: loss = 0.035629 (* 1 = 0.035629 loss)
I0614 11:00:43.099337   290 sgd_solver.cpp:106] Iteration 18400, lr = 1e-10
I0614 11:00:55.716977   290 solver.cpp:270] Iteration 18450 (3.96283 iter/s, 12.6173s/50 iter), loss = 0.052303, remaining 0 hours and 6 minutes
I0614 11:00:55.717025   290 solver.cpp:291]     Train net output #0: loss = 0.0523031 (* 1 = 0.0523031 loss)
I0614 11:00:55.717051   290 sgd_solver.cpp:106] Iteration 18450, lr = 1e-10
I0614 11:01:08.344717   290 solver.cpp:270] Iteration 18500 (3.95968 iter/s, 12.6273s/50 iter), loss = 0.0316413, remaining 0 hours and 6 minutes
I0614 11:01:08.344749   290 solver.cpp:291]     Train net output #0: loss = 0.0316414 (* 1 = 0.0316414 loss)
I0614 11:01:08.344774   290 sgd_solver.cpp:106] Iteration 18500, lr = 1e-10
I0614 11:01:20.953486   290 solver.cpp:270] Iteration 18550 (3.96563 iter/s, 12.6083s/50 iter), loss = 0.0505371, remaining 0 hours and 6 minutes
I0614 11:01:20.953519   290 solver.cpp:291]     Train net output #0: loss = 0.0505371 (* 1 = 0.0505371 loss)
I0614 11:01:20.953528   290 sgd_solver.cpp:106] Iteration 18550, lr = 1e-10
I0614 11:01:33.562644   290 solver.cpp:270] Iteration 18600 (3.96551 iter/s, 12.6087s/50 iter), loss = 0.0483889, remaining 0 hours and 5 minutes
I0614 11:01:33.562691   290 solver.cpp:291]     Train net output #0: loss = 0.0483889 (* 1 = 0.0483889 loss)
I0614 11:01:33.562701   290 sgd_solver.cpp:106] Iteration 18600, lr = 1e-10
I0614 11:01:46.171900   290 solver.cpp:270] Iteration 18650 (3.96548 iter/s, 12.6088s/50 iter), loss = 0.0510266, remaining 0 hours and 5 minutes
I0614 11:01:46.171933   290 solver.cpp:291]     Train net output #0: loss = 0.0510267 (* 1 = 0.0510267 loss)
I0614 11:01:46.171943   290 sgd_solver.cpp:106] Iteration 18650, lr = 1e-10
I0614 11:01:58.788837   290 solver.cpp:270] Iteration 18700 (3.96307 iter/s, 12.6165s/50 iter), loss = 0.0111079, remaining 0 hours and 5 minutes
I0614 11:01:58.788872   290 solver.cpp:291]     Train net output #0: loss = 0.0111079 (* 1 = 0.0111079 loss)
I0614 11:01:58.788882   290 sgd_solver.cpp:106] Iteration 18700, lr = 1e-10
I0614 11:02:11.392751   290 solver.cpp:270] Iteration 18750 (3.96716 iter/s, 12.6035s/50 iter), loss = 0.0441035, remaining 0 hours and 5 minutes
I0614 11:02:11.392799   290 solver.cpp:291]     Train net output #0: loss = 0.0441036 (* 1 = 0.0441036 loss)
I0614 11:02:11.392809   290 sgd_solver.cpp:106] Iteration 18750, lr = 1e-10
I0614 11:02:24.011215   290 solver.cpp:270] Iteration 18800 (3.96259 iter/s, 12.618s/50 iter), loss = 0.0425941, remaining 0 hours and 5 minutes
I0614 11:02:24.011250   290 solver.cpp:291]     Train net output #0: loss = 0.0425942 (* 1 = 0.0425942 loss)
I0614 11:02:24.011260   290 sgd_solver.cpp:106] Iteration 18800, lr = 1e-10
I0614 11:02:36.630827   290 solver.cpp:270] Iteration 18850 (3.96223 iter/s, 12.6192s/50 iter), loss = 0.0345436, remaining 0 hours and 4 minutes
I0614 11:02:36.630861   290 solver.cpp:291]     Train net output #0: loss = 0.0345437 (* 1 = 0.0345437 loss)
I0614 11:02:36.630885   290 sgd_solver.cpp:106] Iteration 18850, lr = 1e-10
I0614 11:02:49.238308   290 solver.cpp:270] Iteration 18900 (3.96604 iter/s, 12.607s/50 iter), loss = 0.0346844, remaining 0 hours and 4 minutes
I0614 11:02:49.238365   290 solver.cpp:291]     Train net output #0: loss = 0.0346845 (* 1 = 0.0346845 loss)
I0614 11:02:49.238375   290 sgd_solver.cpp:106] Iteration 18900, lr = 1e-10
I0614 11:03:01.854274   290 solver.cpp:270] Iteration 18950 (3.96338 iter/s, 12.6155s/50 iter), loss = 0.0316209, remaining 0 hours and 4 minutes
I0614 11:03:01.854306   290 solver.cpp:291]     Train net output #0: loss = 0.031621 (* 1 = 0.031621 loss)
I0614 11:03:01.854316   290 sgd_solver.cpp:106] Iteration 18950, lr = 1e-10
I0614 11:03:14.218103   290 solver.cpp:424] Iteration 19000, Testing net (#0)
I0614 11:03:15.726038   290 solver.cpp:523]     Test net output #0: accuracy = 0.95375
I0614 11:03:15.726069   290 solver.cpp:523]     Test net output #1: loss = 0.157148 (* 1 = 0.157148 loss)
I0614 11:03:15.726074   290 solver.cpp:523]     Test net output #2: top-1 = 0.95375
I0614 11:03:15.973006   290 solver.cpp:270] Iteration 19000 (3.54152 iter/s, 14.1182s/50 iter), loss = 0.0570848, remaining 0 hours and 4 minutes
I0614 11:03:15.973038   290 solver.cpp:291]     Train net output #0: loss = 0.0570849 (* 1 = 0.0570849 loss)
I0614 11:03:15.973048   290 sgd_solver.cpp:106] Iteration 19000, lr = 1e-10
I0614 11:03:28.584398   290 solver.cpp:270] Iteration 19050 (3.96481 iter/s, 12.611s/50 iter), loss = 0.029354, remaining 0 hours and 3 minutes
I0614 11:03:28.584447   290 solver.cpp:291]     Train net output #0: loss = 0.0293541 (* 1 = 0.0293541 loss)
I0614 11:03:28.584457   290 sgd_solver.cpp:106] Iteration 19050, lr = 1e-10
I0614 11:03:41.186755   290 solver.cpp:270] Iteration 19100 (3.96766 iter/s, 12.6019s/50 iter), loss = 0.0539132, remaining 0 hours and 3 minutes
I0614 11:03:41.186787   290 solver.cpp:291]     Train net output #0: loss = 0.0539133 (* 1 = 0.0539133 loss)
I0614 11:03:41.186796   290 sgd_solver.cpp:106] Iteration 19100, lr = 1e-10
I0614 11:03:53.808872   290 solver.cpp:270] Iteration 19150 (3.96144 iter/s, 12.6217s/50 iter), loss = 0.0476492, remaining 0 hours and 3 minutes
I0614 11:03:53.808907   290 solver.cpp:291]     Train net output #0: loss = 0.0476493 (* 1 = 0.0476493 loss)
I0614 11:03:53.808915   290 sgd_solver.cpp:106] Iteration 19150, lr = 1e-10
I0614 11:04:06.412811   290 solver.cpp:270] Iteration 19200 (3.96715 iter/s, 12.6035s/50 iter), loss = 0.0582289, remaining 0 hours and 3 minutes
I0614 11:04:06.412859   290 solver.cpp:291]     Train net output #0: loss = 0.058229 (* 1 = 0.058229 loss)
I0614 11:04:06.412868   290 sgd_solver.cpp:106] Iteration 19200, lr = 1e-10
I0614 11:04:19.040069   290 solver.cpp:270] Iteration 19250 (3.95983 iter/s, 12.6268s/50 iter), loss = 0.0570417, remaining 0 hours and 3 minutes
I0614 11:04:19.040103   290 solver.cpp:291]     Train net output #0: loss = 0.0570418 (* 1 = 0.0570418 loss)
I0614 11:04:19.040112   290 sgd_solver.cpp:106] Iteration 19250, lr = 1e-10
I0614 11:04:31.653867   290 solver.cpp:270] Iteration 19300 (3.96405 iter/s, 12.6134s/50 iter), loss = 0.0428953, remaining 0 hours and 2 minutes
I0614 11:04:31.653903   290 solver.cpp:291]     Train net output #0: loss = 0.0428954 (* 1 = 0.0428954 loss)
I0614 11:04:31.653911   290 sgd_solver.cpp:106] Iteration 19300, lr = 1e-10
I0614 11:04:44.264690   290 solver.cpp:270] Iteration 19350 (3.96499 iter/s, 12.6104s/50 iter), loss = 0.032474, remaining 0 hours and 2 minutes
I0614 11:04:44.264748   290 solver.cpp:291]     Train net output #0: loss = 0.0324741 (* 1 = 0.0324741 loss)
I0614 11:04:44.264758   290 sgd_solver.cpp:106] Iteration 19350, lr = 1e-10
I0614 11:04:56.873733   290 solver.cpp:270] Iteration 19400 (3.96555 iter/s, 12.6086s/50 iter), loss = 0.0374307, remaining 0 hours and 2 minutes
I0614 11:04:56.873765   290 solver.cpp:291]     Train net output #0: loss = 0.0374308 (* 1 = 0.0374308 loss)
I0614 11:04:56.873775   290 sgd_solver.cpp:106] Iteration 19400, lr = 1e-10
I0614 11:05:09.486469   290 solver.cpp:270] Iteration 19450 (3.96438 iter/s, 12.6123s/50 iter), loss = 0.0295091, remaining 0 hours and 2 minutes
I0614 11:05:09.486501   290 solver.cpp:291]     Train net output #0: loss = 0.0295092 (* 1 = 0.0295092 loss)
I0614 11:05:09.486510   290 sgd_solver.cpp:106] Iteration 19450, lr = 1e-10
I0614 11:05:22.099701   290 solver.cpp:270] Iteration 19500 (3.96423 iter/s, 12.6128s/50 iter), loss = 0.0505829, remaining 0 hours and 2 minutes
I0614 11:05:22.099761   290 solver.cpp:291]     Train net output #0: loss = 0.0505829 (* 1 = 0.0505829 loss)
I0614 11:05:22.099786   290 sgd_solver.cpp:106] Iteration 19500, lr = 1e-10
I0614 11:05:34.697142   290 solver.cpp:270] Iteration 19550 (3.96921 iter/s, 12.597s/50 iter), loss = 0.0276462, remaining 0 hours and 1 minutes
I0614 11:05:34.697178   290 solver.cpp:291]     Train net output #0: loss = 0.0276463 (* 1 = 0.0276463 loss)
I0614 11:05:34.697188   290 sgd_solver.cpp:106] Iteration 19550, lr = 1e-10
I0614 11:05:47.308352   290 solver.cpp:270] Iteration 19600 (3.96487 iter/s, 12.6108s/50 iter), loss = 0.0205896, remaining 0 hours and 1 minutes
I0614 11:05:47.308384   290 solver.cpp:291]     Train net output #0: loss = 0.0205897 (* 1 = 0.0205897 loss)
I0614 11:05:47.308409   290 sgd_solver.cpp:106] Iteration 19600, lr = 1e-10
I0614 11:05:59.913173   290 solver.cpp:270] Iteration 19650 (3.96688 iter/s, 12.6044s/50 iter), loss = 0.0446318, remaining 0 hours and 1 minutes
I0614 11:05:59.913223   290 solver.cpp:291]     Train net output #0: loss = 0.0446319 (* 1 = 0.0446319 loss)
I0614 11:05:59.913247   290 sgd_solver.cpp:106] Iteration 19650, lr = 1e-10
I0614 11:06:12.525532   290 solver.cpp:270] Iteration 19700 (3.96451 iter/s, 12.6119s/50 iter), loss = 0.0545729, remaining 0 hours and 1 minutes
I0614 11:06:12.525565   290 solver.cpp:291]     Train net output #0: loss = 0.054573 (* 1 = 0.054573 loss)
I0614 11:06:12.525573   290 sgd_solver.cpp:106] Iteration 19700, lr = 1e-10
I0614 11:06:25.138460   290 solver.cpp:270] Iteration 19750 (3.96432 iter/s, 12.6125s/50 iter), loss = 0.0206914, remaining 0 hours and 1 minutes
I0614 11:06:25.138495   290 solver.cpp:291]     Train net output #0: loss = 0.0206914 (* 1 = 0.0206914 loss)
I0614 11:06:25.138504   290 sgd_solver.cpp:106] Iteration 19750, lr = 1e-10
I0614 11:06:37.749238   290 solver.cpp:270] Iteration 19800 (3.965 iter/s, 12.6103s/50 iter), loss = 0.0319968, remaining 0 hours and 0 minutes
I0614 11:06:37.749282   290 solver.cpp:291]     Train net output #0: loss = 0.0319969 (* 1 = 0.0319969 loss)
I0614 11:06:37.749292   290 sgd_solver.cpp:106] Iteration 19800, lr = 1e-10
I0614 11:06:50.370540   290 solver.cpp:270] Iteration 19850 (3.9617 iter/s, 12.6209s/50 iter), loss = 0.020977, remaining 0 hours and 0 minutes
I0614 11:06:50.370573   290 solver.cpp:291]     Train net output #0: loss = 0.0209771 (* 1 = 0.0209771 loss)
I0614 11:06:50.370581   290 sgd_solver.cpp:106] Iteration 19850, lr = 1e-10
I0614 11:07:02.988703   290 solver.cpp:270] Iteration 19900 (3.96268 iter/s, 12.6177s/50 iter), loss = 0.0438643, remaining 0 hours and 0 minutes
I0614 11:07:02.988737   290 solver.cpp:291]     Train net output #0: loss = 0.0438643 (* 1 = 0.0438643 loss)
I0614 11:07:02.988746   290 sgd_solver.cpp:106] Iteration 19900, lr = 1e-10
I0614 11:07:15.598029   290 solver.cpp:270] Iteration 19950 (3.96546 iter/s, 12.6089s/50 iter), loss = 0.0425601, remaining 0 hours and 0 minutes
I0614 11:07:15.598079   290 solver.cpp:291]     Train net output #0: loss = 0.0425602 (* 1 = 0.0425602 loss)
I0614 11:07:15.598089   290 sgd_solver.cpp:106] Iteration 19950, lr = 1e-10
I0614 11:07:27.956144   290 solver.cpp:935] Snapshotting to binary proto file caffe/models/alexnetBNnoLRN/m2/snapshot_2_alexnetBNnoLRN__iter_20000.caffemodel
I0614 11:07:32.882597   290 sgd_solver.cpp:273] Snapshotting solver state to binary proto file caffe/models/alexnetBNnoLRN/m2/snapshot_2_alexnetBNnoLRN__iter_20000.solverstate
I0614 11:07:36.423449   290 solver.cpp:384] Iteration 20000, loss = 0.0319048
I0614 11:07:36.423475   290 solver.cpp:424] Iteration 20000, Testing net (#0)
I0614 11:07:37.850008   290 solver.cpp:523]     Test net output #0: accuracy = 0.9535
I0614 11:07:37.850041   290 solver.cpp:523]     Test net output #1: loss = 0.158723 (* 1 = 0.158723 loss)
I0614 11:07:37.850046   290 solver.cpp:523]     Test net output #2: top-1 = 0.9535
I0614 11:07:37.850051   290 solver.cpp:392] Optimization Done (3.92886 iter/s).
I0614 11:07:37.850055   290 caffe.cpp:250] Optimization Done.
TRAINING WITH CAFFE


Elapsed time for Caffe training (s):  5116.466557


PLOT LEARNING CURVERS (METHOD1)
COMPUTE PREDICTIONS
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0614 11:07:42.122509   413 gpu_memory.cpp:53] GPUMemory::Manager initialized with Caching (CUB) GPU Allocator
I0614 11:07:42.122534   413 gpu_memory.cpp:55] Total memory: 25635127296, Free: 24673189888, dev_info[0]: total=25635127296 free=24673189888
I0614 11:07:42.127949   413 net.cpp:52] Initializing net from parameters: 
name: "AlexNet_BNnoLRN m2 deploy"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 1
      dim: 3
      dim: 227
      dim: 227
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 0
    kernel_size: 8
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "bn1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "bn2"
  top: "relu2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "relu6"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "drop6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn7"
  type: "BatchNorm"
  bottom: "fc7"
  top: "bn7"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "bn7"
  top: "relu7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "relu7"
  top: "drop7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "drop7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc8"
  top: "prob"
}
I0614 11:07:42.128103   413 layer_factory.hpp:77] Creating layer data
I0614 11:07:42.128113   413 net.cpp:94] Creating Layer data
I0614 11:07:42.128118   413 net.cpp:409] data -> data
I0614 11:07:42.128152   413 net.cpp:144] Setting up data
I0614 11:07:42.128155   413 net.cpp:151] Top shape: 1 3 227 227 (154587)
I0614 11:07:42.128161   413 net.cpp:159] Memory required for data: 618348
I0614 11:07:42.128165   413 layer_factory.hpp:77] Creating layer conv1
I0614 11:07:42.128173   413 net.cpp:94] Creating Layer conv1
I0614 11:07:42.128175   413 net.cpp:435] conv1 <- data
I0614 11:07:42.128180   413 net.cpp:409] conv1 -> conv1
I0614 11:07:42.128504   413 net.cpp:144] Setting up conv1
I0614 11:07:42.128508   413 net.cpp:151] Top shape: 1 96 55 55 (290400)
I0614 11:07:42.128513   413 net.cpp:159] Memory required for data: 1779948
I0614 11:07:42.128521   413 layer_factory.hpp:77] Creating layer bn1
I0614 11:07:42.128528   413 net.cpp:94] Creating Layer bn1
I0614 11:07:42.128531   413 net.cpp:435] bn1 <- conv1
I0614 11:07:42.128535   413 net.cpp:409] bn1 -> bn1
I0614 11:07:42.128824   413 net.cpp:144] Setting up bn1
I0614 11:07:42.128831   413 net.cpp:151] Top shape: 1 96 55 55 (290400)
I0614 11:07:42.128836   413 net.cpp:159] Memory required for data: 2941548
I0614 11:07:42.128844   413 layer_factory.hpp:77] Creating layer relu1
I0614 11:07:42.128849   413 net.cpp:94] Creating Layer relu1
I0614 11:07:42.128852   413 net.cpp:435] relu1 <- bn1
I0614 11:07:42.128856   413 net.cpp:409] relu1 -> relu1
I0614 11:07:42.128875   413 net.cpp:144] Setting up relu1
I0614 11:07:42.128877   413 net.cpp:151] Top shape: 1 96 55 55 (290400)
I0614 11:07:42.128881   413 net.cpp:159] Memory required for data: 4103148
I0614 11:07:42.128885   413 layer_factory.hpp:77] Creating layer pool1
I0614 11:07:42.128890   413 net.cpp:94] Creating Layer pool1
I0614 11:07:42.128892   413 net.cpp:435] pool1 <- relu1
I0614 11:07:42.128895   413 net.cpp:409] pool1 -> pool1
I0614 11:07:42.128913   413 net.cpp:144] Setting up pool1
I0614 11:07:42.128916   413 net.cpp:151] Top shape: 1 96 27 27 (69984)
I0614 11:07:42.128921   413 net.cpp:159] Memory required for data: 4383084
I0614 11:07:42.128923   413 layer_factory.hpp:77] Creating layer conv2
I0614 11:07:42.128930   413 net.cpp:94] Creating Layer conv2
I0614 11:07:42.128933   413 net.cpp:435] conv2 <- pool1
I0614 11:07:42.128937   413 net.cpp:409] conv2 -> conv2
I0614 11:07:42.135273   413 net.cpp:144] Setting up conv2
I0614 11:07:42.135285   413 net.cpp:151] Top shape: 1 256 27 27 (186624)
I0614 11:07:42.135293   413 net.cpp:159] Memory required for data: 5129580
I0614 11:07:42.135300   413 layer_factory.hpp:77] Creating layer bn2
I0614 11:07:42.135308   413 net.cpp:94] Creating Layer bn2
I0614 11:07:42.135311   413 net.cpp:435] bn2 <- conv2
I0614 11:07:42.135316   413 net.cpp:409] bn2 -> bn2
I0614 11:07:42.135572   413 net.cpp:144] Setting up bn2
I0614 11:07:42.135576   413 net.cpp:151] Top shape: 1 256 27 27 (186624)
I0614 11:07:42.135581   413 net.cpp:159] Memory required for data: 5876076
I0614 11:07:42.135587   413 layer_factory.hpp:77] Creating layer relu2
I0614 11:07:42.135592   413 net.cpp:94] Creating Layer relu2
I0614 11:07:42.135596   413 net.cpp:435] relu2 <- bn2
I0614 11:07:42.135599   413 net.cpp:409] relu2 -> relu2
I0614 11:07:42.135608   413 net.cpp:144] Setting up relu2
I0614 11:07:42.135612   413 net.cpp:151] Top shape: 1 256 27 27 (186624)
I0614 11:07:42.135617   413 net.cpp:159] Memory required for data: 6622572
I0614 11:07:42.135619   413 layer_factory.hpp:77] Creating layer pool2
I0614 11:07:42.135625   413 net.cpp:94] Creating Layer pool2
I0614 11:07:42.135628   413 net.cpp:435] pool2 <- relu2
I0614 11:07:42.135632   413 net.cpp:409] pool2 -> pool2
I0614 11:07:42.135648   413 net.cpp:144] Setting up pool2
I0614 11:07:42.135650   413 net.cpp:151] Top shape: 1 256 13 13 (43264)
I0614 11:07:42.135654   413 net.cpp:159] Memory required for data: 6795628
I0614 11:07:42.135658   413 layer_factory.hpp:77] Creating layer conv3
I0614 11:07:42.135665   413 net.cpp:94] Creating Layer conv3
I0614 11:07:42.135668   413 net.cpp:435] conv3 <- pool2
I0614 11:07:42.135672   413 net.cpp:409] conv3 -> conv3
I0614 11:07:42.144655   413 net.cpp:144] Setting up conv3
I0614 11:07:42.144666   413 net.cpp:151] Top shape: 1 384 13 13 (64896)
I0614 11:07:42.144672   413 net.cpp:159] Memory required for data: 7055212
I0614 11:07:42.144678   413 layer_factory.hpp:77] Creating layer relu3
I0614 11:07:42.144686   413 net.cpp:94] Creating Layer relu3
I0614 11:07:42.144690   413 net.cpp:435] relu3 <- conv3
I0614 11:07:42.144695   413 net.cpp:409] relu3 -> relu3
I0614 11:07:42.144707   413 net.cpp:144] Setting up relu3
I0614 11:07:42.144711   413 net.cpp:151] Top shape: 1 384 13 13 (64896)
I0614 11:07:42.144714   413 net.cpp:159] Memory required for data: 7314796
I0614 11:07:42.144716   413 layer_factory.hpp:77] Creating layer conv4
I0614 11:07:42.144723   413 net.cpp:94] Creating Layer conv4
I0614 11:07:42.144726   413 net.cpp:435] conv4 <- relu3
I0614 11:07:42.144730   413 net.cpp:409] conv4 -> conv4
I0614 11:07:42.156183   413 net.cpp:144] Setting up conv4
I0614 11:07:42.156193   413 net.cpp:151] Top shape: 1 384 13 13 (64896)
I0614 11:07:42.156199   413 net.cpp:159] Memory required for data: 7574380
I0614 11:07:42.156208   413 layer_factory.hpp:77] Creating layer relu4
I0614 11:07:42.156214   413 net.cpp:94] Creating Layer relu4
I0614 11:07:42.156219   413 net.cpp:435] relu4 <- conv4
I0614 11:07:42.156221   413 net.cpp:409] relu4 -> relu4
I0614 11:07:42.156234   413 net.cpp:144] Setting up relu4
I0614 11:07:42.156236   413 net.cpp:151] Top shape: 1 384 13 13 (64896)
I0614 11:07:42.156240   413 net.cpp:159] Memory required for data: 7833964
I0614 11:07:42.156242   413 layer_factory.hpp:77] Creating layer conv5
I0614 11:07:42.156250   413 net.cpp:94] Creating Layer conv5
I0614 11:07:42.156253   413 net.cpp:435] conv5 <- relu4
I0614 11:07:42.156256   413 net.cpp:409] conv5 -> conv5
I0614 11:07:42.164125   413 net.cpp:144] Setting up conv5
I0614 11:07:42.164136   413 net.cpp:151] Top shape: 1 256 13 13 (43264)
I0614 11:07:42.164142   413 net.cpp:159] Memory required for data: 8007020
I0614 11:07:42.164147   413 layer_factory.hpp:77] Creating layer relu5
I0614 11:07:42.164153   413 net.cpp:94] Creating Layer relu5
I0614 11:07:42.164156   413 net.cpp:435] relu5 <- conv5
I0614 11:07:42.164160   413 net.cpp:409] relu5 -> relu5
I0614 11:07:42.164172   413 net.cpp:144] Setting up relu5
I0614 11:07:42.164175   413 net.cpp:151] Top shape: 1 256 13 13 (43264)
I0614 11:07:42.164178   413 net.cpp:159] Memory required for data: 8180076
I0614 11:07:42.164181   413 layer_factory.hpp:77] Creating layer pool5
I0614 11:07:42.164187   413 net.cpp:94] Creating Layer pool5
I0614 11:07:42.164191   413 net.cpp:435] pool5 <- relu5
I0614 11:07:42.164193   413 net.cpp:409] pool5 -> pool5
I0614 11:07:42.164207   413 net.cpp:144] Setting up pool5
I0614 11:07:42.164211   413 net.cpp:151] Top shape: 1 256 6 6 (9216)
I0614 11:07:42.164213   413 net.cpp:159] Memory required for data: 8216940
I0614 11:07:42.164216   413 layer_factory.hpp:77] Creating layer fc6
I0614 11:07:42.164223   413 net.cpp:94] Creating Layer fc6
I0614 11:07:42.164227   413 net.cpp:435] fc6 <- pool5
I0614 11:07:42.164229   413 net.cpp:409] fc6 -> fc6
I0614 11:07:42.486274   413 net.cpp:144] Setting up fc6
I0614 11:07:42.486294   413 net.cpp:151] Top shape: 1 4096 (4096)
I0614 11:07:42.486300   413 net.cpp:159] Memory required for data: 8233324
I0614 11:07:42.486311   413 layer_factory.hpp:77] Creating layer relu6
I0614 11:07:42.486320   413 net.cpp:94] Creating Layer relu6
I0614 11:07:42.486325   413 net.cpp:435] relu6 <- fc6
I0614 11:07:42.486330   413 net.cpp:409] relu6 -> relu6
I0614 11:07:42.486346   413 net.cpp:144] Setting up relu6
I0614 11:07:42.486348   413 net.cpp:151] Top shape: 1 4096 (4096)
I0614 11:07:42.486351   413 net.cpp:159] Memory required for data: 8249708
I0614 11:07:42.486354   413 layer_factory.hpp:77] Creating layer drop6
I0614 11:07:42.486359   413 net.cpp:94] Creating Layer drop6
I0614 11:07:42.486361   413 net.cpp:435] drop6 <- relu6
I0614 11:07:42.486366   413 net.cpp:409] drop6 -> drop6
I0614 11:07:42.486379   413 net.cpp:144] Setting up drop6
I0614 11:07:42.486382   413 net.cpp:151] Top shape: 1 4096 (4096)
I0614 11:07:42.486384   413 net.cpp:159] Memory required for data: 8266092
I0614 11:07:42.486387   413 layer_factory.hpp:77] Creating layer fc7
I0614 11:07:42.486393   413 net.cpp:94] Creating Layer fc7
I0614 11:07:42.486397   413 net.cpp:435] fc7 <- drop6
I0614 11:07:42.486399   413 net.cpp:409] fc7 -> fc7
I0614 11:07:42.629344   413 net.cpp:144] Setting up fc7
I0614 11:07:42.629367   413 net.cpp:151] Top shape: 1 4096 (4096)
I0614 11:07:42.629374   413 net.cpp:159] Memory required for data: 8282476
I0614 11:07:42.629392   413 layer_factory.hpp:77] Creating layer bn7
I0614 11:07:42.629403   413 net.cpp:94] Creating Layer bn7
I0614 11:07:42.629407   413 net.cpp:435] bn7 <- fc7
I0614 11:07:42.629412   413 net.cpp:409] bn7 -> bn7
I0614 11:07:42.629703   413 net.cpp:144] Setting up bn7
I0614 11:07:42.629709   413 net.cpp:151] Top shape: 1 4096 (4096)
I0614 11:07:42.629714   413 net.cpp:159] Memory required for data: 8298860
I0614 11:07:42.629720   413 layer_factory.hpp:77] Creating layer relu7
I0614 11:07:42.629725   413 net.cpp:94] Creating Layer relu7
I0614 11:07:42.629729   413 net.cpp:435] relu7 <- bn7
I0614 11:07:42.629732   413 net.cpp:409] relu7 -> relu7
I0614 11:07:42.629745   413 net.cpp:144] Setting up relu7
I0614 11:07:42.629747   413 net.cpp:151] Top shape: 1 4096 (4096)
I0614 11:07:42.629751   413 net.cpp:159] Memory required for data: 8315244
I0614 11:07:42.629753   413 layer_factory.hpp:77] Creating layer drop7
I0614 11:07:42.629758   413 net.cpp:94] Creating Layer drop7
I0614 11:07:42.629761   413 net.cpp:435] drop7 <- relu7
I0614 11:07:42.629765   413 net.cpp:409] drop7 -> drop7
I0614 11:07:42.629778   413 net.cpp:144] Setting up drop7
I0614 11:07:42.629781   413 net.cpp:151] Top shape: 1 4096 (4096)
I0614 11:07:42.629786   413 net.cpp:159] Memory required for data: 8331628
I0614 11:07:42.629787   413 layer_factory.hpp:77] Creating layer fc8
I0614 11:07:42.629796   413 net.cpp:94] Creating Layer fc8
I0614 11:07:42.629798   413 net.cpp:435] fc8 <- drop7
I0614 11:07:42.629801   413 net.cpp:409] fc8 -> fc8
I0614 11:07:42.629910   413 net.cpp:144] Setting up fc8
I0614 11:07:42.629913   413 net.cpp:151] Top shape: 1 2 (2)
I0614 11:07:42.629917   413 net.cpp:159] Memory required for data: 8331636
I0614 11:07:42.629921   413 layer_factory.hpp:77] Creating layer prob
I0614 11:07:42.629927   413 net.cpp:94] Creating Layer prob
I0614 11:07:42.629930   413 net.cpp:435] prob <- fc8
I0614 11:07:42.629935   413 net.cpp:409] prob -> prob
I0614 11:07:42.629981   413 net.cpp:144] Setting up prob
I0614 11:07:42.629984   413 net.cpp:151] Top shape: 1 2 (2)
I0614 11:07:42.629987   413 net.cpp:159] Memory required for data: 8331644
I0614 11:07:42.629990   413 net.cpp:222] prob does not need backward computation.
I0614 11:07:42.629994   413 net.cpp:222] fc8 does not need backward computation.
I0614 11:07:42.629997   413 net.cpp:222] drop7 does not need backward computation.
I0614 11:07:42.630000   413 net.cpp:222] relu7 does not need backward computation.
I0614 11:07:42.630003   413 net.cpp:222] bn7 does not need backward computation.
I0614 11:07:42.630007   413 net.cpp:222] fc7 does not need backward computation.
I0614 11:07:42.630010   413 net.cpp:222] drop6 does not need backward computation.
I0614 11:07:42.630013   413 net.cpp:222] relu6 does not need backward computation.
I0614 11:07:42.630017   413 net.cpp:222] fc6 does not need backward computation.
I0614 11:07:42.630020   413 net.cpp:222] pool5 does not need backward computation.
I0614 11:07:42.630023   413 net.cpp:222] relu5 does not need backward computation.
I0614 11:07:42.630028   413 net.cpp:222] conv5 does not need backward computation.
I0614 11:07:42.630030   413 net.cpp:222] relu4 does not need backward computation.
I0614 11:07:42.630034   413 net.cpp:222] conv4 does not need backward computation.
I0614 11:07:42.630038   413 net.cpp:222] relu3 does not need backward computation.
I0614 11:07:42.630040   413 net.cpp:222] conv3 does not need backward computation.
I0614 11:07:42.630043   413 net.cpp:222] pool2 does not need backward computation.
I0614 11:07:42.630048   413 net.cpp:222] relu2 does not need backward computation.
I0614 11:07:42.630050   413 net.cpp:222] bn2 does not need backward computation.
I0614 11:07:42.630053   413 net.cpp:222] conv2 does not need backward computation.
I0614 11:07:42.630057   413 net.cpp:222] pool1 does not need backward computation.
I0614 11:07:42.630060   413 net.cpp:222] relu1 does not need backward computation.
I0614 11:07:42.630064   413 net.cpp:222] bn1 does not need backward computation.
I0614 11:07:42.630066   413 net.cpp:222] conv1 does not need backward computation.
I0614 11:07:42.630069   413 net.cpp:222] data does not need backward computation.
I0614 11:07:42.630072   413 net.cpp:264] This network produces output prob
I0614 11:07:42.630089   413 net.cpp:284] Network initialization done.
I0614 11:07:43.246075   413 net.cpp:823] Ignoring source layer loss
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8074.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8074.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7643.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7643.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7660.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7660.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7678.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7678.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7695.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7695.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7711.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7711.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7729.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7729.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7746.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7746.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7763.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7763.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7769.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7769.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.777.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.777.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7770.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7770.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7771.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7771.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7772.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7772.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7773.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7773.jpg
PREDICTED: 1
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7774.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7774.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7775.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7775.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7776.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7776.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7777.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7777.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7778.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7778.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7779.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7779.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.778.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.778.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7780.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7780.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7781.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7781.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7782.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7782.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7783.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7783.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7784.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7784.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7785.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7785.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7787.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7787.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7788.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7788.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7789.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7789.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.779.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.779.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7790.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7790.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7791.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7791.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7792.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7792.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7793.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7793.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7794.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7794.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7795.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7795.jpg
PREDICTED: 1
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7796.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7796.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7797.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7797.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7798.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7798.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7799.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7799.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.78.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.78.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.780.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.780.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7800.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7800.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7801.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7801.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7802.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7802.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7804.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7804.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7805.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7805.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7806.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7806.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7807.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7807.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7808.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7808.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7809.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7809.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.781.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.781.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7810.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7810.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7811.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7811.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7812.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7812.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7813.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7813.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7814.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7814.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7815.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7815.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7816.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7816.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7817.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7817.jpg
PREDICTED: 1
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7818.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7818.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7819.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7819.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.782.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.782.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7820.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7820.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7822.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7822.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7823.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7823.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7824.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7824.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7825.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7825.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7826.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7826.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7827.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7827.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7828.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7828.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7829.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7829.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.783.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.783.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7830.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7830.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7831.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7831.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7832.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7832.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7833.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7833.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7834.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7834.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7835.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7835.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7836.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7836.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7837.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7837.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7838.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7838.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7839.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7839.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7786.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7786.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7803.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7803.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7821.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7821.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.784.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.784.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7858.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7858.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7876.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7876.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7894.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7894.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7911.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7911.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.793.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.793.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7948.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7948.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7966.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7966.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7984.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7984.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8000.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8000.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.802.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.802.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8038.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8038.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8056.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8056.jpg
PREDICTED: 1
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7840.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7840.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7841.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7841.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7842.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7842.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7843.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7843.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7844.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7844.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7845.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7845.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7846.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7846.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7847.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7847.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7848.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7848.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7849.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7849.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.785.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.785.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7850.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7850.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7851.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7851.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7852.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7852.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7853.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7853.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7854.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7854.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7855.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7855.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7856.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7856.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7857.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7857.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7859.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7859.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.786.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.786.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7860.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7860.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7861.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7861.jpg
PREDICTED: 1
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7862.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7862.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7863.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7863.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7864.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7864.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7865.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7865.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7866.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7866.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7867.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7867.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7868.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7868.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7869.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7869.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.787.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.787.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7870.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7870.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7871.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7871.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7872.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7872.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7873.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7873.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7874.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7874.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7875.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7875.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7877.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7877.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7878.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7878.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7879.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7879.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.788.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.788.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7880.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7880.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7881.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7881.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7882.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7882.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7883.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7883.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7884.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7884.jpg
PREDICTED: 1
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7885.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7885.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7886.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7886.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7887.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7887.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7888.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7888.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7889.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7889.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.789.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.789.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7890.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7890.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7891.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7891.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7892.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7892.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7893.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7893.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7895.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7895.jpg
PREDICTED: 1
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7896.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7896.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7897.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7897.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7898.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7898.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7899.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7899.jpg
PREDICTED: 1
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.79.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.79.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.790.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.790.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7900.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7900.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7901.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7901.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7902.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7902.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7903.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7903.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7904.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7904.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7905.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7905.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7906.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7906.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7907.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7907.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7908.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7908.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7909.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7909.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.791.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.791.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7910.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7910.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7912.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7912.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7913.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7913.jpg
PREDICTED: 1
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7914.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7914.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7915.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7915.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7916.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7916.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7918.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7918.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7919.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7919.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.792.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.792.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7920.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7920.jpg
PREDICTED: 1
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7921.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7921.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7922.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7922.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7923.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7923.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7924.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7924.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7925.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7925.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7926.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7926.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7927.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7927.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7928.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7928.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7929.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7929.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7930.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7930.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7931.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7931.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7932.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7932.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7933.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7933.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7934.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7934.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7935.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7935.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7936.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7936.jpg
PREDICTED: 1
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7937.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7937.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7938.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7938.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7939.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7939.jpg
PREDICTED: 1
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.794.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.794.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7940.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7940.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7941.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7941.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7942.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7942.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7943.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7943.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7944.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7944.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7945.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7945.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7946.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7946.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7947.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7947.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7949.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7949.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.795.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.795.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7950.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7950.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7951.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7951.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7952.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7952.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7953.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7953.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7954.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7954.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7955.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7955.jpg
PREDICTED: 1
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7956.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7956.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7957.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7957.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7958.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7958.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7959.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7959.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.796.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.796.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7960.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7960.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7961.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7961.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7962.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7962.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7963.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7963.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7964.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7964.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7965.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7965.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7967.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7967.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7968.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7968.jpg
PREDICTED: 1
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7969.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7969.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.797.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.797.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7970.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7970.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7971.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7971.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7972.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7972.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7973.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7973.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7974.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7974.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7975.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7975.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7976.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7976.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7977.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7977.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7978.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7978.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7979.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7979.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.798.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.798.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7980.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7980.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7981.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7981.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7982.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7982.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7983.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7983.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7985.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7985.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7987.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7987.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7988.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7988.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7989.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7989.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.799.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.799.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7990.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7990.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7991.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7991.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7992.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7992.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7993.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7993.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7994.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7994.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7995.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7995.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7996.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7996.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7997.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7997.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7998.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7998.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7999.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.7999.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.80.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.80.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.800.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.800.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8002.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8002.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8003.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8003.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8004.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8004.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8005.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8005.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8006.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8006.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8007.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8007.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8008.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8008.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8009.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8009.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.801.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.801.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8010.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8010.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8011.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8011.jpg
PREDICTED: 1
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8012.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8012.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8013.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8013.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8014.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8014.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8015.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8015.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8016.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8016.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8017.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8017.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8018.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8018.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8020.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8020.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8021.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8021.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8022.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8022.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8023.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8023.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8024.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8024.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8025.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8025.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8026.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8026.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8027.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8027.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8028.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8028.jpg
PREDICTED: 1
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8029.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8029.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.803.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.803.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8030.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8030.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8031.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8031.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8032.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8032.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8033.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8033.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8034.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8034.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8035.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8035.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8037.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8037.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8039.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8039.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.804.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.804.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8040.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8040.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8041.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8041.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8042.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8042.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8043.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8043.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8044.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8044.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8045.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8045.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8046.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8046.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8047.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8047.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8048.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8048.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8049.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8049.jpg
PREDICTED: 1
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.805.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.805.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8050.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8050.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8051.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8051.jpg
PREDICTED: 1
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8052.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8052.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8054.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8054.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8055.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8055.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8057.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8057.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8058.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8058.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8059.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8059.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.806.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.806.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8060.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8060.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8061.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8061.jpg
PREDICTED: 1
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8062.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8062.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8063.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8063.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8064.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8064.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8065.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8065.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8066.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8066.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8067.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8067.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8068.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8068.jpg
PREDICTED: 1
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8069.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8069.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.807.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.807.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8071.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8071.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8072.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8072.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8073.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8073.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8075.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8075.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8076.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8076.jpg
PREDICTED: 1
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8077.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8077.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8078.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8078.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8079.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8079.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.808.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.808.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8080.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8080.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8081.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8081.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8082.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8082.jpg
PREDICTED: 1
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8083.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8083.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8084.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8084.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8085.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8085.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8086.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8086.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8087.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8087.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8089.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8089.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.809.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.809.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8090.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8090.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8091.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8091.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8093.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8093.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8094.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8094.jpg
PREDICTED: 1
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8095.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8095.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8096.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8096.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8097.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8097.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8098.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8098.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8099.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8099.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.81.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.81.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.810.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.810.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8100.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8100.jpg
PREDICTED: 1
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8101.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8101.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8102.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8102.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8103.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8103.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8105.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8105.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8106.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8106.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8107.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8107.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8108.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8108.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8109.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8109.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8110.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8110.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8111.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8111.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8112.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8112.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8113.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8113.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8114.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8114.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8115.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8115.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8116.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8116.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8117.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8117.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8118.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8118.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8119.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8119.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.812.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.812.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8120.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8120.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8122.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8122.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8123.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8123.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8124.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8124.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8125.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8125.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8126.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8126.jpg
PREDICTED: 1
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8127.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8127.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8129.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8129.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.813.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.813.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8130.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8130.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8131.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8131.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8132.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8132.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8133.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8133.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8134.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8134.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8135.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8135.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8136.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8136.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8137.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8137.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8138.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8138.jpg
PREDICTED: 1
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.814.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.814.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8140.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8140.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8141.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8141.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8142.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8142.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8143.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8143.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8144.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8144.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8145.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8145.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8147.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8147.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8148.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8148.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8149.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8149.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.815.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.815.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8150.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8150.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8151.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8151.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8152.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8152.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8153.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8153.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8154.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8154.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8155.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8155.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8157.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8157.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8158.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8158.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8159.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8159.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.816.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.816.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8160.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8160.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8161.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8161.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8162.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8162.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8163.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8163.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8165.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8165.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8166.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8166.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8167.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8167.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8168.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8168.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8169.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8169.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.817.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.817.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8170.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8170.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8171.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8171.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8172.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8172.jpg
PREDICTED: 1
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8174.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8174.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8175.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8175.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8176.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8176.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8177.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8177.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8178.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8178.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8179.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8179.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.818.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.818.jpg
PREDICTED: 1
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8180.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8180.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8181.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8181.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8183.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8183.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8184.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8184.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8185.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8185.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8186.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8186.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8187.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8187.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8188.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8188.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8189.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8189.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.819.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.819.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8191.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8191.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8192.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8192.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8193.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8193.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8194.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8194.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8195.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8195.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8196.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8196.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8197.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8197.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8198.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8198.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8199.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8199.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.82.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.82.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8200.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8200.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8201.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8201.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8202.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8202.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8203.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8203.jpg
PREDICTED: 1
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8204.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8204.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8205.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8205.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8206.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8206.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8208.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8208.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8209.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8209.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.821.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.821.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8210.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8210.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8211.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8211.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8212.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8212.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8213.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8213.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8214.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8214.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8215.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8215.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8216.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8216.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8217.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8217.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8219.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8219.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.822.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.822.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8220.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8220.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8221.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8221.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8222.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8222.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8223.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8223.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7643.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7643.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7660.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7660.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7678.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7678.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7695.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7695.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7711.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7711.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7729.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7729.jpg
PREDICTED: 0
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7746.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7746.jpg
PREDICTED: 0
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7763.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7763.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7769.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7769.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.777.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.777.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7770.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7770.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7771.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7771.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7772.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7772.jpg
PREDICTED: 0
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7773.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7773.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7774.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7774.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7775.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7775.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7776.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7776.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7777.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7777.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7778.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7778.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7779.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7779.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7780.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7780.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7781.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7781.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7782.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7782.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7783.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7783.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7784.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7784.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7785.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7785.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7786.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7786.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7787.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7787.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7788.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7788.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7789.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7789.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.779.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.779.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7790.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7790.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7791.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7791.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7792.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7792.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7793.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7793.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7794.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7794.jpg
PREDICTED: 0
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7795.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7795.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7796.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7796.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7797.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7797.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7798.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7798.jpg
PREDICTED: 0
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.78.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.78.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.780.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.780.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7800.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7800.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7801.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7801.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7802.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7802.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7803.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7803.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7804.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7804.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7805.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7805.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7806.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7806.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7807.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7807.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7808.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7808.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7809.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7809.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.781.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.781.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7810.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7810.jpg
PREDICTED: 0
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7811.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7811.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7812.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7812.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7813.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7813.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7814.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7814.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7815.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7815.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7817.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7817.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7818.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7818.jpg
PREDICTED: 0
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7819.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7819.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.782.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.782.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7820.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7820.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7821.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7821.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7822.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7822.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7823.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7823.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7824.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7824.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7825.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7825.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7826.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7826.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7827.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7827.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7828.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7828.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7829.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7829.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.783.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.783.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7830.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7830.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7831.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7831.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7832.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7832.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7833.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7833.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7835.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7835.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7836.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7836.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7837.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7837.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7838.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7838.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7839.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7839.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.784.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.784.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7840.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7840.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7841.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7841.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7842.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7842.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7843.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7843.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7844.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7844.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7845.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7845.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7846.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7846.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7847.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7847.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7848.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7848.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7849.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7849.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.785.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.785.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7850.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7850.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7851.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7851.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7853.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7853.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7854.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7854.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7855.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7855.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7856.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7856.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7857.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7857.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7858.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7858.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7859.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7859.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.786.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.786.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7860.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7860.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7861.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7861.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7862.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7862.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7863.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7863.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7864.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7864.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7865.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7865.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7866.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7866.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7867.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7867.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7868.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7868.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7869.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7869.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.787.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.787.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7871.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7871.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7872.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7872.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7873.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7873.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7874.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7874.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7875.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7875.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7876.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7876.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7877.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7877.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7878.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7878.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7879.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7879.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.788.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.788.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7880.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7880.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7881.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7881.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7882.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7882.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7883.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7883.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7884.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7884.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7885.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7885.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7886.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7886.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7887.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7887.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7888.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7888.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.789.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.789.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7890.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7890.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7891.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7891.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7892.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7892.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7893.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7893.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7894.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7894.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7895.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7895.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7896.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7896.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7897.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7897.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7898.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7898.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7899.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7899.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.79.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.79.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.790.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.790.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7900.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7900.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7901.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7901.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7902.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7902.jpg
PREDICTED: 0
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7903.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7903.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7904.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7904.jpg
PREDICTED: 0
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7905.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7905.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7907.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7907.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7908.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7908.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7909.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7909.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.791.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.791.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7910.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7910.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7911.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7911.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7912.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7912.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7913.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7913.jpg
PREDICTED: 0
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7914.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7914.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7915.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7915.jpg
PREDICTED: 0
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7916.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7916.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7918.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7918.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7919.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7919.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.792.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.792.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7920.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7920.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7921.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7921.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7922.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7922.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7923.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7923.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7925.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7925.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7926.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7926.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7927.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7927.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7928.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7928.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7929.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7929.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.793.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.793.jpg
PREDICTED: 0
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7930.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7930.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7931.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7931.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7932.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7932.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7933.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7933.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7934.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7934.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7935.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7935.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7936.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7936.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7937.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7937.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7938.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7938.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7939.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7939.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.794.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.794.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7940.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7940.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7941.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7941.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8092.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8092.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.811.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.811.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8128.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8128.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8146.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8146.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8164.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8164.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8182.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8182.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.820.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.820.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8218.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/cat.8218.jpg
PREDICTED: 0
EXPECTED : 0
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.778.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.778.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7799.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7799.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7816.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7816.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7834.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7834.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7852.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7852.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7870.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7870.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7889.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7889.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7906.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7906.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7924.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7924.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7942.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7942.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7960.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7960.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7979.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7979.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7997.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7997.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8013.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8013.jpg
PREDICTED: 0
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8031.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8031.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.805.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.805.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8068.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8068.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8086.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8086.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8103.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8103.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8122.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8122.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8140.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8140.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8159.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8159.jpg
PREDICTED: 0
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8177.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8177.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8195.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8195.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7943.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7943.jpg
PREDICTED: 0
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7944.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7944.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7945.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7945.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7946.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7946.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7947.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7947.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7948.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7948.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7949.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7949.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.795.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.795.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7950.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7950.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7951.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7951.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7952.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7952.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7953.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7953.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7954.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7954.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7955.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7955.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7956.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7956.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7957.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7957.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7958.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7958.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7959.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7959.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.796.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.796.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7961.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7961.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7962.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7962.jpg
PREDICTED: 0
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7963.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7963.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7964.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7964.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7965.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7965.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7966.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7966.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7967.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7967.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7968.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7968.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7969.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7969.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.797.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.797.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7970.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7970.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7971.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7971.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7972.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7972.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7973.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7973.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7974.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7974.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7975.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7975.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7976.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7976.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7977.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7977.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7978.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7978.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.798.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.798.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7980.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7980.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7981.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7981.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7982.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7982.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7983.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7983.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7984.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7984.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7985.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7985.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7987.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7987.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7988.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7988.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7989.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7989.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.799.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.799.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7990.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7990.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7991.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7991.jpg
PREDICTED: 0
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7992.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7992.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7993.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7993.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7994.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7994.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7995.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7995.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7996.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7996.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7998.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7998.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7999.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.7999.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.80.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.80.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.800.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.800.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8000.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8000.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8002.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8002.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8003.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8003.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8004.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8004.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8005.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8005.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8006.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8006.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8007.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8007.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8008.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8008.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8009.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8009.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.801.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.801.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8010.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8010.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8011.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8011.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8012.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8012.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8014.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8014.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8015.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8015.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8016.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8016.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8017.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8017.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8018.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8018.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.802.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.802.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8020.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8020.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8021.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8021.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8022.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8022.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8023.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8023.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8024.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8024.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8025.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8025.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8026.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8026.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8027.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8027.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8028.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8028.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8029.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8029.jpg
PREDICTED: 0
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.803.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.803.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8030.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8030.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8032.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8032.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8033.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8033.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8034.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8034.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8035.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8035.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8037.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8037.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8038.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8038.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8039.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8039.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.804.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.804.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8040.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8040.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8041.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8041.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8042.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8042.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8043.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8043.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8044.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8044.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8045.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8045.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8046.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8046.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8047.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8047.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8048.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8048.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8049.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8049.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8050.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8050.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8051.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8051.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8052.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8052.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8054.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8054.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8055.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8055.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8056.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8056.jpg
PREDICTED: 0
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8057.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8057.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8058.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8058.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8059.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8059.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.806.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.806.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8060.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8060.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8061.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8061.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8062.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8062.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8063.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8063.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8064.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8064.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8065.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8065.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8066.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8066.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8067.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8067.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8069.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8069.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.807.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.807.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8071.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8071.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8072.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8072.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8073.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8073.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8074.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8074.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8075.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8075.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8076.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8076.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8077.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8077.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8078.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8078.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8079.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8079.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.808.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.808.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8080.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8080.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8081.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8081.jpg
PREDICTED: 0
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8082.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8082.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8083.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8083.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8084.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8084.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8085.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8085.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8087.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8087.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8089.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8089.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.809.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.809.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8090.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8090.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8091.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8091.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8092.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8092.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8093.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8093.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8094.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8094.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8095.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8095.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8096.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8096.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8097.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8097.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8098.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8098.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8099.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8099.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.81.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.81.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.810.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.810.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8100.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8100.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8101.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8101.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8102.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8102.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8105.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8105.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8106.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8106.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8107.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8107.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8108.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8108.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8109.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8109.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.811.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.811.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8110.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8110.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8111.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8111.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8112.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8112.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8113.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8113.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8114.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8114.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8115.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8115.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8116.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8116.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8117.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8117.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8118.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8118.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8119.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8119.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.812.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.812.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8120.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8120.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8123.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8123.jpg
PREDICTED: 0
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8124.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8124.jpg
PREDICTED: 0
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8125.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8125.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8126.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8126.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8127.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8127.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8128.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8128.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8129.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8129.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.813.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.813.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8130.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8130.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8131.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8131.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8132.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8132.jpg
PREDICTED: 0
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8133.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8133.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8134.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8134.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8135.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8135.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8136.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8136.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8137.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8137.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8138.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8138.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.814.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.814.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8141.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8141.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8142.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8142.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8143.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8143.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8144.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8144.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8145.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8145.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8146.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8146.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8147.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8147.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8148.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8148.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8149.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8149.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.815.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.815.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8150.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8150.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8151.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8151.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8152.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8152.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8153.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8153.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8154.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8154.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8155.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8155.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8157.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8157.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8158.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8158.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.816.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.816.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8160.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8160.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8161.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8161.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8162.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8162.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8163.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8163.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8164.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8164.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8165.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8165.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8166.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8166.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8167.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8167.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8168.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8168.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8169.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8169.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.817.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.817.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8170.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8170.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8171.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8171.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8172.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8172.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8174.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8174.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8175.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8175.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8176.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8176.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8178.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8178.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8179.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8179.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.818.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.818.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8180.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8180.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8181.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8181.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8182.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8182.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8183.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8183.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8184.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8184.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8185.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8185.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8186.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8186.jpg
PREDICTED: 0
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8187.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8187.jpg
PREDICTED: 0
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8188.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8188.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8189.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8189.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.819.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.819.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8191.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8191.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8192.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8192.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8193.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8193.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8194.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8194.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8196.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8196.jpg
PREDICTED: 0
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8197.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8197.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8198.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8198.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8199.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8199.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.82.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.82.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.820.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.820.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8200.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8200.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8201.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8201.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8202.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8202.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8203.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8203.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8204.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8204.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8205.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8205.jpg
PREDICTED: 0
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8206.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8206.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8208.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8208.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8209.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8209.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.821.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.821.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8210.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8210.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8211.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8211.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8212.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8212.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8213.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8213.jpg
PREDICTED: 0
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8214.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8214.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8215.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8215.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8216.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8216.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8217.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8217.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8218.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8218.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8219.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8219.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.822.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.822.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8220.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8220.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8221.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8221.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8222.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8222.jpg
PREDICTED: 1
EXPECTED : 1
-------
/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8223.jpg
IMAGE: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/input/jpg/test/dog.8223.jpg
PREDICTED: 1
EXPECTED : 1
-------
              precision    recall  f1-score   support

         cat       0.94      0.94      0.94       500
         dog       0.94      0.94      0.94       500

    accuracy                           0.94      1000
   macro avg       0.94      0.94      0.94      1000
weighted avg       0.94      0.94      0.94      1000

SKLEARN Accuracy = 0.94
I0614 11:07:47.554375   446 gpu_memory.cpp:53] GPUMemory::Manager initialized with Caching (CUB) GPU Allocator
I0614 11:07:47.554584   446 gpu_memory.cpp:55] Total memory: 25635127296, Free: 24855642112, dev_info[0]: total=25635127296 free=24855642112
I0614 11:07:47.554729   446 caffe.cpp:213] Using GPUs 0
I0614 11:07:47.554816   446 caffe.cpp:218] GPU 0: Quadro P6000
I0614 11:07:48.222834   446 solver.cpp:51] Initializing solver from parameters: 
test_iter: 80
test_interval: 1000
base_lr: 0.001
display: 50
max_iter: 20000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 2500
snapshot: 5000
snapshot_prefix: "caffe/models/alexnetBNnoLRN/m2/snapshot_2_alexnetBNnoLRN_"
solver_mode: GPU
device_id: 0
random_seed: 1201
net: "caffe/models/alexnetBNnoLRN/m2/train_val_2_alexnetBNnoLRN.prototxt"
type: "Adam"
I0614 11:07:48.223749   446 solver.cpp:99] Creating training net from net file: caffe/models/alexnetBNnoLRN/m2/train_val_2_alexnetBNnoLRN.prototxt
I0614 11:07:48.224808   446 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0614 11:07:48.224826   446 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0614 11:07:48.224830   446 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy-top1
I0614 11:07:48.224835   446 net.cpp:52] Initializing net from parameters: 
name: "alexnetBNnoLRN m2 (as m3 but less DROP and less BN)"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_value: 106
    mean_value: 116
    mean_value: 124
  }
  data_param {
    source: "input/lmdb/train_lmdb"
    batch_size: 256
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 0
    kernel_size: 8
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "bn1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "bn2"
  top: "relu2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "relu6"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "drop6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn7"
  type: "BatchNorm"
  bottom: "fc7"
  top: "bn7"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "bn7"
  top: "relu7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "relu7"
  top: "drop7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "drop7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0614 11:07:48.225023   446 layer_factory.hpp:77] Creating layer data
I0614 11:07:48.225136   446 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0614 11:07:48.227406   446 net.cpp:94] Creating Layer data
I0614 11:07:48.227449   446 net.cpp:409] data -> data
I0614 11:07:48.227483   446 net.cpp:409] data -> label
I0614 11:07:48.229182   478 db_lmdb.cpp:35] Opened lmdb input/lmdb/train_lmdb
I0614 11:07:48.229212   478 db_lmdb.cpp:38] Items count: 20000
I0614 11:07:48.229246   478 data_reader.cpp:124] TRAIN: reading data using 1 channel(s)
I0614 11:07:48.229682   446 data_layer.cpp:78] ReshapePrefetch 256, 3, 227, 227
I0614 11:07:48.229872   446 data_layer.cpp:83] output data size: 256,3,227,227
I0614 11:07:48.766398   446 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0614 11:07:48.766626   446 net.cpp:144] Setting up data
I0614 11:07:48.766652   446 net.cpp:151] Top shape: 256 3 227 227 (39574272)
I0614 11:07:48.766664   446 net.cpp:151] Top shape: 256 (256)
I0614 11:07:48.766669   446 net.cpp:159] Memory required for data: 158298112
I0614 11:07:48.766677   446 layer_factory.hpp:77] Creating layer conv1
I0614 11:07:48.766716   446 net.cpp:94] Creating Layer conv1
I0614 11:07:48.766721   446 net.cpp:435] conv1 <- data
I0614 11:07:48.766728   446 net.cpp:409] conv1 -> conv1
I0614 11:07:48.767122   446 net.cpp:144] Setting up conv1
I0614 11:07:48.767130   446 net.cpp:151] Top shape: 256 96 55 55 (74342400)
I0614 11:07:48.767136   446 net.cpp:159] Memory required for data: 455667712
I0614 11:07:48.767148   446 layer_factory.hpp:77] Creating layer bn1
I0614 11:07:48.767174   446 net.cpp:94] Creating Layer bn1
I0614 11:07:48.767179   446 net.cpp:435] bn1 <- conv1
I0614 11:07:48.767184   446 net.cpp:409] bn1 -> bn1
I0614 11:07:48.767484   446 net.cpp:144] Setting up bn1
I0614 11:07:48.767491   446 net.cpp:151] Top shape: 256 96 55 55 (74342400)
I0614 11:07:48.767498   446 net.cpp:159] Memory required for data: 753037312
I0614 11:07:48.767509   446 layer_factory.hpp:77] Creating layer relu1
I0614 11:07:48.767516   446 net.cpp:94] Creating Layer relu1
I0614 11:07:48.767519   446 net.cpp:435] relu1 <- bn1
I0614 11:07:48.767524   446 net.cpp:409] relu1 -> relu1
I0614 11:07:48.767541   446 net.cpp:144] Setting up relu1
I0614 11:07:48.767545   446 net.cpp:151] Top shape: 256 96 55 55 (74342400)
I0614 11:07:48.767550   446 net.cpp:159] Memory required for data: 1050406912
I0614 11:07:48.767554   446 layer_factory.hpp:77] Creating layer pool1
I0614 11:07:48.767560   446 net.cpp:94] Creating Layer pool1
I0614 11:07:48.767565   446 net.cpp:435] pool1 <- relu1
I0614 11:07:48.767568   446 net.cpp:409] pool1 -> pool1
I0614 11:07:48.767585   446 net.cpp:144] Setting up pool1
I0614 11:07:48.767587   446 net.cpp:151] Top shape: 256 96 27 27 (17915904)
I0614 11:07:48.767592   446 net.cpp:159] Memory required for data: 1122070528
I0614 11:07:48.767596   446 layer_factory.hpp:77] Creating layer conv2
I0614 11:07:48.767606   446 net.cpp:94] Creating Layer conv2
I0614 11:07:48.767611   446 net.cpp:435] conv2 <- pool1
I0614 11:07:48.767616   446 net.cpp:409] conv2 -> conv2
I0614 11:07:48.783948   446 net.cpp:144] Setting up conv2
I0614 11:07:48.783967   446 net.cpp:151] Top shape: 256 256 27 27 (47775744)
I0614 11:07:48.783975   446 net.cpp:159] Memory required for data: 1313173504
I0614 11:07:48.783989   446 layer_factory.hpp:77] Creating layer bn2
I0614 11:07:48.784003   446 net.cpp:94] Creating Layer bn2
I0614 11:07:48.784010   446 net.cpp:435] bn2 <- conv2
I0614 11:07:48.784019   446 net.cpp:409] bn2 -> bn2
I0614 11:07:48.784355   446 net.cpp:144] Setting up bn2
I0614 11:07:48.784365   446 net.cpp:151] Top shape: 256 256 27 27 (47775744)
I0614 11:07:48.784372   446 net.cpp:159] Memory required for data: 1504276480
I0614 11:07:48.784384   446 layer_factory.hpp:77] Creating layer relu2
I0614 11:07:48.784391   446 net.cpp:94] Creating Layer relu2
I0614 11:07:48.784399   446 net.cpp:435] relu2 <- bn2
I0614 11:07:48.784406   446 net.cpp:409] relu2 -> relu2
I0614 11:07:48.784422   446 net.cpp:144] Setting up relu2
I0614 11:07:48.784427   446 net.cpp:151] Top shape: 256 256 27 27 (47775744)
I0614 11:07:48.784433   446 net.cpp:159] Memory required for data: 1695379456
I0614 11:07:48.784437   446 layer_factory.hpp:77] Creating layer pool2
I0614 11:07:48.784446   446 net.cpp:94] Creating Layer pool2
I0614 11:07:48.784453   446 net.cpp:435] pool2 <- relu2
I0614 11:07:48.784458   446 net.cpp:409] pool2 -> pool2
I0614 11:07:48.784477   446 net.cpp:144] Setting up pool2
I0614 11:07:48.784482   446 net.cpp:151] Top shape: 256 256 13 13 (11075584)
I0614 11:07:48.784487   446 net.cpp:159] Memory required for data: 1739681792
I0614 11:07:48.784492   446 layer_factory.hpp:77] Creating layer conv3
I0614 11:07:48.784500   446 net.cpp:94] Creating Layer conv3
I0614 11:07:48.784505   446 net.cpp:435] conv3 <- pool2
I0614 11:07:48.784512   446 net.cpp:409] conv3 -> conv3
I0614 11:07:48.823937   446 net.cpp:144] Setting up conv3
I0614 11:07:48.824036   446 net.cpp:151] Top shape: 256 384 13 13 (16613376)
I0614 11:07:48.824057   446 net.cpp:159] Memory required for data: 1806135296
I0614 11:07:48.824079   446 layer_factory.hpp:77] Creating layer relu3
I0614 11:07:48.824097   446 net.cpp:94] Creating Layer relu3
I0614 11:07:48.824108   446 net.cpp:435] relu3 <- conv3
I0614 11:07:48.824124   446 net.cpp:409] relu3 -> relu3
I0614 11:07:48.824170   446 net.cpp:144] Setting up relu3
I0614 11:07:48.824179   446 net.cpp:151] Top shape: 256 384 13 13 (16613376)
I0614 11:07:48.824193   446 net.cpp:159] Memory required for data: 1872588800
I0614 11:07:48.824201   446 layer_factory.hpp:77] Creating layer conv4
I0614 11:07:48.824256   446 net.cpp:94] Creating Layer conv4
I0614 11:07:48.824266   446 net.cpp:435] conv4 <- relu3
I0614 11:07:48.824278   446 net.cpp:409] conv4 -> conv4
I0614 11:07:48.859364   446 net.cpp:144] Setting up conv4
I0614 11:07:48.859400   446 net.cpp:151] Top shape: 256 384 13 13 (16613376)
I0614 11:07:48.859416   446 net.cpp:159] Memory required for data: 1939042304
I0614 11:07:48.859437   446 layer_factory.hpp:77] Creating layer relu4
I0614 11:07:48.859450   446 net.cpp:94] Creating Layer relu4
I0614 11:07:48.859459   446 net.cpp:435] relu4 <- conv4
I0614 11:07:48.859472   446 net.cpp:409] relu4 -> relu4
I0614 11:07:48.859513   446 net.cpp:144] Setting up relu4
I0614 11:07:48.859520   446 net.cpp:151] Top shape: 256 384 13 13 (16613376)
I0614 11:07:48.859529   446 net.cpp:159] Memory required for data: 2005495808
I0614 11:07:48.859534   446 layer_factory.hpp:77] Creating layer conv5
I0614 11:07:48.859547   446 net.cpp:94] Creating Layer conv5
I0614 11:07:48.859553   446 net.cpp:435] conv5 <- relu4
I0614 11:07:48.859563   446 net.cpp:409] conv5 -> conv5
I0614 11:07:48.877527   446 net.cpp:144] Setting up conv5
I0614 11:07:48.877550   446 net.cpp:151] Top shape: 256 256 13 13 (11075584)
I0614 11:07:48.877559   446 net.cpp:159] Memory required for data: 2049798144
I0614 11:07:48.877570   446 layer_factory.hpp:77] Creating layer relu5
I0614 11:07:48.877579   446 net.cpp:94] Creating Layer relu5
I0614 11:07:48.877584   446 net.cpp:435] relu5 <- conv5
I0614 11:07:48.877591   446 net.cpp:409] relu5 -> relu5
I0614 11:07:48.877611   446 net.cpp:144] Setting up relu5
I0614 11:07:48.877614   446 net.cpp:151] Top shape: 256 256 13 13 (11075584)
I0614 11:07:48.877619   446 net.cpp:159] Memory required for data: 2094100480
I0614 11:07:48.877622   446 layer_factory.hpp:77] Creating layer pool5
I0614 11:07:48.877629   446 net.cpp:94] Creating Layer pool5
I0614 11:07:48.877631   446 net.cpp:435] pool5 <- relu5
I0614 11:07:48.877636   446 net.cpp:409] pool5 -> pool5
I0614 11:07:48.877655   446 net.cpp:144] Setting up pool5
I0614 11:07:48.877658   446 net.cpp:151] Top shape: 256 256 6 6 (2359296)
I0614 11:07:48.877662   446 net.cpp:159] Memory required for data: 2103537664
I0614 11:07:48.877666   446 layer_factory.hpp:77] Creating layer fc6
I0614 11:07:48.877681   446 net.cpp:94] Creating Layer fc6
I0614 11:07:48.877684   446 net.cpp:435] fc6 <- pool5
I0614 11:07:48.877689   446 net.cpp:409] fc6 -> fc6
I0614 11:07:49.222203   446 net.cpp:144] Setting up fc6
I0614 11:07:49.222230   446 net.cpp:151] Top shape: 256 4096 (1048576)
I0614 11:07:49.222239   446 net.cpp:159] Memory required for data: 2107731968
I0614 11:07:49.222265   446 layer_factory.hpp:77] Creating layer relu6
I0614 11:07:49.222275   446 net.cpp:94] Creating Layer relu6
I0614 11:07:49.222278   446 net.cpp:435] relu6 <- fc6
I0614 11:07:49.222285   446 net.cpp:409] relu6 -> relu6
I0614 11:07:49.222301   446 net.cpp:144] Setting up relu6
I0614 11:07:49.222303   446 net.cpp:151] Top shape: 256 4096 (1048576)
I0614 11:07:49.222307   446 net.cpp:159] Memory required for data: 2111926272
I0614 11:07:49.222311   446 layer_factory.hpp:77] Creating layer drop6
I0614 11:07:49.222316   446 net.cpp:94] Creating Layer drop6
I0614 11:07:49.222318   446 net.cpp:435] drop6 <- relu6
I0614 11:07:49.222321   446 net.cpp:409] drop6 -> drop6
I0614 11:07:49.222335   446 net.cpp:144] Setting up drop6
I0614 11:07:49.222338   446 net.cpp:151] Top shape: 256 4096 (1048576)
I0614 11:07:49.222342   446 net.cpp:159] Memory required for data: 2116120576
I0614 11:07:49.222345   446 layer_factory.hpp:77] Creating layer fc7
I0614 11:07:49.222368   446 net.cpp:94] Creating Layer fc7
I0614 11:07:49.222370   446 net.cpp:435] fc7 <- drop6
I0614 11:07:49.222374   446 net.cpp:409] fc7 -> fc7
I0614 11:07:49.365600   446 net.cpp:144] Setting up fc7
I0614 11:07:49.365628   446 net.cpp:151] Top shape: 256 4096 (1048576)
I0614 11:07:49.365635   446 net.cpp:159] Memory required for data: 2120314880
I0614 11:07:49.365662   446 layer_factory.hpp:77] Creating layer bn7
I0614 11:07:49.365696   446 net.cpp:94] Creating Layer bn7
I0614 11:07:49.365701   446 net.cpp:435] bn7 <- fc7
I0614 11:07:49.365708   446 net.cpp:409] bn7 -> bn7
I0614 11:07:49.365952   446 net.cpp:144] Setting up bn7
I0614 11:07:49.365957   446 net.cpp:151] Top shape: 256 4096 (1048576)
I0614 11:07:49.365962   446 net.cpp:159] Memory required for data: 2124509184
I0614 11:07:49.365984   446 layer_factory.hpp:77] Creating layer relu7
I0614 11:07:49.365989   446 net.cpp:94] Creating Layer relu7
I0614 11:07:49.365993   446 net.cpp:435] relu7 <- bn7
I0614 11:07:49.365998   446 net.cpp:409] relu7 -> relu7
I0614 11:07:49.366009   446 net.cpp:144] Setting up relu7
I0614 11:07:49.366012   446 net.cpp:151] Top shape: 256 4096 (1048576)
I0614 11:07:49.366017   446 net.cpp:159] Memory required for data: 2128703488
I0614 11:07:49.366020   446 layer_factory.hpp:77] Creating layer drop7
I0614 11:07:49.366025   446 net.cpp:94] Creating Layer drop7
I0614 11:07:49.366029   446 net.cpp:435] drop7 <- relu7
I0614 11:07:49.366034   446 net.cpp:409] drop7 -> drop7
I0614 11:07:49.366048   446 net.cpp:144] Setting up drop7
I0614 11:07:49.366051   446 net.cpp:151] Top shape: 256 4096 (1048576)
I0614 11:07:49.366056   446 net.cpp:159] Memory required for data: 2132897792
I0614 11:07:49.366060   446 layer_factory.hpp:77] Creating layer fc8
I0614 11:07:49.366065   446 net.cpp:94] Creating Layer fc8
I0614 11:07:49.366068   446 net.cpp:435] fc8 <- drop7
I0614 11:07:49.366072   446 net.cpp:409] fc8 -> fc8
I0614 11:07:49.366199   446 net.cpp:144] Setting up fc8
I0614 11:07:49.366204   446 net.cpp:151] Top shape: 256 2 (512)
I0614 11:07:49.366207   446 net.cpp:159] Memory required for data: 2132899840
I0614 11:07:49.366212   446 layer_factory.hpp:77] Creating layer loss
I0614 11:07:49.366226   446 net.cpp:94] Creating Layer loss
I0614 11:07:49.366230   446 net.cpp:435] loss <- fc8
I0614 11:07:49.366235   446 net.cpp:435] loss <- label
I0614 11:07:49.366240   446 net.cpp:409] loss -> loss
I0614 11:07:49.366248   446 layer_factory.hpp:77] Creating layer loss
I0614 11:07:49.366284   446 net.cpp:144] Setting up loss
I0614 11:07:49.366287   446 net.cpp:151] Top shape: (1)
I0614 11:07:49.366291   446 net.cpp:154]     with loss weight 1
I0614 11:07:49.366315   446 net.cpp:159] Memory required for data: 2132899844
I0614 11:07:49.366319   446 net.cpp:220] loss needs backward computation.
I0614 11:07:49.366323   446 net.cpp:220] fc8 needs backward computation.
I0614 11:07:49.366328   446 net.cpp:220] drop7 needs backward computation.
I0614 11:07:49.366330   446 net.cpp:220] relu7 needs backward computation.
I0614 11:07:49.366334   446 net.cpp:220] bn7 needs backward computation.
I0614 11:07:49.366338   446 net.cpp:220] fc7 needs backward computation.
I0614 11:07:49.366341   446 net.cpp:220] drop6 needs backward computation.
I0614 11:07:49.366345   446 net.cpp:220] relu6 needs backward computation.
I0614 11:07:49.366349   446 net.cpp:220] fc6 needs backward computation.
I0614 11:07:49.366354   446 net.cpp:220] pool5 needs backward computation.
I0614 11:07:49.366358   446 net.cpp:220] relu5 needs backward computation.
I0614 11:07:49.366362   446 net.cpp:220] conv5 needs backward computation.
I0614 11:07:49.366366   446 net.cpp:220] relu4 needs backward computation.
I0614 11:07:49.366369   446 net.cpp:220] conv4 needs backward computation.
I0614 11:07:49.366374   446 net.cpp:220] relu3 needs backward computation.
I0614 11:07:49.366377   446 net.cpp:220] conv3 needs backward computation.
I0614 11:07:49.366381   446 net.cpp:220] pool2 needs backward computation.
I0614 11:07:49.366384   446 net.cpp:220] relu2 needs backward computation.
I0614 11:07:49.366389   446 net.cpp:220] bn2 needs backward computation.
I0614 11:07:49.366392   446 net.cpp:220] conv2 needs backward computation.
I0614 11:07:49.366396   446 net.cpp:220] pool1 needs backward computation.
I0614 11:07:49.366400   446 net.cpp:220] relu1 needs backward computation.
I0614 11:07:49.366403   446 net.cpp:220] bn1 needs backward computation.
I0614 11:07:49.366407   446 net.cpp:220] conv1 needs backward computation.
I0614 11:07:49.366421   446 net.cpp:222] data does not need backward computation.
I0614 11:07:49.366425   446 net.cpp:264] This network produces output loss
I0614 11:07:49.366439   446 net.cpp:284] Network initialization done.
I0614 11:07:49.367430   446 solver.cpp:189] Creating test net (#0) specified by net file: caffe/models/alexnetBNnoLRN/m2/train_val_2_alexnetBNnoLRN.prototxt
I0614 11:07:49.367468   446 net.cpp:323] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0614 11:07:49.367483   446 net.cpp:52] Initializing net from parameters: 
name: "alexnetBNnoLRN m2 (as m3 but less DROP and less BN)"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_value: 106
    mean_value: 116
    mean_value: 124
  }
  data_param {
    source: "input/lmdb/valid_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 0
    kernel_size: 8
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "bn1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "bn2"
  top: "relu2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "relu6"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "drop6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn7"
  type: "BatchNorm"
  bottom: "fc7"
  top: "bn7"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "bn7"
  top: "relu7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "relu7"
  top: "drop7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "drop7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy-top1"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "top-1"
  include {
    phase: TEST
  }
}
I0614 11:07:49.367691   446 layer_factory.hpp:77] Creating layer data
I0614 11:07:49.367728   446 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0614 11:07:49.368937   446 net.cpp:94] Creating Layer data
I0614 11:07:49.368983   446 net.cpp:409] data -> data
I0614 11:07:49.369010   446 net.cpp:409] data -> label
I0614 11:07:49.373248   508 db_lmdb.cpp:35] Opened lmdb input/lmdb/valid_lmdb
I0614 11:07:49.373281   508 db_lmdb.cpp:38] Items count: 4000
I0614 11:07:49.373320   508 data_reader.cpp:124] TEST: reading data using 1 channel(s)
I0614 11:07:49.373749   446 data_layer.cpp:78] ReshapePrefetch 50, 3, 227, 227
I0614 11:07:49.373917   446 data_layer.cpp:83] output data size: 50,3,227,227
I0614 11:07:49.496074   446 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0614 11:07:49.496335   446 net.cpp:144] Setting up data
I0614 11:07:49.496342   446 net.cpp:151] Top shape: 50 3 227 227 (7729350)
I0614 11:07:49.496352   446 net.cpp:151] Top shape: 50 (50)
I0614 11:07:49.496356   446 net.cpp:159] Memory required for data: 30917600
I0614 11:07:49.496361   446 layer_factory.hpp:77] Creating layer label_data_1_split
I0614 11:07:49.496387   446 net.cpp:94] Creating Layer label_data_1_split
I0614 11:07:49.496392   446 net.cpp:435] label_data_1_split <- label
I0614 11:07:49.496398   446 net.cpp:409] label_data_1_split -> label_data_1_split_0
I0614 11:07:49.496408   446 net.cpp:409] label_data_1_split -> label_data_1_split_1
I0614 11:07:49.496413   446 net.cpp:409] label_data_1_split -> label_data_1_split_2
I0614 11:07:49.496456   446 net.cpp:144] Setting up label_data_1_split
I0614 11:07:49.496460   446 net.cpp:151] Top shape: 50 (50)
I0614 11:07:49.496464   446 net.cpp:151] Top shape: 50 (50)
I0614 11:07:49.496469   446 net.cpp:151] Top shape: 50 (50)
I0614 11:07:49.496472   446 net.cpp:159] Memory required for data: 30918200
I0614 11:07:49.496475   446 layer_factory.hpp:77] Creating layer conv1
I0614 11:07:49.496487   446 net.cpp:94] Creating Layer conv1
I0614 11:07:49.496511   446 net.cpp:435] conv1 <- data
I0614 11:07:49.496516   446 net.cpp:409] conv1 -> conv1
I0614 11:07:49.496904   446 net.cpp:144] Setting up conv1
I0614 11:07:49.496912   446 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0614 11:07:49.496917   446 net.cpp:159] Memory required for data: 88998200
I0614 11:07:49.496927   446 layer_factory.hpp:77] Creating layer bn1
I0614 11:07:49.496934   446 net.cpp:94] Creating Layer bn1
I0614 11:07:49.496938   446 net.cpp:435] bn1 <- conv1
I0614 11:07:49.496943   446 net.cpp:409] bn1 -> bn1
I0614 11:07:49.497251   446 net.cpp:144] Setting up bn1
I0614 11:07:49.497258   446 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0614 11:07:49.497263   446 net.cpp:159] Memory required for data: 147078200
I0614 11:07:49.497272   446 layer_factory.hpp:77] Creating layer relu1
I0614 11:07:49.497277   446 net.cpp:94] Creating Layer relu1
I0614 11:07:49.497282   446 net.cpp:435] relu1 <- bn1
I0614 11:07:49.497285   446 net.cpp:409] relu1 -> relu1
I0614 11:07:49.497298   446 net.cpp:144] Setting up relu1
I0614 11:07:49.497301   446 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0614 11:07:49.497305   446 net.cpp:159] Memory required for data: 205158200
I0614 11:07:49.497309   446 layer_factory.hpp:77] Creating layer pool1
I0614 11:07:49.497315   446 net.cpp:94] Creating Layer pool1
I0614 11:07:49.497318   446 net.cpp:435] pool1 <- relu1
I0614 11:07:49.497323   446 net.cpp:409] pool1 -> pool1
I0614 11:07:49.497339   446 net.cpp:144] Setting up pool1
I0614 11:07:49.497342   446 net.cpp:151] Top shape: 50 96 27 27 (3499200)
I0614 11:07:49.497347   446 net.cpp:159] Memory required for data: 219155000
I0614 11:07:49.497351   446 layer_factory.hpp:77] Creating layer conv2
I0614 11:07:49.497357   446 net.cpp:94] Creating Layer conv2
I0614 11:07:49.497361   446 net.cpp:435] conv2 <- pool1
I0614 11:07:49.497365   446 net.cpp:409] conv2 -> conv2
I0614 11:07:49.503859   446 net.cpp:144] Setting up conv2
I0614 11:07:49.503876   446 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0614 11:07:49.503885   446 net.cpp:159] Memory required for data: 256479800
I0614 11:07:49.503894   446 layer_factory.hpp:77] Creating layer bn2
I0614 11:07:49.503904   446 net.cpp:94] Creating Layer bn2
I0614 11:07:49.503909   446 net.cpp:435] bn2 <- conv2
I0614 11:07:49.503916   446 net.cpp:409] bn2 -> bn2
I0614 11:07:49.504182   446 net.cpp:144] Setting up bn2
I0614 11:07:49.504186   446 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0614 11:07:49.504192   446 net.cpp:159] Memory required for data: 293804600
I0614 11:07:49.504199   446 layer_factory.hpp:77] Creating layer relu2
I0614 11:07:49.504206   446 net.cpp:94] Creating Layer relu2
I0614 11:07:49.504209   446 net.cpp:435] relu2 <- bn2
I0614 11:07:49.504215   446 net.cpp:409] relu2 -> relu2
I0614 11:07:49.504226   446 net.cpp:144] Setting up relu2
I0614 11:07:49.504230   446 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0614 11:07:49.504235   446 net.cpp:159] Memory required for data: 331129400
I0614 11:07:49.504238   446 layer_factory.hpp:77] Creating layer pool2
I0614 11:07:49.504243   446 net.cpp:94] Creating Layer pool2
I0614 11:07:49.504247   446 net.cpp:435] pool2 <- relu2
I0614 11:07:49.504252   446 net.cpp:409] pool2 -> pool2
I0614 11:07:49.504267   446 net.cpp:144] Setting up pool2
I0614 11:07:49.504271   446 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0614 11:07:49.504276   446 net.cpp:159] Memory required for data: 339782200
I0614 11:07:49.504279   446 layer_factory.hpp:77] Creating layer conv3
I0614 11:07:49.504287   446 net.cpp:94] Creating Layer conv3
I0614 11:07:49.504290   446 net.cpp:435] conv3 <- pool2
I0614 11:07:49.504294   446 net.cpp:409] conv3 -> conv3
I0614 11:07:49.516163   446 net.cpp:144] Setting up conv3
I0614 11:07:49.516229   446 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0614 11:07:49.516244   446 net.cpp:159] Memory required for data: 352761400
I0614 11:07:49.516258   446 layer_factory.hpp:77] Creating layer relu3
I0614 11:07:49.516273   446 net.cpp:94] Creating Layer relu3
I0614 11:07:49.516280   446 net.cpp:435] relu3 <- conv3
I0614 11:07:49.516316   446 net.cpp:409] relu3 -> relu3
I0614 11:07:49.516357   446 net.cpp:144] Setting up relu3
I0614 11:07:49.516363   446 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0614 11:07:49.516371   446 net.cpp:159] Memory required for data: 365740600
I0614 11:07:49.516376   446 layer_factory.hpp:77] Creating layer conv4
I0614 11:07:49.516391   446 net.cpp:94] Creating Layer conv4
I0614 11:07:49.516399   446 net.cpp:435] conv4 <- relu3
I0614 11:07:49.516407   446 net.cpp:409] conv4 -> conv4
I0614 11:07:49.532757   446 net.cpp:144] Setting up conv4
I0614 11:07:49.532776   446 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0614 11:07:49.532785   446 net.cpp:159] Memory required for data: 378719800
I0614 11:07:49.532799   446 layer_factory.hpp:77] Creating layer relu4
I0614 11:07:49.532806   446 net.cpp:94] Creating Layer relu4
I0614 11:07:49.532811   446 net.cpp:435] relu4 <- conv4
I0614 11:07:49.532817   446 net.cpp:409] relu4 -> relu4
I0614 11:07:49.532838   446 net.cpp:144] Setting up relu4
I0614 11:07:49.532842   446 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0614 11:07:49.532848   446 net.cpp:159] Memory required for data: 391699000
I0614 11:07:49.532851   446 layer_factory.hpp:77] Creating layer conv5
I0614 11:07:49.532860   446 net.cpp:94] Creating Layer conv5
I0614 11:07:49.532864   446 net.cpp:435] conv5 <- relu4
I0614 11:07:49.532869   446 net.cpp:409] conv5 -> conv5
I0614 11:07:49.542654   446 net.cpp:144] Setting up conv5
I0614 11:07:49.542714   446 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0614 11:07:49.542729   446 net.cpp:159] Memory required for data: 400351800
I0614 11:07:49.542744   446 layer_factory.hpp:77] Creating layer relu5
I0614 11:07:49.542757   446 net.cpp:94] Creating Layer relu5
I0614 11:07:49.542765   446 net.cpp:435] relu5 <- conv5
I0614 11:07:49.542776   446 net.cpp:409] relu5 -> relu5
I0614 11:07:49.542815   446 net.cpp:144] Setting up relu5
I0614 11:07:49.542822   446 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0614 11:07:49.542830   446 net.cpp:159] Memory required for data: 409004600
I0614 11:07:49.542835   446 layer_factory.hpp:77] Creating layer pool5
I0614 11:07:49.542846   446 net.cpp:94] Creating Layer pool5
I0614 11:07:49.542852   446 net.cpp:435] pool5 <- relu5
I0614 11:07:49.542860   446 net.cpp:409] pool5 -> pool5
I0614 11:07:49.542889   446 net.cpp:144] Setting up pool5
I0614 11:07:49.542896   446 net.cpp:151] Top shape: 50 256 6 6 (460800)
I0614 11:07:49.542901   446 net.cpp:159] Memory required for data: 410847800
I0614 11:07:49.542907   446 layer_factory.hpp:77] Creating layer fc6
I0614 11:07:49.542918   446 net.cpp:94] Creating Layer fc6
I0614 11:07:49.542923   446 net.cpp:435] fc6 <- pool5
I0614 11:07:49.542932   446 net.cpp:409] fc6 -> fc6
I0614 11:07:49.871738   446 net.cpp:144] Setting up fc6
I0614 11:07:49.871764   446 net.cpp:151] Top shape: 50 4096 (204800)
I0614 11:07:49.871773   446 net.cpp:159] Memory required for data: 411667000
I0614 11:07:49.871784   446 layer_factory.hpp:77] Creating layer relu6
I0614 11:07:49.871793   446 net.cpp:94] Creating Layer relu6
I0614 11:07:49.871798   446 net.cpp:435] relu6 <- fc6
I0614 11:07:49.871803   446 net.cpp:409] relu6 -> relu6
I0614 11:07:49.871824   446 net.cpp:144] Setting up relu6
I0614 11:07:49.871826   446 net.cpp:151] Top shape: 50 4096 (204800)
I0614 11:07:49.871830   446 net.cpp:159] Memory required for data: 412486200
I0614 11:07:49.871834   446 layer_factory.hpp:77] Creating layer drop6
I0614 11:07:49.871838   446 net.cpp:94] Creating Layer drop6
I0614 11:07:49.871842   446 net.cpp:435] drop6 <- relu6
I0614 11:07:49.871846   446 net.cpp:409] drop6 -> drop6
I0614 11:07:49.871860   446 net.cpp:144] Setting up drop6
I0614 11:07:49.871863   446 net.cpp:151] Top shape: 50 4096 (204800)
I0614 11:07:49.871867   446 net.cpp:159] Memory required for data: 413305400
I0614 11:07:49.871870   446 layer_factory.hpp:77] Creating layer fc7
I0614 11:07:49.871877   446 net.cpp:94] Creating Layer fc7
I0614 11:07:49.871881   446 net.cpp:435] fc7 <- drop6
I0614 11:07:49.871884   446 net.cpp:409] fc7 -> fc7
I0614 11:07:50.018950   446 net.cpp:144] Setting up fc7
I0614 11:07:50.018978   446 net.cpp:151] Top shape: 50 4096 (204800)
I0614 11:07:50.018986   446 net.cpp:159] Memory required for data: 414124600
I0614 11:07:50.018997   446 layer_factory.hpp:77] Creating layer bn7
I0614 11:07:50.019008   446 net.cpp:94] Creating Layer bn7
I0614 11:07:50.019012   446 net.cpp:435] bn7 <- fc7
I0614 11:07:50.019019   446 net.cpp:409] bn7 -> bn7
I0614 11:07:50.019280   446 net.cpp:144] Setting up bn7
I0614 11:07:50.019284   446 net.cpp:151] Top shape: 50 4096 (204800)
I0614 11:07:50.019289   446 net.cpp:159] Memory required for data: 414943800
I0614 11:07:50.019295   446 layer_factory.hpp:77] Creating layer relu7
I0614 11:07:50.019300   446 net.cpp:94] Creating Layer relu7
I0614 11:07:50.019304   446 net.cpp:435] relu7 <- bn7
I0614 11:07:50.019309   446 net.cpp:409] relu7 -> relu7
I0614 11:07:50.019320   446 net.cpp:144] Setting up relu7
I0614 11:07:50.019322   446 net.cpp:151] Top shape: 50 4096 (204800)
I0614 11:07:50.019341   446 net.cpp:159] Memory required for data: 415763000
I0614 11:07:50.019345   446 layer_factory.hpp:77] Creating layer drop7
I0614 11:07:50.019351   446 net.cpp:94] Creating Layer drop7
I0614 11:07:50.019354   446 net.cpp:435] drop7 <- relu7
I0614 11:07:50.019359   446 net.cpp:409] drop7 -> drop7
I0614 11:07:50.019374   446 net.cpp:144] Setting up drop7
I0614 11:07:50.019377   446 net.cpp:151] Top shape: 50 4096 (204800)
I0614 11:07:50.019381   446 net.cpp:159] Memory required for data: 416582200
I0614 11:07:50.019385   446 layer_factory.hpp:77] Creating layer fc8
I0614 11:07:50.019392   446 net.cpp:94] Creating Layer fc8
I0614 11:07:50.019394   446 net.cpp:435] fc8 <- drop7
I0614 11:07:50.019399   446 net.cpp:409] fc8 -> fc8
I0614 11:07:50.019512   446 net.cpp:144] Setting up fc8
I0614 11:07:50.019516   446 net.cpp:151] Top shape: 50 2 (100)
I0614 11:07:50.019520   446 net.cpp:159] Memory required for data: 416582600
I0614 11:07:50.019526   446 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0614 11:07:50.019531   446 net.cpp:94] Creating Layer fc8_fc8_0_split
I0614 11:07:50.019534   446 net.cpp:435] fc8_fc8_0_split <- fc8
I0614 11:07:50.019539   446 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0614 11:07:50.019544   446 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0614 11:07:50.019549   446 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_2
I0614 11:07:50.019584   446 net.cpp:144] Setting up fc8_fc8_0_split
I0614 11:07:50.019587   446 net.cpp:151] Top shape: 50 2 (100)
I0614 11:07:50.019593   446 net.cpp:151] Top shape: 50 2 (100)
I0614 11:07:50.019596   446 net.cpp:151] Top shape: 50 2 (100)
I0614 11:07:50.019600   446 net.cpp:159] Memory required for data: 416583800
I0614 11:07:50.019604   446 layer_factory.hpp:77] Creating layer accuracy
I0614 11:07:50.019610   446 net.cpp:94] Creating Layer accuracy
I0614 11:07:50.019614   446 net.cpp:435] accuracy <- fc8_fc8_0_split_0
I0614 11:07:50.019618   446 net.cpp:435] accuracy <- label_data_1_split_0
I0614 11:07:50.019623   446 net.cpp:409] accuracy -> accuracy
I0614 11:07:50.019630   446 net.cpp:144] Setting up accuracy
I0614 11:07:50.019634   446 net.cpp:151] Top shape: (1)
I0614 11:07:50.019639   446 net.cpp:159] Memory required for data: 416583804
I0614 11:07:50.019642   446 layer_factory.hpp:77] Creating layer loss
I0614 11:07:50.019647   446 net.cpp:94] Creating Layer loss
I0614 11:07:50.019650   446 net.cpp:435] loss <- fc8_fc8_0_split_1
I0614 11:07:50.019655   446 net.cpp:435] loss <- label_data_1_split_1
I0614 11:07:50.019659   446 net.cpp:409] loss -> loss
I0614 11:07:50.019668   446 layer_factory.hpp:77] Creating layer loss
I0614 11:07:50.019709   446 net.cpp:144] Setting up loss
I0614 11:07:50.019713   446 net.cpp:151] Top shape: (1)
I0614 11:07:50.019717   446 net.cpp:154]     with loss weight 1
I0614 11:07:50.019729   446 net.cpp:159] Memory required for data: 416583808
I0614 11:07:50.019733   446 layer_factory.hpp:77] Creating layer accuracy-top1
I0614 11:07:50.019738   446 net.cpp:94] Creating Layer accuracy-top1
I0614 11:07:50.019742   446 net.cpp:435] accuracy-top1 <- fc8_fc8_0_split_2
I0614 11:07:50.019766   446 net.cpp:435] accuracy-top1 <- label_data_1_split_2
I0614 11:07:50.019771   446 net.cpp:409] accuracy-top1 -> top-1
I0614 11:07:50.019778   446 net.cpp:144] Setting up accuracy-top1
I0614 11:07:50.019783   446 net.cpp:151] Top shape: (1)
I0614 11:07:50.019786   446 net.cpp:159] Memory required for data: 416583812
I0614 11:07:50.019789   446 net.cpp:222] accuracy-top1 does not need backward computation.
I0614 11:07:50.019794   446 net.cpp:220] loss needs backward computation.
I0614 11:07:50.019798   446 net.cpp:222] accuracy does not need backward computation.
I0614 11:07:50.019802   446 net.cpp:220] fc8_fc8_0_split needs backward computation.
I0614 11:07:50.019806   446 net.cpp:220] fc8 needs backward computation.
I0614 11:07:50.019809   446 net.cpp:220] drop7 needs backward computation.
I0614 11:07:50.019814   446 net.cpp:220] relu7 needs backward computation.
I0614 11:07:50.019817   446 net.cpp:220] bn7 needs backward computation.
I0614 11:07:50.019820   446 net.cpp:220] fc7 needs backward computation.
I0614 11:07:50.019824   446 net.cpp:220] drop6 needs backward computation.
I0614 11:07:50.019829   446 net.cpp:220] relu6 needs backward computation.
I0614 11:07:50.019832   446 net.cpp:220] fc6 needs backward computation.
I0614 11:07:50.019836   446 net.cpp:220] pool5 needs backward computation.
I0614 11:07:50.019840   446 net.cpp:220] relu5 needs backward computation.
I0614 11:07:50.019843   446 net.cpp:220] conv5 needs backward computation.
I0614 11:07:50.019847   446 net.cpp:220] relu4 needs backward computation.
I0614 11:07:50.019851   446 net.cpp:220] conv4 needs backward computation.
I0614 11:07:50.019855   446 net.cpp:220] relu3 needs backward computation.
I0614 11:07:50.019860   446 net.cpp:220] conv3 needs backward computation.
I0614 11:07:50.019863   446 net.cpp:220] pool2 needs backward computation.
I0614 11:07:50.019867   446 net.cpp:220] relu2 needs backward computation.
I0614 11:07:50.019870   446 net.cpp:220] bn2 needs backward computation.
I0614 11:07:50.019874   446 net.cpp:220] conv2 needs backward computation.
I0614 11:07:50.019878   446 net.cpp:220] pool1 needs backward computation.
I0614 11:07:50.019882   446 net.cpp:220] relu1 needs backward computation.
I0614 11:07:50.019886   446 net.cpp:220] bn1 needs backward computation.
I0614 11:07:50.019891   446 net.cpp:220] conv1 needs backward computation.
I0614 11:07:50.019894   446 net.cpp:222] label_data_1_split does not need backward computation.
I0614 11:07:50.019899   446 net.cpp:222] data does not need backward computation.
I0614 11:07:50.019902   446 net.cpp:264] This network produces output accuracy
I0614 11:07:50.019906   446 net.cpp:264] This network produces output loss
I0614 11:07:50.019909   446 net.cpp:264] This network produces output top-1
I0614 11:07:50.019927   446 net.cpp:284] Network initialization done.
I0614 11:07:50.019994   446 solver.cpp:63] Solver scaffolding done.
I0614 11:07:50.020535   446 caffe.cpp:247] Starting Optimization
I0614 11:07:50.020543   446 solver.cpp:341] Solving alexnetBNnoLRN m2 (as m3 but less DROP and less BN)
I0614 11:07:50.020546   446 solver.cpp:342] Learning Rate Policy: step
I0614 11:07:50.021795   446 solver.cpp:424] Iteration 0, Testing net (#0)
I0614 11:07:51.504791   446 solver.cpp:523]     Test net output #0: accuracy = 0.492
I0614 11:07:51.504827   446 solver.cpp:523]     Test net output #1: loss = 44.367 (* 1 = 44.367 loss)
I0614 11:07:51.504832   446 solver.cpp:523]     Test net output #2: top-1 = 0.492
I0614 11:07:51.764995   446 solver.cpp:270] Iteration 0 (0 iter/s, 1.74436s/50 iter), loss = 0.793226, remaining 554999 hours and 59 minutes
I0614 11:07:51.765026   446 solver.cpp:291]     Train net output #0: loss = 0.793226 (* 1 = 0.793226 loss)
I0614 11:07:51.765050   446 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0614 11:08:04.229017   446 solver.cpp:270] Iteration 50 (4.01169 iter/s, 12.4636s/50 iter), loss = 0.694899, remaining 1 hours and 22 minutes
I0614 11:08:04.229051   446 solver.cpp:291]     Train net output #0: loss = 0.694899 (* 1 = 0.694899 loss)
I0614 11:08:04.229099   446 sgd_solver.cpp:106] Iteration 50, lr = 0.001
I0614 11:08:16.699214   446 solver.cpp:270] Iteration 100 (4.0097 iter/s, 12.4698s/50 iter), loss = 0.747979, remaining 1 hours and 22 minutes
I0614 11:08:16.699249   446 solver.cpp:291]     Train net output #0: loss = 0.747979 (* 1 = 0.747979 loss)
I0614 11:08:16.699259   446 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I0614 11:08:29.275899   446 solver.cpp:270] Iteration 150 (3.97575 iter/s, 12.5762s/50 iter), loss = 0.7183, remaining 1 hours and 23 minutes
I0614 11:08:29.275946   446 solver.cpp:291]     Train net output #0: loss = 0.7183 (* 1 = 0.7183 loss)
I0614 11:08:29.275971   446 sgd_solver.cpp:106] Iteration 150, lr = 0.001
I0614 11:08:41.888787   446 solver.cpp:270] Iteration 200 (3.96434 iter/s, 12.6124s/50 iter), loss = 0.634697, remaining 1 hours and 23 minutes
I0614 11:08:41.888820   446 solver.cpp:291]     Train net output #0: loss = 0.634697 (* 1 = 0.634697 loss)
I0614 11:08:41.888830   446 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I0614 11:08:54.539901   446 solver.cpp:270] Iteration 250 (3.95236 iter/s, 12.6507s/50 iter), loss = 0.653876, remaining 1 hours and 23 minutes
I0614 11:08:54.539934   446 solver.cpp:291]     Train net output #0: loss = 0.653876 (* 1 = 0.653876 loss)
I0614 11:08:54.539942   446 sgd_solver.cpp:106] Iteration 250, lr = 0.001
I0614 11:09:07.198801   446 solver.cpp:270] Iteration 300 (3.94993 iter/s, 12.6585s/50 iter), loss = 0.734511, remaining 1 hours and 23 minutes
I0614 11:09:07.198851   446 solver.cpp:291]     Train net output #0: loss = 0.734511 (* 1 = 0.734511 loss)
I0614 11:09:07.198860   446 sgd_solver.cpp:106] Iteration 300, lr = 0.001
I0614 11:09:19.852401   446 solver.cpp:270] Iteration 350 (3.95159 iter/s, 12.6531s/50 iter), loss = 0.668219, remaining 1 hours and 22 minutes
I0614 11:09:19.852432   446 solver.cpp:291]     Train net output #0: loss = 0.668219 (* 1 = 0.668219 loss)
I0614 11:09:19.852442   446 sgd_solver.cpp:106] Iteration 350, lr = 0.001
I0614 11:09:32.515825   446 solver.cpp:270] Iteration 400 (3.94852 iter/s, 12.663s/50 iter), loss = 0.629273, remaining 1 hours and 22 minutes
I0614 11:09:32.515856   446 solver.cpp:291]     Train net output #0: loss = 0.629273 (* 1 = 0.629273 loss)
I0614 11:09:32.515880   446 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I0614 11:09:45.161559   446 solver.cpp:270] Iteration 450 (3.95404 iter/s, 12.6453s/50 iter), loss = 0.588952, remaining 1 hours and 22 minutes
I0614 11:09:45.161607   446 solver.cpp:291]     Train net output #0: loss = 0.588952 (* 1 = 0.588952 loss)
I0614 11:09:45.161617   446 sgd_solver.cpp:106] Iteration 450, lr = 0.001
I0614 11:09:57.819173   446 solver.cpp:270] Iteration 500 (3.95033 iter/s, 12.6572s/50 iter), loss = 0.638191, remaining 1 hours and 22 minutes
I0614 11:09:57.819206   446 solver.cpp:291]     Train net output #0: loss = 0.638191 (* 1 = 0.638191 loss)
I0614 11:09:57.819231   446 sgd_solver.cpp:106] Iteration 500, lr = 0.001
I0614 11:10:10.477684   446 solver.cpp:270] Iteration 550 (3.95005 iter/s, 12.6581s/50 iter), loss = 0.649281, remaining 1 hours and 22 minutes
I0614 11:10:10.477717   446 solver.cpp:291]     Train net output #0: loss = 0.649281 (* 1 = 0.649281 loss)
I0614 11:10:10.477725   446 sgd_solver.cpp:106] Iteration 550, lr = 0.001
I0614 11:10:23.113549   446 solver.cpp:270] Iteration 600 (3.95713 iter/s, 12.6354s/50 iter), loss = 0.657944, remaining 1 hours and 21 minutes
I0614 11:10:23.113598   446 solver.cpp:291]     Train net output #0: loss = 0.657944 (* 1 = 0.657944 loss)
I0614 11:10:23.113622   446 sgd_solver.cpp:106] Iteration 600, lr = 0.001
I0614 11:10:35.729450   446 solver.cpp:270] Iteration 650 (3.9634 iter/s, 12.6154s/50 iter), loss = 0.603799, remaining 1 hours and 21 minutes
I0614 11:10:35.729483   446 solver.cpp:291]     Train net output #0: loss = 0.603799 (* 1 = 0.603799 loss)
I0614 11:10:35.729507   446 sgd_solver.cpp:106] Iteration 650, lr = 0.001
I0614 11:10:48.344125   446 solver.cpp:270] Iteration 700 (3.96378 iter/s, 12.6142s/50 iter), loss = 0.564011, remaining 1 hours and 20 minutes
I0614 11:10:48.344159   446 solver.cpp:291]     Train net output #0: loss = 0.564011 (* 1 = 0.564011 loss)
I0614 11:10:48.344183   446 sgd_solver.cpp:106] Iteration 700, lr = 0.001
I0614 11:11:00.941283   446 solver.cpp:270] Iteration 750 (3.96929 iter/s, 12.5967s/50 iter), loss = 0.509252, remaining 1 hours and 20 minutes
I0614 11:11:00.941339   446 solver.cpp:291]     Train net output #0: loss = 0.509252 (* 1 = 0.509252 loss)
I0614 11:11:00.941349   446 sgd_solver.cpp:106] Iteration 750, lr = 0.001
I0614 11:11:13.554863   446 solver.cpp:270] Iteration 800 (3.96413 iter/s, 12.6131s/50 iter), loss = 0.603626, remaining 1 hours and 20 minutes
I0614 11:11:13.554895   446 solver.cpp:291]     Train net output #0: loss = 0.603626 (* 1 = 0.603626 loss)
I0614 11:11:13.554903   446 sgd_solver.cpp:106] Iteration 800, lr = 0.001
I0614 11:11:26.159976   446 solver.cpp:270] Iteration 850 (3.96678 iter/s, 12.6047s/50 iter), loss = 0.418162, remaining 1 hours and 20 minutes
I0614 11:11:26.160008   446 solver.cpp:291]     Train net output #0: loss = 0.418162 (* 1 = 0.418162 loss)
I0614 11:11:26.160032   446 sgd_solver.cpp:106] Iteration 850, lr = 0.001
I0614 11:11:38.768683   446 solver.cpp:270] Iteration 900 (3.96565 iter/s, 12.6083s/50 iter), loss = 0.516228, remaining 1 hours and 20 minutes
I0614 11:11:38.768729   446 solver.cpp:291]     Train net output #0: loss = 0.516228 (* 1 = 0.516228 loss)
I0614 11:11:38.768754   446 sgd_solver.cpp:106] Iteration 900, lr = 0.001
I0614 11:11:51.374320   446 solver.cpp:270] Iteration 950 (3.96662 iter/s, 12.6052s/50 iter), loss = 0.396665, remaining 1 hours and 19 minutes
I0614 11:11:51.374352   446 solver.cpp:291]     Train net output #0: loss = 0.396665 (* 1 = 0.396665 loss)
I0614 11:11:51.374361   446 sgd_solver.cpp:106] Iteration 950, lr = 0.001
I0614 11:12:03.739310   446 solver.cpp:424] Iteration 1000, Testing net (#0)
I0614 11:12:05.210556   446 solver.cpp:523]     Test net output #0: accuracy = 0.72725
I0614 11:12:05.210587   446 solver.cpp:523]     Test net output #1: loss = 0.658473 (* 1 = 0.658473 loss)
I0614 11:12:05.210592   446 solver.cpp:523]     Test net output #2: top-1 = 0.72725
I0614 11:12:05.457496   446 solver.cpp:270] Iteration 1000 (3.55046 iter/s, 14.0827s/50 iter), loss = 0.374149, remaining 1 hours and 29 minutes
I0614 11:12:05.457528   446 solver.cpp:291]     Train net output #0: loss = 0.374149 (* 1 = 0.374149 loss)
I0614 11:12:05.457537   446 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I0614 11:12:18.060806   446 solver.cpp:270] Iteration 1050 (3.96735 iter/s, 12.6029s/50 iter), loss = 0.308096, remaining 1 hours and 19 minutes
I0614 11:12:18.060853   446 solver.cpp:291]     Train net output #0: loss = 0.308096 (* 1 = 0.308096 loss)
I0614 11:12:18.060863   446 sgd_solver.cpp:106] Iteration 1050, lr = 0.001
I0614 11:12:30.666533   446 solver.cpp:270] Iteration 1100 (3.96659 iter/s, 12.6053s/50 iter), loss = 0.377567, remaining 1 hours and 19 minutes
I0614 11:12:30.666566   446 solver.cpp:291]     Train net output #0: loss = 0.377567 (* 1 = 0.377567 loss)
I0614 11:12:30.666575   446 sgd_solver.cpp:106] Iteration 1100, lr = 0.001
I0614 11:12:43.271529   446 solver.cpp:270] Iteration 1150 (3.96682 iter/s, 12.6046s/50 iter), loss = 0.302448, remaining 1 hours and 19 minutes
I0614 11:12:43.271564   446 solver.cpp:291]     Train net output #0: loss = 0.302448 (* 1 = 0.302448 loss)
I0614 11:12:43.271571   446 sgd_solver.cpp:106] Iteration 1150, lr = 0.001
I0614 11:12:55.883320   446 solver.cpp:270] Iteration 1200 (3.96468 iter/s, 12.6114s/50 iter), loss = 0.301592, remaining 1 hours and 18 minutes
I0614 11:12:55.883368   446 solver.cpp:291]     Train net output #0: loss = 0.301592 (* 1 = 0.301592 loss)
I0614 11:12:55.883392   446 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I0614 11:13:08.501744   446 solver.cpp:270] Iteration 1250 (3.9626 iter/s, 12.618s/50 iter), loss = 0.341578, remaining 1 hours and 18 minutes
I0614 11:13:08.501777   446 solver.cpp:291]     Train net output #0: loss = 0.341578 (* 1 = 0.341578 loss)
I0614 11:13:08.501785   446 sgd_solver.cpp:106] Iteration 1250, lr = 0.001
I0614 11:13:21.114363   446 solver.cpp:270] Iteration 1300 (3.96442 iter/s, 12.6122s/50 iter), loss = 0.302015, remaining 1 hours and 18 minutes
I0614 11:13:21.114396   446 solver.cpp:291]     Train net output #0: loss = 0.302015 (* 1 = 0.302015 loss)
I0614 11:13:21.114405   446 sgd_solver.cpp:106] Iteration 1300, lr = 0.001
I0614 11:13:33.711153   446 solver.cpp:270] Iteration 1350 (3.9694 iter/s, 12.5963s/50 iter), loss = 0.303031, remaining 1 hours and 18 minutes
I0614 11:13:33.711208   446 solver.cpp:291]     Train net output #0: loss = 0.303031 (* 1 = 0.303031 loss)
I0614 11:13:33.711217   446 sgd_solver.cpp:106] Iteration 1350, lr = 0.001
I0614 11:13:46.320417   446 solver.cpp:270] Iteration 1400 (3.96548 iter/s, 12.6088s/50 iter), loss = 0.260317, remaining 1 hours and 18 minutes
I0614 11:13:46.320451   446 solver.cpp:291]     Train net output #0: loss = 0.260317 (* 1 = 0.260317 loss)
I0614 11:13:46.320475   446 sgd_solver.cpp:106] Iteration 1400, lr = 0.001
I0614 11:13:58.957784   446 solver.cpp:270] Iteration 1450 (3.95666 iter/s, 12.6369s/50 iter), loss = 0.202262, remaining 1 hours and 18 minutes
I0614 11:13:58.957816   446 solver.cpp:291]     Train net output #0: loss = 0.202262 (* 1 = 0.202262 loss)
I0614 11:13:58.957840   446 sgd_solver.cpp:106] Iteration 1450, lr = 0.001
I0614 11:14:11.573760   446 solver.cpp:270] Iteration 1500 (3.96337 iter/s, 12.6155s/50 iter), loss = 0.29382, remaining 1 hours and 17 minutes
I0614 11:14:11.573807   446 solver.cpp:291]     Train net output #0: loss = 0.29382 (* 1 = 0.29382 loss)
I0614 11:14:11.573817   446 sgd_solver.cpp:106] Iteration 1500, lr = 0.001
I0614 11:14:24.175148   446 solver.cpp:270] Iteration 1550 (3.96796 iter/s, 12.6009s/50 iter), loss = 0.220422, remaining 1 hours and 17 minutes
I0614 11:14:24.175179   446 solver.cpp:291]     Train net output #0: loss = 0.220422 (* 1 = 0.220422 loss)
I0614 11:14:24.175186   446 sgd_solver.cpp:106] Iteration 1550, lr = 0.001
I0614 11:14:36.780532   446 solver.cpp:270] Iteration 1600 (3.9667 iter/s, 12.6049s/50 iter), loss = 0.196371, remaining 1 hours and 17 minutes
I0614 11:14:36.780566   446 solver.cpp:291]     Train net output #0: loss = 0.196371 (* 1 = 0.196371 loss)
I0614 11:14:36.780575   446 sgd_solver.cpp:106] Iteration 1600, lr = 0.001
I0614 11:14:49.410117   446 solver.cpp:270] Iteration 1650 (3.9591 iter/s, 12.6291s/50 iter), loss = 0.227844, remaining 1 hours and 17 minutes
I0614 11:14:49.410182   446 solver.cpp:291]     Train net output #0: loss = 0.227844 (* 1 = 0.227844 loss)
I0614 11:14:49.410192   446 sgd_solver.cpp:106] Iteration 1650, lr = 0.001
I0614 11:15:02.026048   446 solver.cpp:270] Iteration 1700 (3.96339 iter/s, 12.6155s/50 iter), loss = 0.210297, remaining 1 hours and 16 minutes
I0614 11:15:02.026080   446 solver.cpp:291]     Train net output #0: loss = 0.210297 (* 1 = 0.210297 loss)
I0614 11:15:02.026089   446 sgd_solver.cpp:106] Iteration 1700, lr = 0.001
I0614 11:15:14.635561   446 solver.cpp:270] Iteration 1750 (3.9654 iter/s, 12.6091s/50 iter), loss = 0.239455, remaining 1 hours and 16 minutes
I0614 11:15:14.635594   446 solver.cpp:291]     Train net output #0: loss = 0.239455 (* 1 = 0.239455 loss)
I0614 11:15:14.635602   446 sgd_solver.cpp:106] Iteration 1750, lr = 0.001
I0614 11:15:27.233834   446 solver.cpp:270] Iteration 1800 (3.96894 iter/s, 12.5978s/50 iter), loss = 0.261242, remaining 1 hours and 16 minutes
I0614 11:15:27.233882   446 solver.cpp:291]     Train net output #0: loss = 0.261242 (* 1 = 0.261242 loss)
I0614 11:15:27.233892   446 sgd_solver.cpp:106] Iteration 1800, lr = 0.001
I0614 11:15:39.848614   446 solver.cpp:270] Iteration 1850 (3.96375 iter/s, 12.6143s/50 iter), loss = 0.236233, remaining 1 hours and 16 minutes
I0614 11:15:39.848649   446 solver.cpp:291]     Train net output #0: loss = 0.236233 (* 1 = 0.236233 loss)
I0614 11:15:39.848672   446 sgd_solver.cpp:106] Iteration 1850, lr = 0.001
I0614 11:15:52.454681   446 solver.cpp:270] Iteration 1900 (3.96648 iter/s, 12.6056s/50 iter), loss = 0.220857, remaining 1 hours and 15 minutes
I0614 11:15:52.454715   446 solver.cpp:291]     Train net output #0: loss = 0.220857 (* 1 = 0.220857 loss)
I0614 11:15:52.454738   446 sgd_solver.cpp:106] Iteration 1900, lr = 0.001
I0614 11:16:05.056862   446 solver.cpp:270] Iteration 1950 (3.96771 iter/s, 12.6017s/50 iter), loss = 0.218746, remaining 1 hours and 15 minutes
I0614 11:16:05.056917   446 solver.cpp:291]     Train net output #0: loss = 0.218746 (* 1 = 0.218746 loss)
I0614 11:16:05.056941   446 sgd_solver.cpp:106] Iteration 1950, lr = 0.001
I0614 11:16:17.411226   446 solver.cpp:424] Iteration 2000, Testing net (#0)
I0614 11:16:18.917503   446 solver.cpp:523]     Test net output #0: accuracy = 0.54275
I0614 11:16:18.917534   446 solver.cpp:523]     Test net output #1: loss = 0.643111 (* 1 = 0.643111 loss)
I0614 11:16:18.917539   446 solver.cpp:523]     Test net output #2: top-1 = 0.54275
I0614 11:16:19.164008   446 solver.cpp:270] Iteration 2000 (3.54443 iter/s, 14.1066s/50 iter), loss = 0.19163, remaining 1 hours and 24 minutes
I0614 11:16:19.164041   446 solver.cpp:291]     Train net output #0: loss = 0.19163 (* 1 = 0.19163 loss)
I0614 11:16:19.164049   446 sgd_solver.cpp:106] Iteration 2000, lr = 0.001
I0614 11:16:31.786409   446 solver.cpp:270] Iteration 2050 (3.96135 iter/s, 12.622s/50 iter), loss = 0.252677, remaining 1 hours and 15 minutes
I0614 11:16:31.786440   446 solver.cpp:291]     Train net output #0: loss = 0.252677 (* 1 = 0.252677 loss)
I0614 11:16:31.786464   446 sgd_solver.cpp:106] Iteration 2050, lr = 0.001
I0614 11:16:44.387504   446 solver.cpp:270] Iteration 2100 (3.96805 iter/s, 12.6007s/50 iter), loss = 0.153939, remaining 1 hours and 15 minutes
I0614 11:16:44.387553   446 solver.cpp:291]     Train net output #0: loss = 0.153939 (* 1 = 0.153939 loss)
I0614 11:16:44.387562   446 sgd_solver.cpp:106] Iteration 2100, lr = 0.001
I0614 11:16:57.010861   446 solver.cpp:270] Iteration 2150 (3.96105 iter/s, 12.6229s/50 iter), loss = 0.235712, remaining 1 hours and 14 minutes
I0614 11:16:57.010893   446 solver.cpp:291]     Train net output #0: loss = 0.235712 (* 1 = 0.235712 loss)
I0614 11:16:57.010901   446 sgd_solver.cpp:106] Iteration 2150, lr = 0.001
I0614 11:17:09.629992   446 solver.cpp:270] Iteration 2200 (3.96238 iter/s, 12.6187s/50 iter), loss = 0.247884, remaining 1 hours and 14 minutes
I0614 11:17:09.630024   446 solver.cpp:291]     Train net output #0: loss = 0.247884 (* 1 = 0.247884 loss)
I0614 11:17:09.630048   446 sgd_solver.cpp:106] Iteration 2200, lr = 0.001
I0614 11:17:22.248344   446 solver.cpp:270] Iteration 2250 (3.96262 iter/s, 12.6179s/50 iter), loss = 0.218858, remaining 1 hours and 14 minutes
I0614 11:17:22.248392   446 solver.cpp:291]     Train net output #0: loss = 0.218858 (* 1 = 0.218858 loss)
I0614 11:17:22.248404   446 sgd_solver.cpp:106] Iteration 2250, lr = 0.001
I0614 11:17:34.861733   446 solver.cpp:270] Iteration 2300 (3.96418 iter/s, 12.6129s/50 iter), loss = 0.147073, remaining 1 hours and 14 minutes
I0614 11:17:34.861768   446 solver.cpp:291]     Train net output #0: loss = 0.147073 (* 1 = 0.147073 loss)
I0614 11:17:34.861775   446 sgd_solver.cpp:106] Iteration 2300, lr = 0.001
I0614 11:17:47.468957   446 solver.cpp:270] Iteration 2350 (3.96612 iter/s, 12.6068s/50 iter), loss = 0.220944, remaining 1 hours and 14 minutes
I0614 11:17:47.468991   446 solver.cpp:291]     Train net output #0: loss = 0.220944 (* 1 = 0.220944 loss)
I0614 11:17:47.468998   446 sgd_solver.cpp:106] Iteration 2350, lr = 0.001
I0614 11:18:00.088485   446 solver.cpp:270] Iteration 2400 (3.96225 iter/s, 12.6191s/50 iter), loss = 0.189836, remaining 1 hours and 13 minutes
I0614 11:18:00.088534   446 solver.cpp:291]     Train net output #0: loss = 0.189836 (* 1 = 0.189836 loss)
I0614 11:18:00.088558   446 sgd_solver.cpp:106] Iteration 2400, lr = 0.001
I0614 11:18:12.704890   446 solver.cpp:270] Iteration 2450 (3.96324 iter/s, 12.6159s/50 iter), loss = 0.139855, remaining 1 hours and 13 minutes
I0614 11:18:12.704922   446 solver.cpp:291]     Train net output #0: loss = 0.139855 (* 1 = 0.139855 loss)
I0614 11:18:12.704931   446 sgd_solver.cpp:106] Iteration 2450, lr = 0.001
I0614 11:18:25.308985   446 solver.cpp:270] Iteration 2500 (3.9671 iter/s, 12.6037s/50 iter), loss = 0.265514, remaining 1 hours and 13 minutes
I0614 11:18:25.309018   446 solver.cpp:291]     Train net output #0: loss = 0.265514 (* 1 = 0.265514 loss)
I0614 11:18:25.309027   446 sgd_solver.cpp:106] Iteration 2500, lr = 0.0001
I0614 11:18:37.909132   446 solver.cpp:270] Iteration 2550 (3.96835 iter/s, 12.5997s/50 iter), loss = 0.172199, remaining 1 hours and 13 minutes
I0614 11:18:37.909188   446 solver.cpp:291]     Train net output #0: loss = 0.172199 (* 1 = 0.172199 loss)
I0614 11:18:37.909212   446 sgd_solver.cpp:106] Iteration 2550, lr = 0.0001
I0614 11:18:50.517741   446 solver.cpp:270] Iteration 2600 (3.96569 iter/s, 12.6081s/50 iter), loss = 0.146201, remaining 1 hours and 13 minutes
I0614 11:18:50.517776   446 solver.cpp:291]     Train net output #0: loss = 0.146201 (* 1 = 0.146201 loss)
I0614 11:18:50.517783   446 sgd_solver.cpp:106] Iteration 2600, lr = 0.0001
I0614 11:19:03.142181   446 solver.cpp:270] Iteration 2650 (3.96071 iter/s, 12.624s/50 iter), loss = 0.129549, remaining 1 hours and 12 minutes
I0614 11:19:03.142211   446 solver.cpp:291]     Train net output #0: loss = 0.129549 (* 1 = 0.129549 loss)
I0614 11:19:03.142235   446 sgd_solver.cpp:106] Iteration 2650, lr = 0.0001
I0614 11:19:15.808080   446 solver.cpp:270] Iteration 2700 (3.94774 iter/s, 12.6655s/50 iter), loss = 0.0818322, remaining 1 hours and 12 minutes
I0614 11:19:15.808130   446 solver.cpp:291]     Train net output #0: loss = 0.0818322 (* 1 = 0.0818322 loss)
I0614 11:19:15.808138   446 sgd_solver.cpp:106] Iteration 2700, lr = 0.0001
I0614 11:19:28.502236   446 solver.cpp:270] Iteration 2750 (3.93896 iter/s, 12.6937s/50 iter), loss = 0.132566, remaining 1 hours and 12 minutes
I0614 11:19:28.502269   446 solver.cpp:291]     Train net output #0: loss = 0.132566 (* 1 = 0.132566 loss)
I0614 11:19:28.502279   446 sgd_solver.cpp:106] Iteration 2750, lr = 0.0001
I0614 11:19:41.214084   446 solver.cpp:270] Iteration 2800 (3.93348 iter/s, 12.7114s/50 iter), loss = 0.100255, remaining 1 hours and 12 minutes
I0614 11:19:41.214118   446 solver.cpp:291]     Train net output #0: loss = 0.100255 (* 1 = 0.100255 loss)
I0614 11:19:41.214128   446 sgd_solver.cpp:106] Iteration 2800, lr = 0.0001
I0614 11:19:54.740810   446 solver.cpp:270] Iteration 2850 (3.69651 iter/s, 13.5263s/50 iter), loss = 0.125615, remaining 1 hours and 17 minutes
I0614 11:19:54.740859   446 solver.cpp:291]     Train net output #0: loss = 0.125615 (* 1 = 0.125615 loss)
I0614 11:19:54.740868   446 sgd_solver.cpp:106] Iteration 2850, lr = 0.0001
I0614 11:20:07.968923   446 solver.cpp:270] Iteration 2900 (3.77996 iter/s, 13.2276s/50 iter), loss = 0.121969, remaining 1 hours and 15 minutes
I0614 11:20:07.968957   446 solver.cpp:291]     Train net output #0: loss = 0.121969 (* 1 = 0.121969 loss)
I0614 11:20:07.968966   446 sgd_solver.cpp:106] Iteration 2900, lr = 0.0001
I0614 11:20:21.723562   446 solver.cpp:270] Iteration 2950 (3.63526 iter/s, 13.7542s/50 iter), loss = 0.152729, remaining 1 hours and 18 minutes
I0614 11:20:21.723594   446 solver.cpp:291]     Train net output #0: loss = 0.152729 (* 1 = 0.152729 loss)
I0614 11:20:21.723603   446 sgd_solver.cpp:106] Iteration 2950, lr = 0.0001
I0614 11:20:34.961745   446 solver.cpp:424] Iteration 3000, Testing net (#0)
I0614 11:20:36.487661   446 solver.cpp:523]     Test net output #0: accuracy = 0.9115
I0614 11:20:36.487692   446 solver.cpp:523]     Test net output #1: loss = 0.627532 (* 1 = 0.627532 loss)
I0614 11:20:36.487696   446 solver.cpp:523]     Test net output #2: top-1 = 0.9115
I0614 11:20:36.737484   446 solver.cpp:270] Iteration 3000 (3.33036 iter/s, 15.0134s/50 iter), loss = 0.107426, remaining 1 hours and 24 minutes
I0614 11:20:36.737517   446 solver.cpp:291]     Train net output #0: loss = 0.107426 (* 1 = 0.107426 loss)
I0614 11:20:36.737525   446 sgd_solver.cpp:106] Iteration 3000, lr = 0.0001
I0614 11:20:50.171097   446 solver.cpp:270] Iteration 3050 (3.72214 iter/s, 13.4331s/50 iter), loss = 0.152532, remaining 1 hours and 15 minutes
I0614 11:20:50.171129   446 solver.cpp:291]     Train net output #0: loss = 0.152532 (* 1 = 0.152532 loss)
I0614 11:20:50.171152   446 sgd_solver.cpp:106] Iteration 3050, lr = 0.0001
I0614 11:21:03.579183   446 solver.cpp:270] Iteration 3100 (3.72922 iter/s, 13.4076s/50 iter), loss = 0.106048, remaining 1 hours and 15 minutes
I0614 11:21:03.579218   446 solver.cpp:291]     Train net output #0: loss = 0.106048 (* 1 = 0.106048 loss)
I0614 11:21:03.579226   446 sgd_solver.cpp:106] Iteration 3100, lr = 0.0001
I0614 11:21:16.676975   446 solver.cpp:270] Iteration 3150 (3.81757 iter/s, 13.0973s/50 iter), loss = 0.110889, remaining 1 hours and 13 minutes
I0614 11:21:16.677033   446 solver.cpp:291]     Train net output #0: loss = 0.110889 (* 1 = 0.110889 loss)
I0614 11:21:16.677042   446 sgd_solver.cpp:106] Iteration 3150, lr = 0.0001
I0614 11:21:29.581286   446 solver.cpp:270] Iteration 3200 (3.87482 iter/s, 12.9038s/50 iter), loss = 0.074072, remaining 1 hours and 12 minutes
I0614 11:21:29.581321   446 solver.cpp:291]     Train net output #0: loss = 0.074072 (* 1 = 0.074072 loss)
I0614 11:21:29.581532   446 sgd_solver.cpp:106] Iteration 3200, lr = 0.0001
I0614 11:21:42.953035   446 solver.cpp:270] Iteration 3250 (3.73942 iter/s, 13.3711s/50 iter), loss = 0.124069, remaining 1 hours and 14 minutes
I0614 11:21:42.953069   446 solver.cpp:291]     Train net output #0: loss = 0.124069 (* 1 = 0.124069 loss)
I0614 11:21:42.953078   446 sgd_solver.cpp:106] Iteration 3250, lr = 0.0001
I0614 11:21:56.742619   446 solver.cpp:270] Iteration 3300 (3.62605 iter/s, 13.7891s/50 iter), loss = 0.106658, remaining 1 hours and 16 minutes
I0614 11:21:56.742676   446 solver.cpp:291]     Train net output #0: loss = 0.106658 (* 1 = 0.106658 loss)
I0614 11:21:56.742700   446 sgd_solver.cpp:106] Iteration 3300, lr = 0.0001
I0614 11:22:10.016142   446 solver.cpp:270] Iteration 3350 (3.76703 iter/s, 13.273s/50 iter), loss = 0.0654053, remaining 1 hours and 13 minutes
I0614 11:22:10.016176   446 solver.cpp:291]     Train net output #0: loss = 0.0654053 (* 1 = 0.0654053 loss)
I0614 11:22:10.016185   446 sgd_solver.cpp:106] Iteration 3350, lr = 0.0001
I0614 11:22:23.273794   446 solver.cpp:270] Iteration 3400 (3.77154 iter/s, 13.2572s/50 iter), loss = 0.0954787, remaining 1 hours and 13 minutes
I0614 11:22:23.273829   446 solver.cpp:291]     Train net output #0: loss = 0.0954787 (* 1 = 0.0954787 loss)
I0614 11:22:23.273838   446 sgd_solver.cpp:106] Iteration 3400, lr = 0.0001
I0614 11:22:36.648555   446 solver.cpp:270] Iteration 3450 (3.73851 iter/s, 13.3743s/50 iter), loss = 0.123461, remaining 1 hours and 13 minutes
I0614 11:22:36.648605   446 solver.cpp:291]     Train net output #0: loss = 0.123461 (* 1 = 0.123461 loss)
I0614 11:22:36.648630   446 sgd_solver.cpp:106] Iteration 3450, lr = 0.0001
I0614 11:22:49.876332   446 solver.cpp:270] Iteration 3500 (3.78006 iter/s, 13.2273s/50 iter), loss = 0.0944724, remaining 1 hours and 12 minutes
I0614 11:22:49.876364   446 solver.cpp:291]     Train net output #0: loss = 0.0944724 (* 1 = 0.0944724 loss)
I0614 11:22:49.876372   446 sgd_solver.cpp:106] Iteration 3500, lr = 0.0001
I0614 11:23:03.125255   446 solver.cpp:270] Iteration 3550 (3.77402 iter/s, 13.2485s/50 iter), loss = 0.053056, remaining 1 hours and 12 minutes
I0614 11:23:03.125288   446 solver.cpp:291]     Train net output #0: loss = 0.053056 (* 1 = 0.053056 loss)
I0614 11:23:03.125296   446 sgd_solver.cpp:106] Iteration 3550, lr = 0.0001
I0614 11:23:16.106719   446 solver.cpp:270] Iteration 3600 (3.85178 iter/s, 12.981s/50 iter), loss = 0.0729185, remaining 1 hours and 10 minutes
I0614 11:23:16.106770   446 solver.cpp:291]     Train net output #0: loss = 0.0729185 (* 1 = 0.0729185 loss)
I0614 11:23:16.106779   446 sgd_solver.cpp:106] Iteration 3600, lr = 0.0001
I0614 11:23:28.922091   446 solver.cpp:270] Iteration 3650 (3.90171 iter/s, 12.8149s/50 iter), loss = 0.0959032, remaining 1 hours and 9 minutes
I0614 11:23:28.922123   446 solver.cpp:291]     Train net output #0: loss = 0.0959032 (* 1 = 0.0959032 loss)
I0614 11:23:28.922132   446 sgd_solver.cpp:106] Iteration 3650, lr = 0.0001
I0614 11:23:41.631248   446 solver.cpp:270] Iteration 3700 (3.93431 iter/s, 12.7087s/50 iter), loss = 0.0683807, remaining 1 hours and 8 minutes
I0614 11:23:41.631281   446 solver.cpp:291]     Train net output #0: loss = 0.0683807 (* 1 = 0.0683807 loss)
I0614 11:23:41.631306   446 sgd_solver.cpp:106] Iteration 3700, lr = 0.0001
I0614 11:23:54.335563   446 solver.cpp:270] Iteration 3750 (3.93581 iter/s, 12.7039s/50 iter), loss = 0.105041, remaining 1 hours and 8 minutes
I0614 11:23:54.335619   446 solver.cpp:291]     Train net output #0: loss = 0.105041 (* 1 = 0.105041 loss)
I0614 11:23:54.335628   446 sgd_solver.cpp:106] Iteration 3750, lr = 0.0001
I0614 11:24:07.247539   446 solver.cpp:270] Iteration 3800 (3.87252 iter/s, 12.9115s/50 iter), loss = 0.116934, remaining 1 hours and 9 minutes
I0614 11:24:07.247571   446 solver.cpp:291]     Train net output #0: loss = 0.116934 (* 1 = 0.116934 loss)
I0614 11:24:07.247596   446 sgd_solver.cpp:106] Iteration 3800, lr = 0.0001
I0614 11:24:20.184630   446 solver.cpp:270] Iteration 3850 (3.86499 iter/s, 12.9366s/50 iter), loss = 0.122998, remaining 1 hours and 9 minutes
I0614 11:24:20.184662   446 solver.cpp:291]     Train net output #0: loss = 0.122998 (* 1 = 0.122998 loss)
I0614 11:24:20.184686   446 sgd_solver.cpp:106] Iteration 3850, lr = 0.0001
I0614 11:24:32.927119   446 solver.cpp:270] Iteration 3900 (3.92402 iter/s, 12.742s/50 iter), loss = 0.0947435, remaining 1 hours and 8 minutes
I0614 11:24:32.927167   446 solver.cpp:291]     Train net output #0: loss = 0.0947435 (* 1 = 0.0947435 loss)
I0614 11:24:32.927176   446 sgd_solver.cpp:106] Iteration 3900, lr = 0.0001
I0614 11:24:45.587604   446 solver.cpp:270] Iteration 3950 (3.94944 iter/s, 12.66s/50 iter), loss = 0.0393411, remaining 1 hours and 7 minutes
I0614 11:24:45.587638   446 solver.cpp:291]     Train net output #0: loss = 0.0393411 (* 1 = 0.0393411 loss)
I0614 11:24:45.587662   446 sgd_solver.cpp:106] Iteration 3950, lr = 0.0001
I0614 11:24:58.146636   446 solver.cpp:424] Iteration 4000, Testing net (#0)
I0614 11:24:59.661495   446 solver.cpp:523]     Test net output #0: accuracy = 0.59975
I0614 11:24:59.661528   446 solver.cpp:523]     Test net output #1: loss = 0.643847 (* 1 = 0.643847 loss)
I0614 11:24:59.661533   446 solver.cpp:523]     Test net output #2: top-1 = 0.59975
I0614 11:24:59.916007   446 solver.cpp:270] Iteration 4000 (3.48969 iter/s, 14.3279s/50 iter), loss = 0.08408, remaining 1 hours and 16 minutes
I0614 11:24:59.916039   446 solver.cpp:291]     Train net output #0: loss = 0.08408 (* 1 = 0.08408 loss)
I0614 11:24:59.916064   446 sgd_solver.cpp:106] Iteration 4000, lr = 0.0001
I0614 11:25:13.244120   446 solver.cpp:270] Iteration 4050 (3.7516 iter/s, 13.3277s/50 iter), loss = 0.0646876, remaining 1 hours and 10 minutes
I0614 11:25:13.244169   446 solver.cpp:291]     Train net output #0: loss = 0.0646876 (* 1 = 0.0646876 loss)
I0614 11:25:13.244194   446 sgd_solver.cpp:106] Iteration 4050, lr = 0.0001
I0614 11:25:26.040035   446 solver.cpp:270] Iteration 4100 (3.90764 iter/s, 12.7955s/50 iter), loss = 0.0795154, remaining 1 hours and 7 minutes
I0614 11:25:26.040068   446 solver.cpp:291]     Train net output #0: loss = 0.0795154 (* 1 = 0.0795154 loss)
I0614 11:25:26.040093   446 sgd_solver.cpp:106] Iteration 4100, lr = 0.0001
I0614 11:25:38.692929   446 solver.cpp:270] Iteration 4150 (3.9518 iter/s, 12.6525s/50 iter), loss = 0.0764593, remaining 1 hours and 6 minutes
I0614 11:25:38.692960   446 solver.cpp:291]     Train net output #0: loss = 0.0764593 (* 1 = 0.0764593 loss)
I0614 11:25:38.692970   446 sgd_solver.cpp:106] Iteration 4150, lr = 0.0001
I0614 11:25:51.336414   446 solver.cpp:270] Iteration 4200 (3.95474 iter/s, 12.643s/50 iter), loss = 0.0767224, remaining 1 hours and 6 minutes
I0614 11:25:51.336470   446 solver.cpp:291]     Train net output #0: loss = 0.0767224 (* 1 = 0.0767224 loss)
I0614 11:25:51.336496   446 sgd_solver.cpp:106] Iteration 4200, lr = 0.0001
I0614 11:26:03.949287   446 solver.cpp:270] Iteration 4250 (3.96435 iter/s, 12.6124s/50 iter), loss = 0.107298, remaining 1 hours and 6 minutes
I0614 11:26:03.949319   446 solver.cpp:291]     Train net output #0: loss = 0.107298 (* 1 = 0.107298 loss)
I0614 11:26:03.949344   446 sgd_solver.cpp:106] Iteration 4250, lr = 0.0001
I0614 11:26:16.568184   446 solver.cpp:270] Iteration 4300 (3.96245 iter/s, 12.6185s/50 iter), loss = 0.0751663, remaining 1 hours and 5 minutes
I0614 11:26:16.568217   446 solver.cpp:291]     Train net output #0: loss = 0.0751663 (* 1 = 0.0751663 loss)
I0614 11:26:16.568243   446 sgd_solver.cpp:106] Iteration 4300, lr = 0.0001
I0614 11:26:29.204977   446 solver.cpp:270] Iteration 4350 (3.95684 iter/s, 12.6363s/50 iter), loss = 0.0791081, remaining 1 hours and 5 minutes
I0614 11:26:29.205025   446 solver.cpp:291]     Train net output #0: loss = 0.0791081 (* 1 = 0.0791081 loss)
I0614 11:26:29.205034   446 sgd_solver.cpp:106] Iteration 4350, lr = 0.0001
I0614 11:26:41.838994   446 solver.cpp:270] Iteration 4400 (3.95771 iter/s, 12.6336s/50 iter), loss = 0.0695461, remaining 1 hours and 5 minutes
I0614 11:26:41.839027   446 solver.cpp:291]     Train net output #0: loss = 0.0695461 (* 1 = 0.0695461 loss)
I0614 11:26:41.839037   446 sgd_solver.cpp:106] Iteration 4400, lr = 0.0001
I0614 11:26:54.460676   446 solver.cpp:270] Iteration 4450 (3.96158 iter/s, 12.6212s/50 iter), loss = 0.0880108, remaining 1 hours and 5 minutes
I0614 11:26:54.460709   446 solver.cpp:291]     Train net output #0: loss = 0.0880108 (* 1 = 0.0880108 loss)
I0614 11:26:54.460733   446 sgd_solver.cpp:106] Iteration 4450, lr = 0.0001
I0614 11:27:07.119768   446 solver.cpp:270] Iteration 4500 (3.94987 iter/s, 12.6587s/50 iter), loss = 0.0776492, remaining 1 hours and 5 minutes
I0614 11:27:07.119817   446 solver.cpp:291]     Train net output #0: loss = 0.0776491 (* 1 = 0.0776491 loss)
I0614 11:27:07.119827   446 sgd_solver.cpp:106] Iteration 4500, lr = 0.0001
I0614 11:27:19.913587   446 solver.cpp:270] Iteration 4550 (3.90828 iter/s, 12.7934s/50 iter), loss = 0.0835778, remaining 1 hours and 5 minutes
I0614 11:27:19.913620   446 solver.cpp:291]     Train net output #0: loss = 0.0835777 (* 1 = 0.0835777 loss)
I0614 11:27:19.913630   446 sgd_solver.cpp:106] Iteration 4550, lr = 0.0001
I0614 11:27:32.557179   446 solver.cpp:270] Iteration 4600 (3.95471 iter/s, 12.6431s/50 iter), loss = 0.0585811, remaining 1 hours and 4 minutes
I0614 11:27:32.557211   446 solver.cpp:291]     Train net output #0: loss = 0.0585811 (* 1 = 0.0585811 loss)
I0614 11:27:32.557220   446 sgd_solver.cpp:106] Iteration 4600, lr = 0.0001
I0614 11:27:45.173259   446 solver.cpp:270] Iteration 4650 (3.96333 iter/s, 12.6156s/50 iter), loss = 0.104364, remaining 1 hours and 4 minutes
I0614 11:27:45.173307   446 solver.cpp:291]     Train net output #0: loss = 0.104364 (* 1 = 0.104364 loss)
I0614 11:27:45.173316   446 sgd_solver.cpp:106] Iteration 4650, lr = 0.0001
I0614 11:27:57.821305   446 solver.cpp:270] Iteration 4700 (3.95332 iter/s, 12.6476s/50 iter), loss = 0.0947205, remaining 1 hours and 4 minutes
I0614 11:27:57.821338   446 solver.cpp:291]     Train net output #0: loss = 0.0947205 (* 1 = 0.0947205 loss)
I0614 11:27:57.821362   446 sgd_solver.cpp:106] Iteration 4700, lr = 0.0001
I0614 11:28:10.458648   446 solver.cpp:270] Iteration 4750 (3.95667 iter/s, 12.6369s/50 iter), loss = 0.0499405, remaining 1 hours and 4 minutes
I0614 11:28:10.458683   446 solver.cpp:291]     Train net output #0: loss = 0.0499405 (* 1 = 0.0499405 loss)
I0614 11:28:10.458690   446 sgd_solver.cpp:106] Iteration 4750, lr = 0.0001
I0614 11:28:23.092418   446 solver.cpp:270] Iteration 4800 (3.95778 iter/s, 12.6333s/50 iter), loss = 0.0381451, remaining 1 hours and 3 minutes
I0614 11:28:23.092468   446 solver.cpp:291]     Train net output #0: loss = 0.0381451 (* 1 = 0.0381451 loss)
I0614 11:28:23.092478   446 sgd_solver.cpp:106] Iteration 4800, lr = 0.0001
I0614 11:28:35.693295   446 solver.cpp:270] Iteration 4850 (3.96812 iter/s, 12.6004s/50 iter), loss = 0.0660781, remaining 1 hours and 3 minutes
I0614 11:28:35.693329   446 solver.cpp:291]     Train net output #0: loss = 0.0660781 (* 1 = 0.0660781 loss)
I0614 11:28:35.693338   446 sgd_solver.cpp:106] Iteration 4850, lr = 0.0001
I0614 11:28:48.320425   446 solver.cpp:270] Iteration 4900 (3.95987 iter/s, 12.6267s/50 iter), loss = 0.0691337, remaining 1 hours and 3 minutes
I0614 11:28:48.320459   446 solver.cpp:291]     Train net output #0: loss = 0.0691337 (* 1 = 0.0691337 loss)
I0614 11:28:48.320467   446 sgd_solver.cpp:106] Iteration 4900, lr = 0.0001
I0614 11:29:00.925285   446 solver.cpp:270] Iteration 4950 (3.96686 iter/s, 12.6044s/50 iter), loss = 0.0552061, remaining 1 hours and 3 minutes
I0614 11:29:00.925343   446 solver.cpp:291]     Train net output #0: loss = 0.0552061 (* 1 = 0.0552061 loss)
I0614 11:29:00.925367   446 sgd_solver.cpp:106] Iteration 4950, lr = 0.0001
I0614 11:29:13.370501   446 solver.cpp:935] Snapshotting to binary proto file caffe/models/alexnetBNnoLRN/m2/snapshot_2_alexnetBNnoLRN__iter_5000.caffemodel
I0614 11:29:18.535758   446 sgd_solver.cpp:273] Snapshotting solver state to binary proto file caffe/models/alexnetBNnoLRN/m2/snapshot_2_alexnetBNnoLRN__iter_5000.solverstate
I0614 11:29:22.054443   446 solver.cpp:424] Iteration 5000, Testing net (#0)
I0614 11:29:23.483458   446 solver.cpp:523]     Test net output #0: accuracy = 0.73525
I0614 11:29:23.483489   446 solver.cpp:523]     Test net output #1: loss = 0.623404 (* 1 = 0.623404 loss)
I0614 11:29:23.483494   446 solver.cpp:523]     Test net output #2: top-1 = 0.73525
I0614 11:29:23.723932   446 solver.cpp:270] Iteration 5000 (2.19319 iter/s, 22.7979s/50 iter), loss = 0.0997797, remaining 1 hours and 53 minutes
I0614 11:29:23.723963   446 solver.cpp:291]     Train net output #0: loss = 0.0997797 (* 1 = 0.0997797 loss)
I0614 11:29:23.723973   446 sgd_solver.cpp:106] Iteration 5000, lr = 1e-05
I0614 11:29:36.259397   446 solver.cpp:270] Iteration 5050 (3.98882 iter/s, 12.535s/50 iter), loss = 0.0596434, remaining 1 hours and 2 minutes
I0614 11:29:36.259444   446 solver.cpp:291]     Train net output #0: loss = 0.0596434 (* 1 = 0.0596434 loss)
I0614 11:29:36.259454   446 sgd_solver.cpp:106] Iteration 5050, lr = 1e-05
I0614 11:29:48.838789   446 solver.cpp:270] Iteration 5100 (3.9749 iter/s, 12.5789s/50 iter), loss = 0.0359207, remaining 1 hours and 2 minutes
I0614 11:29:48.838824   446 solver.cpp:291]     Train net output #0: loss = 0.0359206 (* 1 = 0.0359206 loss)
I0614 11:29:48.838846   446 sgd_solver.cpp:106] Iteration 5100, lr = 1e-05
I0614 11:30:01.464237   446 solver.cpp:270] Iteration 5150 (3.96039 iter/s, 12.625s/50 iter), loss = 0.0429243, remaining 1 hours and 2 minutes
I0614 11:30:01.464272   446 solver.cpp:291]     Train net output #0: loss = 0.0429243 (* 1 = 0.0429243 loss)
I0614 11:30:01.464279   446 sgd_solver.cpp:106] Iteration 5150, lr = 1e-05
I0614 11:30:14.307996   446 solver.cpp:270] Iteration 5200 (3.89308 iter/s, 12.8433s/50 iter), loss = 0.0255555, remaining 1 hours and 3 minutes
I0614 11:30:14.308043   446 solver.cpp:291]     Train net output #0: loss = 0.0255555 (* 1 = 0.0255555 loss)
I0614 11:30:14.308053   446 sgd_solver.cpp:106] Iteration 5200, lr = 1e-05
I0614 11:30:26.943292   446 solver.cpp:270] Iteration 5250 (3.95731 iter/s, 12.6348s/50 iter), loss = 0.0583046, remaining 1 hours and 1 minutes
I0614 11:30:26.943325   446 solver.cpp:291]     Train net output #0: loss = 0.0583046 (* 1 = 0.0583046 loss)
I0614 11:30:26.943333   446 sgd_solver.cpp:106] Iteration 5250, lr = 1e-05
I0614 11:30:39.558785   446 solver.cpp:270] Iteration 5300 (3.96352 iter/s, 12.6151s/50 iter), loss = 0.0482128, remaining 1 hours and 1 minutes
I0614 11:30:39.558821   446 solver.cpp:291]     Train net output #0: loss = 0.0482127 (* 1 = 0.0482127 loss)
I0614 11:30:39.558845   446 sgd_solver.cpp:106] Iteration 5300, lr = 1e-05
I0614 11:30:52.208698   446 solver.cpp:270] Iteration 5350 (3.95274 iter/s, 12.6495s/50 iter), loss = 0.0536075, remaining 1 hours and 1 minutes
I0614 11:30:52.208753   446 solver.cpp:291]     Train net output #0: loss = 0.0536075 (* 1 = 0.0536075 loss)
I0614 11:30:52.208778   446 sgd_solver.cpp:106] Iteration 5350, lr = 1e-05
I0614 11:31:04.856823   446 solver.cpp:270] Iteration 5400 (3.9533 iter/s, 12.6477s/50 iter), loss = 0.0601142, remaining 1 hours and 1 minutes
I0614 11:31:04.856856   446 solver.cpp:291]     Train net output #0: loss = 0.0601142 (* 1 = 0.0601142 loss)
I0614 11:31:04.856880   446 sgd_solver.cpp:106] Iteration 5400, lr = 1e-05
I0614 11:31:17.484915   446 solver.cpp:270] Iteration 5450 (3.95957 iter/s, 12.6276s/50 iter), loss = 0.0611146, remaining 1 hours and 1 minutes
I0614 11:31:17.484947   446 solver.cpp:291]     Train net output #0: loss = 0.0611146 (* 1 = 0.0611146 loss)
I0614 11:31:17.484972   446 sgd_solver.cpp:106] Iteration 5450, lr = 1e-05
I0614 11:31:30.136795   446 solver.cpp:270] Iteration 5500 (3.95212 iter/s, 12.6514s/50 iter), loss = 0.0644402, remaining 1 hours and 0 minutes
I0614 11:31:30.136847   446 solver.cpp:291]     Train net output #0: loss = 0.0644402 (* 1 = 0.0644402 loss)
I0614 11:31:30.136854   446 sgd_solver.cpp:106] Iteration 5500, lr = 1e-05
I0614 11:31:42.785542   446 solver.cpp:270] Iteration 5550 (3.9531 iter/s, 12.6483s/50 iter), loss = 0.060252, remaining 1 hours and 0 minutes
I0614 11:31:42.785574   446 solver.cpp:291]     Train net output #0: loss = 0.0602519 (* 1 = 0.0602519 loss)
I0614 11:31:42.785583   446 sgd_solver.cpp:106] Iteration 5550, lr = 1e-05
I0614 11:31:55.405187   446 solver.cpp:270] Iteration 5600 (3.96221 iter/s, 12.6192s/50 iter), loss = 0.0495237, remaining 1 hours and 0 minutes
I0614 11:31:55.405220   446 solver.cpp:291]     Train net output #0: loss = 0.0495237 (* 1 = 0.0495237 loss)
I0614 11:31:55.405228   446 sgd_solver.cpp:106] Iteration 5600, lr = 1e-05
I0614 11:32:08.040102   446 solver.cpp:270] Iteration 5650 (3.95743 iter/s, 12.6345s/50 iter), loss = 0.0383163, remaining 1 hours and 0 minutes
I0614 11:32:08.040153   446 solver.cpp:291]     Train net output #0: loss = 0.0383163 (* 1 = 0.0383163 loss)
I0614 11:32:08.040176   446 sgd_solver.cpp:106] Iteration 5650, lr = 1e-05
I0614 11:32:20.677841   446 solver.cpp:270] Iteration 5700 (3.95655 iter/s, 12.6373s/50 iter), loss = 0.0461755, remaining 1 hours and 0 minutes
I0614 11:32:20.677875   446 solver.cpp:291]     Train net output #0: loss = 0.0461754 (* 1 = 0.0461754 loss)
I0614 11:32:20.677884   446 sgd_solver.cpp:106] Iteration 5700, lr = 1e-05
I0614 11:32:33.410276   446 solver.cpp:270] Iteration 5750 (3.92712 iter/s, 12.732s/50 iter), loss = 0.0683635, remaining 1 hours and 0 minutes
I0614 11:32:33.410310   446 solver.cpp:291]     Train net output #0: loss = 0.0683635 (* 1 = 0.0683635 loss)
I0614 11:32:33.410334   446 sgd_solver.cpp:106] Iteration 5750, lr = 1e-05
I0614 11:32:47.004909   446 solver.cpp:270] Iteration 5800 (3.67805 iter/s, 13.5942s/50 iter), loss = 0.0519003, remaining 1 hours and 4 minutes
I0614 11:32:47.004958   446 solver.cpp:291]     Train net output #0: loss = 0.0519003 (* 1 = 0.0519003 loss)
I0614 11:32:47.004968   446 sgd_solver.cpp:106] Iteration 5800, lr = 1e-05
I0614 11:33:00.574808   446 solver.cpp:270] Iteration 5850 (3.68476 iter/s, 13.5694s/50 iter), loss = 0.0437181, remaining 1 hours and 3 minutes
I0614 11:33:00.574843   446 solver.cpp:291]     Train net output #0: loss = 0.0437181 (* 1 = 0.0437181 loss)
I0614 11:33:00.574853   446 sgd_solver.cpp:106] Iteration 5850, lr = 1e-05
I0614 11:33:13.755951   446 solver.cpp:270] Iteration 5900 (3.79343 iter/s, 13.1807s/50 iter), loss = 0.0491781, remaining 1 hours and 1 minutes
I0614 11:33:13.755985   446 solver.cpp:291]     Train net output #0: loss = 0.0491781 (* 1 = 0.0491781 loss)
I0614 11:33:13.756042   446 sgd_solver.cpp:106] Iteration 5900, lr = 1e-05
I0614 11:33:27.027730   446 solver.cpp:270] Iteration 5950 (3.76754 iter/s, 13.2713s/50 iter), loss = 0.0544583, remaining 1 hours and 2 minutes
I0614 11:33:27.027791   446 solver.cpp:291]     Train net output #0: loss = 0.0544583 (* 1 = 0.0544583 loss)
I0614 11:33:27.027799   446 sgd_solver.cpp:106] Iteration 5950, lr = 1e-05
I0614 11:33:39.437773   446 solver.cpp:424] Iteration 6000, Testing net (#0)
I0614 11:33:40.953630   446 solver.cpp:523]     Test net output #0: accuracy = 0.7575
I0614 11:33:40.953662   446 solver.cpp:523]     Test net output #1: loss = 0.598659 (* 1 = 0.598659 loss)
I0614 11:33:40.953667   446 solver.cpp:523]     Test net output #2: top-1 = 0.7575
I0614 11:33:41.204488   446 solver.cpp:270] Iteration 6000 (3.52703 iter/s, 14.1762s/50 iter), loss = 0.0350641, remaining 1 hours and 6 minutes
I0614 11:33:41.204520   446 solver.cpp:291]     Train net output #0: loss = 0.0350641 (* 1 = 0.0350641 loss)
I0614 11:33:41.204545   446 sgd_solver.cpp:106] Iteration 6000, lr = 1e-05
I0614 11:33:53.877449   446 solver.cpp:270] Iteration 6050 (3.94555 iter/s, 12.6725s/50 iter), loss = 0.0417504, remaining 0 hours and 58 minutes
I0614 11:33:53.877482   446 solver.cpp:291]     Train net output #0: loss = 0.0417503 (* 1 = 0.0417503 loss)
I0614 11:33:53.877491   446 sgd_solver.cpp:106] Iteration 6050, lr = 1e-05
I0614 11:34:06.555135   446 solver.cpp:270] Iteration 6100 (3.94407 iter/s, 12.6772s/50 iter), loss = 0.0361467, remaining 0 hours and 58 minutes
I0614 11:34:06.555186   446 solver.cpp:291]     Train net output #0: loss = 0.0361467 (* 1 = 0.0361467 loss)
I0614 11:34:06.555210   446 sgd_solver.cpp:106] Iteration 6100, lr = 1e-05
I0614 11:34:19.212576   446 solver.cpp:270] Iteration 6150 (3.95039 iter/s, 12.657s/50 iter), loss = 0.0558813, remaining 0 hours and 58 minutes
I0614 11:34:19.212611   446 solver.cpp:291]     Train net output #0: loss = 0.0558813 (* 1 = 0.0558813 loss)
I0614 11:34:19.212635   446 sgd_solver.cpp:106] Iteration 6150, lr = 1e-05
I0614 11:34:31.872820   446 solver.cpp:270] Iteration 6200 (3.94951 iter/s, 12.6598s/50 iter), loss = 0.0403608, remaining 0 hours and 58 minutes
I0614 11:34:31.872854   446 solver.cpp:291]     Train net output #0: loss = 0.0403608 (* 1 = 0.0403608 loss)
I0614 11:34:31.872879   446 sgd_solver.cpp:106] Iteration 6200, lr = 1e-05
I0614 11:34:44.532475   446 solver.cpp:270] Iteration 6250 (3.94969 iter/s, 12.6592s/50 iter), loss = 0.0496401, remaining 0 hours and 57 minutes
I0614 11:34:44.532526   446 solver.cpp:291]     Train net output #0: loss = 0.0496401 (* 1 = 0.0496401 loss)
I0614 11:34:44.532550   446 sgd_solver.cpp:106] Iteration 6250, lr = 1e-05
I0614 11:34:57.205010   446 solver.cpp:270] Iteration 6300 (3.94568 iter/s, 12.6721s/50 iter), loss = 0.0374842, remaining 0 hours and 57 minutes
I0614 11:34:57.205044   446 solver.cpp:291]     Train net output #0: loss = 0.0374842 (* 1 = 0.0374842 loss)
I0614 11:34:57.205052   446 sgd_solver.cpp:106] Iteration 6300, lr = 1e-05
I0614 11:35:09.890234   446 solver.cpp:270] Iteration 6350 (3.94173 iter/s, 12.6848s/50 iter), loss = 0.0302949, remaining 0 hours and 57 minutes
I0614 11:35:09.890269   446 solver.cpp:291]     Train net output #0: loss = 0.0302949 (* 1 = 0.0302949 loss)
I0614 11:35:09.890292   446 sgd_solver.cpp:106] Iteration 6350, lr = 1e-05
I0614 11:35:22.595786   446 solver.cpp:270] Iteration 6400 (3.93543 iter/s, 12.7051s/50 iter), loss = 0.0237501, remaining 0 hours and 57 minutes
I0614 11:35:22.595835   446 solver.cpp:291]     Train net output #0: loss = 0.0237501 (* 1 = 0.0237501 loss)
I0614 11:35:22.595860   446 sgd_solver.cpp:106] Iteration 6400, lr = 1e-05
I0614 11:35:35.273030   446 solver.cpp:270] Iteration 6450 (3.94422 iter/s, 12.6768s/50 iter), loss = 0.016175, remaining 0 hours and 57 minutes
I0614 11:35:35.273064   446 solver.cpp:291]     Train net output #0: loss = 0.016175 (* 1 = 0.016175 loss)
I0614 11:35:35.273088   446 sgd_solver.cpp:106] Iteration 6450, lr = 1e-05
I0614 11:35:47.950628   446 solver.cpp:270] Iteration 6500 (3.9441 iter/s, 12.6772s/50 iter), loss = 0.0414805, remaining 0 hours and 57 minutes
I0614 11:35:47.950659   446 solver.cpp:291]     Train net output #0: loss = 0.0414805 (* 1 = 0.0414805 loss)
I0614 11:35:47.950668   446 sgd_solver.cpp:106] Iteration 6500, lr = 1e-05
I0614 11:36:00.640321   446 solver.cpp:270] Iteration 6550 (3.94034 iter/s, 12.6893s/50 iter), loss = 0.0530873, remaining 0 hours and 56 minutes
I0614 11:36:00.640380   446 solver.cpp:291]     Train net output #0: loss = 0.0530873 (* 1 = 0.0530873 loss)
I0614 11:36:00.640389   446 sgd_solver.cpp:106] Iteration 6550, lr = 1e-05
I0614 11:36:13.332777   446 solver.cpp:270] Iteration 6600 (3.93949 iter/s, 12.692s/50 iter), loss = 0.0720534, remaining 0 hours and 56 minutes
I0614 11:36:13.332810   446 solver.cpp:291]     Train net output #0: loss = 0.0720534 (* 1 = 0.0720534 loss)
I0614 11:36:13.332834   446 sgd_solver.cpp:106] Iteration 6600, lr = 1e-05
I0614 11:36:26.010883   446 solver.cpp:270] Iteration 6650 (3.94394 iter/s, 12.6777s/50 iter), loss = 0.0539958, remaining 0 hours and 56 minutes
I0614 11:36:26.010916   446 solver.cpp:291]     Train net output #0: loss = 0.0539958 (* 1 = 0.0539958 loss)
I0614 11:36:26.010924   446 sgd_solver.cpp:106] Iteration 6650, lr = 1e-05
I0614 11:36:38.683176   446 solver.cpp:270] Iteration 6700 (3.94575 iter/s, 12.6719s/50 iter), loss = 0.0656995, remaining 0 hours and 56 minutes
I0614 11:36:38.683223   446 solver.cpp:291]     Train net output #0: loss = 0.0656995 (* 1 = 0.0656995 loss)
I0614 11:36:38.683230   446 sgd_solver.cpp:106] Iteration 6700, lr = 1e-05
I0614 11:36:51.341670   446 solver.cpp:270] Iteration 6750 (3.95006 iter/s, 12.658s/50 iter), loss = 0.0483491, remaining 0 hours and 55 minutes
I0614 11:36:51.341703   446 solver.cpp:291]     Train net output #0: loss = 0.0483491 (* 1 = 0.0483491 loss)
I0614 11:36:51.341711   446 sgd_solver.cpp:106] Iteration 6750, lr = 1e-05
I0614 11:37:03.998165   446 solver.cpp:270] Iteration 6800 (3.95068 iter/s, 12.6561s/50 iter), loss = 0.0624493, remaining 0 hours and 55 minutes
I0614 11:37:03.998198   446 solver.cpp:291]     Train net output #0: loss = 0.0624493 (* 1 = 0.0624493 loss)
I0614 11:37:03.998206   446 sgd_solver.cpp:106] Iteration 6800, lr = 1e-05
I0614 11:37:16.689560   446 solver.cpp:270] Iteration 6850 (3.93981 iter/s, 12.691s/50 iter), loss = 0.0318296, remaining 0 hours and 55 minutes
I0614 11:37:16.689610   446 solver.cpp:291]     Train net output #0: loss = 0.0318296 (* 1 = 0.0318296 loss)
I0614 11:37:16.689618   446 sgd_solver.cpp:106] Iteration 6850, lr = 1e-05
I0614 11:37:29.368444   446 solver.cpp:270] Iteration 6900 (3.94371 iter/s, 12.6784s/50 iter), loss = 0.0448327, remaining 0 hours and 55 minutes
I0614 11:37:29.368479   446 solver.cpp:291]     Train net output #0: loss = 0.0448327 (* 1 = 0.0448327 loss)
I0614 11:37:29.368487   446 sgd_solver.cpp:106] Iteration 6900, lr = 1e-05
I0614 11:37:42.075809   446 solver.cpp:270] Iteration 6950 (3.93486 iter/s, 12.7069s/50 iter), loss = 0.0304985, remaining 0 hours and 55 minutes
I0614 11:37:42.075843   446 solver.cpp:291]     Train net output #0: loss = 0.0304985 (* 1 = 0.0304985 loss)
I0614 11:37:42.075852   446 sgd_solver.cpp:106] Iteration 6950, lr = 1e-05
I0614 11:37:54.513548   446 solver.cpp:424] Iteration 7000, Testing net (#0)
I0614 11:37:55.984082   446 solver.cpp:523]     Test net output #0: accuracy = 0.80775
I0614 11:37:55.984114   446 solver.cpp:523]     Test net output #1: loss = 0.574834 (* 1 = 0.574834 loss)
I0614 11:37:55.984118   446 solver.cpp:523]     Test net output #2: top-1 = 0.80775
I0614 11:37:56.236045   446 solver.cpp:270] Iteration 7000 (3.53114 iter/s, 14.1597s/50 iter), loss = 0.0333306, remaining 1 hours and 1 minutes
I0614 11:37:56.236078   446 solver.cpp:291]     Train net output #0: loss = 0.0333306 (* 1 = 0.0333306 loss)
I0614 11:37:56.236102   446 sgd_solver.cpp:106] Iteration 7000, lr = 1e-05
I0614 11:38:08.911844   446 solver.cpp:270] Iteration 7050 (3.94466 iter/s, 12.6754s/50 iter), loss = 0.0533536, remaining 0 hours and 54 minutes
I0614 11:38:08.911880   446 solver.cpp:291]     Train net output #0: loss = 0.0533536 (* 1 = 0.0533536 loss)
I0614 11:38:08.911888   446 sgd_solver.cpp:106] Iteration 7050, lr = 1e-05
I0614 11:38:21.604970   446 solver.cpp:270] Iteration 7100 (3.93928 iter/s, 12.6927s/50 iter), loss = 0.0179374, remaining 0 hours and 54 minutes
I0614 11:38:21.605003   446 solver.cpp:291]     Train net output #0: loss = 0.0179374 (* 1 = 0.0179374 loss)
I0614 11:38:21.605028   446 sgd_solver.cpp:106] Iteration 7100, lr = 1e-05
I0614 11:38:34.277614   446 solver.cpp:270] Iteration 7150 (3.94564 iter/s, 12.6722s/50 iter), loss = 0.0670131, remaining 0 hours and 54 minutes
I0614 11:38:34.277671   446 solver.cpp:291]     Train net output #0: loss = 0.0670131 (* 1 = 0.0670131 loss)
I0614 11:38:34.277696   446 sgd_solver.cpp:106] Iteration 7150, lr = 1e-05
I0614 11:38:46.954008   446 solver.cpp:270] Iteration 7200 (3.94448 iter/s, 12.6759s/50 iter), loss = 0.049958, remaining 0 hours and 53 minutes
I0614 11:38:46.954043   446 solver.cpp:291]     Train net output #0: loss = 0.049958 (* 1 = 0.049958 loss)
I0614 11:38:46.954067   446 sgd_solver.cpp:106] Iteration 7200, lr = 1e-05
I0614 11:38:59.623509   446 solver.cpp:270] Iteration 7250 (3.94662 iter/s, 12.6691s/50 iter), loss = 0.016341, remaining 0 hours and 53 minutes
I0614 11:38:59.623545   446 solver.cpp:291]     Train net output #0: loss = 0.016341 (* 1 = 0.016341 loss)
I0614 11:38:59.623569   446 sgd_solver.cpp:106] Iteration 7250, lr = 1e-05
I0614 11:39:12.334486   446 solver.cpp:270] Iteration 7300 (3.93375 iter/s, 12.7105s/50 iter), loss = 0.0217379, remaining 0 hours and 53 minutes
I0614 11:39:12.334535   446 solver.cpp:291]     Train net output #0: loss = 0.0217379 (* 1 = 0.0217379 loss)
I0614 11:39:12.334544   446 sgd_solver.cpp:106] Iteration 7300, lr = 1e-05
I0614 11:39:24.993377   446 solver.cpp:270] Iteration 7350 (3.94994 iter/s, 12.6584s/50 iter), loss = 0.0365559, remaining 0 hours and 53 minutes
I0614 11:39:24.993409   446 solver.cpp:291]     Train net output #0: loss = 0.0365559 (* 1 = 0.0365559 loss)
I0614 11:39:24.993417   446 sgd_solver.cpp:106] Iteration 7350, lr = 1e-05
I0614 11:39:37.665165   446 solver.cpp:270] Iteration 7400 (3.94591 iter/s, 12.6713s/50 iter), loss = 0.0306156, remaining 0 hours and 53 minutes
I0614 11:39:37.665199   446 solver.cpp:291]     Train net output #0: loss = 0.0306156 (* 1 = 0.0306156 loss)
I0614 11:39:37.665222   446 sgd_solver.cpp:106] Iteration 7400, lr = 1e-05
I0614 11:39:50.339265   446 solver.cpp:270] Iteration 7450 (3.94519 iter/s, 12.6737s/50 iter), loss = 0.0238295, remaining 0 hours and 52 minutes
I0614 11:39:50.339313   446 solver.cpp:291]     Train net output #0: loss = 0.0238295 (* 1 = 0.0238295 loss)
I0614 11:39:50.339337   446 sgd_solver.cpp:106] Iteration 7450, lr = 1e-05
I0614 11:40:03.027575   446 solver.cpp:270] Iteration 7500 (3.94078 iter/s, 12.6879s/50 iter), loss = 0.0692794, remaining 0 hours and 52 minutes
I0614 11:40:03.027609   446 solver.cpp:291]     Train net output #0: loss = 0.0692794 (* 1 = 0.0692794 loss)
I0614 11:40:03.027618   446 sgd_solver.cpp:106] Iteration 7500, lr = 1e-06
I0614 11:40:15.710409   446 solver.cpp:270] Iteration 7550 (3.94247 iter/s, 12.6824s/50 iter), loss = 0.0388028, remaining 0 hours and 52 minutes
I0614 11:40:15.710443   446 solver.cpp:291]     Train net output #0: loss = 0.0388028 (* 1 = 0.0388028 loss)
I0614 11:40:15.710453   446 sgd_solver.cpp:106] Iteration 7550, lr = 1e-06
I0614 11:40:28.392830   446 solver.cpp:270] Iteration 7600 (3.9426 iter/s, 12.682s/50 iter), loss = 0.0371399, remaining 0 hours and 52 minutes
I0614 11:40:28.392879   446 solver.cpp:291]     Train net output #0: loss = 0.0371399 (* 1 = 0.0371399 loss)
I0614 11:40:28.392889   446 sgd_solver.cpp:106] Iteration 7600, lr = 1e-06
I0614 11:40:41.059329   446 solver.cpp:270] Iteration 7650 (3.94756 iter/s, 12.666s/50 iter), loss = 0.0383949, remaining 0 hours and 51 minutes
I0614 11:40:41.059362   446 solver.cpp:291]     Train net output #0: loss = 0.0383949 (* 1 = 0.0383949 loss)
I0614 11:40:41.059371   446 sgd_solver.cpp:106] Iteration 7650, lr = 1e-06
I0614 11:40:53.714033   446 solver.cpp:270] Iteration 7700 (3.95124 iter/s, 12.6543s/50 iter), loss = 0.0068936, remaining 0 hours and 51 minutes
I0614 11:40:53.714066   446 solver.cpp:291]     Train net output #0: loss = 0.00689361 (* 1 = 0.00689361 loss)
I0614 11:40:53.714092   446 sgd_solver.cpp:106] Iteration 7700, lr = 1e-06
I0614 11:41:06.389200   446 solver.cpp:270] Iteration 7750 (3.94486 iter/s, 12.6747s/50 iter), loss = 0.0446702, remaining 0 hours and 51 minutes
I0614 11:41:06.389258   446 solver.cpp:291]     Train net output #0: loss = 0.0446702 (* 1 = 0.0446702 loss)
I0614 11:41:06.389267   446 sgd_solver.cpp:106] Iteration 7750, lr = 1e-06
I0614 11:41:19.103546   446 solver.cpp:270] Iteration 7800 (3.93271 iter/s, 12.7139s/50 iter), loss = 0.0230567, remaining 0 hours and 51 minutes
I0614 11:41:19.103580   446 solver.cpp:291]     Train net output #0: loss = 0.0230568 (* 1 = 0.0230568 loss)
I0614 11:41:19.103605   446 sgd_solver.cpp:106] Iteration 7800, lr = 1e-06
I0614 11:41:31.779320   446 solver.cpp:270] Iteration 7850 (3.94467 iter/s, 12.6753s/50 iter), loss = 0.0343935, remaining 0 hours and 51 minutes
I0614 11:41:31.779356   446 solver.cpp:291]     Train net output #0: loss = 0.0343935 (* 1 = 0.0343935 loss)
I0614 11:41:31.779364   446 sgd_solver.cpp:106] Iteration 7850, lr = 1e-06
I0614 11:41:44.460790   446 solver.cpp:270] Iteration 7900 (3.9429 iter/s, 12.681s/50 iter), loss = 0.0494707, remaining 0 hours and 50 minutes
I0614 11:41:44.460839   446 solver.cpp:291]     Train net output #0: loss = 0.0494707 (* 1 = 0.0494707 loss)
I0614 11:41:44.460865   446 sgd_solver.cpp:106] Iteration 7900, lr = 1e-06
I0614 11:41:57.130214   446 solver.cpp:270] Iteration 7950 (3.94665 iter/s, 12.669s/50 iter), loss = 0.0896775, remaining 0 hours and 50 minutes
I0614 11:41:57.130249   446 solver.cpp:291]     Train net output #0: loss = 0.0896775 (* 1 = 0.0896775 loss)
I0614 11:41:57.130273   446 sgd_solver.cpp:106] Iteration 7950, lr = 1e-06
I0614 11:42:09.539834   446 solver.cpp:424] Iteration 8000, Testing net (#0)
I0614 11:42:11.042379   446 solver.cpp:523]     Test net output #0: accuracy = 0.8875
I0614 11:42:11.042412   446 solver.cpp:523]     Test net output #1: loss = 0.53429 (* 1 = 0.53429 loss)
I0614 11:42:11.042418   446 solver.cpp:523]     Test net output #2: top-1 = 0.8875
I0614 11:42:11.293179   446 solver.cpp:270] Iteration 8000 (3.53046 iter/s, 14.1625s/50 iter), loss = 0.0335851, remaining 0 hours and 56 minutes
I0614 11:42:11.293210   446 solver.cpp:291]     Train net output #0: loss = 0.0335851 (* 1 = 0.0335851 loss)
I0614 11:42:11.293220   446 sgd_solver.cpp:106] Iteration 8000, lr = 1e-06
I0614 11:42:23.948643   446 solver.cpp:270] Iteration 8050 (3.951 iter/s, 12.655s/50 iter), loss = 0.0649148, remaining 0 hours and 50 minutes
I0614 11:42:23.948695   446 solver.cpp:291]     Train net output #0: loss = 0.0649148 (* 1 = 0.0649148 loss)
I0614 11:42:23.948720   446 sgd_solver.cpp:106] Iteration 8050, lr = 1e-06
I0614 11:42:36.612185   446 solver.cpp:270] Iteration 8100 (3.94849 iter/s, 12.6631s/50 iter), loss = 0.0453782, remaining 0 hours and 50 minutes
I0614 11:42:36.612221   446 solver.cpp:291]     Train net output #0: loss = 0.0453782 (* 1 = 0.0453782 loss)
I0614 11:42:36.612244   446 sgd_solver.cpp:106] Iteration 8100, lr = 1e-06
I0614 11:42:49.289417   446 solver.cpp:270] Iteration 8150 (3.94422 iter/s, 12.6768s/50 iter), loss = 0.0454443, remaining 0 hours and 49 minutes
I0614 11:42:49.289451   446 solver.cpp:291]     Train net output #0: loss = 0.0454443 (* 1 = 0.0454443 loss)
I0614 11:42:49.289476   446 sgd_solver.cpp:106] Iteration 8150, lr = 1e-06
I0614 11:43:01.955243   446 solver.cpp:270] Iteration 8200 (3.94777 iter/s, 12.6654s/50 iter), loss = 0.0234782, remaining 0 hours and 49 minutes
I0614 11:43:01.955293   446 solver.cpp:291]     Train net output #0: loss = 0.0234782 (* 1 = 0.0234782 loss)
I0614 11:43:01.955303   446 sgd_solver.cpp:106] Iteration 8200, lr = 1e-06
I0614 11:43:14.616933   446 solver.cpp:270] Iteration 8250 (3.94906 iter/s, 12.6612s/50 iter), loss = 0.0512955, remaining 0 hours and 49 minutes
I0614 11:43:14.616967   446 solver.cpp:291]     Train net output #0: loss = 0.0512955 (* 1 = 0.0512955 loss)
I0614 11:43:14.616992   446 sgd_solver.cpp:106] Iteration 8250, lr = 1e-06
I0614 11:43:27.281839   446 solver.cpp:270] Iteration 8300 (3.94806 iter/s, 12.6645s/50 iter), loss = 0.0278317, remaining 0 hours and 49 minutes
I0614 11:43:27.281873   446 solver.cpp:291]     Train net output #0: loss = 0.0278317 (* 1 = 0.0278317 loss)
I0614 11:43:27.281883   446 sgd_solver.cpp:106] Iteration 8300, lr = 1e-06
I0614 11:43:39.942618   446 solver.cpp:270] Iteration 8350 (3.94934 iter/s, 12.6603s/50 iter), loss = 0.0237697, remaining 0 hours and 49 minutes
I0614 11:43:39.942695   446 solver.cpp:291]     Train net output #0: loss = 0.0237697 (* 1 = 0.0237697 loss)
I0614 11:43:39.942705   446 sgd_solver.cpp:106] Iteration 8350, lr = 1e-06
I0614 11:43:52.610009   446 solver.cpp:270] Iteration 8400 (3.94729 iter/s, 12.6669s/50 iter), loss = 0.0501832, remaining 0 hours and 48 minutes
I0614 11:43:52.610044   446 solver.cpp:291]     Train net output #0: loss = 0.0501832 (* 1 = 0.0501832 loss)
I0614 11:43:52.610069   446 sgd_solver.cpp:106] Iteration 8400, lr = 1e-06
I0614 11:44:05.281976   446 solver.cpp:270] Iteration 8450 (3.94586 iter/s, 12.6715s/50 iter), loss = 0.0480381, remaining 0 hours and 48 minutes
I0614 11:44:05.282011   446 solver.cpp:291]     Train net output #0: loss = 0.048038 (* 1 = 0.048038 loss)
I0614 11:44:05.282020   446 sgd_solver.cpp:106] Iteration 8450, lr = 1e-06
I0614 11:44:17.956035   446 solver.cpp:270] Iteration 8500 (3.9452 iter/s, 12.6736s/50 iter), loss = 0.0241324, remaining 0 hours and 48 minutes
I0614 11:44:17.956084   446 solver.cpp:291]     Train net output #0: loss = 0.0241324 (* 1 = 0.0241324 loss)
I0614 11:44:17.956094   446 sgd_solver.cpp:106] Iteration 8500, lr = 1e-06
I0614 11:44:30.624374   446 solver.cpp:270] Iteration 8550 (3.94699 iter/s, 12.6679s/50 iter), loss = 0.0339071, remaining 0 hours and 48 minutes
I0614 11:44:30.624408   446 solver.cpp:291]     Train net output #0: loss = 0.0339071 (* 1 = 0.0339071 loss)
I0614 11:44:30.624433   446 sgd_solver.cpp:106] Iteration 8550, lr = 1e-06
I0614 11:44:43.311452   446 solver.cpp:270] Iteration 8600 (3.94116 iter/s, 12.6866s/50 iter), loss = 0.0335153, remaining 0 hours and 48 minutes
I0614 11:44:43.311486   446 solver.cpp:291]     Train net output #0: loss = 0.0335153 (* 1 = 0.0335153 loss)
I0614 11:44:43.311511   446 sgd_solver.cpp:106] Iteration 8600, lr = 1e-06
I0614 11:44:55.989871   446 solver.cpp:270] Iteration 8650 (3.94385 iter/s, 12.678s/50 iter), loss = 0.0454969, remaining 0 hours and 47 minutes
I0614 11:44:55.989917   446 solver.cpp:291]     Train net output #0: loss = 0.0454968 (* 1 = 0.0454968 loss)
I0614 11:44:55.989928   446 sgd_solver.cpp:106] Iteration 8650, lr = 1e-06
I0614 11:45:08.663228   446 solver.cpp:270] Iteration 8700 (3.94543 iter/s, 12.6729s/50 iter), loss = 0.0191024, remaining 0 hours and 47 minutes
I0614 11:45:08.663262   446 solver.cpp:291]     Train net output #0: loss = 0.0191024 (* 1 = 0.0191024 loss)
I0614 11:45:08.663271   446 sgd_solver.cpp:106] Iteration 8700, lr = 1e-06
I0614 11:45:21.328718   446 solver.cpp:270] Iteration 8750 (3.94787 iter/s, 12.665s/50 iter), loss = 0.0529555, remaining 0 hours and 47 minutes
I0614 11:45:21.328753   446 solver.cpp:291]     Train net output #0: loss = 0.0529555 (* 1 = 0.0529555 loss)
I0614 11:45:21.328778   446 sgd_solver.cpp:106] Iteration 8750, lr = 1e-06
I0614 11:45:34.009862   446 solver.cpp:270] Iteration 8800 (3.943 iter/s, 12.6807s/50 iter), loss = 0.0305515, remaining 0 hours and 47 minutes
I0614 11:45:34.009912   446 solver.cpp:291]     Train net output #0: loss = 0.0305515 (* 1 = 0.0305515 loss)
I0614 11:45:34.009936   446 sgd_solver.cpp:106] Iteration 8800, lr = 1e-06
I0614 11:45:46.666163   446 solver.cpp:270] Iteration 8850 (3.95074 iter/s, 12.6558s/50 iter), loss = 0.0221193, remaining 0 hours and 46 minutes
I0614 11:45:46.666198   446 solver.cpp:291]     Train net output #0: loss = 0.0221193 (* 1 = 0.0221193 loss)
I0614 11:45:46.666222   446 sgd_solver.cpp:106] Iteration 8850, lr = 1e-06
I0614 11:45:59.333335   446 solver.cpp:270] Iteration 8900 (3.94735 iter/s, 12.6667s/50 iter), loss = 0.0293535, remaining 0 hours and 46 minutes
I0614 11:45:59.333369   446 solver.cpp:291]     Train net output #0: loss = 0.0293535 (* 1 = 0.0293535 loss)
I0614 11:45:59.333395   446 sgd_solver.cpp:106] Iteration 8900, lr = 1e-06
I0614 11:46:12.021546   446 solver.cpp:270] Iteration 8950 (3.9408 iter/s, 12.6878s/50 iter), loss = 0.0163493, remaining 0 hours and 46 minutes
I0614 11:46:12.021602   446 solver.cpp:291]     Train net output #0: loss = 0.0163493 (* 1 = 0.0163493 loss)
I0614 11:46:12.021611   446 sgd_solver.cpp:106] Iteration 8950, lr = 1e-06
I0614 11:46:24.441264   446 solver.cpp:424] Iteration 9000, Testing net (#0)
I0614 11:46:25.932087   446 solver.cpp:523]     Test net output #0: accuracy = 0.9305
I0614 11:46:25.932121   446 solver.cpp:523]     Test net output #1: loss = 0.463615 (* 1 = 0.463615 loss)
I0614 11:46:25.932124   446 solver.cpp:523]     Test net output #2: top-1 = 0.9305
I0614 11:46:26.183573   446 solver.cpp:270] Iteration 9000 (3.5307 iter/s, 14.1615s/50 iter), loss = 0.0408265, remaining 0 hours and 51 minutes
I0614 11:46:26.183606   446 solver.cpp:291]     Train net output #0: loss = 0.0408264 (* 1 = 0.0408264 loss)
I0614 11:46:26.183615   446 sgd_solver.cpp:106] Iteration 9000, lr = 1e-06
I0614 11:46:38.826670   446 solver.cpp:270] Iteration 9050 (3.95487 iter/s, 12.6427s/50 iter), loss = 0.0254666, remaining 0 hours and 46 minutes
I0614 11:46:38.826704   446 solver.cpp:291]     Train net output #0: loss = 0.0254665 (* 1 = 0.0254665 loss)
I0614 11:46:38.826728   446 sgd_solver.cpp:106] Iteration 9050, lr = 1e-06
I0614 11:46:51.516453   446 solver.cpp:270] Iteration 9100 (3.94032 iter/s, 12.6893s/50 iter), loss = 0.029567, remaining 0 hours and 45 minutes
I0614 11:46:51.516502   446 solver.cpp:291]     Train net output #0: loss = 0.029567 (* 1 = 0.029567 loss)
I0614 11:46:51.516512   446 sgd_solver.cpp:106] Iteration 9100, lr = 1e-06
I0614 11:47:04.184018   446 solver.cpp:270] Iteration 9150 (3.94723 iter/s, 12.6671s/50 iter), loss = 0.0173261, remaining 0 hours and 45 minutes
I0614 11:47:04.184052   446 solver.cpp:291]     Train net output #0: loss = 0.017326 (* 1 = 0.017326 loss)
I0614 11:47:04.184060   446 sgd_solver.cpp:106] Iteration 9150, lr = 1e-06
I0614 11:47:16.858130   446 solver.cpp:270] Iteration 9200 (3.94519 iter/s, 12.6737s/50 iter), loss = 0.0889566, remaining 0 hours and 45 minutes
I0614 11:47:16.858163   446 solver.cpp:291]     Train net output #0: loss = 0.0889566 (* 1 = 0.0889566 loss)
I0614 11:47:16.858188   446 sgd_solver.cpp:106] Iteration 9200, lr = 1e-06
I0614 11:47:29.525485   446 solver.cpp:270] Iteration 9250 (3.94729 iter/s, 12.6669s/50 iter), loss = 0.0415817, remaining 0 hours and 45 minutes
I0614 11:47:29.525533   446 solver.cpp:291]     Train net output #0: loss = 0.0415817 (* 1 = 0.0415817 loss)
I0614 11:47:29.525542   446 sgd_solver.cpp:106] Iteration 9250, lr = 1e-06
I0614 11:47:42.173648   446 solver.cpp:270] Iteration 9300 (3.95329 iter/s, 12.6477s/50 iter), loss = 0.0541857, remaining 0 hours and 45 minutes
I0614 11:47:42.173681   446 solver.cpp:291]     Train net output #0: loss = 0.0541856 (* 1 = 0.0541856 loss)
I0614 11:47:42.173689   446 sgd_solver.cpp:106] Iteration 9300, lr = 1e-06
I0614 11:47:54.844856   446 solver.cpp:270] Iteration 9350 (3.94609 iter/s, 12.6708s/50 iter), loss = 0.0443334, remaining 0 hours and 44 minutes
I0614 11:47:54.844888   446 solver.cpp:291]     Train net output #0: loss = 0.0443334 (* 1 = 0.0443334 loss)
I0614 11:47:54.844913   446 sgd_solver.cpp:106] Iteration 9350, lr = 1e-06
I0614 11:48:07.497381   446 solver.cpp:270] Iteration 9400 (3.95192 iter/s, 12.6521s/50 iter), loss = 0.0494349, remaining 0 hours and 44 minutes
I0614 11:48:07.497431   446 solver.cpp:291]     Train net output #0: loss = 0.0494349 (* 1 = 0.0494349 loss)
I0614 11:48:07.497454   446 sgd_solver.cpp:106] Iteration 9400, lr = 1e-06
I0614 11:48:20.197952   446 solver.cpp:270] Iteration 9450 (3.93697 iter/s, 12.7001s/50 iter), loss = 0.0245951, remaining 0 hours and 44 minutes
I0614 11:48:20.197985   446 solver.cpp:291]     Train net output #0: loss = 0.0245951 (* 1 = 0.0245951 loss)
I0614 11:48:20.197994   446 sgd_solver.cpp:106] Iteration 9450, lr = 1e-06
I0614 11:48:32.873107   446 solver.cpp:270] Iteration 9500 (3.94486 iter/s, 12.6747s/50 iter), loss = 0.0490821, remaining 0 hours and 44 minutes
I0614 11:48:32.873140   446 solver.cpp:291]     Train net output #0: loss = 0.0490821 (* 1 = 0.0490821 loss)
I0614 11:48:32.873150   446 sgd_solver.cpp:106] Iteration 9500, lr = 1e-06
I0614 11:48:45.531809   446 solver.cpp:270] Iteration 9550 (3.94999 iter/s, 12.6583s/50 iter), loss = 0.0204789, remaining 0 hours and 44 minutes
I0614 11:48:45.531864   446 solver.cpp:291]     Train net output #0: loss = 0.0204788 (* 1 = 0.0204788 loss)
I0614 11:48:45.531873   446 sgd_solver.cpp:106] Iteration 9550, lr = 1e-06
I0614 11:48:58.196627   446 solver.cpp:270] Iteration 9600 (3.94809 iter/s, 12.6644s/50 iter), loss = 0.0158569, remaining 0 hours and 43 minutes
I0614 11:48:58.196674   446 solver.cpp:291]     Train net output #0: loss = 0.0158569 (* 1 = 0.0158569 loss)
I0614 11:48:58.196683   446 sgd_solver.cpp:106] Iteration 9600, lr = 1e-06
I0614 11:49:10.882717   446 solver.cpp:270] Iteration 9650 (3.94147 iter/s, 12.6856s/50 iter), loss = 0.0731047, remaining 0 hours and 43 minutes
I0614 11:49:10.882750   446 solver.cpp:291]     Train net output #0: loss = 0.0731047 (* 1 = 0.0731047 loss)
I0614 11:49:10.882761   446 sgd_solver.cpp:106] Iteration 9650, lr = 1e-06
I0614 11:49:23.541441   446 solver.cpp:270] Iteration 9700 (3.94998 iter/s, 12.6583s/50 iter), loss = 0.0506441, remaining 0 hours and 43 minutes
I0614 11:49:23.541488   446 solver.cpp:291]     Train net output #0: loss = 0.0506441 (* 1 = 0.0506441 loss)
I0614 11:49:23.541514   446 sgd_solver.cpp:106] Iteration 9700, lr = 1e-06
I0614 11:49:36.227013   446 solver.cpp:270] Iteration 9750 (3.94163 iter/s, 12.6851s/50 iter), loss = 0.0363153, remaining 0 hours and 43 minutes
I0614 11:49:36.227046   446 solver.cpp:291]     Train net output #0: loss = 0.0363153 (* 1 = 0.0363153 loss)
I0614 11:49:36.227072   446 sgd_solver.cpp:106] Iteration 9750, lr = 1e-06
I0614 11:49:48.915596   446 solver.cpp:270] Iteration 9800 (3.94069 iter/s, 12.6881s/50 iter), loss = 0.0280168, remaining 0 hours and 43 minutes
I0614 11:49:48.915629   446 solver.cpp:291]     Train net output #0: loss = 0.0280167 (* 1 = 0.0280167 loss)
I0614 11:49:48.915638   446 sgd_solver.cpp:106] Iteration 9800, lr = 1e-06
I0614 11:50:01.536381   446 solver.cpp:270] Iteration 9850 (3.96186 iter/s, 12.6203s/50 iter), loss = 0.0333203, remaining 0 hours and 42 minutes
I0614 11:50:01.536427   446 solver.cpp:291]     Train net output #0: loss = 0.0333203 (* 1 = 0.0333203 loss)
I0614 11:50:01.536451   446 sgd_solver.cpp:106] Iteration 9850, lr = 1e-06
I0614 11:50:14.199359   446 solver.cpp:270] Iteration 9900 (3.94866 iter/s, 12.6625s/50 iter), loss = 0.0392669, remaining 0 hours and 42 minutes
I0614 11:50:14.199393   446 solver.cpp:291]     Train net output #0: loss = 0.0392668 (* 1 = 0.0392668 loss)
I0614 11:50:14.199417   446 sgd_solver.cpp:106] Iteration 9900, lr = 1e-06
I0614 11:50:26.849269   446 solver.cpp:270] Iteration 9950 (3.95274 iter/s, 12.6495s/50 iter), loss = 0.0257077, remaining 0 hours and 42 minutes
I0614 11:50:26.849303   446 solver.cpp:291]     Train net output #0: loss = 0.0257076 (* 1 = 0.0257076 loss)
I0614 11:50:26.849326   446 sgd_solver.cpp:106] Iteration 9950, lr = 1e-06
I0614 11:50:39.656991   446 solver.cpp:935] Snapshotting to binary proto file caffe/models/alexnetBNnoLRN/m2/snapshot_2_alexnetBNnoLRN__iter_10000.caffemodel
I0614 11:50:44.746233   446 sgd_solver.cpp:273] Snapshotting solver state to binary proto file caffe/models/alexnetBNnoLRN/m2/snapshot_2_alexnetBNnoLRN__iter_10000.solverstate
I0614 11:50:48.329589   446 solver.cpp:424] Iteration 10000, Testing net (#0)
I0614 11:50:49.757143   446 solver.cpp:523]     Test net output #0: accuracy = 0.94425
I0614 11:50:49.757176   446 solver.cpp:523]     Test net output #1: loss = 0.366615 (* 1 = 0.366615 loss)
I0614 11:50:49.757184   446 solver.cpp:523]     Test net output #2: top-1 = 0.94425
I0614 11:50:49.996047   446 solver.cpp:270] Iteration 10000 (2.1602 iter/s, 23.146s/50 iter), loss = 0.0314566, remaining 1 hours and 16 minutes
I0614 11:50:49.996080   446 solver.cpp:291]     Train net output #0: loss = 0.0314566 (* 1 = 0.0314566 loss)
I0614 11:50:49.996105   446 sgd_solver.cpp:106] Iteration 10000, lr = 1e-07
I0614 11:51:02.481101   446 solver.cpp:270] Iteration 10050 (4.00493 iter/s, 12.4846s/50 iter), loss = 0.0444908, remaining 0 hours and 41 minutes
I0614 11:51:02.481133   446 solver.cpp:291]     Train net output #0: loss = 0.0444908 (* 1 = 0.0444908 loss)
I0614 11:51:02.481158   446 sgd_solver.cpp:106] Iteration 10050, lr = 1e-07
I0614 11:51:14.947410   446 solver.cpp:270] Iteration 10100 (4.01095 iter/s, 12.4659s/50 iter), loss = 0.0364447, remaining 0 hours and 41 minutes
I0614 11:51:14.947468   446 solver.cpp:291]     Train net output #0: loss = 0.0364447 (* 1 = 0.0364447 loss)
I0614 11:51:14.947479   446 sgd_solver.cpp:106] Iteration 10100, lr = 1e-07
I0614 11:51:27.543864   446 solver.cpp:270] Iteration 10150 (3.96952 iter/s, 12.596s/50 iter), loss = 0.0310487, remaining 0 hours and 41 minutes
I0614 11:51:27.543896   446 solver.cpp:291]     Train net output #0: loss = 0.0310486 (* 1 = 0.0310486 loss)
I0614 11:51:27.543905   446 sgd_solver.cpp:106] Iteration 10150, lr = 1e-07
I0614 11:51:40.158979   446 solver.cpp:270] Iteration 10200 (3.96364 iter/s, 12.6147s/50 iter), loss = 0.0153154, remaining 0 hours and 41 minutes
I0614 11:51:40.159013   446 solver.cpp:291]     Train net output #0: loss = 0.0153153 (* 1 = 0.0153153 loss)
I0614 11:51:40.159037   446 sgd_solver.cpp:106] Iteration 10200, lr = 1e-07
I0614 11:51:52.767001   446 solver.cpp:270] Iteration 10250 (3.96587 iter/s, 12.6076s/50 iter), loss = 0.054055, remaining 0 hours and 40 minutes
I0614 11:51:52.767053   446 solver.cpp:291]     Train net output #0: loss = 0.054055 (* 1 = 0.054055 loss)
I0614 11:51:52.767062   446 sgd_solver.cpp:106] Iteration 10250, lr = 1e-07
I0614 11:52:05.373045   446 solver.cpp:270] Iteration 10300 (3.9665 iter/s, 12.6056s/50 iter), loss = 0.0189027, remaining 0 hours and 40 minutes
I0614 11:52:05.373078   446 solver.cpp:291]     Train net output #0: loss = 0.0189027 (* 1 = 0.0189027 loss)
I0614 11:52:05.373087   446 sgd_solver.cpp:106] Iteration 10300, lr = 1e-07
I0614 11:52:17.981148   446 solver.cpp:270] Iteration 10350 (3.96584 iter/s, 12.6077s/50 iter), loss = 0.0273298, remaining 0 hours and 40 minutes
I0614 11:52:17.981180   446 solver.cpp:291]     Train net output #0: loss = 0.0273297 (* 1 = 0.0273297 loss)
I0614 11:52:17.981205   446 sgd_solver.cpp:106] Iteration 10350, lr = 1e-07
I0614 11:52:30.591497   446 solver.cpp:270] Iteration 10400 (3.96514 iter/s, 12.6099s/50 iter), loss = 0.0431895, remaining 0 hours and 40 minutes
I0614 11:52:30.591547   446 solver.cpp:291]     Train net output #0: loss = 0.0431895 (* 1 = 0.0431895 loss)
I0614 11:52:30.591572   446 sgd_solver.cpp:106] Iteration 10400, lr = 1e-07
I0614 11:52:43.212116   446 solver.cpp:270] Iteration 10450 (3.96191 iter/s, 12.6202s/50 iter), loss = 0.0573529, remaining 0 hours and 40 minutes
I0614 11:52:43.212149   446 solver.cpp:291]     Train net output #0: loss = 0.0573529 (* 1 = 0.0573529 loss)
I0614 11:52:43.212174   446 sgd_solver.cpp:106] Iteration 10450, lr = 1e-07
I0614 11:52:55.820034   446 solver.cpp:270] Iteration 10500 (3.9659 iter/s, 12.6075s/50 iter), loss = 0.0385754, remaining 0 hours and 39 minutes
I0614 11:52:55.820067   446 solver.cpp:291]     Train net output #0: loss = 0.0385754 (* 1 = 0.0385754 loss)
I0614 11:52:55.820078   446 sgd_solver.cpp:106] Iteration 10500, lr = 1e-07
I0614 11:53:08.439149   446 solver.cpp:270] Iteration 10550 (3.96238 iter/s, 12.6187s/50 iter), loss = 0.0634091, remaining 0 hours and 39 minutes
I0614 11:53:08.439215   446 solver.cpp:291]     Train net output #0: loss = 0.0634091 (* 1 = 0.0634091 loss)
I0614 11:53:08.439225   446 sgd_solver.cpp:106] Iteration 10550, lr = 1e-07
I0614 11:53:21.054073   446 solver.cpp:270] Iteration 10600 (3.9637 iter/s, 12.6145s/50 iter), loss = 0.0253449, remaining 0 hours and 39 minutes
I0614 11:53:21.054106   446 solver.cpp:291]     Train net output #0: loss = 0.0253449 (* 1 = 0.0253449 loss)
I0614 11:53:21.054116   446 sgd_solver.cpp:106] Iteration 10600, lr = 1e-07
I0614 11:53:33.673619   446 solver.cpp:270] Iteration 10650 (3.96225 iter/s, 12.6191s/50 iter), loss = 0.043779, remaining 0 hours and 39 minutes
I0614 11:53:33.673652   446 solver.cpp:291]     Train net output #0: loss = 0.043779 (* 1 = 0.043779 loss)
I0614 11:53:33.673661   446 sgd_solver.cpp:106] Iteration 10650, lr = 1e-07
I0614 11:53:46.294675   446 solver.cpp:270] Iteration 10700 (3.96177 iter/s, 12.6206s/50 iter), loss = 0.0308948, remaining 0 hours and 39 minutes
I0614 11:53:46.294734   446 solver.cpp:291]     Train net output #0: loss = 0.0308947 (* 1 = 0.0308947 loss)
I0614 11:53:46.294744   446 sgd_solver.cpp:106] Iteration 10700, lr = 1e-07
I0614 11:53:58.911312   446 solver.cpp:270] Iteration 10750 (3.96317 iter/s, 12.6162s/50 iter), loss = 0.0256815, remaining 0 hours and 38 minutes
I0614 11:53:58.911348   446 solver.cpp:291]     Train net output #0: loss = 0.0256815 (* 1 = 0.0256815 loss)
I0614 11:53:58.911373   446 sgd_solver.cpp:106] Iteration 10750, lr = 1e-07
I0614 11:54:11.521625   446 solver.cpp:270] Iteration 10800 (3.96515 iter/s, 12.6099s/50 iter), loss = 0.0627476, remaining 0 hours and 38 minutes
I0614 11:54:11.521656   446 solver.cpp:291]     Train net output #0: loss = 0.0627476 (* 1 = 0.0627476 loss)
I0614 11:54:11.521665   446 sgd_solver.cpp:106] Iteration 10800, lr = 1e-07
I0614 11:54:24.135795   446 solver.cpp:270] Iteration 10850 (3.96393 iter/s, 12.6137s/50 iter), loss = 0.0171163, remaining 0 hours and 38 minutes
I0614 11:54:24.135859   446 solver.cpp:291]     Train net output #0: loss = 0.0171162 (* 1 = 0.0171162 loss)
I0614 11:54:24.135869   446 sgd_solver.cpp:106] Iteration 10850, lr = 1e-07
I0614 11:54:36.755292   446 solver.cpp:270] Iteration 10900 (3.96227 iter/s, 12.619s/50 iter), loss = 0.0845947, remaining 0 hours and 38 minutes
I0614 11:54:36.755326   446 solver.cpp:291]     Train net output #0: loss = 0.0845946 (* 1 = 0.0845946 loss)
I0614 11:54:36.755350   446 sgd_solver.cpp:106] Iteration 10900, lr = 1e-07
I0614 11:54:49.371102   446 solver.cpp:270] Iteration 10950 (3.96342 iter/s, 12.6154s/50 iter), loss = 0.0558348, remaining 0 hours and 37 minutes
I0614 11:54:49.371134   446 solver.cpp:291]     Train net output #0: loss = 0.0558348 (* 1 = 0.0558348 loss)
I0614 11:54:49.371160   446 sgd_solver.cpp:106] Iteration 10950, lr = 1e-07
I0614 11:55:01.738201   446 solver.cpp:424] Iteration 11000, Testing net (#0)
I0614 11:55:03.247165   446 solver.cpp:523]     Test net output #0: accuracy = 0.951
I0614 11:55:03.247196   446 solver.cpp:523]     Test net output #1: loss = 0.258503 (* 1 = 0.258503 loss)
I0614 11:55:03.247201   446 solver.cpp:523]     Test net output #2: top-1 = 0.951
I0614 11:55:03.493988   446 solver.cpp:270] Iteration 11000 (3.54048 iter/s, 14.1224s/50 iter), loss = 0.0262959, remaining 0 hours and 42 minutes
I0614 11:55:03.494020   446 solver.cpp:291]     Train net output #0: loss = 0.0262959 (* 1 = 0.0262959 loss)
I0614 11:55:03.494029   446 sgd_solver.cpp:106] Iteration 11000, lr = 1e-07
I0614 11:55:16.104043   446 solver.cpp:270] Iteration 11050 (3.96523 iter/s, 12.6096s/50 iter), loss = 0.0323451, remaining 0 hours and 37 minutes
I0614 11:55:16.104077   446 solver.cpp:291]     Train net output #0: loss = 0.0323451 (* 1 = 0.0323451 loss)
I0614 11:55:16.104086   446 sgd_solver.cpp:106] Iteration 11050, lr = 1e-07
I0614 11:55:28.713685   446 solver.cpp:270] Iteration 11100 (3.96536 iter/s, 12.6092s/50 iter), loss = 0.0256418, remaining 0 hours and 37 minutes
I0614 11:55:28.713718   446 solver.cpp:291]     Train net output #0: loss = 0.0256418 (* 1 = 0.0256418 loss)
I0614 11:55:28.713729   446 sgd_solver.cpp:106] Iteration 11100, lr = 1e-07
I0614 11:55:41.325115   446 solver.cpp:270] Iteration 11150 (3.9648 iter/s, 12.611s/50 iter), loss = 0.0709662, remaining 0 hours and 37 minutes
I0614 11:55:41.325165   446 solver.cpp:291]     Train net output #0: loss = 0.0709662 (* 1 = 0.0709662 loss)
I0614 11:55:41.325191   446 sgd_solver.cpp:106] Iteration 11150, lr = 1e-07
I0614 11:55:53.929134   446 solver.cpp:270] Iteration 11200 (3.96713 iter/s, 12.6036s/50 iter), loss = 0.022735, remaining 0 hours and 36 minutes
I0614 11:55:53.929167   446 solver.cpp:291]     Train net output #0: loss = 0.022735 (* 1 = 0.022735 loss)
I0614 11:55:53.929176   446 sgd_solver.cpp:106] Iteration 11200, lr = 1e-07
I0614 11:56:06.543903   446 solver.cpp:270] Iteration 11250 (3.96375 iter/s, 12.6143s/50 iter), loss = 0.0483921, remaining 0 hours and 36 minutes
I0614 11:56:06.543937   446 solver.cpp:291]     Train net output #0: loss = 0.0483921 (* 1 = 0.0483921 loss)
I0614 11:56:06.543962   446 sgd_solver.cpp:106] Iteration 11250, lr = 1e-07
I0614 11:56:19.153734   446 solver.cpp:270] Iteration 11300 (3.9653 iter/s, 12.6094s/50 iter), loss = 0.0530849, remaining 0 hours and 36 minutes
I0614 11:56:19.153795   446 solver.cpp:291]     Train net output #0: loss = 0.0530848 (* 1 = 0.0530848 loss)
I0614 11:56:19.153820   446 sgd_solver.cpp:106] Iteration 11300, lr = 1e-07
I0614 11:56:31.763718   446 solver.cpp:270] Iteration 11350 (3.96526 iter/s, 12.6095s/50 iter), loss = 0.0188848, remaining 0 hours and 36 minutes
I0614 11:56:31.763751   446 solver.cpp:291]     Train net output #0: loss = 0.0188848 (* 1 = 0.0188848 loss)
I0614 11:56:31.763759   446 sgd_solver.cpp:106] Iteration 11350, lr = 1e-07
I0614 11:56:44.384873   446 solver.cpp:270] Iteration 11400 (3.96174 iter/s, 12.6207s/50 iter), loss = 0.0244599, remaining 0 hours and 36 minutes
I0614 11:56:44.384908   446 solver.cpp:291]     Train net output #0: loss = 0.0244599 (* 1 = 0.0244599 loss)
I0614 11:56:44.384917   446 sgd_solver.cpp:106] Iteration 11400, lr = 1e-07
I0614 11:56:56.994099   446 solver.cpp:270] Iteration 11450 (3.96549 iter/s, 12.6088s/50 iter), loss = 0.0156604, remaining 0 hours and 35 minutes
I0614 11:56:56.994146   446 solver.cpp:291]     Train net output #0: loss = 0.0156603 (* 1 = 0.0156603 loss)
I0614 11:56:56.994171   446 sgd_solver.cpp:106] Iteration 11450, lr = 1e-07
I0614 11:57:09.607270   446 solver.cpp:270] Iteration 11500 (3.96425 iter/s, 12.6127s/50 iter), loss = 0.0464618, remaining 0 hours and 35 minutes
I0614 11:57:09.607306   446 solver.cpp:291]     Train net output #0: loss = 0.0464617 (* 1 = 0.0464617 loss)
I0614 11:57:09.607314   446 sgd_solver.cpp:106] Iteration 11500, lr = 1e-07
I0614 11:57:22.211055   446 solver.cpp:270] Iteration 11550 (3.9672 iter/s, 12.6033s/50 iter), loss = 0.0224596, remaining 0 hours and 35 minutes
I0614 11:57:22.211088   446 solver.cpp:291]     Train net output #0: loss = 0.0224596 (* 1 = 0.0224596 loss)
I0614 11:57:22.211112   446 sgd_solver.cpp:106] Iteration 11550, lr = 1e-07
I0614 11:57:34.822866   446 solver.cpp:270] Iteration 11600 (3.96468 iter/s, 12.6114s/50 iter), loss = 0.0306089, remaining 0 hours and 35 minutes
I0614 11:57:34.822916   446 solver.cpp:291]     Train net output #0: loss = 0.0306089 (* 1 = 0.0306089 loss)
I0614 11:57:34.822925   446 sgd_solver.cpp:106] Iteration 11600, lr = 1e-07
I0614 11:57:47.437803   446 solver.cpp:270] Iteration 11650 (3.9637 iter/s, 12.6145s/50 iter), loss = 0.0487241, remaining 0 hours and 35 minutes
I0614 11:57:47.437836   446 solver.cpp:291]     Train net output #0: loss = 0.0487241 (* 1 = 0.0487241 loss)
I0614 11:57:47.437861   446 sgd_solver.cpp:106] Iteration 11650, lr = 1e-07
I0614 11:58:00.047713   446 solver.cpp:270] Iteration 11700 (3.96527 iter/s, 12.6095s/50 iter), loss = 0.0436786, remaining 0 hours and 34 minutes
I0614 11:58:00.047746   446 solver.cpp:291]     Train net output #0: loss = 0.0436786 (* 1 = 0.0436786 loss)
I0614 11:58:00.047771   446 sgd_solver.cpp:106] Iteration 11700, lr = 1e-07
I0614 11:58:12.777431   446 solver.cpp:270] Iteration 11750 (3.92795 iter/s, 12.7293s/50 iter), loss = 0.0188561, remaining 0 hours and 34 minutes
I0614 11:58:12.777478   446 solver.cpp:291]     Train net output #0: loss = 0.018856 (* 1 = 0.018856 loss)
I0614 11:58:12.777487   446 sgd_solver.cpp:106] Iteration 11750, lr = 1e-07
I0614 11:58:25.462885   446 solver.cpp:270] Iteration 11800 (3.94166 iter/s, 12.685s/50 iter), loss = 0.0399624, remaining 0 hours and 34 minutes
I0614 11:58:25.462918   446 solver.cpp:291]     Train net output #0: loss = 0.0399624 (* 1 = 0.0399624 loss)
I0614 11:58:25.462926   446 sgd_solver.cpp:106] Iteration 11800, lr = 1e-07
I0614 11:58:38.154222   446 solver.cpp:270] Iteration 11850 (3.93983 iter/s, 12.6909s/50 iter), loss = 0.0347476, remaining 0 hours and 34 minutes
I0614 11:58:38.154258   446 solver.cpp:291]     Train net output #0: loss = 0.0347476 (* 1 = 0.0347476 loss)
I0614 11:58:38.154265   446 sgd_solver.cpp:106] Iteration 11850, lr = 1e-07
I0614 11:58:50.790868   446 solver.cpp:270] Iteration 11900 (3.95689 iter/s, 12.6362s/50 iter), loss = 0.0338437, remaining 0 hours and 34 minutes
I0614 11:58:50.790925   446 solver.cpp:291]     Train net output #0: loss = 0.0338436 (* 1 = 0.0338436 loss)
I0614 11:58:50.790935   446 sgd_solver.cpp:106] Iteration 11900, lr = 1e-07
I0614 11:59:03.406420   446 solver.cpp:270] Iteration 11950 (3.96351 iter/s, 12.6151s/50 iter), loss = 0.0514619, remaining 0 hours and 33 minutes
I0614 11:59:03.406455   446 solver.cpp:291]     Train net output #0: loss = 0.0514618 (* 1 = 0.0514618 loss)
I0614 11:59:03.406464   446 sgd_solver.cpp:106] Iteration 11950, lr = 1e-07
I0614 11:59:15.770054   446 solver.cpp:424] Iteration 12000, Testing net (#0)
I0614 11:59:17.263235   446 solver.cpp:523]     Test net output #0: accuracy = 0.95275
I0614 11:59:17.263265   446 solver.cpp:523]     Test net output #1: loss = 0.17255 (* 1 = 0.17255 loss)
I0614 11:59:17.263269   446 solver.cpp:523]     Test net output #2: top-1 = 0.95275
I0614 11:59:17.509932   446 solver.cpp:270] Iteration 12000 (3.54534 iter/s, 14.103s/50 iter), loss = 0.0532086, remaining 0 hours and 37 minutes
I0614 11:59:17.509963   446 solver.cpp:291]     Train net output #0: loss = 0.0532086 (* 1 = 0.0532086 loss)
I0614 11:59:17.509971   446 sgd_solver.cpp:106] Iteration 12000, lr = 1e-07
I0614 11:59:30.129106   446 solver.cpp:270] Iteration 12050 (3.96236 iter/s, 12.6187s/50 iter), loss = 0.0195288, remaining 0 hours and 33 minutes
I0614 11:59:30.129154   446 solver.cpp:291]     Train net output #0: loss = 0.0195288 (* 1 = 0.0195288 loss)
I0614 11:59:30.129179   446 sgd_solver.cpp:106] Iteration 12050, lr = 1e-07
I0614 11:59:42.744571   446 solver.cpp:270] Iteration 12100 (3.96353 iter/s, 12.615s/50 iter), loss = 0.0387486, remaining 0 hours and 33 minutes
I0614 11:59:42.744606   446 solver.cpp:291]     Train net output #0: loss = 0.0387486 (* 1 = 0.0387486 loss)
I0614 11:59:42.744616   446 sgd_solver.cpp:106] Iteration 12100, lr = 1e-07
I0614 11:59:55.365415   446 solver.cpp:270] Iteration 12150 (3.96184 iter/s, 12.6204s/50 iter), loss = 0.043989, remaining 0 hours and 32 minutes
I0614 11:59:55.365448   446 solver.cpp:291]     Train net output #0: loss = 0.0439889 (* 1 = 0.0439889 loss)
I0614 11:59:55.365460   446 sgd_solver.cpp:106] Iteration 12150, lr = 1e-07
I0614 12:00:07.979944   446 solver.cpp:270] Iteration 12200 (3.96382 iter/s, 12.6141s/50 iter), loss = 0.0527552, remaining 0 hours and 32 minutes
I0614 12:00:07.979993   446 solver.cpp:291]     Train net output #0: loss = 0.0527551 (* 1 = 0.0527551 loss)
I0614 12:00:07.980002   446 sgd_solver.cpp:106] Iteration 12200, lr = 1e-07
I0614 12:00:20.590277   446 solver.cpp:270] Iteration 12250 (3.96515 iter/s, 12.6099s/50 iter), loss = 0.0226475, remaining 0 hours and 32 minutes
I0614 12:00:20.590310   446 solver.cpp:291]     Train net output #0: loss = 0.0226475 (* 1 = 0.0226475 loss)
I0614 12:00:20.590319   446 sgd_solver.cpp:106] Iteration 12250, lr = 1e-07
I0614 12:00:33.206542   446 solver.cpp:270] Iteration 12300 (3.96328 iter/s, 12.6158s/50 iter), loss = 0.036579, remaining 0 hours and 32 minutes
I0614 12:00:33.206575   446 solver.cpp:291]     Train net output #0: loss = 0.036579 (* 1 = 0.036579 loss)
I0614 12:00:33.206586   446 sgd_solver.cpp:106] Iteration 12300, lr = 1e-07
I0614 12:00:45.810425   446 solver.cpp:270] Iteration 12350 (3.96717 iter/s, 12.6034s/50 iter), loss = 0.0232578, remaining 0 hours and 32 minutes
I0614 12:00:45.810479   446 solver.cpp:291]     Train net output #0: loss = 0.0232577 (* 1 = 0.0232577 loss)
I0614 12:00:45.810504   446 sgd_solver.cpp:106] Iteration 12350, lr = 1e-07
I0614 12:00:58.429287   446 solver.cpp:270] Iteration 12400 (3.96247 iter/s, 12.6184s/50 iter), loss = 0.0527202, remaining 0 hours and 31 minutes
I0614 12:00:58.429320   446 solver.cpp:291]     Train net output #0: loss = 0.0527202 (* 1 = 0.0527202 loss)
I0614 12:00:58.429345   446 sgd_solver.cpp:106] Iteration 12400, lr = 1e-07
I0614 12:01:11.045279   446 solver.cpp:270] Iteration 12450 (3.96336 iter/s, 12.6156s/50 iter), loss = 0.0247821, remaining 0 hours and 31 minutes
I0614 12:01:11.045311   446 solver.cpp:291]     Train net output #0: loss = 0.0247821 (* 1 = 0.0247821 loss)
I0614 12:01:11.045336   446 sgd_solver.cpp:106] Iteration 12450, lr = 1e-07
I0614 12:01:23.654521   446 solver.cpp:270] Iteration 12500 (3.96548 iter/s, 12.6088s/50 iter), loss = 0.0378734, remaining 0 hours and 31 minutes
I0614 12:01:23.654568   446 solver.cpp:291]     Train net output #0: loss = 0.0378733 (* 1 = 0.0378733 loss)
I0614 12:01:23.654593   446 sgd_solver.cpp:106] Iteration 12500, lr = 1e-08
I0614 12:01:36.275676   446 solver.cpp:270] Iteration 12550 (3.96175 iter/s, 12.6207s/50 iter), loss = 0.0620707, remaining 0 hours and 31 minutes
I0614 12:01:36.275709   446 solver.cpp:291]     Train net output #0: loss = 0.0620707 (* 1 = 0.0620707 loss)
I0614 12:01:36.275719   446 sgd_solver.cpp:106] Iteration 12550, lr = 1e-08
I0614 12:01:48.892072   446 solver.cpp:270] Iteration 12600 (3.96324 iter/s, 12.616s/50 iter), loss = 0.0247721, remaining 0 hours and 31 minutes
I0614 12:01:48.892107   446 solver.cpp:291]     Train net output #0: loss = 0.0247721 (* 1 = 0.0247721 loss)
I0614 12:01:48.892132   446 sgd_solver.cpp:106] Iteration 12600, lr = 1e-08
I0614 12:02:01.508587   446 solver.cpp:270] Iteration 12650 (3.9632 iter/s, 12.6161s/50 iter), loss = 0.0319538, remaining 0 hours and 30 minutes
I0614 12:02:01.508635   446 solver.cpp:291]     Train net output #0: loss = 0.0319538 (* 1 = 0.0319538 loss)
I0614 12:02:01.508658   446 sgd_solver.cpp:106] Iteration 12650, lr = 1e-08
I0614 12:02:14.125844   446 solver.cpp:270] Iteration 12700 (3.96297 iter/s, 12.6168s/50 iter), loss = 0.019537, remaining 0 hours and 30 minutes
I0614 12:02:14.125876   446 solver.cpp:291]     Train net output #0: loss = 0.019537 (* 1 = 0.019537 loss)
I0614 12:02:14.125900   446 sgd_solver.cpp:106] Iteration 12700, lr = 1e-08
I0614 12:02:26.734786   446 solver.cpp:270] Iteration 12750 (3.96558 iter/s, 12.6085s/50 iter), loss = 0.0395586, remaining 0 hours and 30 minutes
I0614 12:02:26.734817   446 solver.cpp:291]     Train net output #0: loss = 0.0395585 (* 1 = 0.0395585 loss)
I0614 12:02:26.734841   446 sgd_solver.cpp:106] Iteration 12750, lr = 1e-08
I0614 12:02:39.360618   446 solver.cpp:270] Iteration 12800 (3.96027 iter/s, 12.6254s/50 iter), loss = 0.0203021, remaining 0 hours and 30 minutes
I0614 12:02:39.360667   446 solver.cpp:291]     Train net output #0: loss = 0.0203021 (* 1 = 0.0203021 loss)
I0614 12:02:39.360692   446 sgd_solver.cpp:106] Iteration 12800, lr = 1e-08
I0614 12:02:51.983433   446 solver.cpp:270] Iteration 12850 (3.96123 iter/s, 12.6224s/50 iter), loss = 0.0166319, remaining 0 hours and 30 minutes
I0614 12:02:51.983466   446 solver.cpp:291]     Train net output #0: loss = 0.0166319 (* 1 = 0.0166319 loss)
I0614 12:02:51.983475   446 sgd_solver.cpp:106] Iteration 12850, lr = 1e-08
I0614 12:03:04.606182   446 solver.cpp:270] Iteration 12900 (3.96124 iter/s, 12.6223s/50 iter), loss = 0.043477, remaining 0 hours and 29 minutes
I0614 12:03:04.606216   446 solver.cpp:291]     Train net output #0: loss = 0.043477 (* 1 = 0.043477 loss)
I0614 12:03:04.606227   446 sgd_solver.cpp:106] Iteration 12900, lr = 1e-08
I0614 12:03:17.222955   446 solver.cpp:270] Iteration 12950 (3.96312 iter/s, 12.6163s/50 iter), loss = 0.0599303, remaining 0 hours and 29 minutes
I0614 12:03:17.223006   446 solver.cpp:291]     Train net output #0: loss = 0.0599303 (* 1 = 0.0599303 loss)
I0614 12:03:17.223014   446 sgd_solver.cpp:106] Iteration 12950, lr = 1e-08
I0614 12:03:29.581426   446 solver.cpp:424] Iteration 13000, Testing net (#0)
I0614 12:03:31.073920   446 solver.cpp:523]     Test net output #0: accuracy = 0.95425
I0614 12:03:31.073951   446 solver.cpp:523]     Test net output #1: loss = 0.129707 (* 1 = 0.129707 loss)
I0614 12:03:31.073956   446 solver.cpp:523]     Test net output #2: top-1 = 0.95425
I0614 12:03:31.320294   446 solver.cpp:270] Iteration 13000 (3.5469 iter/s, 14.0968s/50 iter), loss = 0.0392155, remaining 0 hours and 32 minutes
I0614 12:03:31.320327   446 solver.cpp:291]     Train net output #0: loss = 0.0392155 (* 1 = 0.0392155 loss)
I0614 12:03:31.320353   446 sgd_solver.cpp:106] Iteration 13000, lr = 1e-08
I0614 12:03:43.945607   446 solver.cpp:270] Iteration 13050 (3.96044 iter/s, 12.6249s/50 iter), loss = 0.0481768, remaining 0 hours and 29 minutes
I0614 12:03:43.945641   446 solver.cpp:291]     Train net output #0: loss = 0.0481768 (* 1 = 0.0481768 loss)
I0614 12:03:43.945667   446 sgd_solver.cpp:106] Iteration 13050, lr = 1e-08
I0614 12:03:56.566287   446 solver.cpp:270] Iteration 13100 (3.96189 iter/s, 12.6202s/50 iter), loss = 0.0187296, remaining 0 hours and 29 minutes
I0614 12:03:56.566344   446 solver.cpp:291]     Train net output #0: loss = 0.0187296 (* 1 = 0.0187296 loss)
I0614 12:03:56.566354   446 sgd_solver.cpp:106] Iteration 13100, lr = 1e-08
I0614 12:04:09.173656   446 solver.cpp:270] Iteration 13150 (3.96608 iter/s, 12.6069s/50 iter), loss = 0.050485, remaining 0 hours and 28 minutes
I0614 12:04:09.173689   446 solver.cpp:291]     Train net output #0: loss = 0.050485 (* 1 = 0.050485 loss)
I0614 12:04:09.173697   446 sgd_solver.cpp:106] Iteration 13150, lr = 1e-08
I0614 12:04:21.790284   446 solver.cpp:270] Iteration 13200 (3.96316 iter/s, 12.6162s/50 iter), loss = 0.0347848, remaining 0 hours and 28 minutes
I0614 12:04:21.790318   446 solver.cpp:291]     Train net output #0: loss = 0.0347848 (* 1 = 0.0347848 loss)
I0614 12:04:21.790343   446 sgd_solver.cpp:106] Iteration 13200, lr = 1e-08
I0614 12:04:34.408596   446 solver.cpp:270] Iteration 13250 (3.96263 iter/s, 12.6179s/50 iter), loss = 0.0243251, remaining 0 hours and 28 minutes
I0614 12:04:34.408644   446 solver.cpp:291]     Train net output #0: loss = 0.0243251 (* 1 = 0.0243251 loss)
I0614 12:04:34.408669   446 sgd_solver.cpp:106] Iteration 13250, lr = 1e-08
I0614 12:04:47.021893   446 solver.cpp:270] Iteration 13300 (3.96421 iter/s, 12.6128s/50 iter), loss = 0.0286295, remaining 0 hours and 28 minutes
I0614 12:04:47.021926   446 solver.cpp:291]     Train net output #0: loss = 0.0286295 (* 1 = 0.0286295 loss)
I0614 12:04:47.021935   446 sgd_solver.cpp:106] Iteration 13300, lr = 1e-08
I0614 12:04:59.634388   446 solver.cpp:270] Iteration 13350 (3.96446 iter/s, 12.6121s/50 iter), loss = 0.010687, remaining 0 hours and 27 minutes
I0614 12:04:59.634420   446 solver.cpp:291]     Train net output #0: loss = 0.010687 (* 1 = 0.010687 loss)
I0614 12:04:59.634444   446 sgd_solver.cpp:106] Iteration 13350, lr = 1e-08
I0614 12:05:12.237548   446 solver.cpp:270] Iteration 13400 (3.9674 iter/s, 12.6027s/50 iter), loss = 0.028626, remaining 0 hours and 27 minutes
I0614 12:05:12.237596   446 solver.cpp:291]     Train net output #0: loss = 0.028626 (* 1 = 0.028626 loss)
I0614 12:05:12.237620   446 sgd_solver.cpp:106] Iteration 13400, lr = 1e-08
I0614 12:05:24.858883   446 solver.cpp:270] Iteration 13450 (3.96169 iter/s, 12.6209s/50 iter), loss = 0.039758, remaining 0 hours and 27 minutes
I0614 12:05:24.858918   446 solver.cpp:291]     Train net output #0: loss = 0.039758 (* 1 = 0.039758 loss)
I0614 12:05:24.858927   446 sgd_solver.cpp:106] Iteration 13450, lr = 1e-08
I0614 12:05:37.484406   446 solver.cpp:270] Iteration 13500 (3.96037 iter/s, 12.6251s/50 iter), loss = 0.0298984, remaining 0 hours and 27 minutes
I0614 12:05:37.484438   446 solver.cpp:291]     Train net output #0: loss = 0.0298984 (* 1 = 0.0298984 loss)
I0614 12:05:37.484462   446 sgd_solver.cpp:106] Iteration 13500, lr = 1e-08
I0614 12:05:50.094265   446 solver.cpp:270] Iteration 13550 (3.96529 iter/s, 12.6094s/50 iter), loss = 0.0344466, remaining 0 hours and 26 minutes
I0614 12:05:50.094321   446 solver.cpp:291]     Train net output #0: loss = 0.0344466 (* 1 = 0.0344466 loss)
I0614 12:05:50.094329   446 sgd_solver.cpp:106] Iteration 13550, lr = 1e-08
I0614 12:06:02.711575   446 solver.cpp:270] Iteration 13600 (3.96296 iter/s, 12.6168s/50 iter), loss = 0.0476611, remaining 0 hours and 26 minutes
I0614 12:06:02.711608   446 solver.cpp:291]     Train net output #0: loss = 0.0476611 (* 1 = 0.0476611 loss)
I0614 12:06:02.711617   446 sgd_solver.cpp:106] Iteration 13600, lr = 1e-08
I0614 12:06:15.325580   446 solver.cpp:270] Iteration 13650 (3.96399 iter/s, 12.6136s/50 iter), loss = 0.0635228, remaining 0 hours and 26 minutes
I0614 12:06:15.325613   446 solver.cpp:291]     Train net output #0: loss = 0.0635228 (* 1 = 0.0635228 loss)
I0614 12:06:15.325623   446 sgd_solver.cpp:106] Iteration 13650, lr = 1e-08
I0614 12:06:27.933414   446 solver.cpp:270] Iteration 13700 (3.96593 iter/s, 12.6074s/50 iter), loss = 0.0322789, remaining 0 hours and 26 minutes
I0614 12:06:27.933463   446 solver.cpp:291]     Train net output #0: loss = 0.0322789 (* 1 = 0.0322789 loss)
I0614 12:06:27.933488   446 sgd_solver.cpp:106] Iteration 13700, lr = 1e-08
I0614 12:06:40.548758   446 solver.cpp:270] Iteration 13750 (3.96357 iter/s, 12.6149s/50 iter), loss = 0.0555496, remaining 0 hours and 26 minutes
I0614 12:06:40.548790   446 solver.cpp:291]     Train net output #0: loss = 0.0555496 (* 1 = 0.0555496 loss)
I0614 12:06:40.548815   446 sgd_solver.cpp:106] Iteration 13750, lr = 1e-08
I0614 12:06:53.158305   446 solver.cpp:270] Iteration 13800 (3.96539 iter/s, 12.6091s/50 iter), loss = 0.0521436, remaining 0 hours and 25 minutes
I0614 12:06:53.158339   446 solver.cpp:291]     Train net output #0: loss = 0.0521436 (* 1 = 0.0521436 loss)
I0614 12:06:53.158347   446 sgd_solver.cpp:106] Iteration 13800, lr = 1e-08
I0614 12:07:05.769946   446 solver.cpp:270] Iteration 13850 (3.96473 iter/s, 12.6112s/50 iter), loss = 0.0274764, remaining 0 hours and 25 minutes
I0614 12:07:05.769994   446 solver.cpp:291]     Train net output #0: loss = 0.0274764 (* 1 = 0.0274764 loss)
I0614 12:07:05.770018   446 sgd_solver.cpp:106] Iteration 13850, lr = 1e-08
I0614 12:07:18.374428   446 solver.cpp:270] Iteration 13900 (3.96699 iter/s, 12.604s/50 iter), loss = 0.0134587, remaining 0 hours and 25 minutes
I0614 12:07:18.374460   446 solver.cpp:291]     Train net output #0: loss = 0.0134587 (* 1 = 0.0134587 loss)
I0614 12:07:18.374485   446 sgd_solver.cpp:106] Iteration 13900, lr = 1e-08
I0614 12:07:30.980636   446 solver.cpp:270] Iteration 13950 (3.96644 iter/s, 12.6058s/50 iter), loss = 0.0152533, remaining 0 hours and 25 minutes
I0614 12:07:30.980670   446 solver.cpp:291]     Train net output #0: loss = 0.0152533 (* 1 = 0.0152533 loss)
I0614 12:07:30.980695   446 sgd_solver.cpp:106] Iteration 13950, lr = 1e-08
I0614 12:07:43.342337   446 solver.cpp:424] Iteration 14000, Testing net (#0)
I0614 12:07:44.838773   446 solver.cpp:523]     Test net output #0: accuracy = 0.9535
I0614 12:07:44.838804   446 solver.cpp:523]     Test net output #1: loss = 0.122223 (* 1 = 0.122223 loss)
I0614 12:07:44.838809   446 solver.cpp:523]     Test net output #2: top-1 = 0.9535
I0614 12:07:45.085145   446 solver.cpp:270] Iteration 14000 (3.54509 iter/s, 14.104s/50 iter), loss = 0.0453938, remaining 0 hours and 28 minutes
I0614 12:07:45.085177   446 solver.cpp:291]     Train net output #0: loss = 0.0453938 (* 1 = 0.0453938 loss)
I0614 12:07:45.085188   446 sgd_solver.cpp:106] Iteration 14000, lr = 1e-08
I0614 12:07:57.700481   446 solver.cpp:270] Iteration 14050 (3.96357 iter/s, 12.6149s/50 iter), loss = 0.0160909, remaining 0 hours and 24 minutes
I0614 12:07:57.700515   446 solver.cpp:291]     Train net output #0: loss = 0.016091 (* 1 = 0.016091 loss)
I0614 12:07:57.700525   446 sgd_solver.cpp:106] Iteration 14050, lr = 1e-08
I0614 12:08:10.311141   446 solver.cpp:270] Iteration 14100 (3.96504 iter/s, 12.6102s/50 iter), loss = 0.0384818, remaining 0 hours and 24 minutes
I0614 12:08:10.311174   446 solver.cpp:291]     Train net output #0: loss = 0.0384818 (* 1 = 0.0384818 loss)
I0614 12:08:10.311199   446 sgd_solver.cpp:106] Iteration 14100, lr = 1e-08
I0614 12:08:22.919952   446 solver.cpp:270] Iteration 14150 (3.96562 iter/s, 12.6084s/50 iter), loss = 0.0290638, remaining 0 hours and 24 minutes
I0614 12:08:22.920011   446 solver.cpp:291]     Train net output #0: loss = 0.0290638 (* 1 = 0.0290638 loss)
I0614 12:08:22.920020   446 sgd_solver.cpp:106] Iteration 14150, lr = 1e-08
I0614 12:08:35.525713   446 solver.cpp:270] Iteration 14200 (3.96659 iter/s, 12.6053s/50 iter), loss = 0.0569436, remaining 0 hours and 24 minutes
I0614 12:08:35.525746   446 solver.cpp:291]     Train net output #0: loss = 0.0569437 (* 1 = 0.0569437 loss)
I0614 12:08:35.525770   446 sgd_solver.cpp:106] Iteration 14200, lr = 1e-08
I0614 12:08:48.136356   446 solver.cpp:270] Iteration 14250 (3.96504 iter/s, 12.6102s/50 iter), loss = 0.0441602, remaining 0 hours and 23 minutes
I0614 12:08:48.136389   446 solver.cpp:291]     Train net output #0: loss = 0.0441602 (* 1 = 0.0441602 loss)
I0614 12:08:48.136413   446 sgd_solver.cpp:106] Iteration 14250, lr = 1e-08
I0614 12:09:00.768533   446 solver.cpp:270] Iteration 14300 (3.95828 iter/s, 12.6317s/50 iter), loss = 0.0340637, remaining 0 hours and 24 minutes
I0614 12:09:00.768597   446 solver.cpp:291]     Train net output #0: loss = 0.0340637 (* 1 = 0.0340637 loss)
I0614 12:09:00.768606   446 sgd_solver.cpp:106] Iteration 14300, lr = 1e-08
I0614 12:09:13.380172   446 solver.cpp:270] Iteration 14350 (3.96474 iter/s, 12.6112s/50 iter), loss = 0.0355245, remaining 0 hours and 23 minutes
I0614 12:09:13.380205   446 solver.cpp:291]     Train net output #0: loss = 0.0355245 (* 1 = 0.0355245 loss)
I0614 12:09:13.380230   446 sgd_solver.cpp:106] Iteration 14350, lr = 1e-08
I0614 12:09:25.983476   446 solver.cpp:270] Iteration 14400 (3.96735 iter/s, 12.6029s/50 iter), loss = 0.0302619, remaining 0 hours and 23 minutes
I0614 12:09:25.983510   446 solver.cpp:291]     Train net output #0: loss = 0.0302619 (* 1 = 0.0302619 loss)
I0614 12:09:25.983520   446 sgd_solver.cpp:106] Iteration 14400, lr = 1e-08
I0614 12:09:38.594242   446 solver.cpp:270] Iteration 14450 (3.96501 iter/s, 12.6103s/50 iter), loss = 0.0399122, remaining 0 hours and 23 minutes
I0614 12:09:38.594293   446 solver.cpp:291]     Train net output #0: loss = 0.0399122 (* 1 = 0.0399122 loss)
I0614 12:09:38.594303   446 sgd_solver.cpp:106] Iteration 14450, lr = 1e-08
I0614 12:09:51.202484   446 solver.cpp:270] Iteration 14500 (3.9658 iter/s, 12.6078s/50 iter), loss = 0.0371053, remaining 0 hours and 22 minutes
I0614 12:09:51.202519   446 solver.cpp:291]     Train net output #0: loss = 0.0371053 (* 1 = 0.0371053 loss)
I0614 12:09:51.202528   446 sgd_solver.cpp:106] Iteration 14500, lr = 1e-08
I0614 12:10:03.814895   446 solver.cpp:270] Iteration 14550 (3.96449 iter/s, 12.612s/50 iter), loss = 0.0509227, remaining 0 hours and 22 minutes
I0614 12:10:03.814929   446 solver.cpp:291]     Train net output #0: loss = 0.0509228 (* 1 = 0.0509228 loss)
I0614 12:10:03.814954   446 sgd_solver.cpp:106] Iteration 14550, lr = 1e-08
I0614 12:10:16.428750   446 solver.cpp:270] Iteration 14600 (3.96403 iter/s, 12.6134s/50 iter), loss = 0.0173096, remaining 0 hours and 22 minutes
I0614 12:10:16.428797   446 solver.cpp:291]     Train net output #0: loss = 0.0173096 (* 1 = 0.0173096 loss)
I0614 12:10:16.428807   446 sgd_solver.cpp:106] Iteration 14600, lr = 1e-08
I0614 12:10:29.038282   446 solver.cpp:270] Iteration 14650 (3.9654 iter/s, 12.6091s/50 iter), loss = 0.0363185, remaining 0 hours and 22 minutes
I0614 12:10:29.038316   446 solver.cpp:291]     Train net output #0: loss = 0.0363185 (* 1 = 0.0363185 loss)
I0614 12:10:29.038340   446 sgd_solver.cpp:106] Iteration 14650, lr = 1e-08
I0614 12:10:41.656764   446 solver.cpp:270] Iteration 14700 (3.96258 iter/s, 12.618s/50 iter), loss = 0.0397545, remaining 0 hours and 22 minutes
I0614 12:10:41.656796   446 solver.cpp:291]     Train net output #0: loss = 0.0397545 (* 1 = 0.0397545 loss)
I0614 12:10:41.656805   446 sgd_solver.cpp:106] Iteration 14700, lr = 1e-08
I0614 12:10:54.277026   446 solver.cpp:270] Iteration 14750 (3.96202 iter/s, 12.6198s/50 iter), loss = 0.0290107, remaining 0 hours and 21 minutes
I0614 12:10:54.277082   446 solver.cpp:291]     Train net output #0: loss = 0.0290108 (* 1 = 0.0290108 loss)
I0614 12:10:54.277092   446 sgd_solver.cpp:106] Iteration 14750, lr = 1e-08
I0614 12:11:06.892767   446 solver.cpp:270] Iteration 14800 (3.96345 iter/s, 12.6153s/50 iter), loss = 0.0208533, remaining 0 hours and 21 minutes
I0614 12:11:06.892807   446 solver.cpp:291]     Train net output #0: loss = 0.0208533 (* 1 = 0.0208533 loss)
I0614 12:11:06.892817   446 sgd_solver.cpp:106] Iteration 14800, lr = 1e-08
I0614 12:11:19.503235   446 solver.cpp:270] Iteration 14850 (3.9651 iter/s, 12.61s/50 iter), loss = 0.0317902, remaining 0 hours and 21 minutes
I0614 12:11:19.503268   446 solver.cpp:291]     Train net output #0: loss = 0.0317902 (* 1 = 0.0317902 loss)
I0614 12:11:19.503293   446 sgd_solver.cpp:106] Iteration 14850, lr = 1e-08
I0614 12:11:32.100036   446 solver.cpp:270] Iteration 14900 (3.9694 iter/s, 12.5964s/50 iter), loss = 0.0502471, remaining 0 hours and 21 minutes
I0614 12:11:32.100085   446 solver.cpp:291]     Train net output #0: loss = 0.0502471 (* 1 = 0.0502471 loss)
I0614 12:11:32.100095   446 sgd_solver.cpp:106] Iteration 14900, lr = 1e-08
I0614 12:11:44.724994   446 solver.cpp:270] Iteration 14950 (3.96055 iter/s, 12.6245s/50 iter), loss = 0.021341, remaining 0 hours and 21 minutes
I0614 12:11:44.725028   446 solver.cpp:291]     Train net output #0: loss = 0.0213411 (* 1 = 0.0213411 loss)
I0614 12:11:44.725039   446 sgd_solver.cpp:106] Iteration 14950, lr = 1e-08
I0614 12:11:57.086409   446 solver.cpp:935] Snapshotting to binary proto file caffe/models/alexnetBNnoLRN/m2/snapshot_2_alexnetBNnoLRN__iter_15000.caffemodel
I0614 12:12:02.110148   446 sgd_solver.cpp:273] Snapshotting solver state to binary proto file caffe/models/alexnetBNnoLRN/m2/snapshot_2_alexnetBNnoLRN__iter_15000.solverstate
I0614 12:12:05.777110   446 solver.cpp:424] Iteration 15000, Testing net (#0)
I0614 12:12:07.205798   446 solver.cpp:523]     Test net output #0: accuracy = 0.954
I0614 12:12:07.205832   446 solver.cpp:523]     Test net output #1: loss = 0.130263 (* 1 = 0.130263 loss)
I0614 12:12:07.205837   446 solver.cpp:523]     Test net output #2: top-1 = 0.954
I0614 12:12:07.445820   446 solver.cpp:270] Iteration 15000 (2.2007 iter/s, 22.7201s/50 iter), loss = 0.0584513, remaining 0 hours and 37 minutes
I0614 12:12:07.445852   446 solver.cpp:291]     Train net output #0: loss = 0.0584513 (* 1 = 0.0584513 loss)
I0614 12:12:07.445863   446 sgd_solver.cpp:106] Iteration 15000, lr = 1e-09
I0614 12:12:19.975095   446 solver.cpp:270] Iteration 15050 (3.99079 iter/s, 12.5288s/50 iter), loss = 0.0397301, remaining 0 hours and 20 minutes
I0614 12:12:19.975128   446 solver.cpp:291]     Train net output #0: loss = 0.0397301 (* 1 = 0.0397301 loss)
I0614 12:12:19.975152   446 sgd_solver.cpp:106] Iteration 15050, lr = 1e-09
I0614 12:12:32.513548   446 solver.cpp:270] Iteration 15100 (3.98787 iter/s, 12.538s/50 iter), loss = 0.0427798, remaining 0 hours and 20 minutes
I0614 12:12:32.513597   446 solver.cpp:291]     Train net output #0: loss = 0.0427799 (* 1 = 0.0427799 loss)
I0614 12:12:32.513607   446 sgd_solver.cpp:106] Iteration 15100, lr = 1e-09
I0614 12:12:45.137435   446 solver.cpp:270] Iteration 15150 (3.96089 iter/s, 12.6234s/50 iter), loss = 0.0230493, remaining 0 hours and 20 minutes
I0614 12:12:45.137470   446 solver.cpp:291]     Train net output #0: loss = 0.0230494 (* 1 = 0.0230494 loss)
I0614 12:12:45.137478   446 sgd_solver.cpp:106] Iteration 15150, lr = 1e-09
I0614 12:12:57.753719   446 solver.cpp:270] Iteration 15200 (3.96327 iter/s, 12.6158s/50 iter), loss = 0.0112882, remaining 0 hours and 20 minutes
I0614 12:12:57.753753   446 solver.cpp:291]     Train net output #0: loss = 0.0112883 (* 1 = 0.0112883 loss)
I0614 12:12:57.753762   446 sgd_solver.cpp:106] Iteration 15200, lr = 1e-09
I0614 12:13:10.378827   446 solver.cpp:270] Iteration 15250 (3.9605 iter/s, 12.6247s/50 iter), loss = 0.028322, remaining 0 hours and 19 minutes
I0614 12:13:10.378885   446 solver.cpp:291]     Train net output #0: loss = 0.028322 (* 1 = 0.028322 loss)
I0614 12:13:10.378911   446 sgd_solver.cpp:106] Iteration 15250, lr = 1e-09
I0614 12:13:22.984462   446 solver.cpp:270] Iteration 15300 (3.96663 iter/s, 12.6052s/50 iter), loss = 0.0221405, remaining 0 hours and 19 minutes
I0614 12:13:22.984495   446 solver.cpp:291]     Train net output #0: loss = 0.0221405 (* 1 = 0.0221405 loss)
I0614 12:13:22.984520   446 sgd_solver.cpp:106] Iteration 15300, lr = 1e-09
I0614 12:13:35.603585   446 solver.cpp:270] Iteration 15350 (3.96238 iter/s, 12.6187s/50 iter), loss = 0.0182605, remaining 0 hours and 19 minutes
I0614 12:13:35.603619   446 solver.cpp:291]     Train net output #0: loss = 0.0182606 (* 1 = 0.0182606 loss)
I0614 12:13:35.603631   446 sgd_solver.cpp:106] Iteration 15350, lr = 1e-09
I0614 12:13:48.224117   446 solver.cpp:270] Iteration 15400 (3.96194 iter/s, 12.6201s/50 iter), loss = 0.0442019, remaining 0 hours and 19 minutes
I0614 12:13:48.224165   446 solver.cpp:291]     Train net output #0: loss = 0.044202 (* 1 = 0.044202 loss)
I0614 12:13:48.224174   446 sgd_solver.cpp:106] Iteration 15400, lr = 1e-09
I0614 12:14:00.844626   446 solver.cpp:270] Iteration 15450 (3.96195 iter/s, 12.6201s/50 iter), loss = 0.0671162, remaining 0 hours and 18 minutes
I0614 12:14:00.844660   446 solver.cpp:291]     Train net output #0: loss = 0.0671163 (* 1 = 0.0671163 loss)
I0614 12:14:00.844671   446 sgd_solver.cpp:106] Iteration 15450, lr = 1e-09
I0614 12:14:13.463404   446 solver.cpp:270] Iteration 15500 (3.96249 iter/s, 12.6183s/50 iter), loss = 0.0333611, remaining 0 hours and 18 minutes
I0614 12:14:13.463438   446 solver.cpp:291]     Train net output #0: loss = 0.0333611 (* 1 = 0.0333611 loss)
I0614 12:14:13.463447   446 sgd_solver.cpp:106] Iteration 15500, lr = 1e-09
I0614 12:14:26.073808   446 solver.cpp:270] Iteration 15550 (3.96512 iter/s, 12.61s/50 iter), loss = 0.0394243, remaining 0 hours and 18 minutes
I0614 12:14:26.073855   446 solver.cpp:291]     Train net output #0: loss = 0.0394244 (* 1 = 0.0394244 loss)
I0614 12:14:26.073880   446 sgd_solver.cpp:106] Iteration 15550, lr = 1e-09
I0614 12:14:38.689007   446 solver.cpp:270] Iteration 15600 (3.96362 iter/s, 12.6147s/50 iter), loss = 0.0160394, remaining 0 hours and 18 minutes
I0614 12:14:38.689041   446 solver.cpp:291]     Train net output #0: loss = 0.0160394 (* 1 = 0.0160394 loss)
I0614 12:14:38.689050   446 sgd_solver.cpp:106] Iteration 15600, lr = 1e-09
I0614 12:14:51.310024   446 solver.cpp:270] Iteration 15650 (3.96179 iter/s, 12.6206s/50 iter), loss = 0.0273541, remaining 0 hours and 18 minutes
I0614 12:14:51.310058   446 solver.cpp:291]     Train net output #0: loss = 0.0273541 (* 1 = 0.0273541 loss)
I0614 12:14:51.310082   446 sgd_solver.cpp:106] Iteration 15650, lr = 1e-09
I0614 12:15:03.919965   446 solver.cpp:270] Iteration 15700 (3.96526 iter/s, 12.6095s/50 iter), loss = 0.0433011, remaining 0 hours and 17 minutes
I0614 12:15:03.920032   446 solver.cpp:291]     Train net output #0: loss = 0.0433011 (* 1 = 0.0433011 loss)
I0614 12:15:03.920042   446 sgd_solver.cpp:106] Iteration 15700, lr = 1e-09
I0614 12:15:16.545683   446 solver.cpp:270] Iteration 15750 (3.96031 iter/s, 12.6253s/50 iter), loss = 0.0458769, remaining 0 hours and 17 minutes
I0614 12:15:16.545717   446 solver.cpp:291]     Train net output #0: loss = 0.045877 (* 1 = 0.045877 loss)
I0614 12:15:16.545728   446 sgd_solver.cpp:106] Iteration 15750, lr = 1e-09
I0614 12:15:29.154419   446 solver.cpp:270] Iteration 15800 (3.96564 iter/s, 12.6083s/50 iter), loss = 0.0421461, remaining 0 hours and 17 minutes
I0614 12:15:29.154454   446 solver.cpp:291]     Train net output #0: loss = 0.0421461 (* 1 = 0.0421461 loss)
I0614 12:15:29.154464   446 sgd_solver.cpp:106] Iteration 15800, lr = 1e-09
I0614 12:15:41.770282   446 solver.cpp:270] Iteration 15850 (3.9634 iter/s, 12.6154s/50 iter), loss = 0.0340776, remaining 0 hours and 17 minutes
I0614 12:15:41.770340   446 solver.cpp:291]     Train net output #0: loss = 0.0340777 (* 1 = 0.0340777 loss)
I0614 12:15:41.770350   446 sgd_solver.cpp:106] Iteration 15850, lr = 1e-09
I0614 12:15:54.417806   446 solver.cpp:270] Iteration 15900 (3.95349 iter/s, 12.6471s/50 iter), loss = 0.0686604, remaining 0 hours and 17 minutes
I0614 12:15:54.417838   446 solver.cpp:291]     Train net output #0: loss = 0.0686604 (* 1 = 0.0686604 loss)
I0614 12:15:54.417848   446 sgd_solver.cpp:106] Iteration 15900, lr = 1e-09
I0614 12:16:07.044575   446 solver.cpp:270] Iteration 15950 (3.95998 iter/s, 12.6263s/50 iter), loss = 0.0519485, remaining 0 hours and 16 minutes
I0614 12:16:07.044610   446 solver.cpp:291]     Train net output #0: loss = 0.0519485 (* 1 = 0.0519485 loss)
I0614 12:16:07.044620   446 sgd_solver.cpp:106] Iteration 15950, lr = 1e-09
I0614 12:16:19.407792   446 solver.cpp:424] Iteration 16000, Testing net (#0)
I0614 12:16:20.899979   446 solver.cpp:523]     Test net output #0: accuracy = 0.95375
I0614 12:16:20.900012   446 solver.cpp:523]     Test net output #1: loss = 0.140785 (* 1 = 0.140785 loss)
I0614 12:16:20.900015   446 solver.cpp:523]     Test net output #2: top-1 = 0.95375
I0614 12:16:21.146831   446 solver.cpp:270] Iteration 16000 (3.54566 iter/s, 14.1018s/50 iter), loss = 0.0393008, remaining 0 hours and 18 minutes
I0614 12:16:21.146862   446 solver.cpp:291]     Train net output #0: loss = 0.0393008 (* 1 = 0.0393008 loss)
I0614 12:16:21.146872   446 sgd_solver.cpp:106] Iteration 16000, lr = 1e-09
I0614 12:16:33.762121   446 solver.cpp:270] Iteration 16050 (3.96358 iter/s, 12.6149s/50 iter), loss = 0.0229604, remaining 0 hours and 16 minutes
I0614 12:16:33.762156   446 solver.cpp:291]     Train net output #0: loss = 0.0229605 (* 1 = 0.0229605 loss)
I0614 12:16:33.762164   446 sgd_solver.cpp:106] Iteration 16050, lr = 1e-09
I0614 12:16:46.371798   446 solver.cpp:270] Iteration 16100 (3.96535 iter/s, 12.6092s/50 iter), loss = 0.0448191, remaining 0 hours and 16 minutes
I0614 12:16:46.371831   446 solver.cpp:291]     Train net output #0: loss = 0.0448191 (* 1 = 0.0448191 loss)
I0614 12:16:46.371840   446 sgd_solver.cpp:106] Iteration 16100, lr = 1e-09
I0614 12:16:58.979306   446 solver.cpp:270] Iteration 16150 (3.96603 iter/s, 12.6071s/50 iter), loss = 0.0409082, remaining 0 hours and 16 minutes
I0614 12:16:58.979357   446 solver.cpp:291]     Train net output #0: loss = 0.0409082 (* 1 = 0.0409082 loss)
I0614 12:16:58.979367   446 sgd_solver.cpp:106] Iteration 16150, lr = 1e-09
I0614 12:17:11.612952   446 solver.cpp:270] Iteration 16200 (3.95783 iter/s, 12.6332s/50 iter), loss = 0.0183035, remaining 0 hours and 15 minutes
I0614 12:17:11.612985   446 solver.cpp:291]     Train net output #0: loss = 0.0183035 (* 1 = 0.0183035 loss)
I0614 12:17:11.613009   446 sgd_solver.cpp:106] Iteration 16200, lr = 1e-09
I0614 12:17:24.223208   446 solver.cpp:270] Iteration 16250 (3.96517 iter/s, 12.6098s/50 iter), loss = 0.0533864, remaining 0 hours and 15 minutes
I0614 12:17:24.223241   446 solver.cpp:291]     Train net output #0: loss = 0.0533864 (* 1 = 0.0533864 loss)
I0614 12:17:24.223253   446 sgd_solver.cpp:106] Iteration 16250, lr = 1e-09
I0614 12:17:36.843670   446 solver.cpp:270] Iteration 16300 (3.96196 iter/s, 12.62s/50 iter), loss = 0.0313985, remaining 0 hours and 15 minutes
I0614 12:17:36.843716   446 solver.cpp:291]     Train net output #0: loss = 0.0313986 (* 1 = 0.0313986 loss)
I0614 12:17:36.843741   446 sgd_solver.cpp:106] Iteration 16300, lr = 1e-09
I0614 12:17:49.448444   446 solver.cpp:270] Iteration 16350 (3.96689 iter/s, 12.6043s/50 iter), loss = 0.0396472, remaining 0 hours and 15 minutes
I0614 12:17:49.448477   446 solver.cpp:291]     Train net output #0: loss = 0.0396472 (* 1 = 0.0396472 loss)
I0614 12:17:49.448503   446 sgd_solver.cpp:106] Iteration 16350, lr = 1e-09
I0614 12:18:02.103405   446 solver.cpp:270] Iteration 16400 (3.95116 iter/s, 12.6545s/50 iter), loss = 0.0528617, remaining 0 hours and 15 minutes
I0614 12:18:02.103436   446 solver.cpp:291]     Train net output #0: loss = 0.0528617 (* 1 = 0.0528617 loss)
I0614 12:18:02.103461   446 sgd_solver.cpp:106] Iteration 16400, lr = 1e-09
I0614 12:18:14.795702   446 solver.cpp:270] Iteration 16450 (3.93953 iter/s, 12.6919s/50 iter), loss = 0.0239222, remaining 0 hours and 14 minutes
I0614 12:18:14.795758   446 solver.cpp:291]     Train net output #0: loss = 0.0239222 (* 1 = 0.0239222 loss)
I0614 12:18:14.795768   446 sgd_solver.cpp:106] Iteration 16450, lr = 1e-09
I0614 12:18:27.517755   446 solver.cpp:270] Iteration 16500 (3.93033 iter/s, 12.7216s/50 iter), loss = 0.040379, remaining 0 hours and 14 minutes
I0614 12:18:27.517787   446 solver.cpp:291]     Train net output #0: loss = 0.040379 (* 1 = 0.040379 loss)
I0614 12:18:27.517796   446 sgd_solver.cpp:106] Iteration 16500, lr = 1e-09
I0614 12:18:40.130878   446 solver.cpp:270] Iteration 16550 (3.96426 iter/s, 12.6127s/50 iter), loss = 0.02724, remaining 0 hours and 14 minutes
I0614 12:18:40.130913   446 solver.cpp:291]     Train net output #0: loss = 0.02724 (* 1 = 0.02724 loss)
I0614 12:18:40.130937   446 sgd_solver.cpp:106] Iteration 16550, lr = 1e-09
I0614 12:18:52.747542   446 solver.cpp:270] Iteration 16600 (3.96315 iter/s, 12.6162s/50 iter), loss = 0.0307488, remaining 0 hours and 14 minutes
I0614 12:18:52.747592   446 solver.cpp:291]     Train net output #0: loss = 0.0307488 (* 1 = 0.0307488 loss)
I0614 12:18:52.747601   446 sgd_solver.cpp:106] Iteration 16600, lr = 1e-09
I0614 12:19:05.362828   446 solver.cpp:270] Iteration 16650 (3.96359 iter/s, 12.6148s/50 iter), loss = 0.0257957, remaining 0 hours and 13 minutes
I0614 12:19:05.362862   446 solver.cpp:291]     Train net output #0: loss = 0.0257957 (* 1 = 0.0257957 loss)
I0614 12:19:05.362888   446 sgd_solver.cpp:106] Iteration 16650, lr = 1e-09
I0614 12:19:17.974923   446 solver.cpp:270] Iteration 16700 (3.96459 iter/s, 12.6117s/50 iter), loss = 0.0573327, remaining 0 hours and 13 minutes
I0614 12:19:17.974959   446 solver.cpp:291]     Train net output #0: loss = 0.0573328 (* 1 = 0.0573328 loss)
I0614 12:19:17.974970   446 sgd_solver.cpp:106] Iteration 16700, lr = 1e-09
I0614 12:19:30.587143   446 solver.cpp:270] Iteration 16750 (3.96455 iter/s, 12.6118s/50 iter), loss = 0.042775, remaining 0 hours and 13 minutes
I0614 12:19:30.587208   446 solver.cpp:291]     Train net output #0: loss = 0.042775 (* 1 = 0.042775 loss)
I0614 12:19:30.587217   446 sgd_solver.cpp:106] Iteration 16750, lr = 1e-09
I0614 12:19:43.196442   446 solver.cpp:270] Iteration 16800 (3.96547 iter/s, 12.6088s/50 iter), loss = 0.0753403, remaining 0 hours and 13 minutes
I0614 12:19:43.196476   446 solver.cpp:291]     Train net output #0: loss = 0.0753404 (* 1 = 0.0753404 loss)
I0614 12:19:43.196485   446 sgd_solver.cpp:106] Iteration 16800, lr = 1e-09
I0614 12:19:55.802498   446 solver.cpp:270] Iteration 16850 (3.96649 iter/s, 12.6056s/50 iter), loss = 0.0245394, remaining 0 hours and 13 minutes
I0614 12:19:55.802532   446 solver.cpp:291]     Train net output #0: loss = 0.0245395 (* 1 = 0.0245395 loss)
I0614 12:19:55.802541   446 sgd_solver.cpp:106] Iteration 16850, lr = 1e-09
I0614 12:20:08.437069   446 solver.cpp:270] Iteration 16900 (3.95753 iter/s, 12.6341s/50 iter), loss = 0.0365526, remaining 0 hours and 12 minutes
I0614 12:20:08.437119   446 solver.cpp:291]     Train net output #0: loss = 0.0365527 (* 1 = 0.0365527 loss)
I0614 12:20:08.437144   446 sgd_solver.cpp:106] Iteration 16900, lr = 1e-09
I0614 12:20:21.160012   446 solver.cpp:270] Iteration 16950 (3.93005 iter/s, 12.7225s/50 iter), loss = 0.0194078, remaining 0 hours and 12 minutes
I0614 12:20:21.160046   446 solver.cpp:291]     Train net output #0: loss = 0.0194079 (* 1 = 0.0194079 loss)
I0614 12:20:21.160055   446 sgd_solver.cpp:106] Iteration 16950, lr = 1e-09
I0614 12:20:33.625427   446 solver.cpp:424] Iteration 17000, Testing net (#0)
I0614 12:20:35.131733   446 solver.cpp:523]     Test net output #0: accuracy = 0.954
I0614 12:20:35.131763   446 solver.cpp:523]     Test net output #1: loss = 0.148926 (* 1 = 0.148926 loss)
I0614 12:20:35.131768   446 solver.cpp:523]     Test net output #2: top-1 = 0.954
I0614 12:20:35.378386   446 solver.cpp:270] Iteration 17000 (3.5167 iter/s, 14.2179s/50 iter), loss = 0.0374113, remaining 0 hours and 14 minutes
I0614 12:20:35.378418   446 solver.cpp:291]     Train net output #0: loss = 0.0374113 (* 1 = 0.0374113 loss)
I0614 12:20:35.378443   446 sgd_solver.cpp:106] Iteration 17000, lr = 1e-09
I0614 12:20:47.970793   446 solver.cpp:270] Iteration 17050 (3.97079 iter/s, 12.592s/50 iter), loss = 0.0249127, remaining 0 hours and 12 minutes
I0614 12:20:47.970854   446 solver.cpp:291]     Train net output #0: loss = 0.0249127 (* 1 = 0.0249127 loss)
I0614 12:20:47.970880   446 sgd_solver.cpp:106] Iteration 17050, lr = 1e-09
I0614 12:21:00.592226   446 solver.cpp:270] Iteration 17100 (3.96166 iter/s, 12.621s/50 iter), loss = 0.0336652, remaining 0 hours and 12 minutes
I0614 12:21:00.592260   446 solver.cpp:291]     Train net output #0: loss = 0.0336652 (* 1 = 0.0336652 loss)
I0614 12:21:00.592270   446 sgd_solver.cpp:106] Iteration 17100, lr = 1e-09
I0614 12:21:13.199692   446 solver.cpp:270] Iteration 17150 (3.96604 iter/s, 12.607s/50 iter), loss = 0.0580533, remaining 0 hours and 11 minutes
I0614 12:21:13.199725   446 solver.cpp:291]     Train net output #0: loss = 0.0580533 (* 1 = 0.0580533 loss)
I0614 12:21:13.199735   446 sgd_solver.cpp:106] Iteration 17150, lr = 1e-09
I0614 12:21:25.819205   446 solver.cpp:270] Iteration 17200 (3.96226 iter/s, 12.6191s/50 iter), loss = 0.0457209, remaining 0 hours and 11 minutes
I0614 12:21:25.819252   446 solver.cpp:291]     Train net output #0: loss = 0.045721 (* 1 = 0.045721 loss)
I0614 12:21:25.819262   446 sgd_solver.cpp:106] Iteration 17200, lr = 1e-09
I0614 12:21:38.430591   446 solver.cpp:270] Iteration 17250 (3.96481 iter/s, 12.6109s/50 iter), loss = 0.0260482, remaining 0 hours and 11 minutes
I0614 12:21:38.430624   446 solver.cpp:291]     Train net output #0: loss = 0.0260482 (* 1 = 0.0260482 loss)
I0614 12:21:38.430634   446 sgd_solver.cpp:106] Iteration 17250, lr = 1e-09
I0614 12:21:51.038736   446 solver.cpp:270] Iteration 17300 (3.96583 iter/s, 12.6077s/50 iter), loss = 0.028587, remaining 0 hours and 11 minutes
I0614 12:21:51.038770   446 solver.cpp:291]     Train net output #0: loss = 0.028587 (* 1 = 0.028587 loss)
I0614 12:21:51.038779   446 sgd_solver.cpp:106] Iteration 17300, lr = 1e-09
I0614 12:22:03.655288   446 solver.cpp:270] Iteration 17350 (3.96319 iter/s, 12.6161s/50 iter), loss = 0.0303851, remaining 0 hours and 11 minutes
I0614 12:22:03.655337   446 solver.cpp:291]     Train net output #0: loss = 0.0303851 (* 1 = 0.0303851 loss)
I0614 12:22:03.655345   446 sgd_solver.cpp:106] Iteration 17350, lr = 1e-09
I0614 12:22:16.278968   446 solver.cpp:270] Iteration 17400 (3.96095 iter/s, 12.6232s/50 iter), loss = 0.039082, remaining 0 hours and 10 minutes
I0614 12:22:16.279000   446 solver.cpp:291]     Train net output #0: loss = 0.0390821 (* 1 = 0.0390821 loss)
I0614 12:22:16.279009   446 sgd_solver.cpp:106] Iteration 17400, lr = 1e-09
I0614 12:22:28.899958   446 solver.cpp:270] Iteration 17450 (3.96179 iter/s, 12.6205s/50 iter), loss = 0.0353514, remaining 0 hours and 10 minutes
I0614 12:22:28.899991   446 solver.cpp:291]     Train net output #0: loss = 0.0353514 (* 1 = 0.0353514 loss)
I0614 12:22:28.900000   446 sgd_solver.cpp:106] Iteration 17450, lr = 1e-09
I0614 12:22:41.527004   446 solver.cpp:270] Iteration 17500 (3.95989 iter/s, 12.6266s/50 iter), loss = 0.0524817, remaining 0 hours and 10 minutes
I0614 12:22:41.527050   446 solver.cpp:291]     Train net output #0: loss = 0.0524817 (* 1 = 0.0524817 loss)
I0614 12:22:41.527060   446 sgd_solver.cpp:106] Iteration 17500, lr = 1e-10
I0614 12:22:54.145292   446 solver.cpp:270] Iteration 17550 (3.96264 iter/s, 12.6178s/50 iter), loss = 0.0385717, remaining 0 hours and 10 minutes
I0614 12:22:54.145326   446 solver.cpp:291]     Train net output #0: loss = 0.0385718 (* 1 = 0.0385718 loss)
I0614 12:22:54.145336   446 sgd_solver.cpp:106] Iteration 17550, lr = 1e-10
I0614 12:23:06.756417   446 solver.cpp:270] Iteration 17600 (3.96489 iter/s, 12.6107s/50 iter), loss = 0.0165603, remaining 0 hours and 10 minutes
I0614 12:23:06.756450   446 solver.cpp:291]     Train net output #0: loss = 0.0165603 (* 1 = 0.0165603 loss)
I0614 12:23:06.756475   446 sgd_solver.cpp:106] Iteration 17600, lr = 1e-10
I0614 12:23:19.360841   446 solver.cpp:270] Iteration 17650 (3.967 iter/s, 12.604s/50 iter), loss = 0.0184683, remaining 0 hours and 9 minutes
I0614 12:23:19.360896   446 solver.cpp:291]     Train net output #0: loss = 0.0184684 (* 1 = 0.0184684 loss)
I0614 12:23:19.360921   446 sgd_solver.cpp:106] Iteration 17650, lr = 1e-10
I0614 12:23:31.983024   446 solver.cpp:270] Iteration 17700 (3.96143 iter/s, 12.6217s/50 iter), loss = 0.0178433, remaining 0 hours and 9 minutes
I0614 12:23:31.983057   446 solver.cpp:291]     Train net output #0: loss = 0.0178434 (* 1 = 0.0178434 loss)
I0614 12:23:31.983083   446 sgd_solver.cpp:106] Iteration 17700, lr = 1e-10
I0614 12:23:44.610633   446 solver.cpp:270] Iteration 17750 (3.95972 iter/s, 12.6272s/50 iter), loss = 0.0634374, remaining 0 hours and 9 minutes
I0614 12:23:44.610666   446 solver.cpp:291]     Train net output #0: loss = 0.0634375 (* 1 = 0.0634375 loss)
I0614 12:23:44.610677   446 sgd_solver.cpp:106] Iteration 17750, lr = 1e-10
I0614 12:23:57.217072   446 solver.cpp:270] Iteration 17800 (3.96637 iter/s, 12.606s/50 iter), loss = 0.0231827, remaining 0 hours and 9 minutes
I0614 12:23:57.217123   446 solver.cpp:291]     Train net output #0: loss = 0.0231828 (* 1 = 0.0231828 loss)
I0614 12:23:57.217134   446 sgd_solver.cpp:106] Iteration 17800, lr = 1e-10
I0614 12:24:09.836728   446 solver.cpp:270] Iteration 17850 (3.96222 iter/s, 12.6192s/50 iter), loss = 0.0246097, remaining 0 hours and 8 minutes
I0614 12:24:09.836761   446 solver.cpp:291]     Train net output #0: loss = 0.0246098 (* 1 = 0.0246098 loss)
I0614 12:24:09.836771   446 sgd_solver.cpp:106] Iteration 17850, lr = 1e-10
I0614 12:24:22.441380   446 solver.cpp:270] Iteration 17900 (3.96693 iter/s, 12.6042s/50 iter), loss = 0.0440732, remaining 0 hours and 8 minutes
I0614 12:24:22.441411   446 solver.cpp:291]     Train net output #0: loss = 0.0440733 (* 1 = 0.0440733 loss)
I0614 12:24:22.441437   446 sgd_solver.cpp:106] Iteration 17900, lr = 1e-10
I0614 12:24:35.057756   446 solver.cpp:270] Iteration 17950 (3.96324 iter/s, 12.6159s/50 iter), loss = 0.0538701, remaining 0 hours and 8 minutes
I0614 12:24:35.057803   446 solver.cpp:291]     Train net output #0: loss = 0.0538702 (* 1 = 0.0538702 loss)
I0614 12:24:35.057828   446 sgd_solver.cpp:106] Iteration 17950, lr = 1e-10
I0614 12:24:47.412137   446 solver.cpp:424] Iteration 18000, Testing net (#0)
I0614 12:24:48.921105   446 solver.cpp:523]     Test net output #0: accuracy = 0.95375
I0614 12:24:48.921139   446 solver.cpp:523]     Test net output #1: loss = 0.154146 (* 1 = 0.154146 loss)
I0614 12:24:48.921146   446 solver.cpp:523]     Test net output #2: top-1 = 0.95375
I0614 12:24:49.167532   446 solver.cpp:270] Iteration 18000 (3.54377 iter/s, 14.1093s/50 iter), loss = 0.020961, remaining 0 hours and 9 minutes
I0614 12:24:49.167564   446 solver.cpp:291]     Train net output #0: loss = 0.0209611 (* 1 = 0.0209611 loss)
I0614 12:24:49.167589   446 sgd_solver.cpp:106] Iteration 18000, lr = 1e-10
I0614 12:25:01.791692   446 solver.cpp:270] Iteration 18050 (3.9608 iter/s, 12.6237s/50 iter), loss = 0.0586522, remaining 0 hours and 8 minutes
I0614 12:25:01.791725   446 solver.cpp:291]     Train net output #0: loss = 0.0586523 (* 1 = 0.0586523 loss)
I0614 12:25:01.791734   446 sgd_solver.cpp:106] Iteration 18050, lr = 1e-10
I0614 12:25:14.399765   446 solver.cpp:270] Iteration 18100 (3.96585 iter/s, 12.6076s/50 iter), loss = 0.0514326, remaining 0 hours and 7 minutes
I0614 12:25:14.399811   446 solver.cpp:291]     Train net output #0: loss = 0.0514327 (* 1 = 0.0514327 loss)
I0614 12:25:14.399821   446 sgd_solver.cpp:106] Iteration 18100, lr = 1e-10
I0614 12:25:27.016028   446 solver.cpp:270] Iteration 18150 (3.96328 iter/s, 12.6158s/50 iter), loss = 0.0602924, remaining 0 hours and 7 minutes
I0614 12:25:27.016062   446 solver.cpp:291]     Train net output #0: loss = 0.0602925 (* 1 = 0.0602925 loss)
I0614 12:25:27.016086   446 sgd_solver.cpp:106] Iteration 18150, lr = 1e-10
I0614 12:25:39.617352   446 solver.cpp:270] Iteration 18200 (3.96798 iter/s, 12.6009s/50 iter), loss = 0.0292826, remaining 0 hours and 7 minutes
I0614 12:25:39.617388   446 solver.cpp:291]     Train net output #0: loss = 0.0292826 (* 1 = 0.0292826 loss)
I0614 12:25:39.617396   446 sgd_solver.cpp:106] Iteration 18200, lr = 1e-10
I0614 12:25:52.226991   446 solver.cpp:270] Iteration 18250 (3.96536 iter/s, 12.6092s/50 iter), loss = 0.0690387, remaining 0 hours and 7 minutes
I0614 12:25:52.227046   446 solver.cpp:291]     Train net output #0: loss = 0.0690388 (* 1 = 0.0690388 loss)
I0614 12:25:52.227072   446 sgd_solver.cpp:106] Iteration 18250, lr = 1e-10
I0614 12:26:04.843276   446 solver.cpp:270] Iteration 18300 (3.96328 iter/s, 12.6158s/50 iter), loss = 0.0464413, remaining 0 hours and 7 minutes
I0614 12:26:04.843312   446 solver.cpp:291]     Train net output #0: loss = 0.0464414 (* 1 = 0.0464414 loss)
I0614 12:26:04.843322   446 sgd_solver.cpp:106] Iteration 18300, lr = 1e-10
I0614 12:26:17.456902   446 solver.cpp:270] Iteration 18350 (3.96411 iter/s, 12.6132s/50 iter), loss = 0.021752, remaining 0 hours and 6 minutes
I0614 12:26:17.456934   446 solver.cpp:291]     Train net output #0: loss = 0.0217521 (* 1 = 0.0217521 loss)
I0614 12:26:17.456943   446 sgd_solver.cpp:106] Iteration 18350, lr = 1e-10
I0614 12:26:30.072183   446 solver.cpp:270] Iteration 18400 (3.96359 iter/s, 12.6148s/50 iter), loss = 0.0356289, remaining 0 hours and 6 minutes
I0614 12:26:30.072247   446 solver.cpp:291]     Train net output #0: loss = 0.035629 (* 1 = 0.035629 loss)
I0614 12:26:30.072257   446 sgd_solver.cpp:106] Iteration 18400, lr = 1e-10
I0614 12:26:42.684437   446 solver.cpp:270] Iteration 18450 (3.96454 iter/s, 12.6118s/50 iter), loss = 0.052303, remaining 0 hours and 6 minutes
I0614 12:26:42.684470   446 solver.cpp:291]     Train net output #0: loss = 0.0523031 (* 1 = 0.0523031 loss)
I0614 12:26:42.684480   446 sgd_solver.cpp:106] Iteration 18450, lr = 1e-10
I0614 12:26:55.300738   446 solver.cpp:270] Iteration 18500 (3.96326 iter/s, 12.6159s/50 iter), loss = 0.0316413, remaining 0 hours and 6 minutes
I0614 12:26:55.300771   446 solver.cpp:291]     Train net output #0: loss = 0.0316414 (* 1 = 0.0316414 loss)
I0614 12:26:55.300781   446 sgd_solver.cpp:106] Iteration 18500, lr = 1e-10
I0614 12:27:07.906661   446 solver.cpp:270] Iteration 18550 (3.96653 iter/s, 12.6055s/50 iter), loss = 0.0505371, remaining 0 hours and 6 minutes
I0614 12:27:07.906711   446 solver.cpp:291]     Train net output #0: loss = 0.0505371 (* 1 = 0.0505371 loss)
I0614 12:27:07.906736   446 sgd_solver.cpp:106] Iteration 18550, lr = 1e-10
I0614 12:27:20.526005   446 solver.cpp:270] Iteration 18600 (3.96231 iter/s, 12.6189s/50 iter), loss = 0.0483889, remaining 0 hours and 5 minutes
I0614 12:27:20.526039   446 solver.cpp:291]     Train net output #0: loss = 0.0483889 (* 1 = 0.0483889 loss)
I0614 12:27:20.526049   446 sgd_solver.cpp:106] Iteration 18600, lr = 1e-10
I0614 12:27:33.143846   446 solver.cpp:270] Iteration 18650 (3.96278 iter/s, 12.6174s/50 iter), loss = 0.0510266, remaining 0 hours and 5 minutes
I0614 12:27:33.143880   446 solver.cpp:291]     Train net output #0: loss = 0.0510267 (* 1 = 0.0510267 loss)
I0614 12:27:33.143889   446 sgd_solver.cpp:106] Iteration 18650, lr = 1e-10
I0614 12:27:45.751883   446 solver.cpp:270] Iteration 18700 (3.96586 iter/s, 12.6076s/50 iter), loss = 0.0111079, remaining 0 hours and 5 minutes
I0614 12:27:45.751933   446 solver.cpp:291]     Train net output #0: loss = 0.0111079 (* 1 = 0.0111079 loss)
I0614 12:27:45.751943   446 sgd_solver.cpp:106] Iteration 18700, lr = 1e-10
I0614 12:27:58.373520   446 solver.cpp:270] Iteration 18750 (3.96159 iter/s, 12.6212s/50 iter), loss = 0.0441035, remaining 0 hours and 5 minutes
I0614 12:27:58.373556   446 solver.cpp:291]     Train net output #0: loss = 0.0441036 (* 1 = 0.0441036 loss)
I0614 12:27:58.373581   446 sgd_solver.cpp:106] Iteration 18750, lr = 1e-10
I0614 12:28:10.981775   446 solver.cpp:270] Iteration 18800 (3.96579 iter/s, 12.6078s/50 iter), loss = 0.0425941, remaining 0 hours and 5 minutes
I0614 12:28:10.981808   446 solver.cpp:291]     Train net output #0: loss = 0.0425942 (* 1 = 0.0425942 loss)
I0614 12:28:10.981832   446 sgd_solver.cpp:106] Iteration 18800, lr = 1e-10
I0614 12:28:23.591634   446 solver.cpp:270] Iteration 18850 (3.96529 iter/s, 12.6094s/50 iter), loss = 0.0345436, remaining 0 hours and 4 minutes
I0614 12:28:23.591696   446 solver.cpp:291]     Train net output #0: loss = 0.0345437 (* 1 = 0.0345437 loss)
I0614 12:28:23.591706   446 sgd_solver.cpp:106] Iteration 18850, lr = 1e-10
I0614 12:28:36.195549   446 solver.cpp:270] Iteration 18900 (3.96717 iter/s, 12.6034s/50 iter), loss = 0.0346844, remaining 0 hours and 4 minutes
I0614 12:28:36.195581   446 solver.cpp:291]     Train net output #0: loss = 0.0346845 (* 1 = 0.0346845 loss)
I0614 12:28:36.195590   446 sgd_solver.cpp:106] Iteration 18900, lr = 1e-10
I0614 12:28:48.809401   446 solver.cpp:270] Iteration 18950 (3.96403 iter/s, 12.6134s/50 iter), loss = 0.0316209, remaining 0 hours and 4 minutes
I0614 12:28:48.809433   446 solver.cpp:291]     Train net output #0: loss = 0.031621 (* 1 = 0.031621 loss)
I0614 12:28:48.809442   446 sgd_solver.cpp:106] Iteration 18950, lr = 1e-10
I0614 12:29:01.167400   446 solver.cpp:424] Iteration 19000, Testing net (#0)
I0614 12:29:02.677362   446 solver.cpp:523]     Test net output #0: accuracy = 0.95375
I0614 12:29:02.677397   446 solver.cpp:523]     Test net output #1: loss = 0.157148 (* 1 = 0.157148 loss)
I0614 12:29:02.677402   446 solver.cpp:523]     Test net output #2: top-1 = 0.95375
I0614 12:29:02.924059   446 solver.cpp:270] Iteration 19000 (3.54254 iter/s, 14.1142s/50 iter), loss = 0.0570848, remaining 0 hours and 4 minutes
I0614 12:29:02.924090   446 solver.cpp:291]     Train net output #0: loss = 0.0570849 (* 1 = 0.0570849 loss)
I0614 12:29:02.924101   446 sgd_solver.cpp:106] Iteration 19000, lr = 1e-10
I0614 12:29:15.529819   446 solver.cpp:270] Iteration 19050 (3.96658 iter/s, 12.6053s/50 iter), loss = 0.029354, remaining 0 hours and 3 minutes
I0614 12:29:15.529852   446 solver.cpp:291]     Train net output #0: loss = 0.0293541 (* 1 = 0.0293541 loss)
I0614 12:29:15.529861   446 sgd_solver.cpp:106] Iteration 19050, lr = 1e-10
I0614 12:29:28.138237   446 solver.cpp:270] Iteration 19100 (3.96574 iter/s, 12.608s/50 iter), loss = 0.0539132, remaining 0 hours and 3 minutes
I0614 12:29:28.138273   446 solver.cpp:291]     Train net output #0: loss = 0.0539133 (* 1 = 0.0539133 loss)
I0614 12:29:28.138283   446 sgd_solver.cpp:106] Iteration 19100, lr = 1e-10
I0614 12:29:40.736224   446 solver.cpp:270] Iteration 19150 (3.96903 iter/s, 12.5975s/50 iter), loss = 0.0476492, remaining 0 hours and 3 minutes
I0614 12:29:40.736272   446 solver.cpp:291]     Train net output #0: loss = 0.0476493 (* 1 = 0.0476493 loss)
I0614 12:29:40.736296   446 sgd_solver.cpp:106] Iteration 19150, lr = 1e-10
I0614 12:29:53.348734   446 solver.cpp:270] Iteration 19200 (3.96446 iter/s, 12.6121s/50 iter), loss = 0.0582289, remaining 0 hours and 3 minutes
I0614 12:29:53.348768   446 solver.cpp:291]     Train net output #0: loss = 0.058229 (* 1 = 0.058229 loss)
I0614 12:29:53.348793   446 sgd_solver.cpp:106] Iteration 19200, lr = 1e-10
I0614 12:30:05.964625   446 solver.cpp:270] Iteration 19250 (3.96339 iter/s, 12.6154s/50 iter), loss = 0.0570417, remaining 0 hours and 3 minutes
I0614 12:30:05.964658   446 solver.cpp:291]     Train net output #0: loss = 0.0570418 (* 1 = 0.0570418 loss)
I0614 12:30:05.964682   446 sgd_solver.cpp:106] Iteration 19250, lr = 1e-10
I0614 12:30:18.578876   446 solver.cpp:270] Iteration 19300 (3.96391 iter/s, 12.6138s/50 iter), loss = 0.0428953, remaining 0 hours and 2 minutes
I0614 12:30:18.578925   446 solver.cpp:291]     Train net output #0: loss = 0.0428954 (* 1 = 0.0428954 loss)
I0614 12:30:18.578938   446 sgd_solver.cpp:106] Iteration 19300, lr = 1e-10
I0614 12:30:31.191203   446 solver.cpp:270] Iteration 19350 (3.96452 iter/s, 12.6119s/50 iter), loss = 0.032474, remaining 0 hours and 2 minutes
I0614 12:30:31.191237   446 solver.cpp:291]     Train net output #0: loss = 0.0324741 (* 1 = 0.0324741 loss)
I0614 12:30:31.191246   446 sgd_solver.cpp:106] Iteration 19350, lr = 1e-10
I0614 12:30:43.806227   446 solver.cpp:270] Iteration 19400 (3.96367 iter/s, 12.6146s/50 iter), loss = 0.0374307, remaining 0 hours and 2 minutes
I0614 12:30:43.806260   446 solver.cpp:291]     Train net output #0: loss = 0.0374308 (* 1 = 0.0374308 loss)
I0614 12:30:43.806285   446 sgd_solver.cpp:106] Iteration 19400, lr = 1e-10
I0614 12:30:56.427815   446 solver.cpp:270] Iteration 19450 (3.96161 iter/s, 12.6211s/50 iter), loss = 0.0295091, remaining 0 hours and 2 minutes
I0614 12:30:56.427886   446 solver.cpp:291]     Train net output #0: loss = 0.0295092 (* 1 = 0.0295092 loss)
I0614 12:30:56.427896   446 sgd_solver.cpp:106] Iteration 19450, lr = 1e-10
I0614 12:31:09.039170   446 solver.cpp:270] Iteration 19500 (3.96483 iter/s, 12.6109s/50 iter), loss = 0.0505829, remaining 0 hours and 2 minutes
I0614 12:31:09.039206   446 solver.cpp:291]     Train net output #0: loss = 0.0505829 (* 1 = 0.0505829 loss)
I0614 12:31:09.039216   446 sgd_solver.cpp:106] Iteration 19500, lr = 1e-10
I0614 12:31:21.647584   446 solver.cpp:270] Iteration 19550 (3.96575 iter/s, 12.608s/50 iter), loss = 0.0276462, remaining 0 hours and 1 minutes
I0614 12:31:21.647615   446 solver.cpp:291]     Train net output #0: loss = 0.0276463 (* 1 = 0.0276463 loss)
I0614 12:31:21.647624   446 sgd_solver.cpp:106] Iteration 19550, lr = 1e-10
I0614 12:31:34.259255   446 solver.cpp:270] Iteration 19600 (3.96472 iter/s, 12.6112s/50 iter), loss = 0.0205896, remaining 0 hours and 1 minutes
I0614 12:31:34.259305   446 solver.cpp:291]     Train net output #0: loss = 0.0205897 (* 1 = 0.0205897 loss)
I0614 12:31:34.259330   446 sgd_solver.cpp:106] Iteration 19600, lr = 1e-10
I0614 12:31:46.873195   446 solver.cpp:270] Iteration 19650 (3.96401 iter/s, 12.6135s/50 iter), loss = 0.0446318, remaining 0 hours and 1 minutes
I0614 12:31:46.873229   446 solver.cpp:291]     Train net output #0: loss = 0.0446319 (* 1 = 0.0446319 loss)
I0614 12:31:46.873252   446 sgd_solver.cpp:106] Iteration 19650, lr = 1e-10
I0614 12:31:59.495756   446 solver.cpp:270] Iteration 19700 (3.9613 iter/s, 12.6221s/50 iter), loss = 0.0545729, remaining 0 hours and 1 minutes
I0614 12:31:59.495790   446 solver.cpp:291]     Train net output #0: loss = 0.054573 (* 1 = 0.054573 loss)
I0614 12:31:59.495813   446 sgd_solver.cpp:106] Iteration 19700, lr = 1e-10
I0614 12:32:12.113983   446 solver.cpp:270] Iteration 19750 (3.96266 iter/s, 12.6178s/50 iter), loss = 0.0206914, remaining 0 hours and 1 minutes
I0614 12:32:12.114032   446 solver.cpp:291]     Train net output #0: loss = 0.0206914 (* 1 = 0.0206914 loss)
I0614 12:32:12.114042   446 sgd_solver.cpp:106] Iteration 19750, lr = 1e-10
I0614 12:32:24.726089   446 solver.cpp:270] Iteration 19800 (3.96459 iter/s, 12.6117s/50 iter), loss = 0.0319968, remaining 0 hours and 0 minutes
I0614 12:32:24.726122   446 solver.cpp:291]     Train net output #0: loss = 0.0319969 (* 1 = 0.0319969 loss)
I0614 12:32:24.726132   446 sgd_solver.cpp:106] Iteration 19800, lr = 1e-10
I0614 12:32:37.344383   446 solver.cpp:270] Iteration 19850 (3.96264 iter/s, 12.6179s/50 iter), loss = 0.020977, remaining 0 hours and 0 minutes
I0614 12:32:37.344415   446 solver.cpp:291]     Train net output #0: loss = 0.0209771 (* 1 = 0.0209771 loss)
I0614 12:32:37.344440   446 sgd_solver.cpp:106] Iteration 19850, lr = 1e-10
I0614 12:32:49.950222   446 solver.cpp:270] Iteration 19900 (3.96655 iter/s, 12.6054s/50 iter), loss = 0.0438643, remaining 0 hours and 0 minutes
I0614 12:32:49.950270   446 solver.cpp:291]     Train net output #0: loss = 0.0438643 (* 1 = 0.0438643 loss)
I0614 12:32:49.950278   446 sgd_solver.cpp:106] Iteration 19900, lr = 1e-10
I0614 12:33:02.572760   446 solver.cpp:270] Iteration 19950 (3.96131 iter/s, 12.6221s/50 iter), loss = 0.0425601, remaining 0 hours and 0 minutes
I0614 12:33:02.572793   446 solver.cpp:291]     Train net output #0: loss = 0.0425602 (* 1 = 0.0425602 loss)
I0614 12:33:02.572818   446 sgd_solver.cpp:106] Iteration 19950, lr = 1e-10
I0614 12:33:14.928608   446 solver.cpp:935] Snapshotting to binary proto file caffe/models/alexnetBNnoLRN/m2/snapshot_2_alexnetBNnoLRN__iter_20000.caffemodel
I0614 12:33:20.016973   446 sgd_solver.cpp:273] Snapshotting solver state to binary proto file caffe/models/alexnetBNnoLRN/m2/snapshot_2_alexnetBNnoLRN__iter_20000.solverstate
I0614 12:33:23.605964   446 solver.cpp:384] Iteration 20000, loss = 0.0319048
I0614 12:33:23.605993   446 solver.cpp:424] Iteration 20000, Testing net (#0)
I0614 12:33:25.022163   446 solver.cpp:523]     Test net output #0: accuracy = 0.9535
I0614 12:33:25.022193   446 solver.cpp:523]     Test net output #1: loss = 0.158723 (* 1 = 0.158723 loss)
I0614 12:33:25.022197   446 solver.cpp:523]     Test net output #2: top-1 = 0.9535
I0614 12:33:25.022217   446 solver.cpp:392] Optimization Done (3.91208 iter/s).
I0614 12:33:25.022222   446 caffe.cpp:250] Optimization Done.
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0614 12:33:25.879247   543 gpu_memory.cpp:53] GPUMemory::Manager initialized with Caching (CUB) GPU Allocator
I0614 12:33:25.879287   543 gpu_memory.cpp:55] Total memory: 25635127296, Free: 24801640448, dev_info[0]: total=25635127296 free=24801640448
I0614 12:33:25.879426   543 vai_q.cpp:260] Using GPUs 0
I0614 12:33:25.879527   543 vai_q.cpp:265] GPU 0: Quadro P6000
I0614 12:33:29.190788   543 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0614 12:33:29.190815   543 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0614 12:33:29.190819   543 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy-top1
I0614 12:33:29.190822   543 net.cpp:52] Initializing net from parameters: 
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    crop_size: 227
    mean_value: 106
    mean_value: 116
    mean_value: 124
  }
  image_data_param {
    source: "deploy/alexnetBNnoLRN/quantiz/data/calib/calibration.txt"
    batch_size: 10
    shuffle: true
    root_folder: "deploy/alexnetBNnoLRN/quantiz/data/calib/"
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 0
    kernel_size: 8
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "bn1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "bn2"
  top: "relu2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "relu6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn7"
  type: "BatchNorm"
  bottom: "fc7"
  top: "bn7"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "bn7"
  top: "relu7"
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "relu7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0614 12:33:29.191020   543 layer_factory.hpp:77] Creating layer data
I0614 12:33:29.191040   543 net.cpp:94] Creating Layer data
I0614 12:33:29.191044   543 net.cpp:409] data -> data
I0614 12:33:29.191052   543 net.cpp:409] data -> label
I0614 12:33:29.191120   543 image_data_layer.cpp:41] Opening file deploy/alexnetBNnoLRN/quantiz/data/calib/calibration.txt
I0614 12:33:29.192238   543 image_data_layer.cpp:51] Shuffling data
I0614 12:33:29.192257   543 image_data_layer.cpp:56] A total of 200 images.
I0614 12:33:29.200052   543 image_data_layer.cpp:84] output data size: 10,3,227,227
I0614 12:33:29.235939   543 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0614 12:33:29.236012   543 net.cpp:144] Setting up data
I0614 12:33:29.236017   543 net.cpp:151] Top shape: 10 3 227 227 (1545870)
I0614 12:33:29.236027   543 net.cpp:151] Top shape: 10 (10)
I0614 12:33:29.236030   543 net.cpp:159] Memory required for data: 6183520
I0614 12:33:29.236034   543 layer_factory.hpp:77] Creating layer conv1
I0614 12:33:29.236053   543 net.cpp:94] Creating Layer conv1
I0614 12:33:29.236057   543 net.cpp:435] conv1 <- data
I0614 12:33:29.236063   543 net.cpp:409] conv1 -> conv1
I0614 12:33:29.236505   543 net.cpp:144] Setting up conv1
I0614 12:33:29.236510   543 net.cpp:151] Top shape: 10 96 55 55 (2904000)
I0614 12:33:29.236515   543 net.cpp:159] Memory required for data: 17799520
I0614 12:33:29.236538   543 layer_factory.hpp:77] Creating layer bn1
I0614 12:33:29.236547   543 net.cpp:94] Creating Layer bn1
I0614 12:33:29.236550   543 net.cpp:435] bn1 <- conv1
I0614 12:33:29.236555   543 net.cpp:409] bn1 -> bn1
I0614 12:33:29.236852   543 net.cpp:144] Setting up bn1
I0614 12:33:29.236858   543 net.cpp:151] Top shape: 10 96 55 55 (2904000)
I0614 12:33:29.236863   543 net.cpp:159] Memory required for data: 29415520
I0614 12:33:29.236871   543 layer_factory.hpp:77] Creating layer relu1
I0614 12:33:29.236877   543 net.cpp:94] Creating Layer relu1
I0614 12:33:29.236881   543 net.cpp:435] relu1 <- bn1
I0614 12:33:29.236883   543 net.cpp:409] relu1 -> relu1
I0614 12:33:29.236907   543 net.cpp:144] Setting up relu1
I0614 12:33:29.236909   543 net.cpp:151] Top shape: 10 96 55 55 (2904000)
I0614 12:33:29.236913   543 net.cpp:159] Memory required for data: 41031520
I0614 12:33:29.236917   543 layer_factory.hpp:77] Creating layer pool1
I0614 12:33:29.236922   543 net.cpp:94] Creating Layer pool1
I0614 12:33:29.236925   543 net.cpp:435] pool1 <- relu1
I0614 12:33:29.236929   543 net.cpp:409] pool1 -> pool1
I0614 12:33:29.236945   543 net.cpp:144] Setting up pool1
I0614 12:33:29.236948   543 net.cpp:151] Top shape: 10 96 27 27 (699840)
I0614 12:33:29.236953   543 net.cpp:159] Memory required for data: 43830880
I0614 12:33:29.236955   543 layer_factory.hpp:77] Creating layer conv2
I0614 12:33:29.236963   543 net.cpp:94] Creating Layer conv2
I0614 12:33:29.236965   543 net.cpp:435] conv2 <- pool1
I0614 12:33:29.236969   543 net.cpp:409] conv2 -> conv2
I0614 12:33:29.243165   543 net.cpp:144] Setting up conv2
I0614 12:33:29.243177   543 net.cpp:151] Top shape: 10 256 27 27 (1866240)
I0614 12:33:29.243183   543 net.cpp:159] Memory required for data: 51295840
I0614 12:33:29.243191   543 layer_factory.hpp:77] Creating layer bn2
I0614 12:33:29.243199   543 net.cpp:94] Creating Layer bn2
I0614 12:33:29.243202   543 net.cpp:435] bn2 <- conv2
I0614 12:33:29.243208   543 net.cpp:409] bn2 -> bn2
I0614 12:33:29.243464   543 net.cpp:144] Setting up bn2
I0614 12:33:29.243469   543 net.cpp:151] Top shape: 10 256 27 27 (1866240)
I0614 12:33:29.243474   543 net.cpp:159] Memory required for data: 58760800
I0614 12:33:29.243481   543 layer_factory.hpp:77] Creating layer relu2
I0614 12:33:29.243486   543 net.cpp:94] Creating Layer relu2
I0614 12:33:29.243489   543 net.cpp:435] relu2 <- bn2
I0614 12:33:29.243492   543 net.cpp:409] relu2 -> relu2
I0614 12:33:29.243503   543 net.cpp:144] Setting up relu2
I0614 12:33:29.243506   543 net.cpp:151] Top shape: 10 256 27 27 (1866240)
I0614 12:33:29.243510   543 net.cpp:159] Memory required for data: 66225760
I0614 12:33:29.243513   543 layer_factory.hpp:77] Creating layer pool2
I0614 12:33:29.243520   543 net.cpp:94] Creating Layer pool2
I0614 12:33:29.243522   543 net.cpp:435] pool2 <- relu2
I0614 12:33:29.243526   543 net.cpp:409] pool2 -> pool2
I0614 12:33:29.243539   543 net.cpp:144] Setting up pool2
I0614 12:33:29.243542   543 net.cpp:151] Top shape: 10 256 13 13 (432640)
I0614 12:33:29.243546   543 net.cpp:159] Memory required for data: 67956320
I0614 12:33:29.243549   543 layer_factory.hpp:77] Creating layer conv3
I0614 12:33:29.243556   543 net.cpp:94] Creating Layer conv3
I0614 12:33:29.243558   543 net.cpp:435] conv3 <- pool2
I0614 12:33:29.243562   543 net.cpp:409] conv3 -> conv3
I0614 12:33:29.252367   543 net.cpp:144] Setting up conv3
I0614 12:33:29.252382   543 net.cpp:151] Top shape: 10 384 13 13 (648960)
I0614 12:33:29.252388   543 net.cpp:159] Memory required for data: 70552160
I0614 12:33:29.252394   543 layer_factory.hpp:77] Creating layer relu3
I0614 12:33:29.252401   543 net.cpp:94] Creating Layer relu3
I0614 12:33:29.252404   543 net.cpp:435] relu3 <- conv3
I0614 12:33:29.252409   543 net.cpp:409] relu3 -> relu3
I0614 12:33:29.252424   543 net.cpp:144] Setting up relu3
I0614 12:33:29.252426   543 net.cpp:151] Top shape: 10 384 13 13 (648960)
I0614 12:33:29.252429   543 net.cpp:159] Memory required for data: 73148000
I0614 12:33:29.252432   543 layer_factory.hpp:77] Creating layer conv4
I0614 12:33:29.252440   543 net.cpp:94] Creating Layer conv4
I0614 12:33:29.252444   543 net.cpp:435] conv4 <- relu3
I0614 12:33:29.252447   543 net.cpp:409] conv4 -> conv4
I0614 12:33:29.264554   543 net.cpp:144] Setting up conv4
I0614 12:33:29.264567   543 net.cpp:151] Top shape: 10 384 13 13 (648960)
I0614 12:33:29.264573   543 net.cpp:159] Memory required for data: 75743840
I0614 12:33:29.264581   543 layer_factory.hpp:77] Creating layer relu4
I0614 12:33:29.264586   543 net.cpp:94] Creating Layer relu4
I0614 12:33:29.264590   543 net.cpp:435] relu4 <- conv4
I0614 12:33:29.264595   543 net.cpp:409] relu4 -> relu4
I0614 12:33:29.264623   543 net.cpp:144] Setting up relu4
I0614 12:33:29.264626   543 net.cpp:151] Top shape: 10 384 13 13 (648960)
I0614 12:33:29.264631   543 net.cpp:159] Memory required for data: 78339680
I0614 12:33:29.264633   543 layer_factory.hpp:77] Creating layer conv5
I0614 12:33:29.264640   543 net.cpp:94] Creating Layer conv5
I0614 12:33:29.264643   543 net.cpp:435] conv5 <- relu4
I0614 12:33:29.264647   543 net.cpp:409] conv5 -> conv5
I0614 12:33:29.272593   543 net.cpp:144] Setting up conv5
I0614 12:33:29.272604   543 net.cpp:151] Top shape: 10 256 13 13 (432640)
I0614 12:33:29.272610   543 net.cpp:159] Memory required for data: 80070240
I0614 12:33:29.272616   543 layer_factory.hpp:77] Creating layer relu5
I0614 12:33:29.272621   543 net.cpp:94] Creating Layer relu5
I0614 12:33:29.272625   543 net.cpp:435] relu5 <- conv5
I0614 12:33:29.272629   543 net.cpp:409] relu5 -> relu5
I0614 12:33:29.272642   543 net.cpp:144] Setting up relu5
I0614 12:33:29.272644   543 net.cpp:151] Top shape: 10 256 13 13 (432640)
I0614 12:33:29.272647   543 net.cpp:159] Memory required for data: 81800800
I0614 12:33:29.272650   543 layer_factory.hpp:77] Creating layer pool5
I0614 12:33:29.272655   543 net.cpp:94] Creating Layer pool5
I0614 12:33:29.272657   543 net.cpp:435] pool5 <- relu5
I0614 12:33:29.272660   543 net.cpp:409] pool5 -> pool5
I0614 12:33:29.272675   543 net.cpp:144] Setting up pool5
I0614 12:33:29.272677   543 net.cpp:151] Top shape: 10 256 6 6 (92160)
I0614 12:33:29.272681   543 net.cpp:159] Memory required for data: 82169440
I0614 12:33:29.272683   543 layer_factory.hpp:77] Creating layer fc6
I0614 12:33:29.272696   543 net.cpp:94] Creating Layer fc6
I0614 12:33:29.272699   543 net.cpp:435] fc6 <- pool5
I0614 12:33:29.272702   543 net.cpp:409] fc6 -> fc6
I0614 12:33:29.592342   543 net.cpp:144] Setting up fc6
I0614 12:33:29.592362   543 net.cpp:151] Top shape: 10 4096 (40960)
I0614 12:33:29.592370   543 net.cpp:159] Memory required for data: 82333280
I0614 12:33:29.592379   543 layer_factory.hpp:77] Creating layer relu6
I0614 12:33:29.592386   543 net.cpp:94] Creating Layer relu6
I0614 12:33:29.592391   543 net.cpp:435] relu6 <- fc6
I0614 12:33:29.592412   543 net.cpp:409] relu6 -> relu6
I0614 12:33:29.592429   543 net.cpp:144] Setting up relu6
I0614 12:33:29.592432   543 net.cpp:151] Top shape: 10 4096 (40960)
I0614 12:33:29.592435   543 net.cpp:159] Memory required for data: 82497120
I0614 12:33:29.592437   543 layer_factory.hpp:77] Creating layer fc7
I0614 12:33:29.592443   543 net.cpp:94] Creating Layer fc7
I0614 12:33:29.592447   543 net.cpp:435] fc7 <- relu6
I0614 12:33:29.592450   543 net.cpp:409] fc7 -> fc7
I0614 12:33:29.727209   543 net.cpp:144] Setting up fc7
I0614 12:33:29.727236   543 net.cpp:151] Top shape: 10 4096 (40960)
I0614 12:33:29.727242   543 net.cpp:159] Memory required for data: 82660960
I0614 12:33:29.727252   543 layer_factory.hpp:77] Creating layer bn7
I0614 12:33:29.727262   543 net.cpp:94] Creating Layer bn7
I0614 12:33:29.727267   543 net.cpp:435] bn7 <- fc7
I0614 12:33:29.727272   543 net.cpp:409] bn7 -> bn7
I0614 12:33:29.727536   543 net.cpp:144] Setting up bn7
I0614 12:33:29.727540   543 net.cpp:151] Top shape: 10 4096 (40960)
I0614 12:33:29.727543   543 net.cpp:159] Memory required for data: 82824800
I0614 12:33:29.727548   543 layer_factory.hpp:77] Creating layer relu7
I0614 12:33:29.727552   543 net.cpp:94] Creating Layer relu7
I0614 12:33:29.727555   543 net.cpp:435] relu7 <- bn7
I0614 12:33:29.727560   543 net.cpp:409] relu7 -> relu7
I0614 12:33:29.727568   543 net.cpp:144] Setting up relu7
I0614 12:33:29.727571   543 net.cpp:151] Top shape: 10 4096 (40960)
I0614 12:33:29.727574   543 net.cpp:159] Memory required for data: 82988640
I0614 12:33:29.727576   543 layer_factory.hpp:77] Creating layer fc8
I0614 12:33:29.727581   543 net.cpp:94] Creating Layer fc8
I0614 12:33:29.727584   543 net.cpp:435] fc8 <- relu7
I0614 12:33:29.727588   543 net.cpp:409] fc8 -> fc8
I0614 12:33:29.727720   543 net.cpp:144] Setting up fc8
I0614 12:33:29.727725   543 net.cpp:151] Top shape: 10 2 (20)
I0614 12:33:29.727727   543 net.cpp:159] Memory required for data: 82988720
I0614 12:33:29.727732   543 layer_factory.hpp:77] Creating layer loss
I0614 12:33:29.727746   543 net.cpp:94] Creating Layer loss
I0614 12:33:29.727749   543 net.cpp:435] loss <- fc8
I0614 12:33:29.727752   543 net.cpp:435] loss <- label
I0614 12:33:29.727756   543 net.cpp:409] loss -> loss
I0614 12:33:29.727764   543 layer_factory.hpp:77] Creating layer loss
I0614 12:33:29.727804   543 net.cpp:144] Setting up loss
I0614 12:33:29.727807   543 net.cpp:151] Top shape: (1)
I0614 12:33:29.727826   543 net.cpp:154]     with loss weight 1
I0614 12:33:29.727851   543 net.cpp:159] Memory required for data: 82988724
I0614 12:33:29.727854   543 net.cpp:220] loss needs backward computation.
I0614 12:33:29.727859   543 net.cpp:220] fc8 needs backward computation.
I0614 12:33:29.727861   543 net.cpp:220] relu7 needs backward computation.
I0614 12:33:29.727864   543 net.cpp:220] bn7 needs backward computation.
I0614 12:33:29.727867   543 net.cpp:220] fc7 needs backward computation.
I0614 12:33:29.727871   543 net.cpp:220] relu6 needs backward computation.
I0614 12:33:29.727874   543 net.cpp:220] fc6 needs backward computation.
I0614 12:33:29.727877   543 net.cpp:220] pool5 needs backward computation.
I0614 12:33:29.727880   543 net.cpp:220] relu5 needs backward computation.
I0614 12:33:29.727885   543 net.cpp:220] conv5 needs backward computation.
I0614 12:33:29.727887   543 net.cpp:220] relu4 needs backward computation.
I0614 12:33:29.727890   543 net.cpp:220] conv4 needs backward computation.
I0614 12:33:29.727893   543 net.cpp:220] relu3 needs backward computation.
I0614 12:33:29.727896   543 net.cpp:220] conv3 needs backward computation.
I0614 12:33:29.727900   543 net.cpp:220] pool2 needs backward computation.
I0614 12:33:29.727903   543 net.cpp:220] relu2 needs backward computation.
I0614 12:33:29.727906   543 net.cpp:220] bn2 needs backward computation.
I0614 12:33:29.727910   543 net.cpp:220] conv2 needs backward computation.
I0614 12:33:29.727912   543 net.cpp:220] pool1 needs backward computation.
I0614 12:33:29.727916   543 net.cpp:220] relu1 needs backward computation.
I0614 12:33:29.727919   543 net.cpp:220] bn1 needs backward computation.
I0614 12:33:29.727922   543 net.cpp:220] conv1 needs backward computation.
I0614 12:33:29.727926   543 net.cpp:222] data does not need backward computation.
I0614 12:33:29.727929   543 net.cpp:264] This network produces output loss
I0614 12:33:29.727943   543 net.cpp:284] Network initialization done.
I0614 12:33:29.914573   543 convert_proto.cpp:184] Opening file deploy/alexnetBNnoLRN/quantiz/data/calib/calibration.txt
I0614 12:33:29.915167   543 convert_proto.cpp:195] A total of 200 images.
I0614 12:33:29.973995   543 convert_proto.cpp:2712]  Merge InnerProductBatchNorm -> InnerProduct: fc7 + bn7
I0614 12:33:30.268059   543 convert_proto.cpp:2712]  Merge InnerProductBatchNorm -> InnerProduct: fc7 + bn7
I0614 12:33:30.629230   543 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0614 12:33:30.629256   543 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0614 12:33:30.629258   543 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy-top1
I0614 12:33:30.629261   543 net.cpp:52] Initializing net from parameters: 
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    crop_size: 227
    mean_value: 106
    mean_value: 116
    mean_value: 124
  }
  image_data_param {
    source: "deploy/alexnetBNnoLRN/quantiz/data/calib/calibration.txt"
    batch_size: 10
    shuffle: true
    root_folder: "deploy/alexnetBNnoLRN/quantiz/data/calib/"
  }
}
layer {
  name: "data_fixed"
  type: "FixedNeuron"
  bottom: "data"
  top: "data"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: OVER_FLOW
    bit_width: 8
    follow_data_layer: true
  }
}
layer {
  name: "conv1"
  type: "ConvolutionFixed"
  bottom: "data"
  top: "bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    bias_term: true
    pad: 0
    kernel_size: 8
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "bn1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "pool1_fixed"
  type: "FixedNeuron"
  bottom: "pool1"
  top: "pool1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "conv2"
  type: "ConvolutionFixed"
  bottom: "pool1"
  top: "bn2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 2
    kernel_size: 5
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "bn2"
  top: "relu2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "pool2_fixed"
  type: "FixedNeuron"
  bottom: "pool2"
  top: "pool2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "conv3"
  type: "ConvolutionFixed"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "relu3_fixed"
  type: "FixedNeuron"
  bottom: "relu3"
  top: "relu3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "conv4"
  type: "ConvolutionFixed"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "relu4_fixed"
  type: "FixedNeuron"
  bottom: "relu4"
  top: "relu4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "conv5"
  type: "ConvolutionFixed"
  bottom: "relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "pool5_fixed"
  type: "FixedNeuron"
  bottom: "pool5"
  top: "pool5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "fc6"
  type: "InnerProductFixed"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "relu6_fixed"
  type: "FixedNeuron"
  bottom: "relu6"
  top: "relu6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "fc7"
  type: "InnerProductFixed"
  bottom: "relu6"
  top: "bn7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    bias_term: true
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "bn7"
  top: "relu7"
}
layer {
  name: "relu7_fixed"
  type: "FixedNeuron"
  bottom: "relu7"
  top: "relu7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "fc8"
  type: "InnerProductFixed"
  bottom: "relu7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "fc8_fixed"
  type: "FixedNeuron"
  bottom: "fc8"
  top: "fc8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0614 12:33:30.629431   543 layer_factory.hpp:77] Creating layer data
I0614 12:33:30.629444   543 net.cpp:94] Creating Layer data
I0614 12:33:30.629448   543 net.cpp:409] data -> data
I0614 12:33:30.629456   543 net.cpp:409] data -> label
I0614 12:33:30.629464   543 image_data_layer.cpp:41] Opening file deploy/alexnetBNnoLRN/quantiz/data/calib/calibration.txt
I0614 12:33:30.630156   543 image_data_layer.cpp:51] Shuffling data
I0614 12:33:30.630170   543 image_data_layer.cpp:56] A total of 200 images.
I0614 12:33:30.632896   543 image_data_layer.cpp:84] output data size: 10,3,227,227
I0614 12:33:30.654491   543 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0614 12:33:30.654551   543 net.cpp:144] Setting up data
I0614 12:33:30.654556   543 net.cpp:151] Top shape: 10 3 227 227 (1545870)
I0614 12:33:30.654563   543 net.cpp:151] Top shape: 10 (10)
I0614 12:33:30.654567   543 net.cpp:159] Memory required for data: 6183520
I0614 12:33:30.654572   543 layer_factory.hpp:77] Creating layer data_fixed
I0614 12:33:30.654588   543 net.cpp:94] Creating Layer data_fixed
I0614 12:33:30.654608   543 net.cpp:435] data_fixed <- data
I0614 12:33:30.654614   543 net.cpp:396] data_fixed -> data (in-place)
I0614 12:33:30.654647   543 net.cpp:144] Setting up data_fixed
I0614 12:33:30.654650   543 net.cpp:151] Top shape: 10 3 227 227 (1545870)
I0614 12:33:30.654654   543 net.cpp:159] Memory required for data: 12367000
I0614 12:33:30.654661   543 layer_factory.hpp:77] Creating layer conv1
I0614 12:33:30.654675   543 net.cpp:94] Creating Layer conv1
I0614 12:33:30.654680   543 net.cpp:435] conv1 <- data
I0614 12:33:30.654685   543 net.cpp:409] conv1 -> bn1
I0614 12:33:30.655015   543 layer_factory.hpp:77] Creating layer conv1
I0614 12:33:30.655303   543 net.cpp:144] Setting up conv1
I0614 12:33:30.655309   543 net.cpp:151] Top shape: 10 96 55 55 (2904000)
I0614 12:33:30.655315   543 net.cpp:159] Memory required for data: 23983000
I0614 12:33:30.655323   543 layer_factory.hpp:77] Creating layer relu1
I0614 12:33:30.655328   543 net.cpp:94] Creating Layer relu1
I0614 12:33:30.655330   543 net.cpp:435] relu1 <- bn1
I0614 12:33:30.655334   543 net.cpp:409] relu1 -> relu1
I0614 12:33:30.655346   543 net.cpp:144] Setting up relu1
I0614 12:33:30.655349   543 net.cpp:151] Top shape: 10 96 55 55 (2904000)
I0614 12:33:30.655354   543 net.cpp:159] Memory required for data: 35599000
I0614 12:33:30.655356   543 layer_factory.hpp:77] Creating layer pool1
I0614 12:33:30.655362   543 net.cpp:94] Creating Layer pool1
I0614 12:33:30.655365   543 net.cpp:435] pool1 <- relu1
I0614 12:33:30.655369   543 net.cpp:409] pool1 -> pool1
I0614 12:33:30.655385   543 net.cpp:144] Setting up pool1
I0614 12:33:30.655387   543 net.cpp:151] Top shape: 10 96 27 27 (699840)
I0614 12:33:30.655391   543 net.cpp:159] Memory required for data: 38398360
I0614 12:33:30.655395   543 layer_factory.hpp:77] Creating layer pool1_fixed
I0614 12:33:30.655400   543 net.cpp:94] Creating Layer pool1_fixed
I0614 12:33:30.655402   543 net.cpp:435] pool1_fixed <- pool1
I0614 12:33:30.655406   543 net.cpp:396] pool1_fixed -> pool1 (in-place)
I0614 12:33:30.655421   543 net.cpp:144] Setting up pool1_fixed
I0614 12:33:30.655423   543 net.cpp:151] Top shape: 10 96 27 27 (699840)
I0614 12:33:30.655426   543 net.cpp:159] Memory required for data: 41197720
I0614 12:33:30.655431   543 layer_factory.hpp:77] Creating layer conv2
I0614 12:33:30.655436   543 net.cpp:94] Creating Layer conv2
I0614 12:33:30.655439   543 net.cpp:435] conv2 <- pool1
I0614 12:33:30.655443   543 net.cpp:409] conv2 -> bn2
I0614 12:33:30.661667   543 layer_factory.hpp:77] Creating layer conv2
I0614 12:33:30.667696   543 net.cpp:144] Setting up conv2
I0614 12:33:30.667708   543 net.cpp:151] Top shape: 10 256 27 27 (1866240)
I0614 12:33:30.667716   543 net.cpp:159] Memory required for data: 48662680
I0614 12:33:30.667723   543 layer_factory.hpp:77] Creating layer relu2
I0614 12:33:30.667728   543 net.cpp:94] Creating Layer relu2
I0614 12:33:30.667732   543 net.cpp:435] relu2 <- bn2
I0614 12:33:30.667737   543 net.cpp:409] relu2 -> relu2
I0614 12:33:30.667747   543 net.cpp:144] Setting up relu2
I0614 12:33:30.667764   543 net.cpp:151] Top shape: 10 256 27 27 (1866240)
I0614 12:33:30.667768   543 net.cpp:159] Memory required for data: 56127640
I0614 12:33:30.667771   543 layer_factory.hpp:77] Creating layer pool2
I0614 12:33:30.667778   543 net.cpp:94] Creating Layer pool2
I0614 12:33:30.667780   543 net.cpp:435] pool2 <- relu2
I0614 12:33:30.667783   543 net.cpp:409] pool2 -> pool2
I0614 12:33:30.667798   543 net.cpp:144] Setting up pool2
I0614 12:33:30.667800   543 net.cpp:151] Top shape: 10 256 13 13 (432640)
I0614 12:33:30.667804   543 net.cpp:159] Memory required for data: 57858200
I0614 12:33:30.667807   543 layer_factory.hpp:77] Creating layer pool2_fixed
I0614 12:33:30.667812   543 net.cpp:94] Creating Layer pool2_fixed
I0614 12:33:30.667815   543 net.cpp:435] pool2_fixed <- pool2
I0614 12:33:30.667819   543 net.cpp:396] pool2_fixed -> pool2 (in-place)
I0614 12:33:30.667831   543 net.cpp:144] Setting up pool2_fixed
I0614 12:33:30.667834   543 net.cpp:151] Top shape: 10 256 13 13 (432640)
I0614 12:33:30.667838   543 net.cpp:159] Memory required for data: 59588760
I0614 12:33:30.667841   543 layer_factory.hpp:77] Creating layer conv3
I0614 12:33:30.667848   543 net.cpp:94] Creating Layer conv3
I0614 12:33:30.667850   543 net.cpp:435] conv3 <- pool2
I0614 12:33:30.667855   543 net.cpp:409] conv3 -> conv3
I0614 12:33:30.676079   543 layer_factory.hpp:77] Creating layer conv3
I0614 12:33:30.684182   543 net.cpp:144] Setting up conv3
I0614 12:33:30.684195   543 net.cpp:151] Top shape: 10 384 13 13 (648960)
I0614 12:33:30.684201   543 net.cpp:159] Memory required for data: 62184600
I0614 12:33:30.684211   543 layer_factory.hpp:77] Creating layer relu3
I0614 12:33:30.684216   543 net.cpp:94] Creating Layer relu3
I0614 12:33:30.684219   543 net.cpp:435] relu3 <- conv3
I0614 12:33:30.684224   543 net.cpp:409] relu3 -> relu3
I0614 12:33:30.684235   543 net.cpp:144] Setting up relu3
I0614 12:33:30.684238   543 net.cpp:151] Top shape: 10 384 13 13 (648960)
I0614 12:33:30.684242   543 net.cpp:159] Memory required for data: 64780440
I0614 12:33:30.684243   543 layer_factory.hpp:77] Creating layer relu3_fixed
I0614 12:33:30.684249   543 net.cpp:94] Creating Layer relu3_fixed
I0614 12:33:30.684252   543 net.cpp:435] relu3_fixed <- relu3
I0614 12:33:30.684255   543 net.cpp:396] relu3_fixed -> relu3 (in-place)
I0614 12:33:30.684267   543 net.cpp:144] Setting up relu3_fixed
I0614 12:33:30.684269   543 net.cpp:151] Top shape: 10 384 13 13 (648960)
I0614 12:33:30.684273   543 net.cpp:159] Memory required for data: 67376280
I0614 12:33:30.684276   543 layer_factory.hpp:77] Creating layer conv4
I0614 12:33:30.684283   543 net.cpp:94] Creating Layer conv4
I0614 12:33:30.684284   543 net.cpp:435] conv4 <- relu3
I0614 12:33:30.684288   543 net.cpp:409] conv4 -> conv4
I0614 12:33:30.695799   543 layer_factory.hpp:77] Creating layer conv4
I0614 12:33:30.707671   543 net.cpp:144] Setting up conv4
I0614 12:33:30.707684   543 net.cpp:151] Top shape: 10 384 13 13 (648960)
I0614 12:33:30.707691   543 net.cpp:159] Memory required for data: 69972120
I0614 12:33:30.707700   543 layer_factory.hpp:77] Creating layer relu4
I0614 12:33:30.707705   543 net.cpp:94] Creating Layer relu4
I0614 12:33:30.707710   543 net.cpp:435] relu4 <- conv4
I0614 12:33:30.707715   543 net.cpp:409] relu4 -> relu4
I0614 12:33:30.707726   543 net.cpp:144] Setting up relu4
I0614 12:33:30.707728   543 net.cpp:151] Top shape: 10 384 13 13 (648960)
I0614 12:33:30.707731   543 net.cpp:159] Memory required for data: 72567960
I0614 12:33:30.707734   543 layer_factory.hpp:77] Creating layer relu4_fixed
I0614 12:33:30.707739   543 net.cpp:94] Creating Layer relu4_fixed
I0614 12:33:30.707742   543 net.cpp:435] relu4_fixed <- relu4
I0614 12:33:30.707746   543 net.cpp:396] relu4_fixed -> relu4 (in-place)
I0614 12:33:30.707757   543 net.cpp:144] Setting up relu4_fixed
I0614 12:33:30.707759   543 net.cpp:151] Top shape: 10 384 13 13 (648960)
I0614 12:33:30.707763   543 net.cpp:159] Memory required for data: 75163800
I0614 12:33:30.707767   543 layer_factory.hpp:77] Creating layer conv5
I0614 12:33:30.707773   543 net.cpp:94] Creating Layer conv5
I0614 12:33:30.707775   543 net.cpp:435] conv5 <- relu4
I0614 12:33:30.707779   543 net.cpp:409] conv5 -> conv5
I0614 12:33:30.716024   543 layer_factory.hpp:77] Creating layer conv5
I0614 12:33:30.724192   543 net.cpp:144] Setting up conv5
I0614 12:33:30.724205   543 net.cpp:151] Top shape: 10 256 13 13 (432640)
I0614 12:33:30.724213   543 net.cpp:159] Memory required for data: 76894360
I0614 12:33:30.724221   543 layer_factory.hpp:77] Creating layer relu5
I0614 12:33:30.724226   543 net.cpp:94] Creating Layer relu5
I0614 12:33:30.724231   543 net.cpp:435] relu5 <- conv5
I0614 12:33:30.724236   543 net.cpp:409] relu5 -> relu5
I0614 12:33:30.724246   543 net.cpp:144] Setting up relu5
I0614 12:33:30.724249   543 net.cpp:151] Top shape: 10 256 13 13 (432640)
I0614 12:33:30.724252   543 net.cpp:159] Memory required for data: 78624920
I0614 12:33:30.724256   543 layer_factory.hpp:77] Creating layer pool5
I0614 12:33:30.724259   543 net.cpp:94] Creating Layer pool5
I0614 12:33:30.724262   543 net.cpp:435] pool5 <- relu5
I0614 12:33:30.724265   543 net.cpp:409] pool5 -> pool5
I0614 12:33:30.724277   543 net.cpp:144] Setting up pool5
I0614 12:33:30.724280   543 net.cpp:151] Top shape: 10 256 6 6 (92160)
I0614 12:33:30.724283   543 net.cpp:159] Memory required for data: 78993560
I0614 12:33:30.724287   543 layer_factory.hpp:77] Creating layer pool5_fixed
I0614 12:33:30.724292   543 net.cpp:94] Creating Layer pool5_fixed
I0614 12:33:30.724293   543 net.cpp:435] pool5_fixed <- pool5
I0614 12:33:30.724296   543 net.cpp:396] pool5_fixed -> pool5 (in-place)
I0614 12:33:30.724324   543 net.cpp:144] Setting up pool5_fixed
I0614 12:33:30.724328   543 net.cpp:151] Top shape: 10 256 6 6 (92160)
I0614 12:33:30.724330   543 net.cpp:159] Memory required for data: 79362200
I0614 12:33:30.724335   543 layer_factory.hpp:77] Creating layer fc6
I0614 12:33:30.724342   543 net.cpp:94] Creating Layer fc6
I0614 12:33:30.724346   543 net.cpp:435] fc6 <- pool5
I0614 12:33:30.724352   543 net.cpp:409] fc6 -> fc6
I0614 12:33:31.047943   543 layer_factory.hpp:77] Creating layer fc6
I0614 12:33:31.363417   543 net.cpp:144] Setting up fc6
I0614 12:33:31.363438   543 net.cpp:151] Top shape: 10 4096 (40960)
I0614 12:33:31.363445   543 net.cpp:159] Memory required for data: 79526040
I0614 12:33:31.363471   543 layer_factory.hpp:77] Creating layer relu6
I0614 12:33:31.363477   543 net.cpp:94] Creating Layer relu6
I0614 12:33:31.363481   543 net.cpp:435] relu6 <- fc6
I0614 12:33:31.363487   543 net.cpp:409] relu6 -> relu6
I0614 12:33:31.363502   543 net.cpp:144] Setting up relu6
I0614 12:33:31.363504   543 net.cpp:151] Top shape: 10 4096 (40960)
I0614 12:33:31.363507   543 net.cpp:159] Memory required for data: 79689880
I0614 12:33:31.363509   543 layer_factory.hpp:77] Creating layer relu6_fixed
I0614 12:33:31.363516   543 net.cpp:94] Creating Layer relu6_fixed
I0614 12:33:31.363518   543 net.cpp:435] relu6_fixed <- relu6
I0614 12:33:31.363523   543 net.cpp:396] relu6_fixed -> relu6 (in-place)
I0614 12:33:31.363534   543 net.cpp:144] Setting up relu6_fixed
I0614 12:33:31.363536   543 net.cpp:151] Top shape: 10 4096 (40960)
I0614 12:33:31.363539   543 net.cpp:159] Memory required for data: 79853720
I0614 12:33:31.363543   543 layer_factory.hpp:77] Creating layer fc7
I0614 12:33:31.363548   543 net.cpp:94] Creating Layer fc7
I0614 12:33:31.363550   543 net.cpp:435] fc7 <- relu6
I0614 12:33:31.363554   543 net.cpp:409] fc7 -> bn7
I0614 12:33:31.499435   543 layer_factory.hpp:77] Creating layer fc7
I0614 12:33:31.639513   543 net.cpp:144] Setting up fc7
I0614 12:33:31.639539   543 net.cpp:151] Top shape: 10 4096 (40960)
I0614 12:33:31.639546   543 net.cpp:159] Memory required for data: 80017560
I0614 12:33:31.639557   543 layer_factory.hpp:77] Creating layer relu7
I0614 12:33:31.639565   543 net.cpp:94] Creating Layer relu7
I0614 12:33:31.639569   543 net.cpp:435] relu7 <- bn7
I0614 12:33:31.639575   543 net.cpp:409] relu7 -> relu7
I0614 12:33:31.639605   543 net.cpp:144] Setting up relu7
I0614 12:33:31.639607   543 net.cpp:151] Top shape: 10 4096 (40960)
I0614 12:33:31.639611   543 net.cpp:159] Memory required for data: 80181400
I0614 12:33:31.639613   543 layer_factory.hpp:77] Creating layer relu7_fixed
I0614 12:33:31.639621   543 net.cpp:94] Creating Layer relu7_fixed
I0614 12:33:31.639622   543 net.cpp:435] relu7_fixed <- relu7
I0614 12:33:31.639626   543 net.cpp:396] relu7_fixed -> relu7 (in-place)
I0614 12:33:31.639638   543 net.cpp:144] Setting up relu7_fixed
I0614 12:33:31.639642   543 net.cpp:151] Top shape: 10 4096 (40960)
I0614 12:33:31.639644   543 net.cpp:159] Memory required for data: 80345240
I0614 12:33:31.639647   543 layer_factory.hpp:77] Creating layer fc8
I0614 12:33:31.639653   543 net.cpp:94] Creating Layer fc8
I0614 12:33:31.639655   543 net.cpp:435] fc8 <- relu7
I0614 12:33:31.639659   543 net.cpp:409] fc8 -> fc8
I0614 12:33:31.639746   543 layer_factory.hpp:77] Creating layer fc8
I0614 12:33:31.639876   543 net.cpp:144] Setting up fc8
I0614 12:33:31.639883   543 net.cpp:151] Top shape: 10 2 (20)
I0614 12:33:31.639885   543 net.cpp:159] Memory required for data: 80345320
I0614 12:33:31.639890   543 layer_factory.hpp:77] Creating layer fc8_fixed
I0614 12:33:31.639895   543 net.cpp:94] Creating Layer fc8_fixed
I0614 12:33:31.639897   543 net.cpp:435] fc8_fixed <- fc8
I0614 12:33:31.639901   543 net.cpp:396] fc8_fixed -> fc8 (in-place)
I0614 12:33:31.639914   543 net.cpp:144] Setting up fc8_fixed
I0614 12:33:31.639917   543 net.cpp:151] Top shape: 10 2 (20)
I0614 12:33:31.639920   543 net.cpp:159] Memory required for data: 80345400
I0614 12:33:31.639925   543 layer_factory.hpp:77] Creating layer loss
I0614 12:33:31.639928   543 net.cpp:94] Creating Layer loss
I0614 12:33:31.639931   543 net.cpp:435] loss <- fc8
I0614 12:33:31.639935   543 net.cpp:435] loss <- label
I0614 12:33:31.639938   543 net.cpp:409] loss -> loss
I0614 12:33:31.639945   543 layer_factory.hpp:77] Creating layer loss
I0614 12:33:31.639981   543 net.cpp:144] Setting up loss
I0614 12:33:31.639984   543 net.cpp:151] Top shape: (1)
I0614 12:33:31.639987   543 net.cpp:154]     with loss weight 1
I0614 12:33:31.639998   543 net.cpp:159] Memory required for data: 80345404
I0614 12:33:31.640002   543 net.cpp:220] loss needs backward computation.
I0614 12:33:31.640004   543 net.cpp:220] fc8_fixed needs backward computation.
I0614 12:33:31.640007   543 net.cpp:220] fc8 needs backward computation.
I0614 12:33:31.640010   543 net.cpp:220] relu7_fixed needs backward computation.
I0614 12:33:31.640012   543 net.cpp:220] relu7 needs backward computation.
I0614 12:33:31.640015   543 net.cpp:220] fc7 needs backward computation.
I0614 12:33:31.640018   543 net.cpp:220] relu6_fixed needs backward computation.
I0614 12:33:31.640022   543 net.cpp:220] relu6 needs backward computation.
I0614 12:33:31.640024   543 net.cpp:220] fc6 needs backward computation.
I0614 12:33:31.640027   543 net.cpp:220] pool5_fixed needs backward computation.
I0614 12:33:31.640030   543 net.cpp:220] pool5 needs backward computation.
I0614 12:33:31.640033   543 net.cpp:220] relu5 needs backward computation.
I0614 12:33:31.640038   543 net.cpp:220] conv5 needs backward computation.
I0614 12:33:31.640039   543 net.cpp:220] relu4_fixed needs backward computation.
I0614 12:33:31.640043   543 net.cpp:220] relu4 needs backward computation.
I0614 12:33:31.640046   543 net.cpp:220] conv4 needs backward computation.
I0614 12:33:31.640049   543 net.cpp:220] relu3_fixed needs backward computation.
I0614 12:33:31.640053   543 net.cpp:220] relu3 needs backward computation.
I0614 12:33:31.640055   543 net.cpp:220] conv3 needs backward computation.
I0614 12:33:31.640058   543 net.cpp:220] pool2_fixed needs backward computation.
I0614 12:33:31.640061   543 net.cpp:220] pool2 needs backward computation.
I0614 12:33:31.640064   543 net.cpp:220] relu2 needs backward computation.
I0614 12:33:31.640067   543 net.cpp:220] conv2 needs backward computation.
I0614 12:33:31.640070   543 net.cpp:220] pool1_fixed needs backward computation.
I0614 12:33:31.640074   543 net.cpp:220] pool1 needs backward computation.
I0614 12:33:31.640076   543 net.cpp:220] relu1 needs backward computation.
I0614 12:33:31.640079   543 net.cpp:220] conv1 needs backward computation.
I0614 12:33:31.640082   543 net.cpp:222] data_fixed does not need backward computation.
I0614 12:33:31.640086   543 net.cpp:222] data does not need backward computation.
I0614 12:33:31.640089   543 net.cpp:264] This network produces output loss
I0614 12:33:31.640102   543 net.cpp:284] Network initialization done.
I0614 12:33:31.673131   543 vai_q.cpp:182] Start Calibration
I0614 12:33:31.760587   543 vai_q.cpp:206] Calibration iter: 1/100 ,loss: 43.9449
I0614 12:33:31.768330   543 vai_q.cpp:206] Calibration iter: 2/100 ,loss: 52.4453
I0614 12:33:31.775974   543 vai_q.cpp:206] Calibration iter: 3/100 ,loss: 61.4679
I0614 12:33:31.783591   543 vai_q.cpp:206] Calibration iter: 4/100 ,loss: 44.8447
I0614 12:33:31.796901   543 vai_q.cpp:206] Calibration iter: 5/100 ,loss: 52.7362
I0614 12:33:31.804226   543 vai_q.cpp:206] Calibration iter: 6/100 ,loss: 44.3983
I0614 12:33:31.812039   543 vai_q.cpp:206] Calibration iter: 7/100 ,loss: 43.9171
I0614 12:33:31.819293   543 vai_q.cpp:206] Calibration iter: 8/100 ,loss: 27.8275
I0614 12:33:31.826529   543 vai_q.cpp:206] Calibration iter: 9/100 ,loss: 70.0039
I0614 12:33:31.833755   543 vai_q.cpp:206] Calibration iter: 10/100 ,loss: 61.3414
I0614 12:33:31.841522   543 vai_q.cpp:206] Calibration iter: 11/100 ,loss: 52.533
I0614 12:33:31.848763   543 vai_q.cpp:206] Calibration iter: 12/100 ,loss: 61.212
I0614 12:33:31.855966   543 vai_q.cpp:206] Calibration iter: 13/100 ,loss: 61.2186
I0614 12:33:31.855978   543 blocking_queue.cpp:50] Data layer prefetch queue empty
I0614 12:33:31.874686   543 vai_q.cpp:206] Calibration iter: 14/100 ,loss: 36.106
I0614 12:33:31.903846   543 vai_q.cpp:206] Calibration iter: 15/100 ,loss: 62.3651
I0614 12:33:31.932158   543 vai_q.cpp:206] Calibration iter: 16/100 ,loss: 43.806
I0614 12:33:31.958979   543 vai_q.cpp:206] Calibration iter: 17/100 ,loss: 53.1394
I0614 12:33:31.985478   543 vai_q.cpp:206] Calibration iter: 18/100 ,loss: 52.7955
I0614 12:33:32.012560   543 vai_q.cpp:206] Calibration iter: 19/100 ,loss: 61.2394
I0614 12:33:32.052587   543 vai_q.cpp:206] Calibration iter: 20/100 ,loss: 61.3843
I0614 12:33:32.104617   543 vai_q.cpp:206] Calibration iter: 21/100 ,loss: 61.246
I0614 12:33:32.133031   543 vai_q.cpp:206] Calibration iter: 22/100 ,loss: 53.2132
I0614 12:33:32.159404   543 vai_q.cpp:206] Calibration iter: 23/100 ,loss: 44.3796
I0614 12:33:32.186501   543 vai_q.cpp:206] Calibration iter: 24/100 ,loss: 43.7972
I0614 12:33:32.213353   543 vai_q.cpp:206] Calibration iter: 25/100 ,loss: 52.533
I0614 12:33:32.262463   543 vai_q.cpp:206] Calibration iter: 26/100 ,loss: 43.7806
I0614 12:33:32.308179   543 vai_q.cpp:206] Calibration iter: 27/100 ,loss: 52.9245
I0614 12:33:32.337492   543 vai_q.cpp:206] Calibration iter: 28/100 ,loss: 27.9787
I0614 12:33:32.363981   543 vai_q.cpp:206] Calibration iter: 29/100 ,loss: 69.9634
I0614 12:33:32.390303   543 vai_q.cpp:206] Calibration iter: 30/100 ,loss: 43.9431
I0614 12:33:32.416774   543 vai_q.cpp:206] Calibration iter: 31/100 ,loss: 44.8276
I0614 12:33:32.443320   543 vai_q.cpp:206] Calibration iter: 32/100 ,loss: 35.962
I0614 12:33:32.470263   543 vai_q.cpp:206] Calibration iter: 33/100 ,loss: 43.9214
I0614 12:33:32.496481   543 vai_q.cpp:206] Calibration iter: 34/100 ,loss: 61.4547
I0614 12:33:32.523509   543 vai_q.cpp:206] Calibration iter: 35/100 ,loss: 44.0917
I0614 12:33:32.550773   543 vai_q.cpp:206] Calibration iter: 36/100 ,loss: 43.8423
I0614 12:33:32.577493   543 vai_q.cpp:206] Calibration iter: 37/100 ,loss: 44.2896
I0614 12:33:32.605221   543 vai_q.cpp:206] Calibration iter: 38/100 ,loss: 61.4373
I0614 12:33:32.631923   543 vai_q.cpp:206] Calibration iter: 39/100 ,loss: 52.4938
I0614 12:33:32.659199   543 vai_q.cpp:206] Calibration iter: 40/100 ,loss: 53.1145
I0614 12:33:32.686514   543 vai_q.cpp:206] Calibration iter: 41/100 ,loss: 52.6034
I0614 12:33:32.713531   543 vai_q.cpp:206] Calibration iter: 42/100 ,loss: 44.6546
I0614 12:33:32.740204   543 vai_q.cpp:206] Calibration iter: 43/100 ,loss: 61.8012
I0614 12:33:32.766517   543 vai_q.cpp:206] Calibration iter: 44/100 ,loss: 61.2959
I0614 12:33:32.811107   543 vai_q.cpp:206] Calibration iter: 45/100 ,loss: 61.4125
I0614 12:33:32.840749   543 vai_q.cpp:206] Calibration iter: 46/100 ,loss: 45.062
I0614 12:33:32.867280   543 vai_q.cpp:206] Calibration iter: 47/100 ,loss: 52.8661
I0614 12:33:32.893175   543 vai_q.cpp:206] Calibration iter: 48/100 ,loss: 26.8847
I0614 12:33:32.919543   543 vai_q.cpp:206] Calibration iter: 49/100 ,loss: 27.606
I0614 12:33:32.946364   543 vai_q.cpp:206] Calibration iter: 50/100 ,loss: 44.166
I0614 12:33:32.973541   543 vai_q.cpp:206] Calibration iter: 51/100 ,loss: 43.9651
I0614 12:33:33.000865   543 vai_q.cpp:206] Calibration iter: 52/100 ,loss: 35.2866
I0614 12:33:33.027398   543 vai_q.cpp:206] Calibration iter: 53/100 ,loss: 35.4107
I0614 12:33:33.054329   543 vai_q.cpp:206] Calibration iter: 54/100 ,loss: 70.0175
I0614 12:33:33.080780   543 vai_q.cpp:206] Calibration iter: 55/100 ,loss: 52.8335
I0614 12:33:33.107908   543 vai_q.cpp:206] Calibration iter: 56/100 ,loss: 44.0903
I0614 12:33:33.134413   543 vai_q.cpp:206] Calibration iter: 57/100 ,loss: 26.9748
I0614 12:33:33.161389   543 vai_q.cpp:206] Calibration iter: 58/100 ,loss: 26.7324
I0614 12:33:33.187929   543 vai_q.cpp:206] Calibration iter: 59/100 ,loss: 44.2513
I0614 12:33:33.231336   543 vai_q.cpp:206] Calibration iter: 60/100 ,loss: 53.7068
I0614 12:33:33.261212   543 vai_q.cpp:206] Calibration iter: 61/100 ,loss: 35.1781
I0614 12:33:33.287815   543 vai_q.cpp:206] Calibration iter: 62/100 ,loss: 53.0037
I0614 12:33:33.314013   543 vai_q.cpp:206] Calibration iter: 63/100 ,loss: 61.5195
I0614 12:33:33.340689   543 vai_q.cpp:206] Calibration iter: 64/100 ,loss: 61.2727
I0614 12:33:33.373198   543 vai_q.cpp:206] Calibration iter: 65/100 ,loss: 26.6307
I0614 12:33:33.418113   543 vai_q.cpp:206] Calibration iter: 66/100 ,loss: 35.478
I0614 12:33:33.445422   543 vai_q.cpp:206] Calibration iter: 67/100 ,loss: 52.6249
I0614 12:33:33.471930   543 vai_q.cpp:206] Calibration iter: 68/100 ,loss: 61.2817
I0614 12:33:33.498750   543 vai_q.cpp:206] Calibration iter: 69/100 ,loss: 69.8951
I0614 12:33:33.524889   543 vai_q.cpp:206] Calibration iter: 70/100 ,loss: 55.5895
I0614 12:33:33.564661   543 vai_q.cpp:206] Calibration iter: 71/100 ,loss: 44.9631
I0614 12:33:33.614396   543 vai_q.cpp:206] Calibration iter: 72/100 ,loss: 44.8283
I0614 12:33:33.642482   543 vai_q.cpp:206] Calibration iter: 73/100 ,loss: 26.8154
I0614 12:33:33.669710   543 vai_q.cpp:206] Calibration iter: 74/100 ,loss: 43.8461
I0614 12:33:33.696369   543 vai_q.cpp:206] Calibration iter: 75/100 ,loss: 44.2756
I0614 12:33:33.723040   543 vai_q.cpp:206] Calibration iter: 76/100 ,loss: 26.6737
I0614 12:33:33.749846   543 vai_q.cpp:206] Calibration iter: 77/100 ,loss: 52.6432
I0614 12:33:33.775822   543 vai_q.cpp:206] Calibration iter: 78/100 ,loss: 53.1983
I0614 12:33:33.802253   543 vai_q.cpp:206] Calibration iter: 79/100 ,loss: 52.5084
I0614 12:33:33.829807   543 vai_q.cpp:206] Calibration iter: 80/100 ,loss: 17.8641
I0614 12:33:33.856750   543 vai_q.cpp:206] Calibration iter: 81/100 ,loss: 61.3008
I0614 12:33:33.883160   543 vai_q.cpp:206] Calibration iter: 82/100 ,loss: 69.9077
I0614 12:33:33.909238   543 vai_q.cpp:206] Calibration iter: 83/100 ,loss: 44.0021
I0614 12:33:33.936211   543 vai_q.cpp:206] Calibration iter: 84/100 ,loss: 69.8692
I0614 12:33:33.962764   543 vai_q.cpp:206] Calibration iter: 85/100 ,loss: 69.9306
I0614 12:33:33.989414   543 vai_q.cpp:206] Calibration iter: 86/100 ,loss: 61.4419
I0614 12:33:34.031186   543 vai_q.cpp:206] Calibration iter: 87/100 ,loss: 27.4239
I0614 12:33:34.063141   543 vai_q.cpp:206] Calibration iter: 88/100 ,loss: 61.1773
I0614 12:33:34.090363   543 vai_q.cpp:206] Calibration iter: 89/100 ,loss: 52.7056
I0614 12:33:34.117251   543 vai_q.cpp:206] Calibration iter: 90/100 ,loss: 43.8493
I0614 12:33:34.145140   543 vai_q.cpp:206] Calibration iter: 91/100 ,loss: 43.893
I0614 12:33:34.171872   543 vai_q.cpp:206] Calibration iter: 92/100 ,loss: 35.0305
I0614 12:33:34.198688   543 vai_q.cpp:206] Calibration iter: 93/100 ,loss: 52.8386
I0614 12:33:34.226742   543 vai_q.cpp:206] Calibration iter: 94/100 ,loss: 27.719
I0614 12:33:34.253772   543 vai_q.cpp:206] Calibration iter: 95/100 ,loss: 52.6688
I0614 12:33:34.281538   543 vai_q.cpp:206] Calibration iter: 96/100 ,loss: 44.1518
I0614 12:33:34.308533   543 vai_q.cpp:206] Calibration iter: 97/100 ,loss: 44.4715
I0614 12:33:34.335953   543 vai_q.cpp:206] Calibration iter: 98/100 ,loss: 53.3618
I0614 12:33:34.364429   543 vai_q.cpp:206] Calibration iter: 99/100 ,loss: 44.7332
I0614 12:33:34.393311   543 vai_q.cpp:206] Calibration iter: 100/100 ,loss: 52.9599
I0614 12:33:34.393352   543 vai_q.cpp:211] Calibration Done!
I0614 12:33:36.741628   543 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0614 12:33:36.741683   543 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0614 12:33:36.741691   543 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy-top1
I0614 12:33:36.741701   543 net.cpp:52] Initializing net from parameters: 
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    crop_size: 227
    mean_value: 106
    mean_value: 116
    mean_value: 124
  }
  image_data_param {
    source: "deploy/alexnetBNnoLRN/quantiz/data/calib/calibration.txt"
    batch_size: 10
    shuffle: true
    root_folder: "deploy/alexnetBNnoLRN/quantiz/data/calib/"
  }
}
layer {
  name: "data_fixed"
  type: "FixedNeuron"
  bottom: "data"
  top: "data"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: OVER_FLOW
    bit_width: 8
    follow_data_layer: true
  }
}
layer {
  name: "conv1"
  type: "ConvolutionFixed"
  bottom: "data"
  top: "bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    bias_term: true
    pad: 0
    kernel_size: 8
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "bn1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "pool1_fixed"
  type: "FixedNeuron"
  bottom: "pool1"
  top: "pool1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "conv2"
  type: "ConvolutionFixed"
  bottom: "pool1"
  top: "bn2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 2
    kernel_size: 5
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "bn2"
  top: "relu2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "pool2_fixed"
  type: "FixedNeuron"
  bottom: "pool2"
  top: "pool2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "conv3"
  type: "ConvolutionFixed"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "relu3_fixed"
  type: "FixedNeuron"
  bottom: "relu3"
  top: "relu3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "conv4"
  type: "ConvolutionFixed"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "relu4_fixed"
  type: "FixedNeuron"
  bottom: "relu4"
  top: "relu4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "conv5"
  type: "ConvolutionFixed"
  bottom: "relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "pool5_fixed"
  type: "FixedNeuron"
  bottom: "pool5"
  top: "pool5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "fc6"
  type: "InnerProductFixed"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "relu6_fixed"
  type: "FixedNeuron"
  bottom: "relu6"
  top: "relu6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "fc7"
  type: "InnerProductFixed"
  bottom: "relu6"
  top: "bn7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    bias_term: true
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "bn7"
  top: "relu7"
}
layer {
  name: "relu7_fixed"
  type: "FixedNeuron"
  bottom: "relu7"
  top: "relu7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "fc8"
  type: "InnerProductFixed"
  bottom: "relu7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "fc8_fixed"
  type: "FixedNeuron"
  bottom: "fc8"
  top: "fc8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0614 12:33:36.742225   543 layer_factory.hpp:77] Creating layer data
I0614 12:33:36.742254   543 net.cpp:94] Creating Layer data
I0614 12:33:36.742265   543 net.cpp:409] data -> data
I0614 12:33:36.742286   543 net.cpp:409] data -> label
I0614 12:33:36.742308   543 image_data_layer.cpp:41] Opening file deploy/alexnetBNnoLRN/quantiz/data/calib/calibration.txt
I0614 12:33:36.742976   543 image_data_layer.cpp:51] Shuffling data
I0614 12:33:36.743012   543 image_data_layer.cpp:56] A total of 200 images.
I0614 12:33:36.746876   543 image_data_layer.cpp:84] output data size: 10,3,227,227
I0614 12:33:36.777878   543 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0614 12:33:36.777927   543 net.cpp:144] Setting up data
I0614 12:33:36.777932   543 net.cpp:151] Top shape: 10 3 227 227 (1545870)
I0614 12:33:36.777941   543 net.cpp:151] Top shape: 10 (10)
I0614 12:33:36.777945   543 net.cpp:159] Memory required for data: 6183520
I0614 12:33:36.777948   543 layer_factory.hpp:77] Creating layer data_fixed
I0614 12:33:36.777976   543 net.cpp:94] Creating Layer data_fixed
I0614 12:33:36.777981   543 net.cpp:435] data_fixed <- data
I0614 12:33:36.777987   543 net.cpp:396] data_fixed -> data (in-place)
I0614 12:33:36.778023   543 net.cpp:144] Setting up data_fixed
I0614 12:33:36.778025   543 net.cpp:151] Top shape: 10 3 227 227 (1545870)
I0614 12:33:36.778029   543 net.cpp:159] Memory required for data: 12367000
I0614 12:33:36.778038   543 layer_factory.hpp:77] Creating layer conv1
I0614 12:33:36.778048   543 net.cpp:94] Creating Layer conv1
I0614 12:33:36.778051   543 net.cpp:435] conv1 <- data
I0614 12:33:36.778056   543 net.cpp:409] conv1 -> bn1
I0614 12:33:36.778378   543 layer_factory.hpp:77] Creating layer conv1
I0614 12:33:36.778663   543 net.cpp:144] Setting up conv1
I0614 12:33:36.778668   543 net.cpp:151] Top shape: 10 96 55 55 (2904000)
I0614 12:33:36.778674   543 net.cpp:159] Memory required for data: 23983000
I0614 12:33:36.778681   543 layer_factory.hpp:77] Creating layer relu1
I0614 12:33:36.778687   543 net.cpp:94] Creating Layer relu1
I0614 12:33:36.778689   543 net.cpp:435] relu1 <- bn1
I0614 12:33:36.778693   543 net.cpp:409] relu1 -> relu1
I0614 12:33:36.778705   543 net.cpp:144] Setting up relu1
I0614 12:33:36.778709   543 net.cpp:151] Top shape: 10 96 55 55 (2904000)
I0614 12:33:36.778713   543 net.cpp:159] Memory required for data: 35599000
I0614 12:33:36.778717   543 layer_factory.hpp:77] Creating layer pool1
I0614 12:33:36.778721   543 net.cpp:94] Creating Layer pool1
I0614 12:33:36.778725   543 net.cpp:435] pool1 <- relu1
I0614 12:33:36.778728   543 net.cpp:409] pool1 -> pool1
I0614 12:33:36.778744   543 net.cpp:144] Setting up pool1
I0614 12:33:36.778748   543 net.cpp:151] Top shape: 10 96 27 27 (699840)
I0614 12:33:36.778753   543 net.cpp:159] Memory required for data: 38398360
I0614 12:33:36.778755   543 layer_factory.hpp:77] Creating layer pool1_fixed
I0614 12:33:36.778759   543 net.cpp:94] Creating Layer pool1_fixed
I0614 12:33:36.778762   543 net.cpp:435] pool1_fixed <- pool1
I0614 12:33:36.778766   543 net.cpp:396] pool1_fixed -> pool1 (in-place)
I0614 12:33:36.778780   543 net.cpp:144] Setting up pool1_fixed
I0614 12:33:36.778784   543 net.cpp:151] Top shape: 10 96 27 27 (699840)
I0614 12:33:36.778787   543 net.cpp:159] Memory required for data: 41197720
I0614 12:33:36.778791   543 layer_factory.hpp:77] Creating layer conv2
I0614 12:33:36.778797   543 net.cpp:94] Creating Layer conv2
I0614 12:33:36.778800   543 net.cpp:435] conv2 <- pool1
I0614 12:33:36.778805   543 net.cpp:409] conv2 -> bn2
I0614 12:33:36.784960   543 layer_factory.hpp:77] Creating layer conv2
I0614 12:33:36.791195   543 net.cpp:144] Setting up conv2
I0614 12:33:36.791209   543 net.cpp:151] Top shape: 10 256 27 27 (1866240)
I0614 12:33:36.791216   543 net.cpp:159] Memory required for data: 48662680
I0614 12:33:36.791225   543 layer_factory.hpp:77] Creating layer relu2
I0614 12:33:36.791232   543 net.cpp:94] Creating Layer relu2
I0614 12:33:36.791236   543 net.cpp:435] relu2 <- bn2
I0614 12:33:36.791241   543 net.cpp:409] relu2 -> relu2
I0614 12:33:36.791254   543 net.cpp:144] Setting up relu2
I0614 12:33:36.791256   543 net.cpp:151] Top shape: 10 256 27 27 (1866240)
I0614 12:33:36.791260   543 net.cpp:159] Memory required for data: 56127640
I0614 12:33:36.791263   543 layer_factory.hpp:77] Creating layer pool2
I0614 12:33:36.791268   543 net.cpp:94] Creating Layer pool2
I0614 12:33:36.791271   543 net.cpp:435] pool2 <- relu2
I0614 12:33:36.791275   543 net.cpp:409] pool2 -> pool2
I0614 12:33:36.791289   543 net.cpp:144] Setting up pool2
I0614 12:33:36.791291   543 net.cpp:151] Top shape: 10 256 13 13 (432640)
I0614 12:33:36.791296   543 net.cpp:159] Memory required for data: 57858200
I0614 12:33:36.791298   543 layer_factory.hpp:77] Creating layer pool2_fixed
I0614 12:33:36.791303   543 net.cpp:94] Creating Layer pool2_fixed
I0614 12:33:36.791306   543 net.cpp:435] pool2_fixed <- pool2
I0614 12:33:36.791311   543 net.cpp:396] pool2_fixed -> pool2 (in-place)
I0614 12:33:36.791322   543 net.cpp:144] Setting up pool2_fixed
I0614 12:33:36.791325   543 net.cpp:151] Top shape: 10 256 13 13 (432640)
I0614 12:33:36.791329   543 net.cpp:159] Memory required for data: 59588760
I0614 12:33:36.791333   543 layer_factory.hpp:77] Creating layer conv3
I0614 12:33:36.791340   543 net.cpp:94] Creating Layer conv3
I0614 12:33:36.791343   543 net.cpp:435] conv3 <- pool2
I0614 12:33:36.791347   543 net.cpp:409] conv3 -> conv3
I0614 12:33:36.799736   543 layer_factory.hpp:77] Creating layer conv3
I0614 12:33:36.808111   543 net.cpp:144] Setting up conv3
I0614 12:33:36.808125   543 net.cpp:151] Top shape: 10 384 13 13 (648960)
I0614 12:33:36.808131   543 net.cpp:159] Memory required for data: 62184600
I0614 12:33:36.808140   543 layer_factory.hpp:77] Creating layer relu3
I0614 12:33:36.808145   543 net.cpp:94] Creating Layer relu3
I0614 12:33:36.808149   543 net.cpp:435] relu3 <- conv3
I0614 12:33:36.808154   543 net.cpp:409] relu3 -> relu3
I0614 12:33:36.808180   543 net.cpp:144] Setting up relu3
I0614 12:33:36.808183   543 net.cpp:151] Top shape: 10 384 13 13 (648960)
I0614 12:33:36.808187   543 net.cpp:159] Memory required for data: 64780440
I0614 12:33:36.808190   543 layer_factory.hpp:77] Creating layer relu3_fixed
I0614 12:33:36.808195   543 net.cpp:94] Creating Layer relu3_fixed
I0614 12:33:36.808198   543 net.cpp:435] relu3_fixed <- relu3
I0614 12:33:36.808202   543 net.cpp:396] relu3_fixed -> relu3 (in-place)
I0614 12:33:36.808214   543 net.cpp:144] Setting up relu3_fixed
I0614 12:33:36.808218   543 net.cpp:151] Top shape: 10 384 13 13 (648960)
I0614 12:33:36.808221   543 net.cpp:159] Memory required for data: 67376280
I0614 12:33:36.808224   543 layer_factory.hpp:77] Creating layer conv4
I0614 12:33:36.808231   543 net.cpp:94] Creating Layer conv4
I0614 12:33:36.808234   543 net.cpp:435] conv4 <- relu3
I0614 12:33:36.808238   543 net.cpp:409] conv4 -> conv4
I0614 12:33:36.820307   543 layer_factory.hpp:77] Creating layer conv4
I0614 12:33:36.832157   543 net.cpp:144] Setting up conv4
I0614 12:33:36.832173   543 net.cpp:151] Top shape: 10 384 13 13 (648960)
I0614 12:33:36.832180   543 net.cpp:159] Memory required for data: 69972120
I0614 12:33:36.832188   543 layer_factory.hpp:77] Creating layer relu4
I0614 12:33:36.832195   543 net.cpp:94] Creating Layer relu4
I0614 12:33:36.832199   543 net.cpp:435] relu4 <- conv4
I0614 12:33:36.832204   543 net.cpp:409] relu4 -> relu4
I0614 12:33:36.832216   543 net.cpp:144] Setting up relu4
I0614 12:33:36.832218   543 net.cpp:151] Top shape: 10 384 13 13 (648960)
I0614 12:33:36.832221   543 net.cpp:159] Memory required for data: 72567960
I0614 12:33:36.832224   543 layer_factory.hpp:77] Creating layer relu4_fixed
I0614 12:33:36.832228   543 net.cpp:94] Creating Layer relu4_fixed
I0614 12:33:36.832231   543 net.cpp:435] relu4_fixed <- relu4
I0614 12:33:36.832234   543 net.cpp:396] relu4_fixed -> relu4 (in-place)
I0614 12:33:36.832245   543 net.cpp:144] Setting up relu4_fixed
I0614 12:33:36.832248   543 net.cpp:151] Top shape: 10 384 13 13 (648960)
I0614 12:33:36.832252   543 net.cpp:159] Memory required for data: 75163800
I0614 12:33:36.832254   543 layer_factory.hpp:77] Creating layer conv5
I0614 12:33:36.832262   543 net.cpp:94] Creating Layer conv5
I0614 12:33:36.832264   543 net.cpp:435] conv5 <- relu4
I0614 12:33:36.832268   543 net.cpp:409] conv5 -> conv5
I0614 12:33:36.840791   543 layer_factory.hpp:77] Creating layer conv5
I0614 12:33:36.849543   543 net.cpp:144] Setting up conv5
I0614 12:33:36.849557   543 net.cpp:151] Top shape: 10 256 13 13 (432640)
I0614 12:33:36.849565   543 net.cpp:159] Memory required for data: 76894360
I0614 12:33:36.849572   543 layer_factory.hpp:77] Creating layer relu5
I0614 12:33:36.849579   543 net.cpp:94] Creating Layer relu5
I0614 12:33:36.849583   543 net.cpp:435] relu5 <- conv5
I0614 12:33:36.849589   543 net.cpp:409] relu5 -> relu5
I0614 12:33:36.849602   543 net.cpp:144] Setting up relu5
I0614 12:33:36.849604   543 net.cpp:151] Top shape: 10 256 13 13 (432640)
I0614 12:33:36.849608   543 net.cpp:159] Memory required for data: 78624920
I0614 12:33:36.849611   543 layer_factory.hpp:77] Creating layer pool5
I0614 12:33:36.849617   543 net.cpp:94] Creating Layer pool5
I0614 12:33:36.849619   543 net.cpp:435] pool5 <- relu5
I0614 12:33:36.849623   543 net.cpp:409] pool5 -> pool5
I0614 12:33:36.849638   543 net.cpp:144] Setting up pool5
I0614 12:33:36.849642   543 net.cpp:151] Top shape: 10 256 6 6 (92160)
I0614 12:33:36.849645   543 net.cpp:159] Memory required for data: 78993560
I0614 12:33:36.849647   543 layer_factory.hpp:77] Creating layer pool5_fixed
I0614 12:33:36.849653   543 net.cpp:94] Creating Layer pool5_fixed
I0614 12:33:36.849656   543 net.cpp:435] pool5_fixed <- pool5
I0614 12:33:36.849659   543 net.cpp:396] pool5_fixed -> pool5 (in-place)
I0614 12:33:36.849673   543 net.cpp:144] Setting up pool5_fixed
I0614 12:33:36.849675   543 net.cpp:151] Top shape: 10 256 6 6 (92160)
I0614 12:33:36.849679   543 net.cpp:159] Memory required for data: 79362200
I0614 12:33:36.849682   543 layer_factory.hpp:77] Creating layer fc6
I0614 12:33:36.849689   543 net.cpp:94] Creating Layer fc6
I0614 12:33:36.849707   543 net.cpp:435] fc6 <- pool5
I0614 12:33:36.849712   543 net.cpp:409] fc6 -> fc6
I0614 12:33:37.178735   543 layer_factory.hpp:77] Creating layer fc6
I0614 12:33:37.498375   543 net.cpp:144] Setting up fc6
I0614 12:33:37.498397   543 net.cpp:151] Top shape: 10 4096 (40960)
I0614 12:33:37.498404   543 net.cpp:159] Memory required for data: 79526040
I0614 12:33:37.498414   543 layer_factory.hpp:77] Creating layer relu6
I0614 12:33:37.498421   543 net.cpp:94] Creating Layer relu6
I0614 12:33:37.498425   543 net.cpp:435] relu6 <- fc6
I0614 12:33:37.498430   543 net.cpp:409] relu6 -> relu6
I0614 12:33:37.498445   543 net.cpp:144] Setting up relu6
I0614 12:33:37.498448   543 net.cpp:151] Top shape: 10 4096 (40960)
I0614 12:33:37.498451   543 net.cpp:159] Memory required for data: 79689880
I0614 12:33:37.498454   543 layer_factory.hpp:77] Creating layer relu6_fixed
I0614 12:33:37.498459   543 net.cpp:94] Creating Layer relu6_fixed
I0614 12:33:37.498462   543 net.cpp:435] relu6_fixed <- relu6
I0614 12:33:37.498466   543 net.cpp:396] relu6_fixed -> relu6 (in-place)
I0614 12:33:37.498478   543 net.cpp:144] Setting up relu6_fixed
I0614 12:33:37.498481   543 net.cpp:151] Top shape: 10 4096 (40960)
I0614 12:33:37.498483   543 net.cpp:159] Memory required for data: 79853720
I0614 12:33:37.498486   543 layer_factory.hpp:77] Creating layer fc7
I0614 12:33:37.498509   543 net.cpp:94] Creating Layer fc7
I0614 12:33:37.498512   543 net.cpp:435] fc7 <- relu6
I0614 12:33:37.498517   543 net.cpp:409] fc7 -> bn7
I0614 12:33:37.639365   543 layer_factory.hpp:77] Creating layer fc7
I0614 12:33:37.779376   543 net.cpp:144] Setting up fc7
I0614 12:33:37.779402   543 net.cpp:151] Top shape: 10 4096 (40960)
I0614 12:33:37.779408   543 net.cpp:159] Memory required for data: 80017560
I0614 12:33:37.779417   543 layer_factory.hpp:77] Creating layer relu7
I0614 12:33:37.779425   543 net.cpp:94] Creating Layer relu7
I0614 12:33:37.779429   543 net.cpp:435] relu7 <- bn7
I0614 12:33:37.779435   543 net.cpp:409] relu7 -> relu7
I0614 12:33:37.779449   543 net.cpp:144] Setting up relu7
I0614 12:33:37.779451   543 net.cpp:151] Top shape: 10 4096 (40960)
I0614 12:33:37.779454   543 net.cpp:159] Memory required for data: 80181400
I0614 12:33:37.779457   543 layer_factory.hpp:77] Creating layer relu7_fixed
I0614 12:33:37.779464   543 net.cpp:94] Creating Layer relu7_fixed
I0614 12:33:37.779465   543 net.cpp:435] relu7_fixed <- relu7
I0614 12:33:37.779469   543 net.cpp:396] relu7_fixed -> relu7 (in-place)
I0614 12:33:37.779481   543 net.cpp:144] Setting up relu7_fixed
I0614 12:33:37.779484   543 net.cpp:151] Top shape: 10 4096 (40960)
I0614 12:33:37.779486   543 net.cpp:159] Memory required for data: 80345240
I0614 12:33:37.779489   543 layer_factory.hpp:77] Creating layer fc8
I0614 12:33:37.779495   543 net.cpp:94] Creating Layer fc8
I0614 12:33:37.779497   543 net.cpp:435] fc8 <- relu7
I0614 12:33:37.779501   543 net.cpp:409] fc8 -> fc8
I0614 12:33:37.779605   543 layer_factory.hpp:77] Creating layer fc8
I0614 12:33:37.779726   543 net.cpp:144] Setting up fc8
I0614 12:33:37.779731   543 net.cpp:151] Top shape: 10 2 (20)
I0614 12:33:37.779736   543 net.cpp:159] Memory required for data: 80345320
I0614 12:33:37.779742   543 layer_factory.hpp:77] Creating layer fc8_fixed
I0614 12:33:37.779747   543 net.cpp:94] Creating Layer fc8_fixed
I0614 12:33:37.779750   543 net.cpp:435] fc8_fixed <- fc8
I0614 12:33:37.779755   543 net.cpp:396] fc8_fixed -> fc8 (in-place)
I0614 12:33:37.779772   543 net.cpp:144] Setting up fc8_fixed
I0614 12:33:37.779775   543 net.cpp:151] Top shape: 10 2 (20)
I0614 12:33:37.779779   543 net.cpp:159] Memory required for data: 80345400
I0614 12:33:37.779783   543 layer_factory.hpp:77] Creating layer loss
I0614 12:33:37.779803   543 net.cpp:94] Creating Layer loss
I0614 12:33:37.779807   543 net.cpp:435] loss <- fc8
I0614 12:33:37.779810   543 net.cpp:435] loss <- label
I0614 12:33:37.779814   543 net.cpp:409] loss -> loss
I0614 12:33:37.779821   543 layer_factory.hpp:77] Creating layer loss
I0614 12:33:37.779861   543 net.cpp:144] Setting up loss
I0614 12:33:37.779865   543 net.cpp:151] Top shape: (1)
I0614 12:33:37.779868   543 net.cpp:154]     with loss weight 1
I0614 12:33:37.779879   543 net.cpp:159] Memory required for data: 80345404
I0614 12:33:37.779882   543 net.cpp:220] loss needs backward computation.
I0614 12:33:37.779886   543 net.cpp:220] fc8_fixed needs backward computation.
I0614 12:33:37.779889   543 net.cpp:220] fc8 needs backward computation.
I0614 12:33:37.779892   543 net.cpp:220] relu7_fixed needs backward computation.
I0614 12:33:37.779896   543 net.cpp:220] relu7 needs backward computation.
I0614 12:33:37.779898   543 net.cpp:220] fc7 needs backward computation.
I0614 12:33:37.779901   543 net.cpp:220] relu6_fixed needs backward computation.
I0614 12:33:37.779904   543 net.cpp:220] relu6 needs backward computation.
I0614 12:33:37.779908   543 net.cpp:220] fc6 needs backward computation.
I0614 12:33:37.779911   543 net.cpp:220] pool5_fixed needs backward computation.
I0614 12:33:37.779914   543 net.cpp:220] pool5 needs backward computation.
I0614 12:33:37.779917   543 net.cpp:220] relu5 needs backward computation.
I0614 12:33:37.779920   543 net.cpp:220] conv5 needs backward computation.
I0614 12:33:37.779924   543 net.cpp:220] relu4_fixed needs backward computation.
I0614 12:33:37.779927   543 net.cpp:220] relu4 needs backward computation.
I0614 12:33:37.779930   543 net.cpp:220] conv4 needs backward computation.
I0614 12:33:37.779934   543 net.cpp:220] relu3_fixed needs backward computation.
I0614 12:33:37.779937   543 net.cpp:220] relu3 needs backward computation.
I0614 12:33:37.779940   543 net.cpp:220] conv3 needs backward computation.
I0614 12:33:37.779943   543 net.cpp:220] pool2_fixed needs backward computation.
I0614 12:33:37.779947   543 net.cpp:220] pool2 needs backward computation.
I0614 12:33:37.779950   543 net.cpp:220] relu2 needs backward computation.
I0614 12:33:37.779953   543 net.cpp:220] conv2 needs backward computation.
I0614 12:33:37.779956   543 net.cpp:220] pool1_fixed needs backward computation.
I0614 12:33:37.779959   543 net.cpp:220] pool1 needs backward computation.
I0614 12:33:37.779963   543 net.cpp:220] relu1 needs backward computation.
I0614 12:33:37.779966   543 net.cpp:220] conv1 needs backward computation.
I0614 12:33:37.779969   543 net.cpp:222] data_fixed does not need backward computation.
I0614 12:33:37.779973   543 net.cpp:222] data does not need backward computation.
I0614 12:33:37.779975   543 net.cpp:264] This network produces output loss
I0614 12:33:37.779990   543 net.cpp:284] Network initialization done.
I0614 12:33:37.883412   543 net.cpp:323] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0614 12:33:37.883440   543 net.cpp:52] Initializing net from parameters: 
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_value: 106
    mean_value: 116
    mean_value: 124
  }
  data_param {
    source: "input/lmdb/valid_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "data_fixed"
  type: "FixedNeuron"
  bottom: "data"
  top: "data"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: OVER_FLOW
    bit_width: 8
    follow_data_layer: true
  }
}
layer {
  name: "conv1"
  type: "ConvolutionFixed"
  bottom: "data"
  top: "bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    bias_term: true
    pad: 0
    kernel_size: 8
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "bn1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "pool1_fixed"
  type: "FixedNeuron"
  bottom: "pool1"
  top: "pool1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "conv2"
  type: "ConvolutionFixed"
  bottom: "pool1"
  top: "bn2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 2
    kernel_size: 5
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "bn2"
  top: "relu2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "pool2_fixed"
  type: "FixedNeuron"
  bottom: "pool2"
  top: "pool2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "conv3"
  type: "ConvolutionFixed"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "relu3_fixed"
  type: "FixedNeuron"
  bottom: "relu3"
  top: "relu3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "conv4"
  type: "ConvolutionFixed"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "relu4_fixed"
  type: "FixedNeuron"
  bottom: "relu4"
  top: "relu4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "conv5"
  type: "ConvolutionFixed"
  bottom: "relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "pool5_fixed"
  type: "FixedNeuron"
  bottom: "pool5"
  top: "pool5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "fc6"
  type: "InnerProductFixed"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "relu6_fixed"
  type: "FixedNeuron"
  bottom: "relu6"
  top: "relu6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "fc7"
  type: "InnerProductFixed"
  bottom: "relu6"
  top: "bn7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    bias_term: true
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "bn7"
  top: "relu7"
}
layer {
  name: "relu7_fixed"
  type: "FixedNeuron"
  bottom: "relu7"
  top: "relu7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "fc8"
  type: "InnerProductFixed"
  bottom: "relu7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "fc8_fixed"
  type: "FixedNeuron"
  bottom: "fc8"
  top: "fc8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy-top1"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "top-1"
  include {
    phase: TEST
  }
}
I0614 12:33:37.883881   543 layer_factory.hpp:77] Creating layer data
I0614 12:33:37.883919   543 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0614 12:33:37.886004   543 net.cpp:94] Creating Layer data
I0614 12:33:37.886044   543 net.cpp:409] data -> data
I0614 12:33:37.886072   543 net.cpp:409] data -> label
I0614 12:33:37.886901   577 db_lmdb.cpp:35] Opened lmdb input/lmdb/valid_lmdb
I0614 12:33:37.886924   577 db_lmdb.cpp:38] Items count: 4000
I0614 12:33:37.886955   577 data_reader.cpp:124] TEST: reading data using 1 channel(s)
I0614 12:33:37.887213   543 data_layer.cpp:78] ReshapePrefetch 50, 3, 227, 227
I0614 12:33:37.887482   543 data_layer.cpp:83] output data size: 50,3,227,227
I0614 12:33:38.013212   543 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0614 12:33:38.013453   543 net.cpp:144] Setting up data
I0614 12:33:38.013463   543 net.cpp:151] Top shape: 50 3 227 227 (7729350)
I0614 12:33:38.013489   543 net.cpp:151] Top shape: 50 (50)
I0614 12:33:38.013495   543 net.cpp:159] Memory required for data: 30917600
I0614 12:33:38.013501   543 layer_factory.hpp:77] Creating layer label_data_1_split
I0614 12:33:38.013515   543 net.cpp:94] Creating Layer label_data_1_split
I0614 12:33:38.013520   543 net.cpp:435] label_data_1_split <- label
I0614 12:33:38.013527   543 net.cpp:409] label_data_1_split -> label_data_1_split_0
I0614 12:33:38.013536   543 net.cpp:409] label_data_1_split -> label_data_1_split_1
I0614 12:33:38.013540   543 net.cpp:409] label_data_1_split -> label_data_1_split_2
I0614 12:33:38.013597   543 net.cpp:144] Setting up label_data_1_split
I0614 12:33:38.013600   543 net.cpp:151] Top shape: 50 (50)
I0614 12:33:38.013604   543 net.cpp:151] Top shape: 50 (50)
I0614 12:33:38.013608   543 net.cpp:151] Top shape: 50 (50)
I0614 12:33:38.013612   543 net.cpp:159] Memory required for data: 30918200
I0614 12:33:38.013614   543 layer_factory.hpp:77] Creating layer data_fixed
I0614 12:33:38.013621   543 net.cpp:94] Creating Layer data_fixed
I0614 12:33:38.013624   543 net.cpp:435] data_fixed <- data
I0614 12:33:38.013629   543 net.cpp:396] data_fixed -> data (in-place)
I0614 12:33:38.013646   543 net.cpp:144] Setting up data_fixed
I0614 12:33:38.013650   543 net.cpp:151] Top shape: 50 3 227 227 (7729350)
I0614 12:33:38.013654   543 net.cpp:159] Memory required for data: 61835600
I0614 12:33:38.013662   543 layer_factory.hpp:77] Creating layer conv1
I0614 12:33:38.013674   543 net.cpp:94] Creating Layer conv1
I0614 12:33:38.013677   543 net.cpp:435] conv1 <- data
I0614 12:33:38.013682   543 net.cpp:409] conv1 -> bn1
I0614 12:33:38.014007   543 layer_factory.hpp:77] Creating layer conv1
I0614 12:33:38.014298   543 net.cpp:144] Setting up conv1
I0614 12:33:38.014304   543 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0614 12:33:38.014309   543 net.cpp:159] Memory required for data: 119915600
I0614 12:33:38.014317   543 layer_factory.hpp:77] Creating layer relu1
I0614 12:33:38.014322   543 net.cpp:94] Creating Layer relu1
I0614 12:33:38.014326   543 net.cpp:435] relu1 <- bn1
I0614 12:33:38.014330   543 net.cpp:409] relu1 -> relu1
I0614 12:33:38.014343   543 net.cpp:144] Setting up relu1
I0614 12:33:38.014345   543 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0614 12:33:38.014349   543 net.cpp:159] Memory required for data: 177995600
I0614 12:33:38.014353   543 layer_factory.hpp:77] Creating layer pool1
I0614 12:33:38.014358   543 net.cpp:94] Creating Layer pool1
I0614 12:33:38.014361   543 net.cpp:435] pool1 <- relu1
I0614 12:33:38.014365   543 net.cpp:409] pool1 -> pool1
I0614 12:33:38.014381   543 net.cpp:144] Setting up pool1
I0614 12:33:38.014384   543 net.cpp:151] Top shape: 50 96 27 27 (3499200)
I0614 12:33:38.014389   543 net.cpp:159] Memory required for data: 191992400
I0614 12:33:38.014391   543 layer_factory.hpp:77] Creating layer pool1_fixed
I0614 12:33:38.014396   543 net.cpp:94] Creating Layer pool1_fixed
I0614 12:33:38.014400   543 net.cpp:435] pool1_fixed <- pool1
I0614 12:33:38.014403   543 net.cpp:396] pool1_fixed -> pool1 (in-place)
I0614 12:33:38.014416   543 net.cpp:144] Setting up pool1_fixed
I0614 12:33:38.014420   543 net.cpp:151] Top shape: 50 96 27 27 (3499200)
I0614 12:33:38.014423   543 net.cpp:159] Memory required for data: 205989200
I0614 12:33:38.014427   543 layer_factory.hpp:77] Creating layer conv2
I0614 12:33:38.014434   543 net.cpp:94] Creating Layer conv2
I0614 12:33:38.014437   543 net.cpp:435] conv2 <- pool1
I0614 12:33:38.014442   543 net.cpp:409] conv2 -> bn2
I0614 12:33:38.020854   543 layer_factory.hpp:77] Creating layer conv2
I0614 12:33:38.032392   543 net.cpp:144] Setting up conv2
I0614 12:33:38.032410   543 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0614 12:33:38.032419   543 net.cpp:159] Memory required for data: 243314000
I0614 12:33:38.032429   543 layer_factory.hpp:77] Creating layer relu2
I0614 12:33:38.032439   543 net.cpp:94] Creating Layer relu2
I0614 12:33:38.032444   543 net.cpp:435] relu2 <- bn2
I0614 12:33:38.032450   543 net.cpp:409] relu2 -> relu2
I0614 12:33:38.032469   543 net.cpp:144] Setting up relu2
I0614 12:33:38.032472   543 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0614 12:33:38.032480   543 net.cpp:159] Memory required for data: 280638800
I0614 12:33:38.032485   543 layer_factory.hpp:77] Creating layer pool2
I0614 12:33:38.032493   543 net.cpp:94] Creating Layer pool2
I0614 12:33:38.032498   543 net.cpp:435] pool2 <- relu2
I0614 12:33:38.032505   543 net.cpp:409] pool2 -> pool2
I0614 12:33:38.032531   543 net.cpp:144] Setting up pool2
I0614 12:33:38.032537   543 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0614 12:33:38.032544   543 net.cpp:159] Memory required for data: 289291600
I0614 12:33:38.032548   543 layer_factory.hpp:77] Creating layer pool2_fixed
I0614 12:33:38.032557   543 net.cpp:94] Creating Layer pool2_fixed
I0614 12:33:38.032562   543 net.cpp:435] pool2_fixed <- pool2
I0614 12:33:38.032569   543 net.cpp:396] pool2_fixed -> pool2 (in-place)
I0614 12:33:38.032598   543 net.cpp:144] Setting up pool2_fixed
I0614 12:33:38.032601   543 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0614 12:33:38.032608   543 net.cpp:159] Memory required for data: 297944400
I0614 12:33:38.032613   543 layer_factory.hpp:77] Creating layer conv3
I0614 12:33:38.032626   543 net.cpp:94] Creating Layer conv3
I0614 12:33:38.032631   543 net.cpp:435] conv3 <- pool2
I0614 12:33:38.032641   543 net.cpp:409] conv3 -> conv3
I0614 12:33:38.043054   543 layer_factory.hpp:77] Creating layer conv3
I0614 12:33:38.052911   543 net.cpp:144] Setting up conv3
I0614 12:33:38.052930   543 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0614 12:33:38.052939   543 net.cpp:159] Memory required for data: 310923600
I0614 12:33:38.052949   543 layer_factory.hpp:77] Creating layer relu3
I0614 12:33:38.052958   543 net.cpp:94] Creating Layer relu3
I0614 12:33:38.052961   543 net.cpp:435] relu3 <- conv3
I0614 12:33:38.052968   543 net.cpp:409] relu3 -> relu3
I0614 12:33:38.052979   543 net.cpp:144] Setting up relu3
I0614 12:33:38.052982   543 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0614 12:33:38.052985   543 net.cpp:159] Memory required for data: 323902800
I0614 12:33:38.052989   543 layer_factory.hpp:77] Creating layer relu3_fixed
I0614 12:33:38.052994   543 net.cpp:94] Creating Layer relu3_fixed
I0614 12:33:38.052996   543 net.cpp:435] relu3_fixed <- relu3
I0614 12:33:38.053000   543 net.cpp:396] relu3_fixed -> relu3 (in-place)
I0614 12:33:38.053012   543 net.cpp:144] Setting up relu3_fixed
I0614 12:33:38.053015   543 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0614 12:33:38.053018   543 net.cpp:159] Memory required for data: 336882000
I0614 12:33:38.053021   543 layer_factory.hpp:77] Creating layer conv4
I0614 12:33:38.053030   543 net.cpp:94] Creating Layer conv4
I0614 12:33:38.053032   543 net.cpp:435] conv4 <- relu3
I0614 12:33:38.053035   543 net.cpp:409] conv4 -> conv4
I0614 12:33:38.067070   543 layer_factory.hpp:77] Creating layer conv4
I0614 12:33:38.082947   543 net.cpp:144] Setting up conv4
I0614 12:33:38.082988   543 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0614 12:33:38.083005   543 net.cpp:159] Memory required for data: 349861200
I0614 12:33:38.083019   543 layer_factory.hpp:77] Creating layer relu4
I0614 12:33:38.083031   543 net.cpp:94] Creating Layer relu4
I0614 12:33:38.083040   543 net.cpp:435] relu4 <- conv4
I0614 12:33:38.083050   543 net.cpp:409] relu4 -> relu4
I0614 12:33:38.083083   543 net.cpp:144] Setting up relu4
I0614 12:33:38.083087   543 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0614 12:33:38.083094   543 net.cpp:159] Memory required for data: 362840400
I0614 12:33:38.083099   543 layer_factory.hpp:77] Creating layer relu4_fixed
I0614 12:33:38.083110   543 net.cpp:94] Creating Layer relu4_fixed
I0614 12:33:38.083115   543 net.cpp:435] relu4_fixed <- relu4
I0614 12:33:38.083122   543 net.cpp:396] relu4_fixed -> relu4 (in-place)
I0614 12:33:38.083148   543 net.cpp:144] Setting up relu4_fixed
I0614 12:33:38.083153   543 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0614 12:33:38.083158   543 net.cpp:159] Memory required for data: 375819600
I0614 12:33:38.083164   543 layer_factory.hpp:77] Creating layer conv5
I0614 12:33:38.083178   543 net.cpp:94] Creating Layer conv5
I0614 12:33:38.083181   543 net.cpp:435] conv5 <- relu4
I0614 12:33:38.083189   543 net.cpp:409] conv5 -> conv5
I0614 12:33:38.093142   543 layer_factory.hpp:77] Creating layer conv5
I0614 12:33:38.103549   543 net.cpp:144] Setting up conv5
I0614 12:33:38.103567   543 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0614 12:33:38.103575   543 net.cpp:159] Memory required for data: 384472400
I0614 12:33:38.103585   543 layer_factory.hpp:77] Creating layer relu5
I0614 12:33:38.103592   543 net.cpp:94] Creating Layer relu5
I0614 12:33:38.103596   543 net.cpp:435] relu5 <- conv5
I0614 12:33:38.103601   543 net.cpp:409] relu5 -> relu5
I0614 12:33:38.103614   543 net.cpp:144] Setting up relu5
I0614 12:33:38.103617   543 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0614 12:33:38.103621   543 net.cpp:159] Memory required for data: 393125200
I0614 12:33:38.103623   543 layer_factory.hpp:77] Creating layer pool5
I0614 12:33:38.103627   543 net.cpp:94] Creating Layer pool5
I0614 12:33:38.103631   543 net.cpp:435] pool5 <- relu5
I0614 12:33:38.103634   543 net.cpp:409] pool5 -> pool5
I0614 12:33:38.103647   543 net.cpp:144] Setting up pool5
I0614 12:33:38.103649   543 net.cpp:151] Top shape: 50 256 6 6 (460800)
I0614 12:33:38.103653   543 net.cpp:159] Memory required for data: 394968400
I0614 12:33:38.103655   543 layer_factory.hpp:77] Creating layer pool5_fixed
I0614 12:33:38.103677   543 net.cpp:94] Creating Layer pool5_fixed
I0614 12:33:38.103679   543 net.cpp:435] pool5_fixed <- pool5
I0614 12:33:38.103683   543 net.cpp:396] pool5_fixed -> pool5 (in-place)
I0614 12:33:38.103698   543 net.cpp:144] Setting up pool5_fixed
I0614 12:33:38.103700   543 net.cpp:151] Top shape: 50 256 6 6 (460800)
I0614 12:33:38.103704   543 net.cpp:159] Memory required for data: 396811600
I0614 12:33:38.103708   543 layer_factory.hpp:77] Creating layer fc6
I0614 12:33:38.103714   543 net.cpp:94] Creating Layer fc6
I0614 12:33:38.103718   543 net.cpp:435] fc6 <- pool5
I0614 12:33:38.103721   543 net.cpp:409] fc6 -> fc6
I0614 12:33:38.426295   543 layer_factory.hpp:77] Creating layer fc6
I0614 12:33:38.748303   543 net.cpp:144] Setting up fc6
I0614 12:33:38.748330   543 net.cpp:151] Top shape: 50 4096 (204800)
I0614 12:33:38.748339   543 net.cpp:159] Memory required for data: 397630800
I0614 12:33:38.748350   543 layer_factory.hpp:77] Creating layer relu6
I0614 12:33:38.748358   543 net.cpp:94] Creating Layer relu6
I0614 12:33:38.748361   543 net.cpp:435] relu6 <- fc6
I0614 12:33:38.748368   543 net.cpp:409] relu6 -> relu6
I0614 12:33:38.748382   543 net.cpp:144] Setting up relu6
I0614 12:33:38.748385   543 net.cpp:151] Top shape: 50 4096 (204800)
I0614 12:33:38.748389   543 net.cpp:159] Memory required for data: 398450000
I0614 12:33:38.748390   543 layer_factory.hpp:77] Creating layer relu6_fixed
I0614 12:33:38.748397   543 net.cpp:94] Creating Layer relu6_fixed
I0614 12:33:38.748399   543 net.cpp:435] relu6_fixed <- relu6
I0614 12:33:38.748404   543 net.cpp:396] relu6_fixed -> relu6 (in-place)
I0614 12:33:38.748418   543 net.cpp:144] Setting up relu6_fixed
I0614 12:33:38.748420   543 net.cpp:151] Top shape: 50 4096 (204800)
I0614 12:33:38.748425   543 net.cpp:159] Memory required for data: 399269200
I0614 12:33:38.748427   543 layer_factory.hpp:77] Creating layer fc7
I0614 12:33:38.748435   543 net.cpp:94] Creating Layer fc7
I0614 12:33:38.748437   543 net.cpp:435] fc7 <- relu6
I0614 12:33:38.748441   543 net.cpp:409] fc7 -> bn7
I0614 12:33:38.889650   543 layer_factory.hpp:77] Creating layer fc7
I0614 12:33:39.031711   543 net.cpp:144] Setting up fc7
I0614 12:33:39.031738   543 net.cpp:151] Top shape: 50 4096 (204800)
I0614 12:33:39.031745   543 net.cpp:159] Memory required for data: 400088400
I0614 12:33:39.031754   543 layer_factory.hpp:77] Creating layer relu7
I0614 12:33:39.031761   543 net.cpp:94] Creating Layer relu7
I0614 12:33:39.031765   543 net.cpp:435] relu7 <- bn7
I0614 12:33:39.031771   543 net.cpp:409] relu7 -> relu7
I0614 12:33:39.031786   543 net.cpp:144] Setting up relu7
I0614 12:33:39.031790   543 net.cpp:151] Top shape: 50 4096 (204800)
I0614 12:33:39.031792   543 net.cpp:159] Memory required for data: 400907600
I0614 12:33:39.031795   543 layer_factory.hpp:77] Creating layer relu7_fixed
I0614 12:33:39.031802   543 net.cpp:94] Creating Layer relu7_fixed
I0614 12:33:39.031805   543 net.cpp:435] relu7_fixed <- relu7
I0614 12:33:39.031808   543 net.cpp:396] relu7_fixed -> relu7 (in-place)
I0614 12:33:39.031822   543 net.cpp:144] Setting up relu7_fixed
I0614 12:33:39.031824   543 net.cpp:151] Top shape: 50 4096 (204800)
I0614 12:33:39.031828   543 net.cpp:159] Memory required for data: 401726800
I0614 12:33:39.031831   543 layer_factory.hpp:77] Creating layer fc8
I0614 12:33:39.031838   543 net.cpp:94] Creating Layer fc8
I0614 12:33:39.031841   543 net.cpp:435] fc8 <- relu7
I0614 12:33:39.031845   543 net.cpp:409] fc8 -> fc8
I0614 12:33:39.031935   543 layer_factory.hpp:77] Creating layer fc8
I0614 12:33:39.032063   543 net.cpp:144] Setting up fc8
I0614 12:33:39.032065   543 net.cpp:151] Top shape: 50 2 (100)
I0614 12:33:39.032069   543 net.cpp:159] Memory required for data: 401727200
I0614 12:33:39.032073   543 layer_factory.hpp:77] Creating layer fc8_fixed
I0614 12:33:39.032078   543 net.cpp:94] Creating Layer fc8_fixed
I0614 12:33:39.032081   543 net.cpp:435] fc8_fixed <- fc8
I0614 12:33:39.032085   543 net.cpp:396] fc8_fixed -> fc8 (in-place)
I0614 12:33:39.032099   543 net.cpp:144] Setting up fc8_fixed
I0614 12:33:39.032100   543 net.cpp:151] Top shape: 50 2 (100)
I0614 12:33:39.032104   543 net.cpp:159] Memory required for data: 401727600
I0614 12:33:39.032107   543 layer_factory.hpp:77] Creating layer fc8_fc8_fixed_0_split
I0614 12:33:39.032114   543 net.cpp:94] Creating Layer fc8_fc8_fixed_0_split
I0614 12:33:39.032115   543 net.cpp:435] fc8_fc8_fixed_0_split <- fc8
I0614 12:33:39.032119   543 net.cpp:409] fc8_fc8_fixed_0_split -> fc8_fc8_fixed_0_split_0
I0614 12:33:39.032124   543 net.cpp:409] fc8_fc8_fixed_0_split -> fc8_fc8_fixed_0_split_1
I0614 12:33:39.032130   543 net.cpp:409] fc8_fc8_fixed_0_split -> fc8_fc8_fixed_0_split_2
I0614 12:33:39.032162   543 net.cpp:144] Setting up fc8_fc8_fixed_0_split
I0614 12:33:39.032166   543 net.cpp:151] Top shape: 50 2 (100)
I0614 12:33:39.032169   543 net.cpp:151] Top shape: 50 2 (100)
I0614 12:33:39.032172   543 net.cpp:151] Top shape: 50 2 (100)
I0614 12:33:39.032176   543 net.cpp:159] Memory required for data: 401728800
I0614 12:33:39.032179   543 layer_factory.hpp:77] Creating layer accuracy
I0614 12:33:39.032186   543 net.cpp:94] Creating Layer accuracy
I0614 12:33:39.032189   543 net.cpp:435] accuracy <- fc8_fc8_fixed_0_split_0
I0614 12:33:39.032193   543 net.cpp:435] accuracy <- label_data_1_split_0
I0614 12:33:39.032197   543 net.cpp:409] accuracy -> accuracy
I0614 12:33:39.032203   543 net.cpp:144] Setting up accuracy
I0614 12:33:39.032207   543 net.cpp:151] Top shape: (1)
I0614 12:33:39.032209   543 net.cpp:159] Memory required for data: 401728804
I0614 12:33:39.032212   543 layer_factory.hpp:77] Creating layer loss
I0614 12:33:39.032217   543 net.cpp:94] Creating Layer loss
I0614 12:33:39.032222   543 net.cpp:435] loss <- fc8_fc8_fixed_0_split_1
I0614 12:33:39.032224   543 net.cpp:435] loss <- label_data_1_split_1
I0614 12:33:39.032228   543 net.cpp:409] loss -> loss
I0614 12:33:39.032235   543 layer_factory.hpp:77] Creating layer loss
I0614 12:33:39.032274   543 net.cpp:144] Setting up loss
I0614 12:33:39.032279   543 net.cpp:151] Top shape: (1)
I0614 12:33:39.032281   543 net.cpp:154]     with loss weight 1
I0614 12:33:39.032294   543 net.cpp:159] Memory required for data: 401728808
I0614 12:33:39.032297   543 layer_factory.hpp:77] Creating layer accuracy-top1
I0614 12:33:39.032303   543 net.cpp:94] Creating Layer accuracy-top1
I0614 12:33:39.032307   543 net.cpp:435] accuracy-top1 <- fc8_fc8_fixed_0_split_2
I0614 12:33:39.032310   543 net.cpp:435] accuracy-top1 <- label_data_1_split_2
I0614 12:33:39.032315   543 net.cpp:409] accuracy-top1 -> top-1
I0614 12:33:39.032320   543 net.cpp:144] Setting up accuracy-top1
I0614 12:33:39.032322   543 net.cpp:151] Top shape: (1)
I0614 12:33:39.032326   543 net.cpp:159] Memory required for data: 401728812
I0614 12:33:39.032330   543 net.cpp:222] accuracy-top1 does not need backward computation.
I0614 12:33:39.032333   543 net.cpp:220] loss needs backward computation.
I0614 12:33:39.032336   543 net.cpp:222] accuracy does not need backward computation.
I0614 12:33:39.032341   543 net.cpp:220] fc8_fc8_fixed_0_split needs backward computation.
I0614 12:33:39.032343   543 net.cpp:220] fc8_fixed needs backward computation.
I0614 12:33:39.032346   543 net.cpp:220] fc8 needs backward computation.
I0614 12:33:39.032349   543 net.cpp:220] relu7_fixed needs backward computation.
I0614 12:33:39.032352   543 net.cpp:220] relu7 needs backward computation.
I0614 12:33:39.032356   543 net.cpp:220] fc7 needs backward computation.
I0614 12:33:39.032358   543 net.cpp:220] relu6_fixed needs backward computation.
I0614 12:33:39.032362   543 net.cpp:220] relu6 needs backward computation.
I0614 12:33:39.032366   543 net.cpp:220] fc6 needs backward computation.
I0614 12:33:39.032368   543 net.cpp:220] pool5_fixed needs backward computation.
I0614 12:33:39.032371   543 net.cpp:220] pool5 needs backward computation.
I0614 12:33:39.032374   543 net.cpp:220] relu5 needs backward computation.
I0614 12:33:39.032378   543 net.cpp:220] conv5 needs backward computation.
I0614 12:33:39.032382   543 net.cpp:220] relu4_fixed needs backward computation.
I0614 12:33:39.032384   543 net.cpp:220] relu4 needs backward computation.
I0614 12:33:39.032387   543 net.cpp:220] conv4 needs backward computation.
I0614 12:33:39.032392   543 net.cpp:220] relu3_fixed needs backward computation.
I0614 12:33:39.032394   543 net.cpp:220] relu3 needs backward computation.
I0614 12:33:39.032397   543 net.cpp:220] conv3 needs backward computation.
I0614 12:33:39.032400   543 net.cpp:220] pool2_fixed needs backward computation.
I0614 12:33:39.032403   543 net.cpp:220] pool2 needs backward computation.
I0614 12:33:39.032407   543 net.cpp:220] relu2 needs backward computation.
I0614 12:33:39.032410   543 net.cpp:220] conv2 needs backward computation.
I0614 12:33:39.032413   543 net.cpp:220] pool1_fixed needs backward computation.
I0614 12:33:39.032416   543 net.cpp:220] pool1 needs backward computation.
I0614 12:33:39.032420   543 net.cpp:220] relu1 needs backward computation.
I0614 12:33:39.032423   543 net.cpp:220] conv1 needs backward computation.
I0614 12:33:39.032428   543 net.cpp:222] data_fixed does not need backward computation.
I0614 12:33:39.032431   543 net.cpp:222] label_data_1_split does not need backward computation.
I0614 12:33:39.032434   543 net.cpp:222] data does not need backward computation.
I0614 12:33:39.032438   543 net.cpp:264] This network produces output accuracy
I0614 12:33:39.032441   543 net.cpp:264] This network produces output loss
I0614 12:33:39.032444   543 net.cpp:264] This network produces output top-1
I0614 12:33:39.032461   543 net.cpp:284] Network initialization done.
I0614 12:33:39.065914   543 net_test.cpp:431] Net type: other
I0614 12:33:39.065928   543 net_test.cpp:439] Test Start, total iterations: 50
I0614 12:33:39.065933   543 net_test.cpp:372] Testing ...
I0614 12:33:39.161741   543 net_test.cpp:394] Test iter: 1/50, accuracy = 0.94
I0614 12:33:39.161762   543 net_test.cpp:394] Test iter: 1/50, loss = 0.304217
I0614 12:33:39.161767   543 net_test.cpp:394] Test iter: 1/50, top-1 = 0.94
I0614 12:33:39.213680   543 net_test.cpp:394] Test iter: 2/50, accuracy = 0.96
I0614 12:33:39.213701   543 net_test.cpp:394] Test iter: 2/50, loss = 0.216499
I0614 12:33:39.213704   543 net_test.cpp:394] Test iter: 2/50, top-1 = 0.96
I0614 12:33:39.265306   543 net_test.cpp:394] Test iter: 3/50, accuracy = 0.98
I0614 12:33:39.265327   543 net_test.cpp:394] Test iter: 3/50, loss = 0.0218349
I0614 12:33:39.265331   543 net_test.cpp:394] Test iter: 3/50, top-1 = 0.98
I0614 12:33:39.317238   543 net_test.cpp:394] Test iter: 4/50, accuracy = 0.96
I0614 12:33:39.317257   543 net_test.cpp:394] Test iter: 4/50, loss = 0.26224
I0614 12:33:39.317261   543 net_test.cpp:394] Test iter: 4/50, top-1 = 0.96
I0614 12:33:39.369522   543 net_test.cpp:394] Test iter: 5/50, accuracy = 0.94
I0614 12:33:39.369541   543 net_test.cpp:394] Test iter: 5/50, loss = 0.17931
I0614 12:33:39.369545   543 net_test.cpp:394] Test iter: 5/50, top-1 = 0.94
I0614 12:33:39.421818   543 net_test.cpp:394] Test iter: 6/50, accuracy = 0.94
I0614 12:33:39.421837   543 net_test.cpp:394] Test iter: 6/50, loss = 0.111201
I0614 12:33:39.421841   543 net_test.cpp:394] Test iter: 6/50, top-1 = 0.94
I0614 12:33:39.473853   543 net_test.cpp:394] Test iter: 7/50, accuracy = 0.98
I0614 12:33:39.473874   543 net_test.cpp:394] Test iter: 7/50, loss = 0.0324087
I0614 12:33:39.473877   543 net_test.cpp:394] Test iter: 7/50, top-1 = 0.98
I0614 12:33:39.526242   543 net_test.cpp:394] Test iter: 8/50, accuracy = 0.96
I0614 12:33:39.526262   543 net_test.cpp:394] Test iter: 8/50, loss = 0.179867
I0614 12:33:39.526266   543 net_test.cpp:394] Test iter: 8/50, top-1 = 0.96
I0614 12:33:39.578161   543 net_test.cpp:394] Test iter: 9/50, accuracy = 1
I0614 12:33:39.578181   543 net_test.cpp:394] Test iter: 9/50, loss = 0.0287515
I0614 12:33:39.578184   543 net_test.cpp:394] Test iter: 9/50, top-1 = 1
I0614 12:33:39.630275   543 net_test.cpp:394] Test iter: 10/50, accuracy = 0.98
I0614 12:33:39.630295   543 net_test.cpp:394] Test iter: 10/50, loss = 0.060113
I0614 12:33:39.630298   543 net_test.cpp:394] Test iter: 10/50, top-1 = 0.98
I0614 12:33:39.682400   543 net_test.cpp:394] Test iter: 11/50, accuracy = 0.98
I0614 12:33:39.682420   543 net_test.cpp:394] Test iter: 11/50, loss = 0.0827074
I0614 12:33:39.682425   543 net_test.cpp:394] Test iter: 11/50, top-1 = 0.98
I0614 12:33:39.734412   543 net_test.cpp:394] Test iter: 12/50, accuracy = 1
I0614 12:33:39.734431   543 net_test.cpp:394] Test iter: 12/50, loss = 0.0121505
I0614 12:33:39.734436   543 net_test.cpp:394] Test iter: 12/50, top-1 = 1
I0614 12:33:39.786288   543 net_test.cpp:394] Test iter: 13/50, accuracy = 0.9
I0614 12:33:39.786309   543 net_test.cpp:394] Test iter: 13/50, loss = 0.300935
I0614 12:33:39.786314   543 net_test.cpp:394] Test iter: 13/50, top-1 = 0.9
I0614 12:33:39.838294   543 net_test.cpp:394] Test iter: 14/50, accuracy = 0.96
I0614 12:33:39.838315   543 net_test.cpp:394] Test iter: 14/50, loss = 0.13142
I0614 12:33:39.838317   543 net_test.cpp:394] Test iter: 14/50, top-1 = 0.96
I0614 12:33:39.890354   543 net_test.cpp:394] Test iter: 15/50, accuracy = 0.98
I0614 12:33:39.890374   543 net_test.cpp:394] Test iter: 15/50, loss = 0.147272
I0614 12:33:39.890378   543 net_test.cpp:394] Test iter: 15/50, top-1 = 0.98
I0614 12:33:39.942493   543 net_test.cpp:394] Test iter: 16/50, accuracy = 0.96
I0614 12:33:39.942513   543 net_test.cpp:394] Test iter: 16/50, loss = 0.239897
I0614 12:33:39.942517   543 net_test.cpp:394] Test iter: 16/50, top-1 = 0.96
I0614 12:33:39.994238   543 net_test.cpp:394] Test iter: 17/50, accuracy = 0.98
I0614 12:33:39.994259   543 net_test.cpp:394] Test iter: 17/50, loss = 0.0470741
I0614 12:33:39.994263   543 net_test.cpp:394] Test iter: 17/50, top-1 = 0.98
I0614 12:33:40.046595   543 net_test.cpp:394] Test iter: 18/50, accuracy = 0.96
I0614 12:33:40.046615   543 net_test.cpp:394] Test iter: 18/50, loss = 0.136568
I0614 12:33:40.046619   543 net_test.cpp:394] Test iter: 18/50, top-1 = 0.96
I0614 12:33:40.098930   543 net_test.cpp:394] Test iter: 19/50, accuracy = 0.94
I0614 12:33:40.098951   543 net_test.cpp:394] Test iter: 19/50, loss = 0.104174
I0614 12:33:40.098955   543 net_test.cpp:394] Test iter: 19/50, top-1 = 0.94
I0614 12:33:40.151083   543 net_test.cpp:394] Test iter: 20/50, accuracy = 0.96
I0614 12:33:40.151103   543 net_test.cpp:394] Test iter: 20/50, loss = 0.107409
I0614 12:33:40.151106   543 net_test.cpp:394] Test iter: 20/50, top-1 = 0.96
I0614 12:33:40.202888   543 net_test.cpp:394] Test iter: 21/50, accuracy = 1
I0614 12:33:40.202908   543 net_test.cpp:394] Test iter: 21/50, loss = 0.00509182
I0614 12:33:40.202911   543 net_test.cpp:394] Test iter: 21/50, top-1 = 1
I0614 12:33:40.254750   543 net_test.cpp:394] Test iter: 22/50, accuracy = 0.96
I0614 12:33:40.254770   543 net_test.cpp:394] Test iter: 22/50, loss = 0.100918
I0614 12:33:40.254774   543 net_test.cpp:394] Test iter: 22/50, top-1 = 0.96
I0614 12:33:40.307016   543 net_test.cpp:394] Test iter: 23/50, accuracy = 0.96
I0614 12:33:40.307037   543 net_test.cpp:394] Test iter: 23/50, loss = 0.139588
I0614 12:33:40.307040   543 net_test.cpp:394] Test iter: 23/50, top-1 = 0.96
I0614 12:33:40.359015   543 net_test.cpp:394] Test iter: 24/50, accuracy = 0.92
I0614 12:33:40.359036   543 net_test.cpp:394] Test iter: 24/50, loss = 0.255835
I0614 12:33:40.359040   543 net_test.cpp:394] Test iter: 24/50, top-1 = 0.92
I0614 12:33:40.410883   543 net_test.cpp:394] Test iter: 25/50, accuracy = 0.94
I0614 12:33:40.410904   543 net_test.cpp:394] Test iter: 25/50, loss = 0.346991
I0614 12:33:40.410907   543 net_test.cpp:394] Test iter: 25/50, top-1 = 0.94
I0614 12:33:40.462865   543 net_test.cpp:394] Test iter: 26/50, accuracy = 0.94
I0614 12:33:40.462886   543 net_test.cpp:394] Test iter: 26/50, loss = 0.257136
I0614 12:33:40.462890   543 net_test.cpp:394] Test iter: 26/50, top-1 = 0.94
I0614 12:33:40.514856   543 net_test.cpp:394] Test iter: 27/50, accuracy = 0.96
I0614 12:33:40.514876   543 net_test.cpp:394] Test iter: 27/50, loss = 0.0624552
I0614 12:33:40.514880   543 net_test.cpp:394] Test iter: 27/50, top-1 = 0.96
I0614 12:33:40.566582   543 net_test.cpp:394] Test iter: 28/50, accuracy = 0.84
I0614 12:33:40.566603   543 net_test.cpp:394] Test iter: 28/50, loss = 0.330787
I0614 12:33:40.566606   543 net_test.cpp:394] Test iter: 28/50, top-1 = 0.84
I0614 12:33:40.618669   543 net_test.cpp:394] Test iter: 29/50, accuracy = 0.92
I0614 12:33:40.618688   543 net_test.cpp:394] Test iter: 29/50, loss = 0.355648
I0614 12:33:40.618692   543 net_test.cpp:394] Test iter: 29/50, top-1 = 0.92
I0614 12:33:40.670531   543 net_test.cpp:394] Test iter: 30/50, accuracy = 0.98
I0614 12:33:40.670552   543 net_test.cpp:394] Test iter: 30/50, loss = 0.0376615
I0614 12:33:40.670557   543 net_test.cpp:394] Test iter: 30/50, top-1 = 0.98
I0614 12:33:40.722436   543 net_test.cpp:394] Test iter: 31/50, accuracy = 0.98
I0614 12:33:40.722457   543 net_test.cpp:394] Test iter: 31/50, loss = 0.0912607
I0614 12:33:40.722460   543 net_test.cpp:394] Test iter: 31/50, top-1 = 0.98
I0614 12:33:40.774413   543 net_test.cpp:394] Test iter: 32/50, accuracy = 0.94
I0614 12:33:40.774433   543 net_test.cpp:394] Test iter: 32/50, loss = 0.192373
I0614 12:33:40.774437   543 net_test.cpp:394] Test iter: 32/50, top-1 = 0.94
I0614 12:33:40.826391   543 net_test.cpp:394] Test iter: 33/50, accuracy = 0.92
I0614 12:33:40.826412   543 net_test.cpp:394] Test iter: 33/50, loss = 0.215591
I0614 12:33:40.826416   543 net_test.cpp:394] Test iter: 33/50, top-1 = 0.92
I0614 12:33:40.878221   543 net_test.cpp:394] Test iter: 34/50, accuracy = 0.98
I0614 12:33:40.878242   543 net_test.cpp:394] Test iter: 34/50, loss = 0.0310834
I0614 12:33:40.878245   543 net_test.cpp:394] Test iter: 34/50, top-1 = 0.98
I0614 12:33:40.930241   543 net_test.cpp:394] Test iter: 35/50, accuracy = 0.98
I0614 12:33:40.930260   543 net_test.cpp:394] Test iter: 35/50, loss = 0.133773
I0614 12:33:40.930264   543 net_test.cpp:394] Test iter: 35/50, top-1 = 0.98
I0614 12:33:40.982385   543 net_test.cpp:394] Test iter: 36/50, accuracy = 0.92
I0614 12:33:40.982405   543 net_test.cpp:394] Test iter: 36/50, loss = 0.206623
I0614 12:33:40.982409   543 net_test.cpp:394] Test iter: 36/50, top-1 = 0.92
I0614 12:33:41.034148   543 net_test.cpp:394] Test iter: 37/50, accuracy = 0.98
I0614 12:33:41.034168   543 net_test.cpp:394] Test iter: 37/50, loss = 0.0500092
I0614 12:33:41.034171   543 net_test.cpp:394] Test iter: 37/50, top-1 = 0.98
I0614 12:33:41.086243   543 net_test.cpp:394] Test iter: 38/50, accuracy = 0.92
I0614 12:33:41.086263   543 net_test.cpp:394] Test iter: 38/50, loss = 0.406247
I0614 12:33:41.086266   543 net_test.cpp:394] Test iter: 38/50, top-1 = 0.92
I0614 12:33:41.138300   543 net_test.cpp:394] Test iter: 39/50, accuracy = 0.96
I0614 12:33:41.138320   543 net_test.cpp:394] Test iter: 39/50, loss = 0.225001
I0614 12:33:41.138324   543 net_test.cpp:394] Test iter: 39/50, top-1 = 0.96
I0614 12:33:41.190438   543 net_test.cpp:394] Test iter: 40/50, accuracy = 0.94
I0614 12:33:41.190459   543 net_test.cpp:394] Test iter: 40/50, loss = 0.184419
I0614 12:33:41.190462   543 net_test.cpp:394] Test iter: 40/50, top-1 = 0.94
I0614 12:33:41.242406   543 net_test.cpp:394] Test iter: 41/50, accuracy = 0.96
I0614 12:33:41.242425   543 net_test.cpp:394] Test iter: 41/50, loss = 0.149653
I0614 12:33:41.242429   543 net_test.cpp:394] Test iter: 41/50, top-1 = 0.96
I0614 12:33:41.294256   543 net_test.cpp:394] Test iter: 42/50, accuracy = 0.94
I0614 12:33:41.294276   543 net_test.cpp:394] Test iter: 42/50, loss = 0.237425
I0614 12:33:41.294279   543 net_test.cpp:394] Test iter: 42/50, top-1 = 0.94
I0614 12:33:41.346279   543 net_test.cpp:394] Test iter: 43/50, accuracy = 0.98
I0614 12:33:41.346300   543 net_test.cpp:394] Test iter: 43/50, loss = 0.0693205
I0614 12:33:41.346303   543 net_test.cpp:394] Test iter: 43/50, top-1 = 0.98
I0614 12:33:41.398310   543 net_test.cpp:394] Test iter: 44/50, accuracy = 0.9
I0614 12:33:41.398331   543 net_test.cpp:394] Test iter: 44/50, loss = 0.285648
I0614 12:33:41.398334   543 net_test.cpp:394] Test iter: 44/50, top-1 = 0.9
I0614 12:33:41.449939   543 net_test.cpp:394] Test iter: 45/50, accuracy = 1
I0614 12:33:41.449959   543 net_test.cpp:394] Test iter: 45/50, loss = 0.0240499
I0614 12:33:41.449963   543 net_test.cpp:394] Test iter: 45/50, top-1 = 1
I0614 12:33:41.501839   543 net_test.cpp:394] Test iter: 46/50, accuracy = 0.98
I0614 12:33:41.501860   543 net_test.cpp:394] Test iter: 46/50, loss = 0.020409
I0614 12:33:41.501864   543 net_test.cpp:394] Test iter: 46/50, top-1 = 0.98
I0614 12:33:41.553882   543 net_test.cpp:394] Test iter: 47/50, accuracy = 0.92
I0614 12:33:41.553901   543 net_test.cpp:394] Test iter: 47/50, loss = 0.256547
I0614 12:33:41.553905   543 net_test.cpp:394] Test iter: 47/50, top-1 = 0.92
I0614 12:33:41.605654   543 net_test.cpp:394] Test iter: 48/50, accuracy = 0.92
I0614 12:33:41.605674   543 net_test.cpp:394] Test iter: 48/50, loss = 0.372481
I0614 12:33:41.605677   543 net_test.cpp:394] Test iter: 48/50, top-1 = 0.92
I0614 12:33:41.657599   543 net_test.cpp:394] Test iter: 49/50, accuracy = 0.96
I0614 12:33:41.657618   543 net_test.cpp:394] Test iter: 49/50, loss = 0.242918
I0614 12:33:41.657621   543 net_test.cpp:394] Test iter: 49/50, top-1 = 0.96
I0614 12:33:41.709542   543 net_test.cpp:394] Test iter: 50/50, accuracy = 0.94
I0614 12:33:41.709561   543 net_test.cpp:394] Test iter: 50/50, loss = 0.203777
I0614 12:33:41.709565   543 net_test.cpp:394] Test iter: 50/50, top-1 = 0.94
I0614 12:33:41.709569   543 net_test.cpp:405] Test Results: 
I0614 12:33:41.709571   543 net_test.cpp:406] Loss: 0.163935
I0614 12:33:41.709575   543 net_test.cpp:421] accuracy = 0.954
I0614 12:33:41.709583   543 net_test.cpp:421] loss = 0.163935 (* 1 = 0.163935 loss)
I0614 12:33:41.709586   543 net_test.cpp:421] top-1 = 0.954
I0614 12:33:41.709589   543 net_test.cpp:450] Test Done!
I0614 12:33:41.889211   543 vai_q.cpp:360] Start Deploy
I0614 12:33:42.735085   543 vai_q.cpp:368] Deploy Done!
--------------------------------------------------
Output Quantized Train&Test Model:   "/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/deploy/alexnetBNnoLRN/quantiz/vaiq_output/quantize_train_test.prototxt"
Output Quantized Train&Test Weights: "/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/deploy/alexnetBNnoLRN/quantiz/vaiq_output/quantize_train_test.caffemodel"
Output Deploy Weights: "/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/deploy/alexnetBNnoLRN/quantiz/vaiq_output/deploy.caffemodel"
Output Deploy Model:   "/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/deploy/alexnetBNnoLRN/quantiz/vaiq_output/deploy.prototxt"
Compiling network: alexnetBNnoLRN for ZCU102
[INFO] Namespace(batchsize=1, inputs_shape=None, layout='NCHW', model_files=['/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/deploy/alexnetBNnoLRN/quantiz/vaiq_output/deploy.caffemodel'], model_type='caffe', named_inputs_shape=None, out_filename='/tmp/alexnetBNnoLRN_org.xmodel', proto='/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/deploy/alexnetBNnoLRN/quantiz/vaiq_output/deploy.prototxt')
[INFO] caffe model: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/deploy/alexnetBNnoLRN/quantiz/vaiq_output/deploy.caffemodel
[INFO] caffe model: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/deploy/alexnetBNnoLRN/quantiz/vaiq_output/deploy.prototxt
[INFO] parse raw model     :  0%|          | 0/29 [00:00<?, ?it/s]                           [INFO] parse raw model     : 24%|âââ       | 7/29 [00:00<00:00, 39.61it/s]                   [INFO] parse raw model     : 38%|ââââ      | 11/29 [00:00<00:00, 23.92it/s]                  [INFO] parse raw model     : 48%|âââââ     | 14/29 [00:00<00:01, 14.77it/s]                  [INFO] parse raw model     : 59%|ââââââ    | 17/29 [00:01<00:00, 13.95it/s]                  [INFO] parse raw model     : 72%|ââââââââ  | 21/29 [00:10<00:07,  1.03it/s]                  [INFO] parse raw model     : 83%|âââââââââ | 24/29 [00:15<00:05,  1.12s/it]                  [INFO] parse raw model     :100%|ââââââââââ| 29/29 [00:15<00:00,  1.89it/s]                  
[INFO] infer shape (NCHW)  :  0%|          | 0/29 [00:00<?, ?it/s]                           [INFO] infer shape (NCHW)  :100%|ââââââââââ| 29/29 [00:00<00:00, 17366.48it/s]               
[INFO] infer shape (NHWC)  :  0%|          | 0/29 [00:00<?, ?it/s]                           [INFO] infer shape (NHWC)  :100%|ââââââââââ| 29/29 [00:00<00:00, 561.76it/s]                 
[INFO] perform level-1 opt :  0%|          | 0/3 [00:00<?, ?it/s]                            [INFO] perform level-1 opt :100%|ââââââââââ| 3/3 [00:00<00:00, 1314.69it/s]                  
[INFO] generate xmodel     :  0%|          | 0/29 [00:00<?, ?it/s]                           [INFO] generate xmodel     : 72%|ââââââââ  | 21/29 [00:00<00:00, 84.67it/s]                  [INFO] generate xmodel     :100%|ââââââââââ| 29/29 [00:00<00:00, 83.69it/s]                  
[INFO] dump xmodel ...[INFO] dump xmodel: /tmp/alexnetBNnoLRN_org.xmodel
[UNILOG][INFO] Compile mode: dpu
[UNILOG][INFO] Debug mode: function
[UNILOG][INFO] Target architecture: DPUCZDX8G_ISA0_B4096_MAX_BG2
[UNILOG][INFO] Graph name: deploy, with op num: 61
[UNILOG][INFO] Begin to compile...
[UNILOG][INFO] Total device subgraph number 3, DPU subgraph number 1
[UNILOG][INFO] Compile done.
[UNILOG][INFO] The meta json is saved to "/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/deploy/alexnetBNnoLRN/quantiz/vaic_output/meta.json"
[UNILOG][INFO] The compiled xmodel is saved to "/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/deploy/alexnetBNnoLRN/quantiz/vaic_output/alexnetBNnoLRN.xmodel"
[UNILOG][INFO] The compiled xmodel's md5sum is 1e073da30b85c0b1bd43a8651aad3224, and has been saved to "/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/deploy/alexnetBNnoLRN/quantiz/vaic_output/md5sum.txt"
**************************************************
* VITIS_AI Compilation - Xilinx Inc.
**************************************************
 copying xmodel file into /../zcu102/baseline/model/arm64_4096 
Compiling network: alexnetBNnoLRN for VCK190
[INFO] Namespace(batchsize=1, inputs_shape=None, layout='NCHW', model_files=['/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/deploy/alexnetBNnoLRN/quantiz/vaiq_output/deploy.caffemodel'], model_type='caffe', named_inputs_shape=None, out_filename='/tmp/alexnetBNnoLRN_org.xmodel', proto='/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/deploy/alexnetBNnoLRN/quantiz/vaiq_output/deploy.prototxt')
[INFO] caffe model: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/deploy/alexnetBNnoLRN/quantiz/vaiq_output/deploy.caffemodel
[INFO] caffe model: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/deploy/alexnetBNnoLRN/quantiz/vaiq_output/deploy.prototxt
[INFO] parse raw model     :  0%|          | 0/29 [00:00<?, ?it/s]                           [INFO] parse raw model     : 24%|âââ       | 7/29 [00:00<00:00, 41.07it/s]                   [INFO] parse raw model     : 41%|âââââ     | 12/29 [00:00<00:00, 27.16it/s]                  [INFO] parse raw model     : 52%|ââââââ    | 15/29 [00:00<00:00, 15.91it/s]                  [INFO] parse raw model     : 59%|ââââââ    | 17/29 [00:01<00:00, 13.38it/s]                  [INFO] parse raw model     : 72%|ââââââââ  | 21/29 [00:10<00:08,  1.01s/it]                  [INFO] parse raw model     : 83%|âââââââââ | 24/29 [00:15<00:05,  1.15s/it]                  [INFO] parse raw model     :100%|ââââââââââ| 29/29 [00:15<00:00,  1.88it/s]                  
[INFO] infer shape (NCHW)  :  0%|          | 0/29 [00:00<?, ?it/s]                           [INFO] infer shape (NCHW)  :100%|ââââââââââ| 29/29 [00:00<00:00, 17112.38it/s]               
[INFO] infer shape (NHWC)  :  0%|          | 0/29 [00:00<?, ?it/s]                           [INFO] infer shape (NHWC)  :100%|ââââââââââ| 29/29 [00:00<00:00, 549.76it/s]                 
[INFO] perform level-1 opt :  0%|          | 0/3 [00:00<?, ?it/s]                            [INFO] perform level-1 opt :100%|ââââââââââ| 3/3 [00:00<00:00, 1298.95it/s]                  
[INFO] generate xmodel     :  0%|          | 0/29 [00:00<?, ?it/s]                           [INFO] generate xmodel     : 72%|ââââââââ  | 21/29 [00:00<00:00, 85.29it/s]                  [INFO] generate xmodel     :100%|ââââââââââ| 29/29 [00:00<00:00, 84.17it/s]                  
[INFO] dump xmodel ...[INFO] dump xmodel: /tmp/alexnetBNnoLRN_org.xmodel
[UNILOG][INFO] Compile mode: dpu
[UNILOG][INFO] Debug mode: function
[UNILOG][INFO] Target architecture: DPUCVDX8G_ISA2_C32B3
[UNILOG][INFO] Graph name: deploy, with op num: 61
[UNILOG][INFO] Begin to compile...
[UNILOG][INFO] Total device subgraph number 3, DPU subgraph number 1
[UNILOG][INFO] Compile done.
[UNILOG][INFO] The meta json is saved to "/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/deploy/alexnetBNnoLRN/quantiz/vaic_output/meta.json"
[UNILOG][INFO] The compiled xmodel is saved to "/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/deploy/alexnetBNnoLRN/quantiz/vaic_output/alexnetBNnoLRN.xmodel"
[UNILOG][INFO] The compiled xmodel's md5sum is 40156416ebe85377ec88815f24317ab1, and has been saved to "/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/deploy/alexnetBNnoLRN/quantiz/vaic_output/md5sum.txt"
**************************************************
* VITIS_AI Compilation - Xilinx Inc.
**************************************************
 copying xmodel file into /../vck190/baseline/model/arm64_4096 
Collecting lmdb==0.98
  Using cached lmdb-0.98.tar.gz (869 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Building wheels for collected packages: lmdb
  Building wheel for lmdb (setup.py): started
  Building wheel for lmdb (setup.py): finished with status 'done'
  Created wheel for lmdb: filename=lmdb-0.98-cp37-cp37m-linux_x86_64.whl size=299324 sha256=22f72ffcb0c41fa39aad6b7ba4bc827ab9c89b2f0d1b6f3aac5c0d560fb81289
  Stored in directory: /home/vitis-ai-user/.cache/pip/wheels/9e/24/96/783d4dddcf63e3f8cc92db8b3af3c70cf6d76398bff77f1d5e
Successfully built lmdb
Installing collected packages: lmdb
Successfully installed lmdb-0.98
project ML_DIR is /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files
CAFFE_TOOLS_DIR is /workspace/VAI2.0/tutorials/caffe-xilinx
(c) Copyright 2016â2019 Xilinx, Inc. All rights reserved.

I0614 12:34:35.543653   729 sens_analyser.cpp:195] Starting analysis of pruning/alexnetBNnoLRN/float.caffemodel
I0614 12:34:40.749742   729 gpu_memory.cpp:53] GPUMemory::Manager initialized with Caching (CUB) GPU Allocator
I0614 12:34:40.749783   729 gpu_memory.cpp:55] Total memory: 25635127296, Free: 24776736768, dev_info[0]: total=25635127296 free=24776736768
I0614 12:34:40.750141   729 caffe_interface.cpp:112] Use GPU with device ID 0
I0614 12:34:40.750443   729 caffe_interface.cpp:116] GPU device name: Quadro P6000
W0614 12:34:41.461057   729 utils.cpp:207] BVLC BatchNormLayer without ScaleLayer detected: 3, it will be converted to NVCaffe Format.
W0614 12:34:41.461505   729 utils.cpp:207] BVLC BatchNormLayer without ScaleLayer detected: 7, it will be converted to NVCaffe Format.
W0614 12:34:41.461567   729 utils.cpp:207] BVLC BatchNormLayer without ScaleLayer detected: 21, it will be converted to NVCaffe Format.
I0614 12:34:41.461830   729 net.cpp:323] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0614 12:34:41.461901   729 net.cpp:52] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_value: 106
    mean_value: 116
    mean_value: 124
  }
  data_param {
    source: "input/lmdb/valid_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 0
    kernel_size: 8
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "bn1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "bn2"
  top: "relu2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "relu6"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "drop6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn7"
  type: "BatchNorm"
  bottom: "fc7"
  top: "bn7"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "bn7"
  top: "relu7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "relu7"
  top: "drop7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "drop7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy-top1"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "top-1"
  include {
    phase: TEST
  }
}
I0614 12:34:41.464836   729 layer_factory.hpp:77] Creating layer data
I0614 12:34:41.465867   729 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0614 12:34:41.469642   729 net.cpp:94] Creating Layer data
I0614 12:34:41.469666   729 net.cpp:409] data -> data
I0614 12:34:41.469691   729 net.cpp:409] data -> label
I0614 12:34:41.470346   764 db_lmdb.cpp:35] Opened lmdb input/lmdb/valid_lmdb
I0614 12:34:41.470378   764 db_lmdb.cpp:38] Items count: 4000
I0614 12:34:41.470410   764 data_reader.cpp:124] TEST: reading data using 1 channel(s)
I0614 12:34:41.470820   729 data_layer.cpp:78] ReshapePrefetch 50, 3, 227, 227
I0614 12:34:41.470980   729 data_layer.cpp:83] output data size: 50,3,227,227
I0614 12:34:41.591599   729 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0614 12:34:41.591830   729 net.cpp:144] Setting up data
I0614 12:34:41.591835   729 net.cpp:151] Top shape: 50 3 227 227 (7729350)
I0614 12:34:41.591843   729 net.cpp:151] Top shape: 50 (50)
I0614 12:34:41.591847   729 net.cpp:159] Memory required for data: 30917600
I0614 12:34:41.591852   729 layer_factory.hpp:77] Creating layer label_data_1_split
I0614 12:34:41.591861   729 net.cpp:94] Creating Layer label_data_1_split
I0614 12:34:41.591902   729 net.cpp:435] label_data_1_split <- label
I0614 12:34:41.591909   729 net.cpp:409] label_data_1_split -> label_data_1_split_0
I0614 12:34:41.591917   729 net.cpp:409] label_data_1_split -> label_data_1_split_1
I0614 12:34:41.591922   729 net.cpp:409] label_data_1_split -> label_data_1_split_2
I0614 12:34:41.591975   729 net.cpp:144] Setting up label_data_1_split
I0614 12:34:41.591979   729 net.cpp:151] Top shape: 50 (50)
I0614 12:34:41.592236   729 net.cpp:151] Top shape: 50 (50)
I0614 12:34:41.592257   729 net.cpp:151] Top shape: 50 (50)
I0614 12:34:41.592262   729 net.cpp:159] Memory required for data: 30918200
I0614 12:34:41.592268   729 layer_factory.hpp:77] Creating layer conv1
I0614 12:34:41.592283   729 net.cpp:94] Creating Layer conv1
I0614 12:34:41.592286   729 net.cpp:435] conv1 <- data
I0614 12:34:41.592293   729 net.cpp:409] conv1 -> conv1
I0614 12:34:41.593206   729 net.cpp:144] Setting up conv1
I0614 12:34:41.593216   729 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0614 12:34:41.593223   729 net.cpp:159] Memory required for data: 88998200
I0614 12:34:41.593235   729 layer_factory.hpp:77] Creating layer bn1
I0614 12:34:41.593242   729 net.cpp:94] Creating Layer bn1
I0614 12:34:41.593246   729 net.cpp:435] bn1 <- conv1
I0614 12:34:41.593252   729 net.cpp:409] bn1 -> bn1
I0614 12:34:41.594707   729 net.cpp:144] Setting up bn1
I0614 12:34:41.594715   729 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0614 12:34:41.594722   729 net.cpp:159] Memory required for data: 147078200
I0614 12:34:41.594730   729 layer_factory.hpp:77] Creating layer relu1
I0614 12:34:41.594736   729 net.cpp:94] Creating Layer relu1
I0614 12:34:41.594739   729 net.cpp:435] relu1 <- bn1
I0614 12:34:41.594744   729 net.cpp:409] relu1 -> relu1
I0614 12:34:41.594786   729 net.cpp:144] Setting up relu1
I0614 12:34:41.594805   729 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0614 12:34:41.594810   729 net.cpp:159] Memory required for data: 205158200
I0614 12:34:41.594813   729 layer_factory.hpp:77] Creating layer pool1
I0614 12:34:41.594820   729 net.cpp:94] Creating Layer pool1
I0614 12:34:41.594822   729 net.cpp:435] pool1 <- relu1
I0614 12:34:41.594827   729 net.cpp:409] pool1 -> pool1
I0614 12:34:41.595306   729 net.cpp:144] Setting up pool1
I0614 12:34:41.595314   729 net.cpp:151] Top shape: 50 96 27 27 (3499200)
I0614 12:34:41.595319   729 net.cpp:159] Memory required for data: 219155000
I0614 12:34:41.595324   729 layer_factory.hpp:77] Creating layer conv2
I0614 12:34:41.595331   729 net.cpp:94] Creating Layer conv2
I0614 12:34:41.595335   729 net.cpp:435] conv2 <- pool1
I0614 12:34:41.595340   729 net.cpp:409] conv2 -> conv2
I0614 12:34:41.602504   729 net.cpp:144] Setting up conv2
I0614 12:34:41.602522   729 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0614 12:34:41.602530   729 net.cpp:159] Memory required for data: 256479800
I0614 12:34:41.602540   729 layer_factory.hpp:77] Creating layer bn2
I0614 12:34:41.602550   729 net.cpp:94] Creating Layer bn2
I0614 12:34:41.602553   729 net.cpp:435] bn2 <- conv2
I0614 12:34:41.602560   729 net.cpp:409] bn2 -> bn2
I0614 12:34:41.602913   729 net.cpp:144] Setting up bn2
I0614 12:34:41.602923   729 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0614 12:34:41.602934   729 net.cpp:159] Memory required for data: 293804600
I0614 12:34:41.602949   729 layer_factory.hpp:77] Creating layer relu2
I0614 12:34:41.602958   729 net.cpp:94] Creating Layer relu2
I0614 12:34:41.602967   729 net.cpp:435] relu2 <- bn2
I0614 12:34:41.602977   729 net.cpp:409] relu2 -> relu2
I0614 12:34:41.602996   729 net.cpp:144] Setting up relu2
I0614 12:34:41.603000   729 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0614 12:34:41.603005   729 net.cpp:159] Memory required for data: 331129400
I0614 12:34:41.603009   729 layer_factory.hpp:77] Creating layer pool2
I0614 12:34:41.603015   729 net.cpp:94] Creating Layer pool2
I0614 12:34:41.603022   729 net.cpp:435] pool2 <- relu2
I0614 12:34:41.603035   729 net.cpp:409] pool2 -> pool2
I0614 12:34:41.603056   729 net.cpp:144] Setting up pool2
I0614 12:34:41.603060   729 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0614 12:34:41.603070   729 net.cpp:159] Memory required for data: 339782200
I0614 12:34:41.603075   729 layer_factory.hpp:77] Creating layer conv3
I0614 12:34:41.603088   729 net.cpp:94] Creating Layer conv3
I0614 12:34:41.603094   729 net.cpp:435] conv3 <- pool2
I0614 12:34:41.603104   729 net.cpp:409] conv3 -> conv3
I0614 12:34:41.614571   729 net.cpp:144] Setting up conv3
I0614 12:34:41.616680   729 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0614 12:34:41.616695   729 net.cpp:159] Memory required for data: 352761400
I0614 12:34:41.616708   729 layer_factory.hpp:77] Creating layer relu3
I0614 12:34:41.616717   729 net.cpp:94] Creating Layer relu3
I0614 12:34:41.616722   729 net.cpp:435] relu3 <- conv3
I0614 12:34:41.616729   729 net.cpp:409] relu3 -> relu3
I0614 12:34:41.616772   729 net.cpp:144] Setting up relu3
I0614 12:34:41.616778   729 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0614 12:34:41.616783   729 net.cpp:159] Memory required for data: 365740600
I0614 12:34:41.616787   729 layer_factory.hpp:77] Creating layer conv4
I0614 12:34:41.616796   729 net.cpp:94] Creating Layer conv4
I0614 12:34:41.616801   729 net.cpp:435] conv4 <- relu3
I0614 12:34:41.616806   729 net.cpp:409] conv4 -> conv4
I0614 12:34:41.634548   729 net.cpp:144] Setting up conv4
I0614 12:34:41.634567   729 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0614 12:34:41.634574   729 net.cpp:159] Memory required for data: 378719800
I0614 12:34:41.634588   729 layer_factory.hpp:77] Creating layer relu4
I0614 12:34:41.634594   729 net.cpp:94] Creating Layer relu4
I0614 12:34:41.634598   729 net.cpp:435] relu4 <- conv4
I0614 12:34:41.634605   729 net.cpp:409] relu4 -> relu4
I0614 12:34:41.634625   729 net.cpp:144] Setting up relu4
I0614 12:34:41.634630   729 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0614 12:34:41.634637   729 net.cpp:159] Memory required for data: 391699000
I0614 12:34:41.634644   729 layer_factory.hpp:77] Creating layer conv5
I0614 12:34:41.634655   729 net.cpp:94] Creating Layer conv5
I0614 12:34:41.634661   729 net.cpp:435] conv5 <- relu4
I0614 12:34:41.634668   729 net.cpp:409] conv5 -> conv5
I0614 12:34:41.646836   729 net.cpp:144] Setting up conv5
I0614 12:34:41.646862   729 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0614 12:34:41.646873   729 net.cpp:159] Memory required for data: 400351800
I0614 12:34:41.646885   729 layer_factory.hpp:77] Creating layer relu5
I0614 12:34:41.646894   729 net.cpp:94] Creating Layer relu5
I0614 12:34:41.646900   729 net.cpp:435] relu5 <- conv5
I0614 12:34:41.646909   729 net.cpp:409] relu5 -> relu5
I0614 12:34:41.646932   729 net.cpp:144] Setting up relu5
I0614 12:34:41.646937   729 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0614 12:34:41.646943   729 net.cpp:159] Memory required for data: 409004600
I0614 12:34:41.646948   729 layer_factory.hpp:77] Creating layer pool5
I0614 12:34:41.646958   729 net.cpp:94] Creating Layer pool5
I0614 12:34:41.646963   729 net.cpp:435] pool5 <- relu5
I0614 12:34:41.646970   729 net.cpp:409] pool5 -> pool5
I0614 12:34:41.646996   729 net.cpp:144] Setting up pool5
I0614 12:34:41.646999   729 net.cpp:151] Top shape: 50 256 6 6 (460800)
I0614 12:34:41.647006   729 net.cpp:159] Memory required for data: 410847800
I0614 12:34:41.647011   729 layer_factory.hpp:77] Creating layer fc6
I0614 12:34:41.647022   729 net.cpp:94] Creating Layer fc6
I0614 12:34:41.647025   729 net.cpp:435] fc6 <- pool5
I0614 12:34:41.647033   729 net.cpp:409] fc6 -> fc6
I0614 12:34:42.019466   729 net.cpp:144] Setting up fc6
I0614 12:34:42.019495   729 net.cpp:151] Top shape: 50 4096 (204800)
I0614 12:34:42.019502   729 net.cpp:159] Memory required for data: 411667000
I0614 12:34:42.019511   729 layer_factory.hpp:77] Creating layer relu6
I0614 12:34:42.019518   729 net.cpp:94] Creating Layer relu6
I0614 12:34:42.019522   729 net.cpp:435] relu6 <- fc6
I0614 12:34:42.019528   729 net.cpp:409] relu6 -> relu6
I0614 12:34:42.019547   729 net.cpp:144] Setting up relu6
I0614 12:34:42.019551   729 net.cpp:151] Top shape: 50 4096 (204800)
I0614 12:34:42.019556   729 net.cpp:159] Memory required for data: 412486200
I0614 12:34:42.019560   729 layer_factory.hpp:77] Creating layer drop6
I0614 12:34:42.019565   729 net.cpp:94] Creating Layer drop6
I0614 12:34:42.019569   729 net.cpp:435] drop6 <- relu6
I0614 12:34:42.019573   729 net.cpp:409] drop6 -> drop6
I0614 12:34:42.019588   729 net.cpp:144] Setting up drop6
I0614 12:34:42.019591   729 net.cpp:151] Top shape: 50 4096 (204800)
I0614 12:34:42.019997   729 net.cpp:159] Memory required for data: 413305400
I0614 12:34:42.020002   729 layer_factory.hpp:77] Creating layer fc7
I0614 12:34:42.020009   729 net.cpp:94] Creating Layer fc7
I0614 12:34:42.020013   729 net.cpp:435] fc7 <- drop6
I0614 12:34:42.020020   729 net.cpp:409] fc7 -> fc7
I0614 12:34:42.179504   729 net.cpp:144] Setting up fc7
I0614 12:34:42.179533   729 net.cpp:151] Top shape: 50 4096 (204800)
I0614 12:34:42.179543   729 net.cpp:159] Memory required for data: 414124600
I0614 12:34:42.179553   729 layer_factory.hpp:77] Creating layer bn7
I0614 12:34:42.179562   729 net.cpp:94] Creating Layer bn7
I0614 12:34:42.179566   729 net.cpp:435] bn7 <- fc7
I0614 12:34:42.179572   729 net.cpp:409] bn7 -> bn7
I0614 12:34:42.179852   729 net.cpp:144] Setting up bn7
I0614 12:34:42.179857   729 net.cpp:151] Top shape: 50 4096 (204800)
I0614 12:34:42.179862   729 net.cpp:159] Memory required for data: 414943800
I0614 12:34:42.179869   729 layer_factory.hpp:77] Creating layer relu7
I0614 12:34:42.179874   729 net.cpp:94] Creating Layer relu7
I0614 12:34:42.179878   729 net.cpp:435] relu7 <- bn7
I0614 12:34:42.179883   729 net.cpp:409] relu7 -> relu7
I0614 12:34:42.179895   729 net.cpp:144] Setting up relu7
I0614 12:34:42.179898   729 net.cpp:151] Top shape: 50 4096 (204800)
I0614 12:34:42.179903   729 net.cpp:159] Memory required for data: 415763000
I0614 12:34:42.179906   729 layer_factory.hpp:77] Creating layer drop7
I0614 12:34:42.179911   729 net.cpp:94] Creating Layer drop7
I0614 12:34:42.179915   729 net.cpp:435] drop7 <- relu7
I0614 12:34:42.179919   729 net.cpp:409] drop7 -> drop7
I0614 12:34:42.179936   729 net.cpp:144] Setting up drop7
I0614 12:34:42.179941   729 net.cpp:151] Top shape: 50 4096 (204800)
I0614 12:34:42.179947   729 net.cpp:159] Memory required for data: 416582200
I0614 12:34:42.179952   729 layer_factory.hpp:77] Creating layer fc8
I0614 12:34:42.179960   729 net.cpp:94] Creating Layer fc8
I0614 12:34:42.179962   729 net.cpp:435] fc8 <- drop7
I0614 12:34:42.179967   729 net.cpp:409] fc8 -> fc8
I0614 12:34:42.180110   729 net.cpp:144] Setting up fc8
I0614 12:34:42.180115   729 net.cpp:151] Top shape: 50 2 (100)
I0614 12:34:42.180119   729 net.cpp:159] Memory required for data: 416582600
I0614 12:34:42.180125   729 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0614 12:34:42.180131   729 net.cpp:94] Creating Layer fc8_fc8_0_split
I0614 12:34:42.180135   729 net.cpp:435] fc8_fc8_0_split <- fc8
I0614 12:34:42.180140   729 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0614 12:34:42.180145   729 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0614 12:34:42.180151   729 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_2
I0614 12:34:42.180173   729 net.cpp:144] Setting up fc8_fc8_0_split
I0614 12:34:42.180177   729 net.cpp:151] Top shape: 50 2 (100)
I0614 12:34:42.180181   729 net.cpp:151] Top shape: 50 2 (100)
I0614 12:34:42.180186   729 net.cpp:151] Top shape: 50 2 (100)
I0614 12:34:42.180189   729 net.cpp:159] Memory required for data: 416583800
I0614 12:34:42.180193   729 layer_factory.hpp:77] Creating layer accuracy
I0614 12:34:42.181931   729 net.cpp:94] Creating Layer accuracy
I0614 12:34:42.181973   729 net.cpp:435] accuracy <- fc8_fc8_0_split_0
I0614 12:34:42.181996   729 net.cpp:435] accuracy <- label_data_1_split_0
I0614 12:34:42.182021   729 net.cpp:409] accuracy -> accuracy
I0614 12:34:42.182062   729 net.cpp:144] Setting up accuracy
I0614 12:34:42.182080   729 net.cpp:151] Top shape: (1)
I0614 12:34:42.182098   729 net.cpp:159] Memory required for data: 416583804
I0614 12:34:42.182111   729 layer_factory.hpp:77] Creating layer loss
I0614 12:34:42.182143   729 net.cpp:94] Creating Layer loss
I0614 12:34:42.182161   729 net.cpp:435] loss <- fc8_fc8_0_split_1
I0614 12:34:42.182180   729 net.cpp:435] loss <- label_data_1_split_1
I0614 12:34:42.182195   729 net.cpp:409] loss -> loss
I0614 12:34:42.182226   729 layer_factory.hpp:77] Creating layer loss
I0614 12:34:42.182431   729 net.cpp:144] Setting up loss
I0614 12:34:42.182750   729 net.cpp:151] Top shape: (1)
I0614 12:34:42.182770   729 net.cpp:154]     with loss weight 1
I0614 12:34:42.182802   729 net.cpp:159] Memory required for data: 416583808
I0614 12:34:42.182816   729 layer_factory.hpp:77] Creating layer accuracy-top1
I0614 12:34:42.182838   729 net.cpp:94] Creating Layer accuracy-top1
I0614 12:34:42.182852   729 net.cpp:435] accuracy-top1 <- fc8_fc8_0_split_2
I0614 12:34:42.182865   729 net.cpp:435] accuracy-top1 <- label_data_1_split_2
I0614 12:34:42.182881   729 net.cpp:409] accuracy-top1 -> top-1
I0614 12:34:42.182909   729 net.cpp:144] Setting up accuracy-top1
I0614 12:34:42.182925   729 net.cpp:151] Top shape: (1)
I0614 12:34:42.182938   729 net.cpp:159] Memory required for data: 416583812
I0614 12:34:42.182951   729 net.cpp:222] accuracy-top1 does not need backward computation.
I0614 12:34:42.182971   729 net.cpp:220] loss needs backward computation.
I0614 12:34:42.182984   729 net.cpp:222] accuracy does not need backward computation.
I0614 12:34:42.182998   729 net.cpp:220] fc8_fc8_0_split needs backward computation.
I0614 12:34:42.183012   729 net.cpp:220] fc8 needs backward computation.
I0614 12:34:42.183023   729 net.cpp:220] drop7 needs backward computation.
I0614 12:34:42.183038   729 net.cpp:220] relu7 needs backward computation.
I0614 12:34:42.183058   729 net.cpp:220] bn7 needs backward computation.
I0614 12:34:42.183073   729 net.cpp:220] fc7 needs backward computation.
I0614 12:34:42.183085   729 net.cpp:220] drop6 needs backward computation.
I0614 12:34:42.183100   729 net.cpp:220] relu6 needs backward computation.
I0614 12:34:42.183117   729 net.cpp:220] fc6 needs backward computation.
I0614 12:34:42.183130   729 net.cpp:220] pool5 needs backward computation.
I0614 12:34:42.183142   729 net.cpp:220] relu5 needs backward computation.
I0614 12:34:42.183156   729 net.cpp:220] conv5 needs backward computation.
I0614 12:34:42.183171   729 net.cpp:220] relu4 needs backward computation.
I0614 12:34:42.183190   729 net.cpp:220] conv4 needs backward computation.
I0614 12:34:42.183204   729 net.cpp:220] relu3 needs backward computation.
I0614 12:34:42.183218   729 net.cpp:220] conv3 needs backward computation.
I0614 12:34:42.183230   729 net.cpp:220] pool2 needs backward computation.
I0614 12:34:42.183248   729 net.cpp:220] relu2 needs backward computation.
I0614 12:34:42.183261   729 net.cpp:220] bn2 needs backward computation.
I0614 12:34:42.183274   729 net.cpp:220] conv2 needs backward computation.
I0614 12:34:42.183286   729 net.cpp:220] pool1 needs backward computation.
I0614 12:34:42.183300   729 net.cpp:220] relu1 needs backward computation.
I0614 12:34:42.183319   729 net.cpp:220] bn1 needs backward computation.
I0614 12:34:42.183336   729 net.cpp:220] conv1 needs backward computation.
I0614 12:34:42.183353   729 net.cpp:222] label_data_1_split does not need backward computation.
I0614 12:34:42.183373   729 net.cpp:222] data does not need backward computation.
I0614 12:34:42.183385   729 net.cpp:264] This network produces output accuracy
I0614 12:34:42.183398   729 net.cpp:264] This network produces output loss
I0614 12:34:42.183410   729 net.cpp:264] This network produces output top-1
I0614 12:34:42.183495   729 net.cpp:284] Network initialization done.
I0614 12:34:42.269846   729 caffe_interface.cpp:409] Running for 80 iterations.
I0614 12:34:42.316121   729 caffe_interface.cpp:171] Batch 0, accuracy = 0.92
I0614 12:34:42.316146   729 caffe_interface.cpp:171] Batch 0, loss = 0.341219
I0614 12:34:42.316150   729 caffe_interface.cpp:171] Batch 0, top-1 = 0.92
I0614 12:34:42.334695   729 caffe_interface.cpp:171] Batch 1, accuracy = 0.96
I0614 12:34:42.334717   729 caffe_interface.cpp:171] Batch 1, loss = 0.214947
I0614 12:34:42.334720   729 caffe_interface.cpp:171] Batch 1, top-1 = 0.96
I0614 12:34:42.353682   729 caffe_interface.cpp:171] Batch 2, accuracy = 1
I0614 12:34:42.353701   729 caffe_interface.cpp:171] Batch 2, loss = 0.0108714
I0614 12:34:42.353705   729 caffe_interface.cpp:171] Batch 2, top-1 = 1
I0614 12:34:42.372606   729 caffe_interface.cpp:171] Batch 3, accuracy = 0.96
I0614 12:34:42.372800   729 caffe_interface.cpp:171] Batch 3, loss = 0.256492
I0614 12:34:42.372804   729 caffe_interface.cpp:171] Batch 3, top-1 = 0.96
I0614 12:34:42.391645   729 caffe_interface.cpp:171] Batch 4, accuracy = 0.94
I0614 12:34:42.391664   729 caffe_interface.cpp:171] Batch 4, loss = 0.176878
I0614 12:34:42.391667   729 caffe_interface.cpp:171] Batch 4, top-1 = 0.94
I0614 12:34:42.409720   729 caffe_interface.cpp:171] Batch 5, accuracy = 0.94
I0614 12:34:42.409740   729 caffe_interface.cpp:171] Batch 5, loss = 0.124104
I0614 12:34:42.409744   729 caffe_interface.cpp:171] Batch 5, top-1 = 0.94
I0614 12:34:42.427438   729 caffe_interface.cpp:171] Batch 6, accuracy = 0.98
I0614 12:34:42.427455   729 caffe_interface.cpp:171] Batch 6, loss = 0.0266741
I0614 12:34:42.427459   729 caffe_interface.cpp:171] Batch 6, top-1 = 0.98
I0614 12:34:42.445189   729 caffe_interface.cpp:171] Batch 7, accuracy = 0.94
I0614 12:34:42.445209   729 caffe_interface.cpp:171] Batch 7, loss = 0.204637
I0614 12:34:42.445211   729 caffe_interface.cpp:171] Batch 7, top-1 = 0.94
I0614 12:34:42.463104   729 caffe_interface.cpp:171] Batch 8, accuracy = 1
I0614 12:34:42.463124   729 caffe_interface.cpp:171] Batch 8, loss = 0.0291976
I0614 12:34:42.463127   729 caffe_interface.cpp:171] Batch 8, top-1 = 1
I0614 12:34:42.481302   729 caffe_interface.cpp:171] Batch 9, accuracy = 0.98
I0614 12:34:42.481320   729 caffe_interface.cpp:171] Batch 9, loss = 0.0450615
I0614 12:34:42.481324   729 caffe_interface.cpp:171] Batch 9, top-1 = 0.98
I0614 12:34:42.499217   729 caffe_interface.cpp:171] Batch 10, accuracy = 0.96
I0614 12:34:42.499235   729 caffe_interface.cpp:171] Batch 10, loss = 0.10993
I0614 12:34:42.499239   729 caffe_interface.cpp:171] Batch 10, top-1 = 0.96
I0614 12:34:42.516846   729 caffe_interface.cpp:171] Batch 11, accuracy = 0.98
I0614 12:34:42.516865   729 caffe_interface.cpp:171] Batch 11, loss = 0.0204155
I0614 12:34:42.516868   729 caffe_interface.cpp:171] Batch 11, top-1 = 0.98
I0614 12:34:42.534989   729 caffe_interface.cpp:171] Batch 12, accuracy = 0.92
I0614 12:34:42.535008   729 caffe_interface.cpp:171] Batch 12, loss = 0.298015
I0614 12:34:42.535012   729 caffe_interface.cpp:171] Batch 12, top-1 = 0.92
I0614 12:34:42.552845   729 caffe_interface.cpp:171] Batch 13, accuracy = 0.96
I0614 12:34:42.552865   729 caffe_interface.cpp:171] Batch 13, loss = 0.111254
I0614 12:34:42.552867   729 caffe_interface.cpp:171] Batch 13, top-1 = 0.96
I0614 12:34:42.570849   729 caffe_interface.cpp:171] Batch 14, accuracy = 0.98
I0614 12:34:42.570868   729 caffe_interface.cpp:171] Batch 14, loss = 0.158838
I0614 12:34:42.570871   729 caffe_interface.cpp:171] Batch 14, top-1 = 0.98
I0614 12:34:42.588472   729 caffe_interface.cpp:171] Batch 15, accuracy = 0.96
I0614 12:34:42.588492   729 caffe_interface.cpp:171] Batch 15, loss = 0.217781
I0614 12:34:42.588495   729 caffe_interface.cpp:171] Batch 15, top-1 = 0.96
I0614 12:34:42.606171   729 caffe_interface.cpp:171] Batch 16, accuracy = 0.96
I0614 12:34:42.606190   729 caffe_interface.cpp:171] Batch 16, loss = 0.0732686
I0614 12:34:42.606194   729 caffe_interface.cpp:171] Batch 16, top-1 = 0.96
I0614 12:34:42.623936   729 caffe_interface.cpp:171] Batch 17, accuracy = 0.96
I0614 12:34:42.623955   729 caffe_interface.cpp:171] Batch 17, loss = 0.156345
I0614 12:34:42.623958   729 caffe_interface.cpp:171] Batch 17, top-1 = 0.96
I0614 12:34:42.641702   729 caffe_interface.cpp:171] Batch 18, accuracy = 0.94
I0614 12:34:42.641721   729 caffe_interface.cpp:171] Batch 18, loss = 0.0732432
I0614 12:34:42.641724   729 caffe_interface.cpp:171] Batch 18, top-1 = 0.94
I0614 12:34:42.659523   729 caffe_interface.cpp:171] Batch 19, accuracy = 0.94
I0614 12:34:42.659543   729 caffe_interface.cpp:171] Batch 19, loss = 0.11075
I0614 12:34:42.659546   729 caffe_interface.cpp:171] Batch 19, top-1 = 0.94
I0614 12:34:42.677397   729 caffe_interface.cpp:171] Batch 20, accuracy = 1
I0614 12:34:42.677417   729 caffe_interface.cpp:171] Batch 20, loss = 0.00295338
I0614 12:34:42.677421   729 caffe_interface.cpp:171] Batch 20, top-1 = 1
I0614 12:34:42.695693   729 caffe_interface.cpp:171] Batch 21, accuracy = 0.96
I0614 12:34:42.695713   729 caffe_interface.cpp:171] Batch 21, loss = 0.0747866
I0614 12:34:42.695716   729 caffe_interface.cpp:171] Batch 21, top-1 = 0.96
I0614 12:34:42.713559   729 caffe_interface.cpp:171] Batch 22, accuracy = 0.94
I0614 12:34:42.713577   729 caffe_interface.cpp:171] Batch 22, loss = 0.157811
I0614 12:34:42.713582   729 caffe_interface.cpp:171] Batch 22, top-1 = 0.94
I0614 12:34:42.731492   729 caffe_interface.cpp:171] Batch 23, accuracy = 0.92
I0614 12:34:42.731511   729 caffe_interface.cpp:171] Batch 23, loss = 0.197715
I0614 12:34:42.731515   729 caffe_interface.cpp:171] Batch 23, top-1 = 0.92
I0614 12:34:42.749056   729 caffe_interface.cpp:171] Batch 24, accuracy = 0.94
I0614 12:34:42.749074   729 caffe_interface.cpp:171] Batch 24, loss = 0.370175
I0614 12:34:42.749078   729 caffe_interface.cpp:171] Batch 24, top-1 = 0.94
I0614 12:34:42.766768   729 caffe_interface.cpp:171] Batch 25, accuracy = 0.94
I0614 12:34:42.766786   729 caffe_interface.cpp:171] Batch 25, loss = 0.239189
I0614 12:34:42.766790   729 caffe_interface.cpp:171] Batch 25, top-1 = 0.94
I0614 12:34:42.784353   729 caffe_interface.cpp:171] Batch 26, accuracy = 0.94
I0614 12:34:42.784372   729 caffe_interface.cpp:171] Batch 26, loss = 0.0774089
I0614 12:34:42.784375   729 caffe_interface.cpp:171] Batch 26, top-1 = 0.94
I0614 12:34:42.802104   729 caffe_interface.cpp:171] Batch 27, accuracy = 0.88
I0614 12:34:42.802124   729 caffe_interface.cpp:171] Batch 27, loss = 0.314411
I0614 12:34:42.802129   729 caffe_interface.cpp:171] Batch 27, top-1 = 0.88
I0614 12:34:42.819789   729 caffe_interface.cpp:171] Batch 28, accuracy = 0.92
I0614 12:34:42.819809   729 caffe_interface.cpp:171] Batch 28, loss = 0.357191
I0614 12:34:42.819813   729 caffe_interface.cpp:171] Batch 28, top-1 = 0.92
I0614 12:34:42.837564   729 caffe_interface.cpp:171] Batch 29, accuracy = 0.98
I0614 12:34:42.837582   729 caffe_interface.cpp:171] Batch 29, loss = 0.0335033
I0614 12:34:42.837586   729 caffe_interface.cpp:171] Batch 29, top-1 = 0.98
I0614 12:34:42.855101   729 caffe_interface.cpp:171] Batch 30, accuracy = 0.98
I0614 12:34:42.855119   729 caffe_interface.cpp:171] Batch 30, loss = 0.0687141
I0614 12:34:42.855123   729 caffe_interface.cpp:171] Batch 30, top-1 = 0.98
I0614 12:34:42.872917   729 caffe_interface.cpp:171] Batch 31, accuracy = 0.94
I0614 12:34:42.872937   729 caffe_interface.cpp:171] Batch 31, loss = 0.155851
I0614 12:34:42.872941   729 caffe_interface.cpp:171] Batch 31, top-1 = 0.94
I0614 12:34:42.890762   729 caffe_interface.cpp:171] Batch 32, accuracy = 0.92
I0614 12:34:42.890782   729 caffe_interface.cpp:171] Batch 32, loss = 0.247596
I0614 12:34:42.890786   729 caffe_interface.cpp:171] Batch 32, top-1 = 0.92
I0614 12:34:42.908231   729 caffe_interface.cpp:171] Batch 33, accuracy = 1
I0614 12:34:42.908250   729 caffe_interface.cpp:171] Batch 33, loss = 0.017786
I0614 12:34:42.908254   729 caffe_interface.cpp:171] Batch 33, top-1 = 1
I0614 12:34:42.926014   729 caffe_interface.cpp:171] Batch 34, accuracy = 0.96
I0614 12:34:42.926034   729 caffe_interface.cpp:171] Batch 34, loss = 0.136674
I0614 12:34:42.926038   729 caffe_interface.cpp:171] Batch 34, top-1 = 0.96
I0614 12:34:42.943794   729 caffe_interface.cpp:171] Batch 35, accuracy = 0.92
I0614 12:34:42.943812   729 caffe_interface.cpp:171] Batch 35, loss = 0.212516
I0614 12:34:42.943816   729 caffe_interface.cpp:171] Batch 35, top-1 = 0.92
I0614 12:34:42.961575   729 caffe_interface.cpp:171] Batch 36, accuracy = 0.98
I0614 12:34:42.961593   729 caffe_interface.cpp:171] Batch 36, loss = 0.0454515
I0614 12:34:42.961598   729 caffe_interface.cpp:171] Batch 36, top-1 = 0.98
I0614 12:34:42.979250   729 caffe_interface.cpp:171] Batch 37, accuracy = 0.9
I0614 12:34:42.979269   729 caffe_interface.cpp:171] Batch 37, loss = 0.419042
I0614 12:34:42.979272   729 caffe_interface.cpp:171] Batch 37, top-1 = 0.9
I0614 12:34:42.996831   729 caffe_interface.cpp:171] Batch 38, accuracy = 0.96
I0614 12:34:42.997032   729 caffe_interface.cpp:171] Batch 38, loss = 0.227499
I0614 12:34:42.997037   729 caffe_interface.cpp:171] Batch 38, top-1 = 0.96
I0614 12:34:43.014823   729 caffe_interface.cpp:171] Batch 39, accuracy = 0.96
I0614 12:34:43.014842   729 caffe_interface.cpp:171] Batch 39, loss = 0.145638
I0614 12:34:43.014845   729 caffe_interface.cpp:171] Batch 39, top-1 = 0.96
I0614 12:34:43.032541   729 caffe_interface.cpp:171] Batch 40, accuracy = 0.96
I0614 12:34:43.032559   729 caffe_interface.cpp:171] Batch 40, loss = 0.164169
I0614 12:34:43.032563   729 caffe_interface.cpp:171] Batch 40, top-1 = 0.96
I0614 12:34:43.050211   729 caffe_interface.cpp:171] Batch 41, accuracy = 0.94
I0614 12:34:43.050228   729 caffe_interface.cpp:171] Batch 41, loss = 0.20041
I0614 12:34:43.050232   729 caffe_interface.cpp:171] Batch 41, top-1 = 0.94
I0614 12:34:43.067932   729 caffe_interface.cpp:171] Batch 42, accuracy = 0.98
I0614 12:34:43.067951   729 caffe_interface.cpp:171] Batch 42, loss = 0.0782527
I0614 12:34:43.067955   729 caffe_interface.cpp:171] Batch 42, top-1 = 0.98
I0614 12:34:43.085417   729 caffe_interface.cpp:171] Batch 43, accuracy = 0.92
I0614 12:34:43.085435   729 caffe_interface.cpp:171] Batch 43, loss = 0.271037
I0614 12:34:43.085439   729 caffe_interface.cpp:171] Batch 43, top-1 = 0.92
I0614 12:34:43.102852   729 caffe_interface.cpp:171] Batch 44, accuracy = 1
I0614 12:34:43.102870   729 caffe_interface.cpp:171] Batch 44, loss = 0.0161606
I0614 12:34:43.102874   729 caffe_interface.cpp:171] Batch 44, top-1 = 1
I0614 12:34:43.120247   729 caffe_interface.cpp:171] Batch 45, accuracy = 0.98
I0614 12:34:43.120265   729 caffe_interface.cpp:171] Batch 45, loss = 0.0311525
I0614 12:34:43.120268   729 caffe_interface.cpp:171] Batch 45, top-1 = 0.98
I0614 12:34:43.137878   729 caffe_interface.cpp:171] Batch 46, accuracy = 0.92
I0614 12:34:43.137897   729 caffe_interface.cpp:171] Batch 46, loss = 0.256979
I0614 12:34:43.137902   729 caffe_interface.cpp:171] Batch 46, top-1 = 0.92
I0614 12:34:43.155599   729 caffe_interface.cpp:171] Batch 47, accuracy = 0.92
I0614 12:34:43.155618   729 caffe_interface.cpp:171] Batch 47, loss = 0.361677
I0614 12:34:43.155622   729 caffe_interface.cpp:171] Batch 47, top-1 = 0.92
I0614 12:34:43.173259   729 caffe_interface.cpp:171] Batch 48, accuracy = 0.94
I0614 12:34:43.173278   729 caffe_interface.cpp:171] Batch 48, loss = 0.272271
I0614 12:34:43.173282   729 caffe_interface.cpp:171] Batch 48, top-1 = 0.94
I0614 12:34:43.190771   729 caffe_interface.cpp:171] Batch 49, accuracy = 0.94
I0614 12:34:43.190790   729 caffe_interface.cpp:171] Batch 49, loss = 0.158942
I0614 12:34:43.190795   729 caffe_interface.cpp:171] Batch 49, top-1 = 0.94
I0614 12:34:43.208504   729 caffe_interface.cpp:171] Batch 50, accuracy = 0.94
I0614 12:34:43.208524   729 caffe_interface.cpp:171] Batch 50, loss = 0.223148
I0614 12:34:43.208528   729 caffe_interface.cpp:171] Batch 50, top-1 = 0.94
I0614 12:34:43.225939   729 caffe_interface.cpp:171] Batch 51, accuracy = 0.98
I0614 12:34:43.225960   729 caffe_interface.cpp:171] Batch 51, loss = 0.106297
I0614 12:34:43.225963   729 caffe_interface.cpp:171] Batch 51, top-1 = 0.98
I0614 12:34:43.243620   729 caffe_interface.cpp:171] Batch 52, accuracy = 0.92
I0614 12:34:43.243639   729 caffe_interface.cpp:171] Batch 52, loss = 0.249101
I0614 12:34:43.243643   729 caffe_interface.cpp:171] Batch 52, top-1 = 0.92
I0614 12:34:43.261386   729 caffe_interface.cpp:171] Batch 53, accuracy = 0.94
I0614 12:34:43.261406   729 caffe_interface.cpp:171] Batch 53, loss = 0.198837
I0614 12:34:43.261409   729 caffe_interface.cpp:171] Batch 53, top-1 = 0.94
I0614 12:34:43.279098   729 caffe_interface.cpp:171] Batch 54, accuracy = 0.9
I0614 12:34:43.279117   729 caffe_interface.cpp:171] Batch 54, loss = 0.409979
I0614 12:34:43.279120   729 caffe_interface.cpp:171] Batch 54, top-1 = 0.9
I0614 12:34:43.296523   729 caffe_interface.cpp:171] Batch 55, accuracy = 0.96
I0614 12:34:43.296542   729 caffe_interface.cpp:171] Batch 55, loss = 0.0967016
I0614 12:34:43.296546   729 caffe_interface.cpp:171] Batch 55, top-1 = 0.96
I0614 12:34:43.314368   729 caffe_interface.cpp:171] Batch 56, accuracy = 0.98
I0614 12:34:43.314388   729 caffe_interface.cpp:171] Batch 56, loss = 0.0865864
I0614 12:34:43.314390   729 caffe_interface.cpp:171] Batch 56, top-1 = 0.98
I0614 12:34:43.331988   729 caffe_interface.cpp:171] Batch 57, accuracy = 0.86
I0614 12:34:43.332010   729 caffe_interface.cpp:171] Batch 57, loss = 0.359039
I0614 12:34:43.332013   729 caffe_interface.cpp:171] Batch 57, top-1 = 0.86
I0614 12:34:43.349509   729 caffe_interface.cpp:171] Batch 58, accuracy = 0.92
I0614 12:34:43.349526   729 caffe_interface.cpp:171] Batch 58, loss = 0.260771
I0614 12:34:43.349530   729 caffe_interface.cpp:171] Batch 58, top-1 = 0.92
I0614 12:34:43.367278   729 caffe_interface.cpp:171] Batch 59, accuracy = 1
I0614 12:34:43.367296   729 caffe_interface.cpp:171] Batch 59, loss = 0.00270662
I0614 12:34:43.367300   729 caffe_interface.cpp:171] Batch 59, top-1 = 1
I0614 12:34:43.385010   729 caffe_interface.cpp:171] Batch 60, accuracy = 0.92
I0614 12:34:43.385030   729 caffe_interface.cpp:171] Batch 60, loss = 0.330292
I0614 12:34:43.385032   729 caffe_interface.cpp:171] Batch 60, top-1 = 0.92
I0614 12:34:43.402702   729 caffe_interface.cpp:171] Batch 61, accuracy = 0.98
I0614 12:34:43.402721   729 caffe_interface.cpp:171] Batch 61, loss = 0.0292018
I0614 12:34:43.402725   729 caffe_interface.cpp:171] Batch 61, top-1 = 0.98
I0614 12:34:43.420732   729 caffe_interface.cpp:171] Batch 62, accuracy = 0.98
I0614 12:34:43.420750   729 caffe_interface.cpp:171] Batch 62, loss = 0.131649
I0614 12:34:43.420754   729 caffe_interface.cpp:171] Batch 62, top-1 = 0.98
I0614 12:34:43.438401   729 caffe_interface.cpp:171] Batch 63, accuracy = 0.96
I0614 12:34:43.438421   729 caffe_interface.cpp:171] Batch 63, loss = 0.10056
I0614 12:34:43.438424   729 caffe_interface.cpp:171] Batch 63, top-1 = 0.96
I0614 12:34:43.456337   729 caffe_interface.cpp:171] Batch 64, accuracy = 0.96
I0614 12:34:43.456357   729 caffe_interface.cpp:171] Batch 64, loss = 0.137079
I0614 12:34:43.456360   729 caffe_interface.cpp:171] Batch 64, top-1 = 0.96
I0614 12:34:43.474053   729 caffe_interface.cpp:171] Batch 65, accuracy = 0.94
I0614 12:34:43.474072   729 caffe_interface.cpp:171] Batch 65, loss = 0.148588
I0614 12:34:43.474076   729 caffe_interface.cpp:171] Batch 65, top-1 = 0.94
I0614 12:34:43.491801   729 caffe_interface.cpp:171] Batch 66, accuracy = 0.98
I0614 12:34:43.491822   729 caffe_interface.cpp:171] Batch 66, loss = 0.081875
I0614 12:34:43.491827   729 caffe_interface.cpp:171] Batch 66, top-1 = 0.98
I0614 12:34:43.509249   729 caffe_interface.cpp:171] Batch 67, accuracy = 0.96
I0614 12:34:43.509267   729 caffe_interface.cpp:171] Batch 67, loss = 0.115875
I0614 12:34:43.509271   729 caffe_interface.cpp:171] Batch 67, top-1 = 0.96
I0614 12:34:43.526718   729 caffe_interface.cpp:171] Batch 68, accuracy = 0.96
I0614 12:34:43.526738   729 caffe_interface.cpp:171] Batch 68, loss = 0.143284
I0614 12:34:43.526742   729 caffe_interface.cpp:171] Batch 68, top-1 = 0.96
I0614 12:34:43.544260   729 caffe_interface.cpp:171] Batch 69, accuracy = 0.92
I0614 12:34:43.544277   729 caffe_interface.cpp:171] Batch 69, loss = 0.261495
I0614 12:34:43.544281   729 caffe_interface.cpp:171] Batch 69, top-1 = 0.92
I0614 12:34:43.561704   729 caffe_interface.cpp:171] Batch 70, accuracy = 0.98
I0614 12:34:43.561722   729 caffe_interface.cpp:171] Batch 70, loss = 0.0978362
I0614 12:34:43.561726   729 caffe_interface.cpp:171] Batch 70, top-1 = 0.98
I0614 12:34:43.579455   729 caffe_interface.cpp:171] Batch 71, accuracy = 1
I0614 12:34:43.579473   729 caffe_interface.cpp:171] Batch 71, loss = 0.0112701
I0614 12:34:43.579478   729 caffe_interface.cpp:171] Batch 71, top-1 = 1
I0614 12:34:43.596908   729 caffe_interface.cpp:171] Batch 72, accuracy = 1
I0614 12:34:43.596925   729 caffe_interface.cpp:171] Batch 72, loss = 0.0108377
I0614 12:34:43.596930   729 caffe_interface.cpp:171] Batch 72, top-1 = 1
I0614 12:34:43.614598   729 caffe_interface.cpp:171] Batch 73, accuracy = 0.96
I0614 12:34:43.614615   729 caffe_interface.cpp:171] Batch 73, loss = 0.211274
I0614 12:34:43.614809   729 caffe_interface.cpp:171] Batch 73, top-1 = 0.96
I0614 12:34:43.632676   729 caffe_interface.cpp:171] Batch 74, accuracy = 0.96
I0614 12:34:43.632696   729 caffe_interface.cpp:171] Batch 74, loss = 0.160629
I0614 12:34:43.632700   729 caffe_interface.cpp:171] Batch 74, top-1 = 0.96
I0614 12:34:43.650461   729 caffe_interface.cpp:171] Batch 75, accuracy = 0.94
I0614 12:34:43.650480   729 caffe_interface.cpp:171] Batch 75, loss = 0.224098
I0614 12:34:43.650485   729 caffe_interface.cpp:171] Batch 75, top-1 = 0.94
I0614 12:34:43.668304   729 caffe_interface.cpp:171] Batch 76, accuracy = 0.94
I0614 12:34:43.668323   729 caffe_interface.cpp:171] Batch 76, loss = 0.175388
I0614 12:34:43.668325   729 caffe_interface.cpp:171] Batch 76, top-1 = 0.94
I0614 12:34:43.685966   729 caffe_interface.cpp:171] Batch 77, accuracy = 0.94
I0614 12:34:43.685986   729 caffe_interface.cpp:171] Batch 77, loss = 0.124661
I0614 12:34:43.685988   729 caffe_interface.cpp:171] Batch 77, top-1 = 0.94
I0614 12:34:43.703698   729 caffe_interface.cpp:171] Batch 78, accuracy = 1
I0614 12:34:43.703716   729 caffe_interface.cpp:171] Batch 78, loss = 0.0181061
I0614 12:34:43.703720   729 caffe_interface.cpp:171] Batch 78, top-1 = 1
I0614 12:34:43.721441   729 caffe_interface.cpp:171] Batch 79, accuracy = 0.98
I0614 12:34:43.721460   729 caffe_interface.cpp:171] Batch 79, loss = 0.117804
I0614 12:34:43.721463   729 caffe_interface.cpp:171] Batch 79, top-1 = 0.98
I0614 12:34:43.721467   729 caffe_interface.cpp:176] Loss: 0.158723
I0614 12:34:43.721470   729 caffe_interface.cpp:188] accuracy = 0.9535
I0614 12:34:43.721478   729 caffe_interface.cpp:188] loss = 0.158723 (* 1 = 0.158723 loss)
I0614 12:34:43.721482   729 caffe_interface.cpp:188] top-1 = 0.9535
I0614 12:34:43.882592   729 sens_analyser.cpp:221] Analysis may take a long time, please wait patiently
I0614 12:34:43.882608   729 sens_analyser.cpp:222] Analysis completed 0%
I0614 12:34:52.454231   729 sens_analyser.cpp:290] Analysis completed 2%
I0614 12:35:01.158200   729 sens_analyser.cpp:290] Analysis completed 4%
I0614 12:35:09.948235   729 sens_analyser.cpp:290] Analysis completed 6%
I0614 12:35:18.777225   729 sens_analyser.cpp:290] Analysis completed 8%
I0614 12:35:27.532528   729 sens_analyser.cpp:290] Analysis completed 11%
I0614 12:35:36.238065   729 sens_analyser.cpp:290] Analysis completed 13%
I0614 12:35:44.947824   729 sens_analyser.cpp:290] Analysis completed 15%
I0614 12:35:53.736481   729 sens_analyser.cpp:290] Analysis completed 17%
I0614 12:36:02.515866   729 sens_analyser.cpp:290] Analysis completed 20%
I0614 12:36:11.161728   729 sens_analyser.cpp:290] Analysis completed 22%
I0614 12:36:19.889430   729 sens_analyser.cpp:290] Analysis completed 24%
I0614 12:36:28.841746   729 sens_analyser.cpp:290] Analysis completed 26%
I0614 12:36:37.601197   729 sens_analyser.cpp:290] Analysis completed 28%
I0614 12:36:46.394075   729 sens_analyser.cpp:290] Analysis completed 31%
I0614 12:36:55.175967   729 sens_analyser.cpp:290] Analysis completed 33%
I0614 12:37:03.846259   729 sens_analyser.cpp:290] Analysis completed 35%
I0614 12:37:12.473774   729 sens_analyser.cpp:290] Analysis completed 37%
I0614 12:37:21.105927   729 sens_analyser.cpp:290] Analysis completed 40%
I0614 12:37:29.844072   729 sens_analyser.cpp:290] Analysis completed 42%
I0614 12:37:38.525020   729 sens_analyser.cpp:290] Analysis completed 44%
I0614 12:37:47.242384   729 sens_analyser.cpp:290] Analysis completed 46%
I0614 12:37:55.851380   729 sens_analyser.cpp:290] Analysis completed 48%
I0614 12:38:04.605585   729 sens_analyser.cpp:290] Analysis completed 51%
I0614 12:38:13.422205   729 sens_analyser.cpp:290] Analysis completed 53%
I0614 12:38:22.241135   729 sens_analyser.cpp:290] Analysis completed 55%
I0614 12:38:30.983100   729 sens_analyser.cpp:290] Analysis completed 57%
I0614 12:38:39.573881   729 sens_analyser.cpp:290] Analysis completed 60%
I0614 12:38:48.288327   729 sens_analyser.cpp:290] Analysis completed 62%
I0614 12:38:56.992177   729 sens_analyser.cpp:290] Analysis completed 64%
I0614 12:39:05.844405   729 sens_analyser.cpp:290] Analysis completed 66%
I0614 12:39:14.567131   729 sens_analyser.cpp:290] Analysis completed 68%
I0614 12:39:23.346585   729 sens_analyser.cpp:290] Analysis completed 71%
I0614 12:39:32.003669   729 sens_analyser.cpp:290] Analysis completed 73%
I0614 12:39:40.717001   729 sens_analyser.cpp:290] Analysis completed 75%
I0614 12:39:49.207209   729 sens_analyser.cpp:290] Analysis completed 77%
I0614 12:39:57.929885   729 sens_analyser.cpp:290] Analysis completed 80%
I0614 12:40:06.704587   729 sens_analyser.cpp:290] Analysis completed 82%
I0614 12:40:15.552323   729 sens_analyser.cpp:290] Analysis completed 84%
I0614 12:40:24.241461   729 sens_analyser.cpp:290] Analysis completed 86%
I0614 12:40:32.955524   729 sens_analyser.cpp:290] Analysis completed 88%
I0614 12:40:41.685564   729 sens_analyser.cpp:290] Analysis completed 91%
I0614 12:40:50.457772   729 sens_analyser.cpp:290] Analysis completed 93%
I0614 12:40:59.188978   729 sens_analyser.cpp:290] Analysis completed 95%
I0614 12:41:07.921294   729 sens_analyser.cpp:290] Analysis completed 97%
I0614 12:41:16.833158   729 sens_analyser.cpp:290] Analysis completed 100%
I0614 12:41:16.854277   729 vai_p_caffe.cpp:259] Analysis done.

Now you can prune the model with the following command:
vai_p_caffe prune -config /workspace/TUTORIALS/VAI2.0bash-Caffe-ML-CATSvsDOGS/files/pruning/alexnetBNnoLRN/config0.prototxt
(c) Copyright 2016â2019 Xilinx, Inc. All rights reserved.

I0614 12:41:17.369849  2144 pruning_runner.cpp:234] Analysis info found.
I0614 12:41:18.429404  2144 pruning_runner.cpp:265] Start pruning, please wait...
I0614 12:41:29.897986  2144 pruning_runner.cpp:365] pruning done, output model: pruning/alexnetBNnoLRN/regular_rate_0/sparse.caffemodel
I0614 12:41:29.898015  2144 pruning_runner.cpp:379] summary of REGULAR compression with rate 0:
+-------------------------------------------------------------------+
| Item           | Baseline       | Compressed     | Delta          |
+-------------------------------------------------------------------+
| Accuracy       | 0.953499794    | 0.953499794    | 0              |
+-------------------------------------------------------------------+
| Weights        | 3.74857903 M   | 3.74857903 M   | 0%             |
+-------------------------------------------------------------------+
| Operations     | 2.05460167 G   | 2.05460167 G   | 0%             |
+-------------------------------------------------------------------+
To fine-tune the pruned model, please run:
vai_p_caffe finetune -config /workspace/TUTORIALS/VAI2.0bash-Caffe-ML-CATSvsDOGS/files/pruning/alexnetBNnoLRN/config0.prototxt
(c) Copyright 2016â2019 Xilinx, Inc. All rights reserved.

W0614 12:41:30.164048  2299 utils.cpp:207] BVLC BatchNormLayer without ScaleLayer detected: 3, it will be converted to NVCaffe Format.
W0614 12:41:30.164553  2299 utils.cpp:207] BVLC BatchNormLayer without ScaleLayer detected: 7, it will be converted to NVCaffe Format.
W0614 12:41:30.164592  2299 utils.cpp:207] BVLC BatchNormLayer without ScaleLayer detected: 21, it will be converted to NVCaffe Format.
I0614 12:41:30.258004  2299 vai_p_caffe.cpp:287] pruning/alexnetBNnoLRN/regular_rate_0/net_finetune.prototxt
I0614 12:41:30.462291  2299 gpu_memory.cpp:53] GPUMemory::Manager initialized with Caching (CUB) GPU Allocator
I0614 12:41:30.462313  2299 gpu_memory.cpp:55] Total memory: 25635127296, Free: 24776736768, dev_info[0]: total=25635127296 free=24776736768
I0614 12:41:30.462466  2299 caffe_interface.cpp:539] Using GPUs 0
I0614 12:41:30.462579  2299 caffe_interface.cpp:544] GPU 0: Quadro P6000
I0614 12:41:31.112977  2299 solver.cpp:51] Initializing solver from parameters: 
test_iter: 80
test_interval: 1000
base_lr: 0.001
display: 50
max_iter: 12000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 2500
snapshot: 6000
snapshot_prefix: "pruning/alexnetBNnoLRN/regular_rate_0/snapshots/"
solver_mode: GPU
device_id: 0
random_seed: 1201
net: "pruning/alexnetBNnoLRN/regular_rate_0/net_finetune.prototxt"
type: "Adam"
I0614 12:41:31.113983  2299 solver.cpp:99] Creating training net from net file: pruning/alexnetBNnoLRN/regular_rate_0/net_finetune.prototxt
I0614 12:41:31.114635  2299 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0614 12:41:31.114651  2299 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0614 12:41:31.114655  2299 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy-top1
I0614 12:41:31.114662  2299 net.cpp:52] Initializing net from parameters: 
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_value: 106
    mean_value: 116
    mean_value: 124
  }
  data_param {
    source: "input/lmdb/train_lmdb"
    batch_size: 256
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 0
    kernel_size: 8
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "bn1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn2"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "bn2"
  top: "relu2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "relu6"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "drop6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn7"
  type: "BatchNorm"
  bottom: "fc7"
  top: "bn7"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "bn7"
  top: "relu7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "relu7"
  top: "drop7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "drop7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0614 12:41:31.115129  2299 layer_factory.hpp:77] Creating layer data
I0614 12:41:31.115270  2299 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0614 12:41:31.119367  2336 db_lmdb.cpp:35] Opened lmdb input/lmdb/train_lmdb
I0614 12:41:31.119400  2336 db_lmdb.cpp:38] Items count: 20000
I0614 12:41:31.119429  2336 data_reader.cpp:124] TRAIN: reading data using 1 channel(s)
I0614 12:41:31.121016  2299 net.cpp:94] Creating Layer data
I0614 12:41:31.121053  2299 net.cpp:409] data -> data
I0614 12:41:31.121081  2299 net.cpp:409] data -> label
I0614 12:41:31.121230  2299 data_layer.cpp:78] ReshapePrefetch 256, 3, 227, 227
I0614 12:41:31.121408  2299 data_layer.cpp:83] output data size: 256,3,227,227
I0614 12:41:31.652305  2299 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0614 12:41:31.652525  2299 net.cpp:144] Setting up data
I0614 12:41:31.652531  2299 net.cpp:151] Top shape: 256 3 227 227 (39574272)
I0614 12:41:31.652539  2299 net.cpp:151] Top shape: 256 (256)
I0614 12:41:31.652544  2299 net.cpp:159] Memory required for data: 158298112
I0614 12:41:31.652549  2299 layer_factory.hpp:77] Creating layer conv1
I0614 12:41:31.652559  2299 net.cpp:94] Creating Layer conv1
I0614 12:41:31.652563  2299 net.cpp:435] conv1 <- data
I0614 12:41:31.652570  2299 net.cpp:409] conv1 -> conv1
I0614 12:41:31.653009  2299 net.cpp:144] Setting up conv1
I0614 12:41:31.653017  2299 net.cpp:151] Top shape: 256 96 55 55 (74342400)
I0614 12:41:31.653023  2299 net.cpp:159] Memory required for data: 455667712
I0614 12:41:31.653033  2299 layer_factory.hpp:77] Creating layer bn1
I0614 12:41:31.653040  2299 net.cpp:94] Creating Layer bn1
I0614 12:41:31.653043  2299 net.cpp:435] bn1 <- conv1
I0614 12:41:31.653048  2299 net.cpp:409] bn1 -> bn1
I0614 12:41:31.653344  2299 net.cpp:144] Setting up bn1
I0614 12:41:31.653352  2299 net.cpp:151] Top shape: 256 96 55 55 (74342400)
I0614 12:41:31.653357  2299 net.cpp:159] Memory required for data: 753037312
I0614 12:41:31.653367  2299 layer_factory.hpp:77] Creating layer relu1
I0614 12:41:31.653371  2299 net.cpp:94] Creating Layer relu1
I0614 12:41:31.653375  2299 net.cpp:435] relu1 <- bn1
I0614 12:41:31.653386  2299 net.cpp:409] relu1 -> relu1
I0614 12:41:31.653398  2299 net.cpp:144] Setting up relu1
I0614 12:41:31.653403  2299 net.cpp:151] Top shape: 256 96 55 55 (74342400)
I0614 12:41:31.653407  2299 net.cpp:159] Memory required for data: 1050406912
I0614 12:41:31.653411  2299 layer_factory.hpp:77] Creating layer pool1
I0614 12:41:31.653417  2299 net.cpp:94] Creating Layer pool1
I0614 12:41:31.653421  2299 net.cpp:435] pool1 <- relu1
I0614 12:41:31.653426  2299 net.cpp:409] pool1 -> pool1
I0614 12:41:31.653450  2299 net.cpp:144] Setting up pool1
I0614 12:41:31.653453  2299 net.cpp:151] Top shape: 256 96 27 27 (17915904)
I0614 12:41:31.653458  2299 net.cpp:159] Memory required for data: 1122070528
I0614 12:41:31.653461  2299 layer_factory.hpp:77] Creating layer conv2
I0614 12:41:31.653468  2299 net.cpp:94] Creating Layer conv2
I0614 12:41:31.653472  2299 net.cpp:435] conv2 <- pool1
I0614 12:41:31.653476  2299 net.cpp:409] conv2 -> conv2
I0614 12:41:31.670047  2299 net.cpp:144] Setting up conv2
I0614 12:41:31.670066  2299 net.cpp:151] Top shape: 256 256 27 27 (47775744)
I0614 12:41:31.670075  2299 net.cpp:159] Memory required for data: 1313173504
I0614 12:41:31.670086  2299 layer_factory.hpp:77] Creating layer bn2
I0614 12:41:31.670095  2299 net.cpp:94] Creating Layer bn2
I0614 12:41:31.670101  2299 net.cpp:435] bn2 <- conv2
I0614 12:41:31.670109  2299 net.cpp:409] bn2 -> bn2
I0614 12:41:31.670423  2299 net.cpp:144] Setting up bn2
I0614 12:41:31.670431  2299 net.cpp:151] Top shape: 256 256 27 27 (47775744)
I0614 12:41:31.670437  2299 net.cpp:159] Memory required for data: 1504276480
I0614 12:41:31.670447  2299 layer_factory.hpp:77] Creating layer relu2
I0614 12:41:31.670454  2299 net.cpp:94] Creating Layer relu2
I0614 12:41:31.670459  2299 net.cpp:435] relu2 <- bn2
I0614 12:41:31.670464  2299 net.cpp:409] relu2 -> relu2
I0614 12:41:31.670478  2299 net.cpp:144] Setting up relu2
I0614 12:41:31.670483  2299 net.cpp:151] Top shape: 256 256 27 27 (47775744)
I0614 12:41:31.670490  2299 net.cpp:159] Memory required for data: 1695379456
I0614 12:41:31.670495  2299 layer_factory.hpp:77] Creating layer pool2
I0614 12:41:31.670501  2299 net.cpp:94] Creating Layer pool2
I0614 12:41:31.670506  2299 net.cpp:435] pool2 <- relu2
I0614 12:41:31.670511  2299 net.cpp:409] pool2 -> pool2
I0614 12:41:31.670529  2299 net.cpp:144] Setting up pool2
I0614 12:41:31.670534  2299 net.cpp:151] Top shape: 256 256 13 13 (11075584)
I0614 12:41:31.670540  2299 net.cpp:159] Memory required for data: 1739681792
I0614 12:41:31.670545  2299 layer_factory.hpp:77] Creating layer conv3
I0614 12:41:31.670819  2299 net.cpp:94] Creating Layer conv3
I0614 12:41:31.670825  2299 net.cpp:435] conv3 <- pool2
I0614 12:41:31.670832  2299 net.cpp:409] conv3 -> conv3
I0614 12:41:31.686761  2299 net.cpp:144] Setting up conv3
I0614 12:41:31.686820  2299 net.cpp:151] Top shape: 256 384 13 13 (16613376)
I0614 12:41:31.686832  2299 net.cpp:159] Memory required for data: 1806135296
I0614 12:41:31.686844  2299 layer_factory.hpp:77] Creating layer relu3
I0614 12:41:31.686856  2299 net.cpp:94] Creating Layer relu3
I0614 12:41:31.686861  2299 net.cpp:435] relu3 <- conv3
I0614 12:41:31.686882  2299 net.cpp:409] relu3 -> relu3
I0614 12:41:31.686909  2299 net.cpp:144] Setting up relu3
I0614 12:41:31.686915  2299 net.cpp:151] Top shape: 256 384 13 13 (16613376)
I0614 12:41:31.686923  2299 net.cpp:159] Memory required for data: 1872588800
I0614 12:41:31.686928  2299 layer_factory.hpp:77] Creating layer conv4
I0614 12:41:31.686939  2299 net.cpp:94] Creating Layer conv4
I0614 12:41:31.686944  2299 net.cpp:435] conv4 <- relu3
I0614 12:41:31.686966  2299 net.cpp:409] conv4 -> conv4
I0614 12:41:31.719290  2299 net.cpp:144] Setting up conv4
I0614 12:41:31.719321  2299 net.cpp:151] Top shape: 256 384 13 13 (16613376)
I0614 12:41:31.719334  2299 net.cpp:159] Memory required for data: 1939042304
I0614 12:41:31.719362  2299 layer_factory.hpp:77] Creating layer relu4
I0614 12:41:31.719374  2299 net.cpp:94] Creating Layer relu4
I0614 12:41:31.719383  2299 net.cpp:435] relu4 <- conv4
I0614 12:41:31.719393  2299 net.cpp:409] relu4 -> relu4
I0614 12:41:31.719421  2299 net.cpp:144] Setting up relu4
I0614 12:41:31.719429  2299 net.cpp:151] Top shape: 256 384 13 13 (16613376)
I0614 12:41:31.719439  2299 net.cpp:159] Memory required for data: 2005495808
I0614 12:41:31.719444  2299 layer_factory.hpp:77] Creating layer conv5
I0614 12:41:31.719457  2299 net.cpp:94] Creating Layer conv5
I0614 12:41:31.719465  2299 net.cpp:435] conv5 <- relu4
I0614 12:41:31.719473  2299 net.cpp:409] conv5 -> conv5
I0614 12:41:31.738821  2299 net.cpp:144] Setting up conv5
I0614 12:41:31.738843  2299 net.cpp:151] Top shape: 256 256 13 13 (11075584)
I0614 12:41:31.738853  2299 net.cpp:159] Memory required for data: 2049798144
I0614 12:41:31.738862  2299 layer_factory.hpp:77] Creating layer relu5
I0614 12:41:31.738869  2299 net.cpp:94] Creating Layer relu5
I0614 12:41:31.738874  2299 net.cpp:435] relu5 <- conv5
I0614 12:41:31.738881  2299 net.cpp:409] relu5 -> relu5
I0614 12:41:31.738899  2299 net.cpp:144] Setting up relu5
I0614 12:41:31.738903  2299 net.cpp:151] Top shape: 256 256 13 13 (11075584)
I0614 12:41:31.738909  2299 net.cpp:159] Memory required for data: 2094100480
I0614 12:41:31.738911  2299 layer_factory.hpp:77] Creating layer pool5
I0614 12:41:31.738917  2299 net.cpp:94] Creating Layer pool5
I0614 12:41:31.738921  2299 net.cpp:435] pool5 <- relu5
I0614 12:41:31.738926  2299 net.cpp:409] pool5 -> pool5
I0614 12:41:31.738945  2299 net.cpp:144] Setting up pool5
I0614 12:41:31.738948  2299 net.cpp:151] Top shape: 256 256 6 6 (2359296)
I0614 12:41:31.738953  2299 net.cpp:159] Memory required for data: 2103537664
I0614 12:41:31.738957  2299 layer_factory.hpp:77] Creating layer fc6
I0614 12:41:31.738965  2299 net.cpp:94] Creating Layer fc6
I0614 12:41:31.738968  2299 net.cpp:435] fc6 <- pool5
I0614 12:41:31.738973  2299 net.cpp:409] fc6 -> fc6
I0614 12:41:32.149092  2299 net.cpp:144] Setting up fc6
I0614 12:41:32.149117  2299 net.cpp:151] Top shape: 256 4096 (1048576)
I0614 12:41:32.149125  2299 net.cpp:159] Memory required for data: 2107731968
I0614 12:41:32.149150  2299 layer_factory.hpp:77] Creating layer relu6
I0614 12:41:32.149156  2299 net.cpp:94] Creating Layer relu6
I0614 12:41:32.149160  2299 net.cpp:435] relu6 <- fc6
I0614 12:41:32.149165  2299 net.cpp:409] relu6 -> relu6
I0614 12:41:32.149180  2299 net.cpp:144] Setting up relu6
I0614 12:41:32.149184  2299 net.cpp:151] Top shape: 256 4096 (1048576)
I0614 12:41:32.149188  2299 net.cpp:159] Memory required for data: 2111926272
I0614 12:41:32.149191  2299 layer_factory.hpp:77] Creating layer drop6
I0614 12:41:32.149196  2299 net.cpp:94] Creating Layer drop6
I0614 12:41:32.149585  2299 net.cpp:435] drop6 <- relu6
I0614 12:41:32.149591  2299 net.cpp:409] drop6 -> drop6
I0614 12:41:32.149610  2299 net.cpp:144] Setting up drop6
I0614 12:41:32.149618  2299 net.cpp:151] Top shape: 256 4096 (1048576)
I0614 12:41:32.149626  2299 net.cpp:159] Memory required for data: 2116120576
I0614 12:41:32.149629  2299 layer_factory.hpp:77] Creating layer fc7
I0614 12:41:32.149639  2299 net.cpp:94] Creating Layer fc7
I0614 12:41:32.149643  2299 net.cpp:435] fc7 <- drop6
I0614 12:41:32.149649  2299 net.cpp:409] fc7 -> fc7
I0614 12:41:32.306823  2299 net.cpp:144] Setting up fc7
I0614 12:41:32.306849  2299 net.cpp:151] Top shape: 256 4096 (1048576)
I0614 12:41:32.306859  2299 net.cpp:159] Memory required for data: 2120314880
I0614 12:41:32.306869  2299 layer_factory.hpp:77] Creating layer bn7
I0614 12:41:32.306879  2299 net.cpp:94] Creating Layer bn7
I0614 12:41:32.306883  2299 net.cpp:435] bn7 <- fc7
I0614 12:41:32.306890  2299 net.cpp:409] bn7 -> bn7
I0614 12:41:32.307157  2299 net.cpp:144] Setting up bn7
I0614 12:41:32.307164  2299 net.cpp:151] Top shape: 256 4096 (1048576)
I0614 12:41:32.307169  2299 net.cpp:159] Memory required for data: 2124509184
I0614 12:41:32.307176  2299 layer_factory.hpp:77] Creating layer relu7
I0614 12:41:32.307183  2299 net.cpp:94] Creating Layer relu7
I0614 12:41:32.307185  2299 net.cpp:435] relu7 <- bn7
I0614 12:41:32.307190  2299 net.cpp:409] relu7 -> relu7
I0614 12:41:32.307202  2299 net.cpp:144] Setting up relu7
I0614 12:41:32.307206  2299 net.cpp:151] Top shape: 256 4096 (1048576)
I0614 12:41:32.307210  2299 net.cpp:159] Memory required for data: 2128703488
I0614 12:41:32.307229  2299 layer_factory.hpp:77] Creating layer drop7
I0614 12:41:32.307235  2299 net.cpp:94] Creating Layer drop7
I0614 12:41:32.307240  2299 net.cpp:435] drop7 <- relu7
I0614 12:41:32.307245  2299 net.cpp:409] drop7 -> drop7
I0614 12:41:32.307261  2299 net.cpp:144] Setting up drop7
I0614 12:41:32.307267  2299 net.cpp:151] Top shape: 256 4096 (1048576)
I0614 12:41:32.307273  2299 net.cpp:159] Memory required for data: 2132897792
I0614 12:41:32.307277  2299 layer_factory.hpp:77] Creating layer fc8
I0614 12:41:32.307286  2299 net.cpp:94] Creating Layer fc8
I0614 12:41:32.307292  2299 net.cpp:435] fc8 <- drop7
I0614 12:41:32.307298  2299 net.cpp:409] fc8 -> fc8
I0614 12:41:32.307431  2299 net.cpp:144] Setting up fc8
I0614 12:41:32.307435  2299 net.cpp:151] Top shape: 256 2 (512)
I0614 12:41:32.307440  2299 net.cpp:159] Memory required for data: 2132899840
I0614 12:41:32.307446  2299 layer_factory.hpp:77] Creating layer loss
I0614 12:41:32.307451  2299 net.cpp:94] Creating Layer loss
I0614 12:41:32.307456  2299 net.cpp:435] loss <- fc8
I0614 12:41:32.307459  2299 net.cpp:435] loss <- label
I0614 12:41:32.307464  2299 net.cpp:409] loss -> loss
I0614 12:41:32.307471  2299 layer_factory.hpp:77] Creating layer loss
I0614 12:41:32.307513  2299 net.cpp:144] Setting up loss
I0614 12:41:32.307518  2299 net.cpp:151] Top shape: (1)
I0614 12:41:32.307521  2299 net.cpp:154]     with loss weight 1
I0614 12:41:32.307533  2299 net.cpp:159] Memory required for data: 2132899844
I0614 12:41:32.307538  2299 net.cpp:220] loss needs backward computation.
I0614 12:41:32.307541  2299 net.cpp:220] fc8 needs backward computation.
I0614 12:41:32.307545  2299 net.cpp:220] drop7 needs backward computation.
I0614 12:41:32.307549  2299 net.cpp:220] relu7 needs backward computation.
I0614 12:41:32.307552  2299 net.cpp:220] bn7 needs backward computation.
I0614 12:41:32.307556  2299 net.cpp:220] fc7 needs backward computation.
I0614 12:41:32.307560  2299 net.cpp:220] drop6 needs backward computation.
I0614 12:41:32.307565  2299 net.cpp:220] relu6 needs backward computation.
I0614 12:41:32.307570  2299 net.cpp:220] fc6 needs backward computation.
I0614 12:41:32.307575  2299 net.cpp:220] pool5 needs backward computation.
I0614 12:41:32.307581  2299 net.cpp:220] relu5 needs backward computation.
I0614 12:41:32.307586  2299 net.cpp:220] conv5 needs backward computation.
I0614 12:41:32.307591  2299 net.cpp:220] relu4 needs backward computation.
I0614 12:41:32.307901  2299 net.cpp:220] conv4 needs backward computation.
I0614 12:41:32.307906  2299 net.cpp:220] relu3 needs backward computation.
I0614 12:41:32.307911  2299 net.cpp:220] conv3 needs backward computation.
I0614 12:41:32.307915  2299 net.cpp:220] pool2 needs backward computation.
I0614 12:41:32.307919  2299 net.cpp:220] relu2 needs backward computation.
I0614 12:41:32.307924  2299 net.cpp:220] bn2 needs backward computation.
I0614 12:41:32.307927  2299 net.cpp:220] conv2 needs backward computation.
I0614 12:41:32.307931  2299 net.cpp:220] pool1 needs backward computation.
I0614 12:41:32.307935  2299 net.cpp:220] relu1 needs backward computation.
I0614 12:41:32.307940  2299 net.cpp:220] bn1 needs backward computation.
I0614 12:41:32.307943  2299 net.cpp:220] conv1 needs backward computation.
I0614 12:41:32.307948  2299 net.cpp:222] data does not need backward computation.
I0614 12:41:32.307952  2299 net.cpp:264] This network produces output loss
I0614 12:41:32.307972  2299 net.cpp:284] Network initialization done.
I0614 12:41:32.308866  2299 solver.cpp:189] Creating test net (#0) specified by net file: pruning/alexnetBNnoLRN/regular_rate_0/net_finetune.prototxt
I0614 12:41:32.308902  2299 net.cpp:323] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0614 12:41:32.308917  2299 net.cpp:52] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_value: 106
    mean_value: 116
    mean_value: 124
  }
  data_param {
    source: "input/lmdb/valid_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 0
    kernel_size: 8
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "bn1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn2"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "bn2"
  top: "relu2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "relu6"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "drop6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn7"
  type: "BatchNorm"
  bottom: "fc7"
  top: "bn7"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "bn7"
  top: "relu7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "relu7"
  top: "drop7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "drop7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy-top1"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "top-1"
  include {
    phase: TEST
  }
}
I0614 12:41:32.309418  2299 layer_factory.hpp:77] Creating layer data
I0614 12:41:32.309466  2299 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0614 12:41:32.311676  2299 net.cpp:94] Creating Layer data
I0614 12:41:32.311717  2299 net.cpp:409] data -> data
I0614 12:41:32.311744  2299 net.cpp:409] data -> label
I0614 12:41:32.313798  2366 db_lmdb.cpp:35] Opened lmdb input/lmdb/valid_lmdb
I0614 12:41:32.313828  2366 db_lmdb.cpp:38] Items count: 4000
I0614 12:41:32.313868  2366 data_reader.cpp:124] TEST: reading data using 1 channel(s)
I0614 12:41:32.314297  2299 data_layer.cpp:78] ReshapePrefetch 50, 3, 227, 227
I0614 12:41:32.314515  2299 data_layer.cpp:83] output data size: 50,3,227,227
I0614 12:41:32.437928  2299 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0614 12:41:32.438165  2299 net.cpp:144] Setting up data
I0614 12:41:32.438170  2299 net.cpp:151] Top shape: 50 3 227 227 (7729350)
I0614 12:41:32.438179  2299 net.cpp:151] Top shape: 50 (50)
I0614 12:41:32.438184  2299 net.cpp:159] Memory required for data: 30917600
I0614 12:41:32.438189  2299 layer_factory.hpp:77] Creating layer label_data_1_split
I0614 12:41:32.438197  2299 net.cpp:94] Creating Layer label_data_1_split
I0614 12:41:32.438201  2299 net.cpp:435] label_data_1_split <- label
I0614 12:41:32.438206  2299 net.cpp:409] label_data_1_split -> label_data_1_split_0
I0614 12:41:32.438215  2299 net.cpp:409] label_data_1_split -> label_data_1_split_1
I0614 12:41:32.438220  2299 net.cpp:409] label_data_1_split -> label_data_1_split_2
I0614 12:41:32.438261  2299 net.cpp:144] Setting up label_data_1_split
I0614 12:41:32.438263  2299 net.cpp:151] Top shape: 50 (50)
I0614 12:41:32.438267  2299 net.cpp:151] Top shape: 50 (50)
I0614 12:41:32.438270  2299 net.cpp:151] Top shape: 50 (50)
I0614 12:41:32.438273  2299 net.cpp:159] Memory required for data: 30918200
I0614 12:41:32.438277  2299 layer_factory.hpp:77] Creating layer conv1
I0614 12:41:32.438285  2299 net.cpp:94] Creating Layer conv1
I0614 12:41:32.438288  2299 net.cpp:435] conv1 <- data
I0614 12:41:32.438292  2299 net.cpp:409] conv1 -> conv1
I0614 12:41:32.438637  2299 net.cpp:144] Setting up conv1
I0614 12:41:32.438645  2299 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0614 12:41:32.438652  2299 net.cpp:159] Memory required for data: 88998200
I0614 12:41:32.438664  2299 layer_factory.hpp:77] Creating layer bn1
I0614 12:41:32.438671  2299 net.cpp:94] Creating Layer bn1
I0614 12:41:32.438674  2299 net.cpp:435] bn1 <- conv1
I0614 12:41:32.438679  2299 net.cpp:409] bn1 -> bn1
I0614 12:41:32.439033  2299 net.cpp:144] Setting up bn1
I0614 12:41:32.439042  2299 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0614 12:41:32.439049  2299 net.cpp:159] Memory required for data: 147078200
I0614 12:41:32.439059  2299 layer_factory.hpp:77] Creating layer relu1
I0614 12:41:32.439066  2299 net.cpp:94] Creating Layer relu1
I0614 12:41:32.439070  2299 net.cpp:435] relu1 <- bn1
I0614 12:41:32.439075  2299 net.cpp:409] relu1 -> relu1
I0614 12:41:32.439087  2299 net.cpp:144] Setting up relu1
I0614 12:41:32.439091  2299 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0614 12:41:32.439096  2299 net.cpp:159] Memory required for data: 205158200
I0614 12:41:32.439100  2299 layer_factory.hpp:77] Creating layer pool1
I0614 12:41:32.439105  2299 net.cpp:94] Creating Layer pool1
I0614 12:41:32.439110  2299 net.cpp:435] pool1 <- relu1
I0614 12:41:32.439114  2299 net.cpp:409] pool1 -> pool1
I0614 12:41:32.439131  2299 net.cpp:144] Setting up pool1
I0614 12:41:32.439134  2299 net.cpp:151] Top shape: 50 96 27 27 (3499200)
I0614 12:41:32.439139  2299 net.cpp:159] Memory required for data: 219155000
I0614 12:41:32.439142  2299 layer_factory.hpp:77] Creating layer conv2
I0614 12:41:32.439149  2299 net.cpp:94] Creating Layer conv2
I0614 12:41:32.439153  2299 net.cpp:435] conv2 <- pool1
I0614 12:41:32.439158  2299 net.cpp:409] conv2 -> conv2
I0614 12:41:32.446702  2299 net.cpp:144] Setting up conv2
I0614 12:41:32.446724  2299 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0614 12:41:32.446735  2299 net.cpp:159] Memory required for data: 256479800
I0614 12:41:32.446749  2299 layer_factory.hpp:77] Creating layer bn2
I0614 12:41:32.446761  2299 net.cpp:94] Creating Layer bn2
I0614 12:41:32.446767  2299 net.cpp:435] bn2 <- conv2
I0614 12:41:32.446775  2299 net.cpp:409] bn2 -> bn2
I0614 12:41:32.447134  2299 net.cpp:144] Setting up bn2
I0614 12:41:32.447168  2299 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0614 12:41:32.447178  2299 net.cpp:159] Memory required for data: 293804600
I0614 12:41:32.447190  2299 layer_factory.hpp:77] Creating layer relu2
I0614 12:41:32.447198  2299 net.cpp:94] Creating Layer relu2
I0614 12:41:32.447203  2299 net.cpp:435] relu2 <- bn2
I0614 12:41:32.447211  2299 net.cpp:409] relu2 -> relu2
I0614 12:41:32.447229  2299 net.cpp:144] Setting up relu2
I0614 12:41:32.447654  2299 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0614 12:41:32.447705  2299 net.cpp:159] Memory required for data: 331129400
I0614 12:41:32.447723  2299 layer_factory.hpp:77] Creating layer pool2
I0614 12:41:32.447751  2299 net.cpp:94] Creating Layer pool2
I0614 12:41:32.447767  2299 net.cpp:435] pool2 <- relu2
I0614 12:41:32.447791  2299 net.cpp:409] pool2 -> pool2
I0614 12:41:32.447901  2299 net.cpp:144] Setting up pool2
I0614 12:41:32.447916  2299 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0614 12:41:32.447939  2299 net.cpp:159] Memory required for data: 339782200
I0614 12:41:32.447959  2299 layer_factory.hpp:77] Creating layer conv3
I0614 12:41:32.447989  2299 net.cpp:94] Creating Layer conv3
I0614 12:41:32.448005  2299 net.cpp:435] conv3 <- pool2
I0614 12:41:32.448022  2299 net.cpp:409] conv3 -> conv3
I0614 12:41:32.474387  2299 net.cpp:144] Setting up conv3
I0614 12:41:32.474416  2299 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0614 12:41:32.474427  2299 net.cpp:159] Memory required for data: 352761400
I0614 12:41:32.474439  2299 layer_factory.hpp:77] Creating layer relu3
I0614 12:41:32.474449  2299 net.cpp:94] Creating Layer relu3
I0614 12:41:32.474455  2299 net.cpp:435] relu3 <- conv3
I0614 12:41:32.474463  2299 net.cpp:409] relu3 -> relu3
I0614 12:41:32.474488  2299 net.cpp:144] Setting up relu3
I0614 12:41:32.474493  2299 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0614 12:41:32.474500  2299 net.cpp:159] Memory required for data: 365740600
I0614 12:41:32.474504  2299 layer_factory.hpp:77] Creating layer conv4
I0614 12:41:32.474515  2299 net.cpp:94] Creating Layer conv4
I0614 12:41:32.474520  2299 net.cpp:435] conv4 <- relu3
I0614 12:41:32.474527  2299 net.cpp:409] conv4 -> conv4
I0614 12:41:32.494649  2299 net.cpp:144] Setting up conv4
I0614 12:41:32.494714  2299 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0614 12:41:32.494727  2299 net.cpp:159] Memory required for data: 378719800
I0614 12:41:32.494745  2299 layer_factory.hpp:77] Creating layer relu4
I0614 12:41:32.494755  2299 net.cpp:94] Creating Layer relu4
I0614 12:41:32.494761  2299 net.cpp:435] relu4 <- conv4
I0614 12:41:32.494771  2299 net.cpp:409] relu4 -> relu4
I0614 12:41:32.494808  2299 net.cpp:144] Setting up relu4
I0614 12:41:32.494814  2299 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0614 12:41:32.494822  2299 net.cpp:159] Memory required for data: 391699000
I0614 12:41:32.494827  2299 layer_factory.hpp:77] Creating layer conv5
I0614 12:41:32.494836  2299 net.cpp:94] Creating Layer conv5
I0614 12:41:32.494843  2299 net.cpp:435] conv5 <- relu4
I0614 12:41:32.494849  2299 net.cpp:409] conv5 -> conv5
I0614 12:41:32.505362  2299 net.cpp:144] Setting up conv5
I0614 12:41:32.505429  2299 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0614 12:41:32.505441  2299 net.cpp:159] Memory required for data: 400351800
I0614 12:41:32.505455  2299 layer_factory.hpp:77] Creating layer relu5
I0614 12:41:32.505463  2299 net.cpp:94] Creating Layer relu5
I0614 12:41:32.505470  2299 net.cpp:435] relu5 <- conv5
I0614 12:41:32.505491  2299 net.cpp:409] relu5 -> relu5
I0614 12:41:32.505522  2299 net.cpp:144] Setting up relu5
I0614 12:41:32.505527  2299 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0614 12:41:32.505534  2299 net.cpp:159] Memory required for data: 409004600
I0614 12:41:32.505539  2299 layer_factory.hpp:77] Creating layer pool5
I0614 12:41:32.505549  2299 net.cpp:94] Creating Layer pool5
I0614 12:41:32.505554  2299 net.cpp:435] pool5 <- relu5
I0614 12:41:32.505563  2299 net.cpp:409] pool5 -> pool5
I0614 12:41:32.505607  2299 net.cpp:144] Setting up pool5
I0614 12:41:32.505614  2299 net.cpp:151] Top shape: 50 256 6 6 (460800)
I0614 12:41:32.505621  2299 net.cpp:159] Memory required for data: 410847800
I0614 12:41:32.505626  2299 layer_factory.hpp:77] Creating layer fc6
I0614 12:41:32.505635  2299 net.cpp:94] Creating Layer fc6
I0614 12:41:32.505641  2299 net.cpp:435] fc6 <- pool5
I0614 12:41:32.505648  2299 net.cpp:409] fc6 -> fc6
I0614 12:41:32.860298  2299 net.cpp:144] Setting up fc6
I0614 12:41:32.860322  2299 net.cpp:151] Top shape: 50 4096 (204800)
I0614 12:41:32.860796  2299 net.cpp:159] Memory required for data: 411667000
I0614 12:41:32.860808  2299 layer_factory.hpp:77] Creating layer relu6
I0614 12:41:32.860816  2299 net.cpp:94] Creating Layer relu6
I0614 12:41:32.860821  2299 net.cpp:435] relu6 <- fc6
I0614 12:41:32.860827  2299 net.cpp:409] relu6 -> relu6
I0614 12:41:32.860853  2299 net.cpp:144] Setting up relu6
I0614 12:41:32.860857  2299 net.cpp:151] Top shape: 50 4096 (204800)
I0614 12:41:32.860863  2299 net.cpp:159] Memory required for data: 412486200
I0614 12:41:32.860867  2299 layer_factory.hpp:77] Creating layer drop6
I0614 12:41:32.860875  2299 net.cpp:94] Creating Layer drop6
I0614 12:41:32.860880  2299 net.cpp:435] drop6 <- relu6
I0614 12:41:32.860888  2299 net.cpp:409] drop6 -> drop6
I0614 12:41:32.860909  2299 net.cpp:144] Setting up drop6
I0614 12:41:32.860914  2299 net.cpp:151] Top shape: 50 4096 (204800)
I0614 12:41:32.860920  2299 net.cpp:159] Memory required for data: 413305400
I0614 12:41:32.860924  2299 layer_factory.hpp:77] Creating layer fc7
I0614 12:41:32.860930  2299 net.cpp:94] Creating Layer fc7
I0614 12:41:32.860934  2299 net.cpp:435] fc7 <- drop6
I0614 12:41:32.860939  2299 net.cpp:409] fc7 -> fc7
I0614 12:41:33.030596  2299 net.cpp:144] Setting up fc7
I0614 12:41:33.030625  2299 net.cpp:151] Top shape: 50 4096 (204800)
I0614 12:41:33.030634  2299 net.cpp:159] Memory required for data: 414124600
I0614 12:41:33.030644  2299 layer_factory.hpp:77] Creating layer bn7
I0614 12:41:33.030654  2299 net.cpp:94] Creating Layer bn7
I0614 12:41:33.030659  2299 net.cpp:435] bn7 <- fc7
I0614 12:41:33.030665  2299 net.cpp:409] bn7 -> bn7
I0614 12:41:33.030985  2299 net.cpp:144] Setting up bn7
I0614 12:41:33.030993  2299 net.cpp:151] Top shape: 50 4096 (204800)
I0614 12:41:33.030998  2299 net.cpp:159] Memory required for data: 414943800
I0614 12:41:33.031006  2299 layer_factory.hpp:77] Creating layer relu7
I0614 12:41:33.031013  2299 net.cpp:94] Creating Layer relu7
I0614 12:41:33.031016  2299 net.cpp:435] relu7 <- bn7
I0614 12:41:33.031021  2299 net.cpp:409] relu7 -> relu7
I0614 12:41:33.031034  2299 net.cpp:144] Setting up relu7
I0614 12:41:33.031038  2299 net.cpp:151] Top shape: 50 4096 (204800)
I0614 12:41:33.031044  2299 net.cpp:159] Memory required for data: 415763000
I0614 12:41:33.031046  2299 layer_factory.hpp:77] Creating layer drop7
I0614 12:41:33.031052  2299 net.cpp:94] Creating Layer drop7
I0614 12:41:33.031056  2299 net.cpp:435] drop7 <- relu7
I0614 12:41:33.031061  2299 net.cpp:409] drop7 -> drop7
I0614 12:41:33.031077  2299 net.cpp:144] Setting up drop7
I0614 12:41:33.031081  2299 net.cpp:151] Top shape: 50 4096 (204800)
I0614 12:41:33.031086  2299 net.cpp:159] Memory required for data: 416582200
I0614 12:41:33.031090  2299 layer_factory.hpp:77] Creating layer fc8
I0614 12:41:33.031097  2299 net.cpp:94] Creating Layer fc8
I0614 12:41:33.031101  2299 net.cpp:435] fc8 <- drop7
I0614 12:41:33.031106  2299 net.cpp:409] fc8 -> fc8
I0614 12:41:33.031235  2299 net.cpp:144] Setting up fc8
I0614 12:41:33.031239  2299 net.cpp:151] Top shape: 50 2 (100)
I0614 12:41:33.031244  2299 net.cpp:159] Memory required for data: 416582600
I0614 12:41:33.031250  2299 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0614 12:41:33.031255  2299 net.cpp:94] Creating Layer fc8_fc8_0_split
I0614 12:41:33.031258  2299 net.cpp:435] fc8_fc8_0_split <- fc8
I0614 12:41:33.031263  2299 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0614 12:41:33.031270  2299 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0614 12:41:33.031275  2299 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_2
I0614 12:41:33.031296  2299 net.cpp:144] Setting up fc8_fc8_0_split
I0614 12:41:33.031299  2299 net.cpp:151] Top shape: 50 2 (100)
I0614 12:41:33.031303  2299 net.cpp:151] Top shape: 50 2 (100)
I0614 12:41:33.031307  2299 net.cpp:151] Top shape: 50 2 (100)
I0614 12:41:33.031312  2299 net.cpp:159] Memory required for data: 416583800
I0614 12:41:33.031316  2299 layer_factory.hpp:77] Creating layer accuracy
I0614 12:41:33.031332  2299 net.cpp:94] Creating Layer accuracy
I0614 12:41:33.031656  2299 net.cpp:435] accuracy <- fc8_fc8_0_split_0
I0614 12:41:33.031661  2299 net.cpp:435] accuracy <- label_data_1_split_0
I0614 12:41:33.031667  2299 net.cpp:409] accuracy -> accuracy
I0614 12:41:33.031675  2299 net.cpp:144] Setting up accuracy
I0614 12:41:33.031678  2299 net.cpp:151] Top shape: (1)
I0614 12:41:33.031682  2299 net.cpp:159] Memory required for data: 416583804
I0614 12:41:33.031687  2299 layer_factory.hpp:77] Creating layer loss
I0614 12:41:33.031692  2299 net.cpp:94] Creating Layer loss
I0614 12:41:33.031695  2299 net.cpp:435] loss <- fc8_fc8_0_split_1
I0614 12:41:33.031700  2299 net.cpp:435] loss <- label_data_1_split_1
I0614 12:41:33.031704  2299 net.cpp:409] loss -> loss
I0614 12:41:33.031713  2299 layer_factory.hpp:77] Creating layer loss
I0614 12:41:33.031759  2299 net.cpp:144] Setting up loss
I0614 12:41:33.031762  2299 net.cpp:151] Top shape: (1)
I0614 12:41:33.031766  2299 net.cpp:154]     with loss weight 1
I0614 12:41:33.031780  2299 net.cpp:159] Memory required for data: 416583808
I0614 12:41:33.031783  2299 layer_factory.hpp:77] Creating layer accuracy-top1
I0614 12:41:33.031788  2299 net.cpp:94] Creating Layer accuracy-top1
I0614 12:41:33.031792  2299 net.cpp:435] accuracy-top1 <- fc8_fc8_0_split_2
I0614 12:41:33.031796  2299 net.cpp:435] accuracy-top1 <- label_data_1_split_2
I0614 12:41:33.031801  2299 net.cpp:409] accuracy-top1 -> top-1
I0614 12:41:33.031807  2299 net.cpp:144] Setting up accuracy-top1
I0614 12:41:33.031810  2299 net.cpp:151] Top shape: (1)
I0614 12:41:33.031814  2299 net.cpp:159] Memory required for data: 416583812
I0614 12:41:33.031818  2299 net.cpp:222] accuracy-top1 does not need backward computation.
I0614 12:41:33.031823  2299 net.cpp:220] loss needs backward computation.
I0614 12:41:33.031827  2299 net.cpp:222] accuracy does not need backward computation.
I0614 12:41:33.031832  2299 net.cpp:220] fc8_fc8_0_split needs backward computation.
I0614 12:41:33.031836  2299 net.cpp:220] fc8 needs backward computation.
I0614 12:41:33.031841  2299 net.cpp:220] drop7 needs backward computation.
I0614 12:41:33.031843  2299 net.cpp:220] relu7 needs backward computation.
I0614 12:41:33.031847  2299 net.cpp:220] bn7 needs backward computation.
I0614 12:41:33.031852  2299 net.cpp:220] fc7 needs backward computation.
I0614 12:41:33.031855  2299 net.cpp:220] drop6 needs backward computation.
I0614 12:41:33.031859  2299 net.cpp:220] relu6 needs backward computation.
I0614 12:41:33.031864  2299 net.cpp:220] fc6 needs backward computation.
I0614 12:41:33.031868  2299 net.cpp:220] pool5 needs backward computation.
I0614 12:41:33.031872  2299 net.cpp:220] relu5 needs backward computation.
I0614 12:41:33.031877  2299 net.cpp:220] conv5 needs backward computation.
I0614 12:41:33.031880  2299 net.cpp:220] relu4 needs backward computation.
I0614 12:41:33.031884  2299 net.cpp:220] conv4 needs backward computation.
I0614 12:41:33.031888  2299 net.cpp:220] relu3 needs backward computation.
I0614 12:41:33.031893  2299 net.cpp:220] conv3 needs backward computation.
I0614 12:41:33.031898  2299 net.cpp:220] pool2 needs backward computation.
I0614 12:41:33.031901  2299 net.cpp:220] relu2 needs backward computation.
I0614 12:41:33.031906  2299 net.cpp:220] bn2 needs backward computation.
I0614 12:41:33.031910  2299 net.cpp:220] conv2 needs backward computation.
I0614 12:41:33.031914  2299 net.cpp:220] pool1 needs backward computation.
I0614 12:41:33.031919  2299 net.cpp:220] relu1 needs backward computation.
I0614 12:41:33.031922  2299 net.cpp:220] bn1 needs backward computation.
I0614 12:41:33.031926  2299 net.cpp:220] conv1 needs backward computation.
I0614 12:41:33.031931  2299 net.cpp:222] label_data_1_split does not need backward computation.
I0614 12:41:33.031935  2299 net.cpp:222] data does not need backward computation.
I0614 12:41:33.031939  2299 net.cpp:264] This network produces output accuracy
I0614 12:41:33.031944  2299 net.cpp:264] This network produces output loss
I0614 12:41:33.031947  2299 net.cpp:264] This network produces output top-1
I0614 12:41:33.032285  2299 net.cpp:284] Network initialization done.
I0614 12:41:33.032353  2299 solver.cpp:63] Solver scaffolding done.
I0614 12:41:33.032891  2299 caffe_interface.cpp:139] Finetuning from pruning/alexnetBNnoLRN/regular_rate_0/sparse.caffemodel
I0614 12:41:35.440624  2299 caffe_interface.cpp:573] Starting Optimization
I0614 12:41:35.440646  2299 solver.cpp:341] Solving 
I0614 12:41:35.440650  2299 solver.cpp:342] Learning Rate Policy: step
I0614 12:41:35.441896  2299 solver.cpp:424] Iteration 0, Testing net (#0)
I0614 12:41:36.930399  2299 solver.cpp:523]     Test net output #0: accuracy = 0.9535
I0614 12:41:36.930433  2299 solver.cpp:523]     Test net output #1: loss = 0.158723 (* 1 = 0.158723 loss)
I0614 12:41:36.930438  2299 solver.cpp:523]     Test net output #2: top-1 = 0.9535
I0614 12:41:37.185250  2299 solver.cpp:270] Iteration 0 (0 iter/s, 1.7445s/50 iter), loss = 0.0645483, remaining 333333 hours and 20 minutes
I0614 12:41:37.185278  2299 solver.cpp:291]     Train net output #0: loss = 0.0645483 (* 1 = 0.0645483 loss)
I0614 12:41:37.185286  2299 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0614 12:41:49.596755  2299 solver.cpp:270] Iteration 50 (4.02868 iter/s, 12.411s/50 iter), loss = 0.204671, remaining 0 hours and 49 minutes
I0614 12:41:49.596786  2299 solver.cpp:291]     Train net output #0: loss = 0.204671 (* 1 = 0.204671 loss)
I0614 12:41:49.596792  2299 sgd_solver.cpp:106] Iteration 50, lr = 0.001
I0614 12:42:02.107968  2299 solver.cpp:270] Iteration 100 (3.99657 iter/s, 12.5107s/50 iter), loss = 0.164647, remaining 0 hours and 49 minutes
I0614 12:42:02.108168  2299 solver.cpp:291]     Train net output #0: loss = 0.164647 (* 1 = 0.164647 loss)
I0614 12:42:02.108176  2299 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I0614 12:42:14.726083  2299 solver.cpp:270] Iteration 150 (3.96274 iter/s, 12.6175s/50 iter), loss = 0.124092, remaining 0 hours and 49 minutes
I0614 12:42:14.726112  2299 solver.cpp:291]     Train net output #0: loss = 0.124092 (* 1 = 0.124092 loss)
I0614 12:42:14.726119  2299 sgd_solver.cpp:106] Iteration 150, lr = 0.001
I0614 12:42:27.337296  2299 solver.cpp:270] Iteration 200 (3.96486 iter/s, 12.6108s/50 iter), loss = 0.0957521, remaining 0 hours and 49 minutes
I0614 12:42:27.337327  2299 solver.cpp:291]     Train net output #0: loss = 0.0957521 (* 1 = 0.0957521 loss)
I0614 12:42:27.337334  2299 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I0614 12:42:40.000185  2299 solver.cpp:270] Iteration 250 (3.94868 iter/s, 12.6624s/50 iter), loss = 0.18771, remaining 0 hours and 49 minutes
I0614 12:42:40.000430  2299 solver.cpp:291]     Train net output #0: loss = 0.18771 (* 1 = 0.18771 loss)
I0614 12:42:40.000438  2299 sgd_solver.cpp:106] Iteration 250, lr = 0.001
I0614 12:42:52.663575  2299 solver.cpp:270] Iteration 300 (3.94859 iter/s, 12.6627s/50 iter), loss = 0.130416, remaining 0 hours and 49 minutes
I0614 12:42:52.663606  2299 solver.cpp:291]     Train net output #0: loss = 0.130416 (* 1 = 0.130416 loss)
I0614 12:42:52.663614  2299 sgd_solver.cpp:106] Iteration 300, lr = 0.001
I0614 12:43:05.305591  2299 solver.cpp:270] Iteration 350 (3.9552 iter/s, 12.6416s/50 iter), loss = 0.0997968, remaining 0 hours and 49 minutes
I0614 12:43:05.305624  2299 solver.cpp:291]     Train net output #0: loss = 0.0997968 (* 1 = 0.0997968 loss)
I0614 12:43:05.305634  2299 sgd_solver.cpp:106] Iteration 350, lr = 0.001
I0614 12:43:17.925137  2299 solver.cpp:270] Iteration 400 (3.96225 iter/s, 12.6191s/50 iter), loss = 0.144326, remaining 0 hours and 48 minutes
I0614 12:43:17.925341  2299 solver.cpp:291]     Train net output #0: loss = 0.144326 (* 1 = 0.144326 loss)
I0614 12:43:17.925349  2299 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I0614 12:43:30.543296  2299 solver.cpp:270] Iteration 450 (3.96274 iter/s, 12.6175s/50 iter), loss = 0.15931, remaining 0 hours and 48 minutes
I0614 12:43:30.543326  2299 solver.cpp:291]     Train net output #0: loss = 0.15931 (* 1 = 0.15931 loss)
I0614 12:43:30.543349  2299 sgd_solver.cpp:106] Iteration 450, lr = 0.001
I0614 12:43:43.163251  2299 solver.cpp:270] Iteration 500 (3.96212 iter/s, 12.6195s/50 iter), loss = 0.120637, remaining 0 hours and 48 minutes
I0614 12:43:43.163280  2299 solver.cpp:291]     Train net output #0: loss = 0.120637 (* 1 = 0.120637 loss)
I0614 12:43:43.163288  2299 sgd_solver.cpp:106] Iteration 500, lr = 0.001
I0614 12:43:55.767573  2299 solver.cpp:270] Iteration 550 (3.96703 iter/s, 12.6039s/50 iter), loss = 0.190007, remaining 0 hours and 47 minutes
I0614 12:43:55.767920  2299 solver.cpp:291]     Train net output #0: loss = 0.190007 (* 1 = 0.190007 loss)
I0614 12:43:55.767928  2299 sgd_solver.cpp:106] Iteration 550, lr = 0.001
I0614 12:44:08.394848  2299 solver.cpp:270] Iteration 600 (3.95992 iter/s, 12.6265s/50 iter), loss = 0.0998169, remaining 0 hours and 47 minutes
I0614 12:44:08.394881  2299 solver.cpp:291]     Train net output #0: loss = 0.0998169 (* 1 = 0.0998169 loss)
I0614 12:44:08.394888  2299 sgd_solver.cpp:106] Iteration 600, lr = 0.001
I0614 12:44:21.005312  2299 solver.cpp:270] Iteration 650 (3.9651 iter/s, 12.61s/50 iter), loss = 0.129887, remaining 0 hours and 47 minutes
I0614 12:44:21.005342  2299 solver.cpp:291]     Train net output #0: loss = 0.129887 (* 1 = 0.129887 loss)
I0614 12:44:21.005350  2299 sgd_solver.cpp:106] Iteration 650, lr = 0.001
I0614 12:44:33.646544  2299 solver.cpp:270] Iteration 700 (3.95545 iter/s, 12.6408s/50 iter), loss = 0.119884, remaining 0 hours and 47 minutes
I0614 12:44:33.646785  2299 solver.cpp:291]     Train net output #0: loss = 0.119884 (* 1 = 0.119884 loss)
I0614 12:44:33.646807  2299 sgd_solver.cpp:106] Iteration 700, lr = 0.001
I0614 12:44:46.271296  2299 solver.cpp:270] Iteration 750 (3.96068 iter/s, 12.6241s/50 iter), loss = 0.146809, remaining 0 hours and 47 minutes
I0614 12:44:46.271325  2299 solver.cpp:291]     Train net output #0: loss = 0.146809 (* 1 = 0.146809 loss)
I0614 12:44:46.271332  2299 sgd_solver.cpp:106] Iteration 750, lr = 0.001
I0614 12:44:58.919248  2299 solver.cpp:270] Iteration 800 (3.95335 iter/s, 12.6475s/50 iter), loss = 0.193762, remaining 0 hours and 47 minutes
I0614 12:44:58.919278  2299 solver.cpp:291]     Train net output #0: loss = 0.193762 (* 1 = 0.193762 loss)
I0614 12:44:58.919286  2299 sgd_solver.cpp:106] Iteration 800, lr = 0.001
I0614 12:45:11.522473  2299 solver.cpp:270] Iteration 850 (3.96738 iter/s, 12.6028s/50 iter), loss = 0.121631, remaining 0 hours and 46 minutes
I0614 12:45:11.522644  2299 solver.cpp:291]     Train net output #0: loss = 0.121631 (* 1 = 0.121631 loss)
I0614 12:45:11.522650  2299 sgd_solver.cpp:106] Iteration 850, lr = 0.001
I0614 12:45:24.132639  2299 solver.cpp:270] Iteration 900 (3.96524 iter/s, 12.6096s/50 iter), loss = 0.155648, remaining 0 hours and 46 minutes
I0614 12:45:24.132668  2299 solver.cpp:291]     Train net output #0: loss = 0.155648 (* 1 = 0.155648 loss)
I0614 12:45:24.132675  2299 sgd_solver.cpp:106] Iteration 900, lr = 0.001
I0614 12:45:36.755903  2299 solver.cpp:270] Iteration 950 (3.96108 iter/s, 12.6228s/50 iter), loss = 0.141465, remaining 0 hours and 46 minutes
I0614 12:45:36.755932  2299 solver.cpp:291]     Train net output #0: loss = 0.141465 (* 1 = 0.141465 loss)
I0614 12:45:36.755940  2299 sgd_solver.cpp:106] Iteration 950, lr = 0.001
I0614 12:45:49.122532  2299 solver.cpp:424] Iteration 1000, Testing net (#0)
I0614 12:45:50.612046  2299 solver.cpp:523]     Test net output #0: accuracy = 0.77925
I0614 12:45:50.612071  2299 solver.cpp:523]     Test net output #1: loss = 0.496132 (* 1 = 0.496132 loss)
I0614 12:45:50.612076  2299 solver.cpp:523]     Test net output #2: top-1 = 0.77925
I0614 12:45:50.858413  2299 solver.cpp:270] Iteration 1000 (3.54559 iter/s, 14.102s/50 iter), loss = 0.145793, remaining 0 hours and 51 minutes
I0614 12:45:50.858443  2299 solver.cpp:291]     Train net output #0: loss = 0.145793 (* 1 = 0.145793 loss)
I0614 12:45:50.858451  2299 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I0614 12:46:03.506783  2299 solver.cpp:270] Iteration 1050 (3.95322 iter/s, 12.6479s/50 iter), loss = 0.113814, remaining 0 hours and 46 minutes
I0614 12:46:03.506810  2299 solver.cpp:291]     Train net output #0: loss = 0.113814 (* 1 = 0.113814 loss)
I0614 12:46:03.506817  2299 sgd_solver.cpp:106] Iteration 1050, lr = 0.001
I0614 12:46:16.152096  2299 solver.cpp:270] Iteration 1100 (3.95417 iter/s, 12.6449s/50 iter), loss = 0.166072, remaining 0 hours and 45 minutes
I0614 12:46:16.152125  2299 solver.cpp:291]     Train net output #0: loss = 0.166072 (* 1 = 0.166072 loss)
I0614 12:46:16.152132  2299 sgd_solver.cpp:106] Iteration 1100, lr = 0.001
I0614 12:46:28.787045  2299 solver.cpp:270] Iteration 1150 (3.95742 iter/s, 12.6345s/50 iter), loss = 0.136183, remaining 0 hours and 45 minutes
I0614 12:46:28.787382  2299 solver.cpp:291]     Train net output #0: loss = 0.136183 (* 1 = 0.136183 loss)
I0614 12:46:28.787406  2299 sgd_solver.cpp:106] Iteration 1150, lr = 0.001
I0614 12:46:41.415923  2299 solver.cpp:270] Iteration 1200 (3.95941 iter/s, 12.6281s/50 iter), loss = 0.118301, remaining 0 hours and 45 minutes
I0614 12:46:41.415954  2299 solver.cpp:291]     Train net output #0: loss = 0.118301 (* 1 = 0.118301 loss)
I0614 12:46:41.415961  2299 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I0614 12:46:54.031644  2299 solver.cpp:270] Iteration 1250 (3.96345 iter/s, 12.6153s/50 iter), loss = 0.210784, remaining 0 hours and 45 minutes
I0614 12:46:54.031674  2299 solver.cpp:291]     Train net output #0: loss = 0.210784 (* 1 = 0.210784 loss)
I0614 12:46:54.031682  2299 sgd_solver.cpp:106] Iteration 1250, lr = 0.001
I0614 12:47:06.657526  2299 solver.cpp:270] Iteration 1300 (3.96026 iter/s, 12.6254s/50 iter), loss = 0.141867, remaining 0 hours and 44 minutes
I0614 12:47:06.657752  2299 solver.cpp:291]     Train net output #0: loss = 0.141867 (* 1 = 0.141867 loss)
I0614 12:47:06.657760  2299 sgd_solver.cpp:106] Iteration 1300, lr = 0.001
I0614 12:47:19.280884  2299 solver.cpp:270] Iteration 1350 (3.96111 iter/s, 12.6227s/50 iter), loss = 0.163987, remaining 0 hours and 44 minutes
I0614 12:47:19.280912  2299 solver.cpp:291]     Train net output #0: loss = 0.163987 (* 1 = 0.163987 loss)
I0614 12:47:19.280920  2299 sgd_solver.cpp:106] Iteration 1350, lr = 0.001
I0614 12:47:31.914533  2299 solver.cpp:270] Iteration 1400 (3.95782 iter/s, 12.6332s/50 iter), loss = 0.142537, remaining 0 hours and 44 minutes
I0614 12:47:31.914564  2299 solver.cpp:291]     Train net output #0: loss = 0.142537 (* 1 = 0.142537 loss)
I0614 12:47:31.914572  2299 sgd_solver.cpp:106] Iteration 1400, lr = 0.001
I0614 12:47:44.549188  2299 solver.cpp:270] Iteration 1450 (3.95751 iter/s, 12.6342s/50 iter), loss = 0.0983106, remaining 0 hours and 44 minutes
I0614 12:47:44.549386  2299 solver.cpp:291]     Train net output #0: loss = 0.0983106 (* 1 = 0.0983106 loss)
I0614 12:47:44.549410  2299 sgd_solver.cpp:106] Iteration 1450, lr = 0.001
I0614 12:47:57.189015  2299 solver.cpp:270] Iteration 1500 (3.95594 iter/s, 12.6392s/50 iter), loss = 0.116841, remaining 0 hours and 44 minutes
I0614 12:47:57.189045  2299 solver.cpp:291]     Train net output #0: loss = 0.116841 (* 1 = 0.116841 loss)
I0614 12:47:57.189052  2299 sgd_solver.cpp:106] Iteration 1500, lr = 0.001
I0614 12:48:09.811882  2299 solver.cpp:270] Iteration 1550 (3.9612 iter/s, 12.6224s/50 iter), loss = 0.135734, remaining 0 hours and 43 minutes
I0614 12:48:09.811913  2299 solver.cpp:291]     Train net output #0: loss = 0.135734 (* 1 = 0.135734 loss)
I0614 12:48:09.811920  2299 sgd_solver.cpp:106] Iteration 1550, lr = 0.001
I0614 12:48:22.441717  2299 solver.cpp:270] Iteration 1600 (3.95902 iter/s, 12.6294s/50 iter), loss = 0.0955947, remaining 0 hours and 43 minutes
I0614 12:48:22.441920  2299 solver.cpp:291]     Train net output #0: loss = 0.0955947 (* 1 = 0.0955947 loss)
I0614 12:48:22.441943  2299 sgd_solver.cpp:106] Iteration 1600, lr = 0.001
I0614 12:48:35.067523  2299 solver.cpp:270] Iteration 1650 (3.96034 iter/s, 12.6252s/50 iter), loss = 0.118502, remaining 0 hours and 43 minutes
I0614 12:48:35.067553  2299 solver.cpp:291]     Train net output #0: loss = 0.118502 (* 1 = 0.118502 loss)
I0614 12:48:35.067561  2299 sgd_solver.cpp:106] Iteration 1650, lr = 0.001
I0614 12:48:47.697722  2299 solver.cpp:270] Iteration 1700 (3.9589 iter/s, 12.6298s/50 iter), loss = 0.121611, remaining 0 hours and 43 minutes
I0614 12:48:47.697752  2299 solver.cpp:291]     Train net output #0: loss = 0.121611 (* 1 = 0.121611 loss)
I0614 12:48:47.697777  2299 sgd_solver.cpp:106] Iteration 1700, lr = 0.001
I0614 12:49:00.343890  2299 solver.cpp:270] Iteration 1750 (3.95391 iter/s, 12.6457s/50 iter), loss = 0.153023, remaining 0 hours and 42 minutes
I0614 12:49:00.344211  2299 solver.cpp:291]     Train net output #0: loss = 0.153023 (* 1 = 0.153023 loss)
I0614 12:49:00.344219  2299 sgd_solver.cpp:106] Iteration 1750, lr = 0.001
I0614 12:49:12.965104  2299 solver.cpp:270] Iteration 1800 (3.96181 iter/s, 12.6205s/50 iter), loss = 0.162475, remaining 0 hours and 42 minutes
I0614 12:49:12.965135  2299 solver.cpp:291]     Train net output #0: loss = 0.162475 (* 1 = 0.162475 loss)
I0614 12:49:12.965142  2299 sgd_solver.cpp:106] Iteration 1800, lr = 0.001
I0614 12:49:25.606391  2299 solver.cpp:270] Iteration 1850 (3.95543 iter/s, 12.6408s/50 iter), loss = 0.10025, remaining 0 hours and 42 minutes
I0614 12:49:25.606420  2299 solver.cpp:291]     Train net output #0: loss = 0.10025 (* 1 = 0.10025 loss)
I0614 12:49:25.606427  2299 sgd_solver.cpp:106] Iteration 1850, lr = 0.001
I0614 12:49:38.210911  2299 solver.cpp:270] Iteration 1900 (3.96697 iter/s, 12.6041s/50 iter), loss = 0.13174, remaining 0 hours and 42 minutes
I0614 12:49:38.211161  2299 solver.cpp:291]     Train net output #0: loss = 0.13174 (* 1 = 0.13174 loss)
I0614 12:49:38.211186  2299 sgd_solver.cpp:106] Iteration 1900, lr = 0.001
I0614 12:49:50.833451  2299 solver.cpp:270] Iteration 1950 (3.96137 iter/s, 12.6219s/50 iter), loss = 0.100298, remaining 0 hours and 42 minutes
I0614 12:49:50.833482  2299 solver.cpp:291]     Train net output #0: loss = 0.100298 (* 1 = 0.100298 loss)
I0614 12:49:50.833488  2299 sgd_solver.cpp:106] Iteration 1950, lr = 0.001
I0614 12:50:03.217258  2299 solver.cpp:424] Iteration 2000, Testing net (#0)
I0614 12:50:04.721171  2299 solver.cpp:523]     Test net output #0: accuracy = 0.937
I0614 12:50:04.721199  2299 solver.cpp:523]     Test net output #1: loss = 0.173822 (* 1 = 0.173822 loss)
I0614 12:50:04.721204  2299 solver.cpp:523]     Test net output #2: top-1 = 0.937
I0614 12:50:04.967437  2299 solver.cpp:270] Iteration 2000 (3.53769 iter/s, 14.1335s/50 iter), loss = 0.0993499, remaining 0 hours and 46 minutes
I0614 12:50:04.967466  2299 solver.cpp:291]     Train net output #0: loss = 0.0993499 (* 1 = 0.0993499 loss)
I0614 12:50:04.967473  2299 sgd_solver.cpp:106] Iteration 2000, lr = 0.001
I0614 12:50:17.592682  2299 solver.cpp:270] Iteration 2050 (3.96046 iter/s, 12.6248s/50 iter), loss = 0.147952, remaining 0 hours and 41 minutes
I0614 12:50:17.592928  2299 solver.cpp:291]     Train net output #0: loss = 0.147952 (* 1 = 0.147952 loss)
I0614 12:50:17.592936  2299 sgd_solver.cpp:106] Iteration 2050, lr = 0.001
I0614 12:50:30.217773  2299 solver.cpp:270] Iteration 2100 (3.96057 iter/s, 12.6244s/50 iter), loss = 0.0945725, remaining 0 hours and 41 minutes
I0614 12:50:30.217803  2299 solver.cpp:291]     Train net output #0: loss = 0.0945725 (* 1 = 0.0945725 loss)
I0614 12:50:30.217809  2299 sgd_solver.cpp:106] Iteration 2100, lr = 0.001
I0614 12:50:42.838510  2299 solver.cpp:270] Iteration 2150 (3.96187 iter/s, 12.6203s/50 iter), loss = 0.0896905, remaining 0 hours and 41 minutes
I0614 12:50:42.838541  2299 solver.cpp:291]     Train net output #0: loss = 0.0896905 (* 1 = 0.0896905 loss)
I0614 12:50:42.838548  2299 sgd_solver.cpp:106] Iteration 2150, lr = 0.001
I0614 12:50:55.450052  2299 solver.cpp:270] Iteration 2200 (3.96476 iter/s, 12.6111s/50 iter), loss = 0.13339, remaining 0 hours and 41 minutes
I0614 12:50:55.450274  2299 solver.cpp:291]     Train net output #0: loss = 0.13339 (* 1 = 0.13339 loss)
I0614 12:50:55.450281  2299 sgd_solver.cpp:106] Iteration 2200, lr = 0.001
I0614 12:51:08.067131  2299 solver.cpp:270] Iteration 2250 (3.96308 iter/s, 12.6164s/50 iter), loss = 0.104821, remaining 0 hours and 40 minutes
I0614 12:51:08.067162  2299 solver.cpp:291]     Train net output #0: loss = 0.104821 (* 1 = 0.104821 loss)
I0614 12:51:08.067185  2299 sgd_solver.cpp:106] Iteration 2250, lr = 0.001
I0614 12:51:20.718911  2299 solver.cpp:270] Iteration 2300 (3.95215 iter/s, 12.6513s/50 iter), loss = 0.10725, remaining 0 hours and 40 minutes
I0614 12:51:20.718943  2299 solver.cpp:291]     Train net output #0: loss = 0.10725 (* 1 = 0.10725 loss)
I0614 12:51:20.718950  2299 sgd_solver.cpp:106] Iteration 2300, lr = 0.001
I0614 12:51:33.352605  2299 solver.cpp:270] Iteration 2350 (3.95781 iter/s, 12.6333s/50 iter), loss = 0.153833, remaining 0 hours and 40 minutes
I0614 12:51:33.352936  2299 solver.cpp:291]     Train net output #0: loss = 0.153833 (* 1 = 0.153833 loss)
I0614 12:51:33.352943  2299 sgd_solver.cpp:106] Iteration 2350, lr = 0.001
I0614 12:51:45.977903  2299 solver.cpp:270] Iteration 2400 (3.96053 iter/s, 12.6246s/50 iter), loss = 0.114809, remaining 0 hours and 40 minutes
I0614 12:51:45.977933  2299 solver.cpp:291]     Train net output #0: loss = 0.114809 (* 1 = 0.114809 loss)
I0614 12:51:45.977941  2299 sgd_solver.cpp:106] Iteration 2400, lr = 0.001
I0614 12:51:58.615062  2299 solver.cpp:270] Iteration 2450 (3.95672 iter/s, 12.6367s/50 iter), loss = 0.186698, remaining 0 hours and 40 minutes
I0614 12:51:58.615092  2299 solver.cpp:291]     Train net output #0: loss = 0.186698 (* 1 = 0.186698 loss)
I0614 12:51:58.615098  2299 sgd_solver.cpp:106] Iteration 2450, lr = 0.001
I0614 12:52:11.243132  2299 solver.cpp:270] Iteration 2500 (3.95957 iter/s, 12.6276s/50 iter), loss = 0.159397, remaining 0 hours and 39 minutes
I0614 12:52:11.243378  2299 solver.cpp:291]     Train net output #0: loss = 0.159397 (* 1 = 0.159397 loss)
I0614 12:52:11.243402  2299 sgd_solver.cpp:106] Iteration 2500, lr = 0.0001
I0614 12:52:23.867280  2299 solver.cpp:270] Iteration 2550 (3.96087 iter/s, 12.6235s/50 iter), loss = 0.0941148, remaining 0 hours and 39 minutes
I0614 12:52:23.867309  2299 solver.cpp:291]     Train net output #0: loss = 0.0941148 (* 1 = 0.0941148 loss)
I0614 12:52:23.867317  2299 sgd_solver.cpp:106] Iteration 2550, lr = 0.0001
I0614 12:52:36.495335  2299 solver.cpp:270] Iteration 2600 (3.95958 iter/s, 12.6276s/50 iter), loss = 0.0653156, remaining 0 hours and 39 minutes
I0614 12:52:36.495365  2299 solver.cpp:291]     Train net output #0: loss = 0.0653156 (* 1 = 0.0653156 loss)
I0614 12:52:36.495373  2299 sgd_solver.cpp:106] Iteration 2600, lr = 0.0001
I0614 12:52:49.103118  2299 solver.cpp:270] Iteration 2650 (3.96594 iter/s, 12.6073s/50 iter), loss = 0.0552925, remaining 0 hours and 39 minutes
I0614 12:52:49.103318  2299 solver.cpp:291]     Train net output #0: loss = 0.0552925 (* 1 = 0.0552925 loss)
I0614 12:52:49.103325  2299 sgd_solver.cpp:106] Iteration 2650, lr = 0.0001
I0614 12:53:01.749274  2299 solver.cpp:270] Iteration 2700 (3.95396 iter/s, 12.6455s/50 iter), loss = 0.0340614, remaining 0 hours and 39 minutes
I0614 12:53:01.749302  2299 solver.cpp:291]     Train net output #0: loss = 0.0340614 (* 1 = 0.0340614 loss)
I0614 12:53:01.749310  2299 sgd_solver.cpp:106] Iteration 2700, lr = 0.0001
I0614 12:53:14.372455  2299 solver.cpp:270] Iteration 2750 (3.9611 iter/s, 12.6227s/50 iter), loss = 0.0710869, remaining 0 hours and 38 minutes
I0614 12:53:14.372484  2299 solver.cpp:291]     Train net output #0: loss = 0.0710869 (* 1 = 0.0710869 loss)
I0614 12:53:14.372491  2299 sgd_solver.cpp:106] Iteration 2750, lr = 0.0001
I0614 12:53:26.991189  2299 solver.cpp:270] Iteration 2800 (3.9625 iter/s, 12.6183s/50 iter), loss = 0.0563765, remaining 0 hours and 38 minutes
I0614 12:53:26.991441  2299 solver.cpp:291]     Train net output #0: loss = 0.0563765 (* 1 = 0.0563765 loss)
I0614 12:53:26.991465  2299 sgd_solver.cpp:106] Iteration 2800, lr = 0.0001
I0614 12:53:39.645550  2299 solver.cpp:270] Iteration 2850 (3.95141 iter/s, 12.6537s/50 iter), loss = 0.0709736, remaining 0 hours and 38 minutes
I0614 12:53:39.645581  2299 solver.cpp:291]     Train net output #0: loss = 0.0709736 (* 1 = 0.0709736 loss)
I0614 12:53:39.645587  2299 sgd_solver.cpp:106] Iteration 2850, lr = 0.0001
I0614 12:53:52.288203  2299 solver.cpp:270] Iteration 2900 (3.955 iter/s, 12.6422s/50 iter), loss = 0.0621861, remaining 0 hours and 38 minutes
I0614 12:53:52.288233  2299 solver.cpp:291]     Train net output #0: loss = 0.0621861 (* 1 = 0.0621861 loss)
I0614 12:53:52.288239  2299 sgd_solver.cpp:106] Iteration 2900, lr = 0.0001
I0614 12:54:04.908394  2299 solver.cpp:270] Iteration 2950 (3.96204 iter/s, 12.6198s/50 iter), loss = 0.0771705, remaining 0 hours and 37 minutes
I0614 12:54:04.908651  2299 solver.cpp:291]     Train net output #0: loss = 0.0771705 (* 1 = 0.0771705 loss)
I0614 12:54:04.908659  2299 sgd_solver.cpp:106] Iteration 2950, lr = 0.0001
I0614 12:54:17.280257  2299 solver.cpp:424] Iteration 3000, Testing net (#0)
I0614 12:54:18.750890  2299 solver.cpp:523]     Test net output #0: accuracy = 0.94375
I0614 12:54:18.750916  2299 solver.cpp:523]     Test net output #1: loss = 0.146391 (* 1 = 0.146391 loss)
I0614 12:54:18.750921  2299 solver.cpp:523]     Test net output #2: top-1 = 0.94375
I0614 12:54:18.997897  2299 solver.cpp:270] Iteration 3000 (3.54892 iter/s, 14.0888s/50 iter), loss = 0.0642131, remaining 0 hours and 42 minutes
I0614 12:54:18.997927  2299 solver.cpp:291]     Train net output #0: loss = 0.0642131 (* 1 = 0.0642131 loss)
I0614 12:54:18.997936  2299 sgd_solver.cpp:106] Iteration 3000, lr = 0.0001
I0614 12:54:31.643416  2299 solver.cpp:270] Iteration 3050 (3.95411 iter/s, 12.6451s/50 iter), loss = 0.0982563, remaining 0 hours and 37 minutes
I0614 12:54:31.643446  2299 solver.cpp:291]     Train net output #0: loss = 0.0982563 (* 1 = 0.0982563 loss)
I0614 12:54:31.643453  2299 sgd_solver.cpp:106] Iteration 3050, lr = 0.0001
I0614 12:54:44.284744  2299 solver.cpp:270] Iteration 3100 (3.95542 iter/s, 12.6409s/50 iter), loss = 0.0310609, remaining 0 hours and 37 minutes
I0614 12:54:44.284942  2299 solver.cpp:291]     Train net output #0: loss = 0.0310609 (* 1 = 0.0310609 loss)
I0614 12:54:44.284966  2299 sgd_solver.cpp:106] Iteration 3100, lr = 0.0001
I0614 12:54:56.920095  2299 solver.cpp:270] Iteration 3150 (3.95734 iter/s, 12.6347s/50 iter), loss = 0.0924679, remaining 0 hours and 37 minutes
I0614 12:54:56.920126  2299 solver.cpp:291]     Train net output #0: loss = 0.0924679 (* 1 = 0.0924679 loss)
I0614 12:54:56.920133  2299 sgd_solver.cpp:106] Iteration 3150, lr = 0.0001
I0614 12:55:09.543501  2299 solver.cpp:270] Iteration 3200 (3.96103 iter/s, 12.623s/50 iter), loss = 0.0271515, remaining 0 hours and 36 minutes
I0614 12:55:09.543530  2299 solver.cpp:291]     Train net output #0: loss = 0.0271515 (* 1 = 0.0271515 loss)
I0614 12:55:09.543537  2299 sgd_solver.cpp:106] Iteration 3200, lr = 0.0001
I0614 12:55:22.158802  2299 solver.cpp:270] Iteration 3250 (3.96358 iter/s, 12.6149s/50 iter), loss = 0.0354415, remaining 0 hours and 36 minutes
I0614 12:55:22.159032  2299 solver.cpp:291]     Train net output #0: loss = 0.0354415 (* 1 = 0.0354415 loss)
I0614 12:55:22.159055  2299 sgd_solver.cpp:106] Iteration 3250, lr = 0.0001
I0614 12:55:34.766968  2299 solver.cpp:270] Iteration 3300 (3.96588 iter/s, 12.6075s/50 iter), loss = 0.0735657, remaining 0 hours and 36 minutes
I0614 12:55:34.766997  2299 solver.cpp:291]     Train net output #0: loss = 0.0735656 (* 1 = 0.0735656 loss)
I0614 12:55:34.767004  2299 sgd_solver.cpp:106] Iteration 3300, lr = 0.0001
I0614 12:55:47.416864  2299 solver.cpp:270] Iteration 3350 (3.95274 iter/s, 12.6495s/50 iter), loss = 0.0387216, remaining 0 hours and 36 minutes
I0614 12:55:47.416893  2299 solver.cpp:291]     Train net output #0: loss = 0.0387215 (* 1 = 0.0387215 loss)
I0614 12:55:47.416901  2299 sgd_solver.cpp:106] Iteration 3350, lr = 0.0001
I0614 12:56:00.043710  2299 solver.cpp:270] Iteration 3400 (3.95995 iter/s, 12.6264s/50 iter), loss = 0.0620019, remaining 0 hours and 36 minutes
I0614 12:56:00.043936  2299 solver.cpp:291]     Train net output #0: loss = 0.0620019 (* 1 = 0.0620019 loss)
I0614 12:56:00.043959  2299 sgd_solver.cpp:106] Iteration 3400, lr = 0.0001
I0614 12:56:12.676862  2299 solver.cpp:270] Iteration 3450 (3.95804 iter/s, 12.6325s/50 iter), loss = 0.0875306, remaining 0 hours and 35 minutes
I0614 12:56:12.676892  2299 solver.cpp:291]     Train net output #0: loss = 0.0875305 (* 1 = 0.0875305 loss)
I0614 12:56:12.676898  2299 sgd_solver.cpp:106] Iteration 3450, lr = 0.0001
I0614 12:56:25.304473  2299 solver.cpp:270] Iteration 3500 (3.95971 iter/s, 12.6272s/50 iter), loss = 0.0426386, remaining 0 hours and 35 minutes
I0614 12:56:25.304503  2299 solver.cpp:291]     Train net output #0: loss = 0.0426386 (* 1 = 0.0426386 loss)
I0614 12:56:25.304510  2299 sgd_solver.cpp:106] Iteration 3500, lr = 0.0001
I0614 12:56:37.926999  2299 solver.cpp:270] Iteration 3550 (3.96131 iter/s, 12.6221s/50 iter), loss = 0.0665379, remaining 0 hours and 35 minutes
I0614 12:56:37.927297  2299 solver.cpp:291]     Train net output #0: loss = 0.0665379 (* 1 = 0.0665379 loss)
I0614 12:56:37.927321  2299 sgd_solver.cpp:106] Iteration 3550, lr = 0.0001
I0614 12:56:50.567127  2299 solver.cpp:270] Iteration 3600 (3.95588 iter/s, 12.6394s/50 iter), loss = 0.0578016, remaining 0 hours and 35 minutes
I0614 12:56:50.567158  2299 solver.cpp:291]     Train net output #0: loss = 0.0578016 (* 1 = 0.0578016 loss)
I0614 12:56:50.567167  2299 sgd_solver.cpp:106] Iteration 3600, lr = 0.0001
I0614 12:57:03.194634  2299 solver.cpp:270] Iteration 3650 (3.95975 iter/s, 12.6271s/50 iter), loss = 0.0382655, remaining 0 hours and 35 minutes
I0614 12:57:03.194665  2299 solver.cpp:291]     Train net output #0: loss = 0.0382655 (* 1 = 0.0382655 loss)
I0614 12:57:03.194672  2299 sgd_solver.cpp:106] Iteration 3650, lr = 0.0001
I0614 12:57:15.831578  2299 solver.cpp:270] Iteration 3700 (3.95679 iter/s, 12.6365s/50 iter), loss = 0.0562802, remaining 0 hours and 34 minutes
I0614 12:57:15.831833  2299 solver.cpp:291]     Train net output #0: loss = 0.0562802 (* 1 = 0.0562802 loss)
I0614 12:57:15.831841  2299 sgd_solver.cpp:106] Iteration 3700, lr = 0.0001
I0614 12:57:28.459336  2299 solver.cpp:270] Iteration 3750 (3.95974 iter/s, 12.6271s/50 iter), loss = 0.0556561, remaining 0 hours and 34 minutes
I0614 12:57:28.459367  2299 solver.cpp:291]     Train net output #0: loss = 0.0556561 (* 1 = 0.0556561 loss)
I0614 12:57:28.459374  2299 sgd_solver.cpp:106] Iteration 3750, lr = 0.0001
I0614 12:57:41.093670  2299 solver.cpp:270] Iteration 3800 (3.95761 iter/s, 12.6339s/50 iter), loss = 0.0486483, remaining 0 hours and 34 minutes
I0614 12:57:41.093701  2299 solver.cpp:291]     Train net output #0: loss = 0.0486482 (* 1 = 0.0486482 loss)
I0614 12:57:41.093709  2299 sgd_solver.cpp:106] Iteration 3800, lr = 0.0001
I0614 12:57:53.710924  2299 solver.cpp:270] Iteration 3850 (3.96297 iter/s, 12.6168s/50 iter), loss = 0.041382, remaining 0 hours and 34 minutes
I0614 12:57:53.711172  2299 solver.cpp:291]     Train net output #0: loss = 0.041382 (* 1 = 0.041382 loss)
I0614 12:57:53.711196  2299 sgd_solver.cpp:106] Iteration 3850, lr = 0.0001
I0614 12:58:06.338470  2299 solver.cpp:270] Iteration 3900 (3.9598 iter/s, 12.6269s/50 iter), loss = 0.0340277, remaining 0 hours and 34 minutes
I0614 12:58:06.338501  2299 solver.cpp:291]     Train net output #0: loss = 0.0340277 (* 1 = 0.0340277 loss)
I0614 12:58:06.338508  2299 sgd_solver.cpp:106] Iteration 3900, lr = 0.0001
I0614 12:58:18.975574  2299 solver.cpp:270] Iteration 3950 (3.95674 iter/s, 12.6367s/50 iter), loss = 0.0171904, remaining 0 hours and 33 minutes
I0614 12:58:18.975602  2299 solver.cpp:291]     Train net output #0: loss = 0.0171904 (* 1 = 0.0171904 loss)
I0614 12:58:18.975610  2299 sgd_solver.cpp:106] Iteration 3950, lr = 0.0001
I0614 12:58:31.362288  2299 solver.cpp:424] Iteration 4000, Testing net (#0)
I0614 12:58:32.864852  2299 solver.cpp:523]     Test net output #0: accuracy = 0.956
I0614 12:58:32.864881  2299 solver.cpp:523]     Test net output #1: loss = 0.133108 (* 1 = 0.133108 loss)
I0614 12:58:32.864886  2299 solver.cpp:523]     Test net output #2: top-1 = 0.956
I0614 12:58:33.111542  2299 solver.cpp:270] Iteration 4000 (3.5372 iter/s, 14.1355s/50 iter), loss = 0.0299861, remaining 0 hours and 37 minutes
I0614 12:58:33.111572  2299 solver.cpp:291]     Train net output #0: loss = 0.0299861 (* 1 = 0.0299861 loss)
I0614 12:58:33.111594  2299 sgd_solver.cpp:106] Iteration 4000, lr = 0.0001
I0614 12:58:45.730684  2299 solver.cpp:270] Iteration 4050 (3.96237 iter/s, 12.6187s/50 iter), loss = 0.0171487, remaining 0 hours and 33 minutes
I0614 12:58:45.730713  2299 solver.cpp:291]     Train net output #0: loss = 0.0171487 (* 1 = 0.0171487 loss)
I0614 12:58:45.730721  2299 sgd_solver.cpp:106] Iteration 4050, lr = 0.0001
I0614 12:58:58.359189  2299 solver.cpp:270] Iteration 4100 (3.95943 iter/s, 12.6281s/50 iter), loss = 0.0403486, remaining 0 hours and 33 minutes
I0614 12:58:58.359220  2299 solver.cpp:291]     Train net output #0: loss = 0.0403486 (* 1 = 0.0403486 loss)
I0614 12:58:58.359226  2299 sgd_solver.cpp:106] Iteration 4100, lr = 0.0001
I0614 12:59:11.007951  2299 solver.cpp:270] Iteration 4150 (3.95309 iter/s, 12.6483s/50 iter), loss = 0.0550077, remaining 0 hours and 32 minutes
I0614 12:59:11.008206  2299 solver.cpp:291]     Train net output #0: loss = 0.0550077 (* 1 = 0.0550077 loss)
I0614 12:59:11.008214  2299 sgd_solver.cpp:106] Iteration 4150, lr = 0.0001
I0614 12:59:23.644838  2299 solver.cpp:270] Iteration 4200 (3.95688 iter/s, 12.6362s/50 iter), loss = 0.0283966, remaining 0 hours and 32 minutes
I0614 12:59:23.644870  2299 solver.cpp:291]     Train net output #0: loss = 0.0283966 (* 1 = 0.0283966 loss)
I0614 12:59:23.644876  2299 sgd_solver.cpp:106] Iteration 4200, lr = 0.0001
I0614 12:59:36.270213  2299 solver.cpp:270] Iteration 4250 (3.96042 iter/s, 12.6249s/50 iter), loss = 0.0327988, remaining 0 hours and 32 minutes
I0614 12:59:36.270244  2299 solver.cpp:291]     Train net output #0: loss = 0.0327988 (* 1 = 0.0327988 loss)
I0614 12:59:36.270251  2299 sgd_solver.cpp:106] Iteration 4250, lr = 0.0001
I0614 12:59:48.985090  2299 solver.cpp:270] Iteration 4300 (3.93254 iter/s, 12.7144s/50 iter), loss = 0.0546627, remaining 0 hours and 32 minutes
I0614 12:59:48.985273  2299 solver.cpp:291]     Train net output #0: loss = 0.0546627 (* 1 = 0.0546627 loss)
I0614 12:59:48.985296  2299 sgd_solver.cpp:106] Iteration 4300, lr = 0.0001
I0614 13:00:01.688948  2299 solver.cpp:270] Iteration 4350 (3.936 iter/s, 12.7033s/50 iter), loss = 0.0431866, remaining 0 hours and 32 minutes
I0614 13:00:01.688978  2299 solver.cpp:291]     Train net output #0: loss = 0.0431865 (* 1 = 0.0431865 loss)
I0614 13:00:01.688985  2299 sgd_solver.cpp:106] Iteration 4350, lr = 0.0001
I0614 13:00:14.369031  2299 solver.cpp:270] Iteration 4400 (3.94333 iter/s, 12.6796s/50 iter), loss = 0.052321, remaining 0 hours and 31 minutes
I0614 13:00:14.369060  2299 solver.cpp:291]     Train net output #0: loss = 0.0523209 (* 1 = 0.0523209 loss)
I0614 13:00:14.369068  2299 sgd_solver.cpp:106] Iteration 4400, lr = 0.0001
I0614 13:00:27.031198  2299 solver.cpp:270] Iteration 4450 (3.94891 iter/s, 12.6617s/50 iter), loss = 0.0204218, remaining 0 hours and 31 minutes
I0614 13:00:27.031446  2299 solver.cpp:291]     Train net output #0: loss = 0.0204218 (* 1 = 0.0204218 loss)
I0614 13:00:27.031456  2299 sgd_solver.cpp:106] Iteration 4450, lr = 0.0001
I0614 13:00:39.670390  2299 solver.cpp:270] Iteration 4500 (3.95615 iter/s, 12.6385s/50 iter), loss = 0.026211, remaining 0 hours and 31 minutes
I0614 13:00:39.670420  2299 solver.cpp:291]     Train net output #0: loss = 0.026211 (* 1 = 0.026211 loss)
I0614 13:00:39.670428  2299 sgd_solver.cpp:106] Iteration 4500, lr = 0.0001
I0614 13:00:52.293467  2299 solver.cpp:270] Iteration 4550 (3.96114 iter/s, 12.6226s/50 iter), loss = 0.0364781, remaining 0 hours and 31 minutes
I0614 13:00:52.293498  2299 solver.cpp:291]     Train net output #0: loss = 0.036478 (* 1 = 0.036478 loss)
I0614 13:00:52.293505  2299 sgd_solver.cpp:106] Iteration 4550, lr = 0.0001
I0614 13:01:05.000671  2299 solver.cpp:270] Iteration 4600 (3.93491 iter/s, 12.7068s/50 iter), loss = 0.0243385, remaining 0 hours and 31 minutes
I0614 13:01:05.000993  2299 solver.cpp:291]     Train net output #0: loss = 0.0243385 (* 1 = 0.0243385 loss)
I0614 13:01:05.001001  2299 sgd_solver.cpp:106] Iteration 4600, lr = 0.0001
I0614 13:01:17.720407  2299 solver.cpp:270] Iteration 4650 (3.93113 iter/s, 12.719s/50 iter), loss = 0.0487077, remaining 0 hours and 31 minutes
I0614 13:01:17.720439  2299 solver.cpp:291]     Train net output #0: loss = 0.0487077 (* 1 = 0.0487077 loss)
I0614 13:01:17.720446  2299 sgd_solver.cpp:106] Iteration 4650, lr = 0.0001
I0614 13:01:30.448647  2299 solver.cpp:270] Iteration 4700 (3.92841 iter/s, 12.7278s/50 iter), loss = 0.0504619, remaining 0 hours and 30 minutes
I0614 13:01:30.448675  2299 solver.cpp:291]     Train net output #0: loss = 0.0504618 (* 1 = 0.0504618 loss)
I0614 13:01:30.448683  2299 sgd_solver.cpp:106] Iteration 4700, lr = 0.0001
I0614 13:01:43.081845  2299 solver.cpp:270] Iteration 4750 (3.95796 iter/s, 12.6328s/50 iter), loss = 0.0255364, remaining 0 hours and 30 minutes
I0614 13:01:43.082116  2299 solver.cpp:291]     Train net output #0: loss = 0.0255364 (* 1 = 0.0255364 loss)
I0614 13:01:43.082124  2299 sgd_solver.cpp:106] Iteration 4750, lr = 0.0001
I0614 13:01:55.705714  2299 solver.cpp:270] Iteration 4800 (3.96097 iter/s, 12.6232s/50 iter), loss = 0.0151263, remaining 0 hours and 30 minutes
I0614 13:01:55.705745  2299 solver.cpp:291]     Train net output #0: loss = 0.0151263 (* 1 = 0.0151263 loss)
I0614 13:01:55.705754  2299 sgd_solver.cpp:106] Iteration 4800, lr = 0.0001
I0614 13:02:08.331027  2299 solver.cpp:270] Iteration 4850 (3.96044 iter/s, 12.6249s/50 iter), loss = 0.0165598, remaining 0 hours and 30 minutes
I0614 13:02:08.331058  2299 solver.cpp:291]     Train net output #0: loss = 0.0165597 (* 1 = 0.0165597 loss)
I0614 13:02:08.331066  2299 sgd_solver.cpp:106] Iteration 4850, lr = 0.0001
I0614 13:02:20.948251  2299 solver.cpp:270] Iteration 4900 (3.96298 iter/s, 12.6168s/50 iter), loss = 0.0229839, remaining 0 hours and 29 minutes
I0614 13:02:20.948498  2299 solver.cpp:291]     Train net output #0: loss = 0.0229839 (* 1 = 0.0229839 loss)
I0614 13:02:20.948504  2299 sgd_solver.cpp:106] Iteration 4900, lr = 0.0001
I0614 13:02:33.586339  2299 solver.cpp:270] Iteration 4950 (3.9565 iter/s, 12.6374s/50 iter), loss = 0.026419, remaining 0 hours and 29 minutes
I0614 13:02:33.586369  2299 solver.cpp:291]     Train net output #0: loss = 0.026419 (* 1 = 0.026419 loss)
I0614 13:02:33.586376  2299 sgd_solver.cpp:106] Iteration 4950, lr = 0.0001
I0614 13:02:45.967057  2299 solver.cpp:424] Iteration 5000, Testing net (#0)
I0614 13:02:47.454316  2299 solver.cpp:523]     Test net output #0: accuracy = 0.95275
I0614 13:02:47.454345  2299 solver.cpp:523]     Test net output #1: loss = 0.12409 (* 1 = 0.12409 loss)
I0614 13:02:47.454350  2299 solver.cpp:523]     Test net output #2: top-1 = 0.95275
I0614 13:02:47.700590  2299 solver.cpp:270] Iteration 5000 (3.54264 iter/s, 14.1138s/50 iter), loss = 0.0348725, remaining 0 hours and 32 minutes
I0614 13:02:47.700618  2299 solver.cpp:291]     Train net output #0: loss = 0.0348725 (* 1 = 0.0348725 loss)
I0614 13:02:47.700625  2299 sgd_solver.cpp:106] Iteration 5000, lr = 1e-05
I0614 13:03:00.334090  2299 solver.cpp:270] Iteration 5050 (3.95787 iter/s, 12.6331s/50 iter), loss = 0.0436254, remaining 0 hours and 29 minutes
I0614 13:03:00.334336  2299 solver.cpp:291]     Train net output #0: loss = 0.0436253 (* 1 = 0.0436253 loss)
I0614 13:03:00.334343  2299 sgd_solver.cpp:106] Iteration 5050, lr = 1e-05
I0614 13:03:12.955240  2299 solver.cpp:270] Iteration 5100 (3.96181 iter/s, 12.6205s/50 iter), loss = 0.0160739, remaining 0 hours and 29 minutes
I0614 13:03:12.955269  2299 solver.cpp:291]     Train net output #0: loss = 0.0160739 (* 1 = 0.0160739 loss)
I0614 13:03:12.955276  2299 sgd_solver.cpp:106] Iteration 5100, lr = 1e-05
I0614 13:03:25.580190  2299 solver.cpp:270] Iteration 5150 (3.96055 iter/s, 12.6245s/50 iter), loss = 0.0133824, remaining 0 hours and 28 minutes
I0614 13:03:25.580219  2299 solver.cpp:291]     Train net output #0: loss = 0.0133824 (* 1 = 0.0133824 loss)
I0614 13:03:25.580242  2299 sgd_solver.cpp:106] Iteration 5150, lr = 1e-05
I0614 13:03:38.203673  2299 solver.cpp:270] Iteration 5200 (3.96101 iter/s, 12.623s/50 iter), loss = 0.00497234, remaining 0 hours and 28 minutes
I0614 13:03:38.203991  2299 solver.cpp:291]     Train net output #0: loss = 0.00497233 (* 1 = 0.00497233 loss)
I0614 13:03:38.203999  2299 sgd_solver.cpp:106] Iteration 5200, lr = 1e-05
I0614 13:03:50.843559  2299 solver.cpp:270] Iteration 5250 (3.95596 iter/s, 12.6392s/50 iter), loss = 0.0180936, remaining 0 hours and 28 minutes
I0614 13:03:50.843590  2299 solver.cpp:291]     Train net output #0: loss = 0.0180936 (* 1 = 0.0180936 loss)
I0614 13:03:50.843612  2299 sgd_solver.cpp:106] Iteration 5250, lr = 1e-05
I0614 13:04:03.460680  2299 solver.cpp:270] Iteration 5300 (3.96301 iter/s, 12.6167s/50 iter), loss = 0.0300912, remaining 0 hours and 28 minutes
I0614 13:04:03.460707  2299 solver.cpp:291]     Train net output #0: loss = 0.0300912 (* 1 = 0.0300912 loss)
I0614 13:04:03.460716  2299 sgd_solver.cpp:106] Iteration 5300, lr = 1e-05
I0614 13:04:16.075137  2299 solver.cpp:270] Iteration 5350 (3.96384 iter/s, 12.614s/50 iter), loss = 0.025592, remaining 0 hours and 27 minutes
I0614 13:04:16.075318  2299 solver.cpp:291]     Train net output #0: loss = 0.0255919 (* 1 = 0.0255919 loss)
I0614 13:04:16.075342  2299 sgd_solver.cpp:106] Iteration 5350, lr = 1e-05
I0614 13:04:28.690409  2299 solver.cpp:270] Iteration 5400 (3.96364 iter/s, 12.6147s/50 iter), loss = 0.0273928, remaining 0 hours and 27 minutes
I0614 13:04:28.690439  2299 solver.cpp:291]     Train net output #0: loss = 0.0273928 (* 1 = 0.0273928 loss)
I0614 13:04:28.690446  2299 sgd_solver.cpp:106] Iteration 5400, lr = 1e-05
I0614 13:04:41.307085  2299 solver.cpp:270] Iteration 5450 (3.96315 iter/s, 12.6162s/50 iter), loss = 0.0627777, remaining 0 hours and 27 minutes
I0614 13:04:41.307113  2299 solver.cpp:291]     Train net output #0: loss = 0.0627777 (* 1 = 0.0627777 loss)
I0614 13:04:41.307121  2299 sgd_solver.cpp:106] Iteration 5450, lr = 1e-05
I0614 13:04:53.937953  2299 solver.cpp:270] Iteration 5500 (3.95869 iter/s, 12.6304s/50 iter), loss = 0.0386382, remaining 0 hours and 27 minutes
I0614 13:04:53.938208  2299 solver.cpp:291]     Train net output #0: loss = 0.0386381 (* 1 = 0.0386381 loss)
I0614 13:04:53.938217  2299 sgd_solver.cpp:106] Iteration 5500, lr = 1e-05
I0614 13:05:06.570674  2299 solver.cpp:270] Iteration 5550 (3.95818 iter/s, 12.6321s/50 iter), loss = 0.0627823, remaining 0 hours and 27 minutes
I0614 13:05:06.570704  2299 solver.cpp:291]     Train net output #0: loss = 0.0627823 (* 1 = 0.0627823 loss)
I0614 13:05:06.570713  2299 sgd_solver.cpp:106] Iteration 5550, lr = 1e-05
I0614 13:05:19.201321  2299 solver.cpp:270] Iteration 5600 (3.95876 iter/s, 12.6302s/50 iter), loss = 0.0352379, remaining 0 hours and 26 minutes
I0614 13:05:19.201350  2299 solver.cpp:291]     Train net output #0: loss = 0.0352379 (* 1 = 0.0352379 loss)
I0614 13:05:19.201357  2299 sgd_solver.cpp:106] Iteration 5600, lr = 1e-05
I0614 13:05:31.811144  2299 solver.cpp:270] Iteration 5650 (3.9653 iter/s, 12.6094s/50 iter), loss = 0.0179951, remaining 0 hours and 26 minutes
I0614 13:05:31.811403  2299 solver.cpp:291]     Train net output #0: loss = 0.0179951 (* 1 = 0.0179951 loss)
I0614 13:05:31.811410  2299 sgd_solver.cpp:106] Iteration 5650, lr = 1e-05
I0614 13:05:44.432217  2299 solver.cpp:270] Iteration 5700 (3.96184 iter/s, 12.6204s/50 iter), loss = 0.0051441, remaining 0 hours and 26 minutes
I0614 13:05:44.432248  2299 solver.cpp:291]     Train net output #0: loss = 0.00514409 (* 1 = 0.00514409 loss)
I0614 13:05:44.432256  2299 sgd_solver.cpp:106] Iteration 5700, lr = 1e-05
I0614 13:05:57.067359  2299 solver.cpp:270] Iteration 5750 (3.95736 iter/s, 12.6347s/50 iter), loss = 0.0380849, remaining 0 hours and 26 minutes
I0614 13:05:57.067389  2299 solver.cpp:291]     Train net output #0: loss = 0.0380849 (* 1 = 0.0380849 loss)
I0614 13:05:57.067396  2299 sgd_solver.cpp:106] Iteration 5750, lr = 1e-05
I0614 13:06:09.696013  2299 solver.cpp:270] Iteration 5800 (3.95939 iter/s, 12.6282s/50 iter), loss = 0.0102086, remaining 0 hours and 26 minutes
I0614 13:06:09.696333  2299 solver.cpp:291]     Train net output #0: loss = 0.0102086 (* 1 = 0.0102086 loss)
I0614 13:06:09.696341  2299 sgd_solver.cpp:106] Iteration 5800, lr = 1e-05
I0614 13:06:22.332684  2299 solver.cpp:270] Iteration 5850 (3.95697 iter/s, 12.6359s/50 iter), loss = 0.0140108, remaining 0 hours and 25 minutes
I0614 13:06:22.332713  2299 solver.cpp:291]     Train net output #0: loss = 0.0140108 (* 1 = 0.0140108 loss)
I0614 13:06:22.332720  2299 sgd_solver.cpp:106] Iteration 5850, lr = 1e-05
I0614 13:06:34.955430  2299 solver.cpp:270] Iteration 5900 (3.96124 iter/s, 12.6223s/50 iter), loss = 0.0491338, remaining 0 hours and 25 minutes
I0614 13:06:34.955458  2299 solver.cpp:291]     Train net output #0: loss = 0.0491338 (* 1 = 0.0491338 loss)
I0614 13:06:34.955466  2299 sgd_solver.cpp:106] Iteration 5900, lr = 1e-05
I0614 13:06:47.589742  2299 solver.cpp:270] Iteration 5950 (3.95761 iter/s, 12.6339s/50 iter), loss = 0.0202705, remaining 0 hours and 25 minutes
I0614 13:06:47.589977  2299 solver.cpp:291]     Train net output #0: loss = 0.0202705 (* 1 = 0.0202705 loss)
I0614 13:06:47.589987  2299 sgd_solver.cpp:106] Iteration 5950, lr = 1e-05
I0614 13:06:59.985123  2299 solver.cpp:935] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0/snapshots/_iter_6000.caffemodel
I0614 13:07:05.781517  2299 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0/snapshots/_iter_6000.solverstate
I0614 13:07:09.303442  2299 solver.cpp:424] Iteration 6000, Testing net (#0)
I0614 13:07:10.729128  2299 solver.cpp:523]     Test net output #0: accuracy = 0.95625
I0614 13:07:10.729159  2299 solver.cpp:523]     Test net output #1: loss = 0.130566 (* 1 = 0.130566 loss)
I0614 13:07:10.729163  2299 solver.cpp:523]     Test net output #2: top-1 = 0.95625
I0614 13:07:10.967696  2299 solver.cpp:270] Iteration 6000 (2.13886 iter/s, 23.377s/50 iter), loss = 0.0321883, remaining 0 hours and 46 minutes
I0614 13:07:10.967725  2299 solver.cpp:291]     Train net output #0: loss = 0.0321883 (* 1 = 0.0321883 loss)
I0614 13:07:10.967733  2299 sgd_solver.cpp:106] Iteration 6000, lr = 1e-05
I0614 13:07:23.459446  2299 solver.cpp:270] Iteration 6050 (4.00278 iter/s, 12.4913s/50 iter), loss = 0.0338698, remaining 0 hours and 24 minutes
I0614 13:07:23.459692  2299 solver.cpp:291]     Train net output #0: loss = 0.0338698 (* 1 = 0.0338698 loss)
I0614 13:07:23.459700  2299 sgd_solver.cpp:106] Iteration 6050, lr = 1e-05
I0614 13:07:35.951460  2299 solver.cpp:270] Iteration 6100 (4.00277 iter/s, 12.4914s/50 iter), loss = 0.0155964, remaining 0 hours and 24 minutes
I0614 13:07:35.951493  2299 solver.cpp:291]     Train net output #0: loss = 0.0155964 (* 1 = 0.0155964 loss)
I0614 13:07:35.951500  2299 sgd_solver.cpp:106] Iteration 6100, lr = 1e-05
I0614 13:07:48.525787  2299 solver.cpp:270] Iteration 6150 (3.9765 iter/s, 12.5739s/50 iter), loss = 0.0254898, remaining 0 hours and 24 minutes
I0614 13:07:48.525817  2299 solver.cpp:291]     Train net output #0: loss = 0.0254897 (* 1 = 0.0254897 loss)
I0614 13:07:48.525825  2299 sgd_solver.cpp:106] Iteration 6150, lr = 1e-05
I0614 13:08:01.167770  2299 solver.cpp:270] Iteration 6200 (3.95521 iter/s, 12.6415s/50 iter), loss = 0.0167452, remaining 0 hours and 24 minutes
I0614 13:08:01.167974  2299 solver.cpp:291]     Train net output #0: loss = 0.0167452 (* 1 = 0.0167452 loss)
I0614 13:08:01.167982  2299 sgd_solver.cpp:106] Iteration 6200, lr = 1e-05
I0614 13:08:13.784622  2299 solver.cpp:270] Iteration 6250 (3.96315 iter/s, 12.6162s/50 iter), loss = 0.0544816, remaining 0 hours and 23 minutes
I0614 13:08:13.784652  2299 solver.cpp:291]     Train net output #0: loss = 0.0544816 (* 1 = 0.0544816 loss)
I0614 13:08:13.784659  2299 sgd_solver.cpp:106] Iteration 6250, lr = 1e-05
I0614 13:08:26.408255  2299 solver.cpp:270] Iteration 6300 (3.96096 iter/s, 12.6232s/50 iter), loss = 0.0206691, remaining 0 hours and 23 minutes
I0614 13:08:26.408288  2299 solver.cpp:291]     Train net output #0: loss = 0.0206691 (* 1 = 0.0206691 loss)
I0614 13:08:26.408298  2299 sgd_solver.cpp:106] Iteration 6300, lr = 1e-05
I0614 13:08:39.019274  2299 solver.cpp:270] Iteration 6350 (3.96493 iter/s, 12.6106s/50 iter), loss = 0.024107, remaining 0 hours and 23 minutes
I0614 13:08:39.019577  2299 solver.cpp:291]     Train net output #0: loss = 0.024107 (* 1 = 0.024107 loss)
I0614 13:08:39.019587  2299 sgd_solver.cpp:106] Iteration 6350, lr = 1e-05
I0614 13:08:51.631465  2299 solver.cpp:270] Iteration 6400 (3.96464 iter/s, 12.6115s/50 iter), loss = 0.00303527, remaining 0 hours and 23 minutes
I0614 13:08:51.631496  2299 solver.cpp:291]     Train net output #0: loss = 0.00303525 (* 1 = 0.00303525 loss)
I0614 13:08:51.631503  2299 sgd_solver.cpp:106] Iteration 6400, lr = 1e-05
I0614 13:09:04.248350  2299 solver.cpp:270] Iteration 6450 (3.96308 iter/s, 12.6164s/50 iter), loss = 0.00429903, remaining 0 hours and 23 minutes
I0614 13:09:04.248380  2299 solver.cpp:291]     Train net output #0: loss = 0.00429902 (* 1 = 0.00429902 loss)
I0614 13:09:04.248389  2299 sgd_solver.cpp:106] Iteration 6450, lr = 1e-05
I0614 13:09:16.860256  2299 solver.cpp:270] Iteration 6500 (3.96465 iter/s, 12.6115s/50 iter), loss = 0.0183825, remaining 0 hours and 22 minutes
I0614 13:09:16.860491  2299 solver.cpp:291]     Train net output #0: loss = 0.0183825 (* 1 = 0.0183825 loss)
I0614 13:09:16.860499  2299 sgd_solver.cpp:106] Iteration 6500, lr = 1e-05
I0614 13:09:29.504669  2299 solver.cpp:270] Iteration 6550 (3.95452 iter/s, 12.6438s/50 iter), loss = 0.0223286, remaining 0 hours and 22 minutes
I0614 13:09:29.504698  2299 solver.cpp:291]     Train net output #0: loss = 0.0223285 (* 1 = 0.0223285 loss)
I0614 13:09:29.504705  2299 sgd_solver.cpp:106] Iteration 6550, lr = 1e-05
I0614 13:09:42.148046  2299 solver.cpp:270] Iteration 6600 (3.95478 iter/s, 12.6429s/50 iter), loss = 0.031216, remaining 0 hours and 22 minutes
I0614 13:09:42.148075  2299 solver.cpp:291]     Train net output #0: loss = 0.031216 (* 1 = 0.031216 loss)
I0614 13:09:42.148082  2299 sgd_solver.cpp:106] Iteration 6600, lr = 1e-05
I0614 13:09:54.797921  2299 solver.cpp:270] Iteration 6650 (3.95275 iter/s, 12.6494s/50 iter), loss = 0.0113096, remaining 0 hours and 22 minutes
I0614 13:09:54.798112  2299 solver.cpp:291]     Train net output #0: loss = 0.0113096 (* 1 = 0.0113096 loss)
I0614 13:09:54.798120  2299 sgd_solver.cpp:106] Iteration 6650, lr = 1e-05
I0614 13:10:07.433800  2299 solver.cpp:270] Iteration 6700 (3.95717 iter/s, 12.6353s/50 iter), loss = 0.00906691, remaining 0 hours and 22 minutes
I0614 13:10:07.433830  2299 solver.cpp:291]     Train net output #0: loss = 0.0090669 (* 1 = 0.0090669 loss)
I0614 13:10:07.433837  2299 sgd_solver.cpp:106] Iteration 6700, lr = 1e-05
I0614 13:10:20.061982  2299 solver.cpp:270] Iteration 6750 (3.95954 iter/s, 12.6277s/50 iter), loss = 0.0147284, remaining 0 hours and 21 minutes
I0614 13:10:20.062011  2299 solver.cpp:291]     Train net output #0: loss = 0.0147284 (* 1 = 0.0147284 loss)
I0614 13:10:20.062019  2299 sgd_solver.cpp:106] Iteration 6750, lr = 1e-05
I0614 13:10:32.695118  2299 solver.cpp:270] Iteration 6800 (3.95798 iter/s, 12.6327s/50 iter), loss = 0.0166497, remaining 0 hours and 21 minutes
I0614 13:10:32.695348  2299 solver.cpp:291]     Train net output #0: loss = 0.0166497 (* 1 = 0.0166497 loss)
I0614 13:10:32.695356  2299 sgd_solver.cpp:106] Iteration 6800, lr = 1e-05
I0614 13:10:45.324112  2299 solver.cpp:270] Iteration 6850 (3.95934 iter/s, 12.6284s/50 iter), loss = 0.00827355, remaining 0 hours and 21 minutes
I0614 13:10:45.324142  2299 solver.cpp:291]     Train net output #0: loss = 0.00827354 (* 1 = 0.00827354 loss)
I0614 13:10:45.324149  2299 sgd_solver.cpp:106] Iteration 6850, lr = 1e-05
I0614 13:10:58.031494  2299 solver.cpp:270] Iteration 6900 (3.93486 iter/s, 12.7069s/50 iter), loss = 0.0158016, remaining 0 hours and 21 minutes
I0614 13:10:58.031527  2299 solver.cpp:291]     Train net output #0: loss = 0.0158016 (* 1 = 0.0158016 loss)
I0614 13:10:58.031549  2299 sgd_solver.cpp:106] Iteration 6900, lr = 1e-05
I0614 13:11:10.733386  2299 solver.cpp:270] Iteration 6950 (3.93656 iter/s, 12.7014s/50 iter), loss = 0.0240777, remaining 0 hours and 21 minutes
I0614 13:11:10.733711  2299 solver.cpp:291]     Train net output #0: loss = 0.0240777 (* 1 = 0.0240777 loss)
I0614 13:11:10.733721  2299 sgd_solver.cpp:106] Iteration 6950, lr = 1e-05
I0614 13:11:23.137193  2299 solver.cpp:424] Iteration 7000, Testing net (#0)
I0614 13:11:24.627549  2299 solver.cpp:523]     Test net output #0: accuracy = 0.95675
I0614 13:11:24.627578  2299 solver.cpp:523]     Test net output #1: loss = 0.143694 (* 1 = 0.143694 loss)
I0614 13:11:24.627583  2299 solver.cpp:523]     Test net output #2: top-1 = 0.95675
I0614 13:11:24.874012  2299 solver.cpp:270] Iteration 7000 (3.53611 iter/s, 14.1398s/50 iter), loss = 0.0154608, remaining 0 hours and 23 minutes
I0614 13:11:24.874040  2299 solver.cpp:291]     Train net output #0: loss = 0.0154608 (* 1 = 0.0154608 loss)
I0614 13:11:24.874047  2299 sgd_solver.cpp:106] Iteration 7000, lr = 1e-05
I0614 13:11:37.507014  2299 solver.cpp:270] Iteration 7050 (3.95803 iter/s, 12.6326s/50 iter), loss = 0.0181223, remaining 0 hours and 20 minutes
I0614 13:11:37.507043  2299 solver.cpp:291]     Train net output #0: loss = 0.0181223 (* 1 = 0.0181223 loss)
I0614 13:11:37.507051  2299 sgd_solver.cpp:106] Iteration 7050, lr = 1e-05
I0614 13:11:50.214627  2299 solver.cpp:270] Iteration 7100 (3.93479 iter/s, 12.7072s/50 iter), loss = 0.0188675, remaining 0 hours and 20 minutes
I0614 13:11:50.214859  2299 solver.cpp:291]     Train net output #0: loss = 0.0188675 (* 1 = 0.0188675 loss)
I0614 13:11:50.214869  2299 sgd_solver.cpp:106] Iteration 7100, lr = 1e-05
I0614 13:12:02.923925  2299 solver.cpp:270] Iteration 7150 (3.93433 iter/s, 12.7087s/50 iter), loss = 0.0208566, remaining 0 hours and 20 minutes
I0614 13:12:02.923954  2299 solver.cpp:291]     Train net output #0: loss = 0.0208566 (* 1 = 0.0208566 loss)
I0614 13:12:02.923961  2299 sgd_solver.cpp:106] Iteration 7150, lr = 1e-05
I0614 13:12:15.603910  2299 solver.cpp:270] Iteration 7200 (3.94336 iter/s, 12.6795s/50 iter), loss = 0.011497, remaining 0 hours and 20 minutes
I0614 13:12:15.603940  2299 solver.cpp:291]     Train net output #0: loss = 0.011497 (* 1 = 0.011497 loss)
I0614 13:12:15.603947  2299 sgd_solver.cpp:106] Iteration 7200, lr = 1e-05
I0614 13:12:28.323948  2299 solver.cpp:270] Iteration 7250 (3.93094 iter/s, 12.7196s/50 iter), loss = 0.0219881, remaining 0 hours and 20 minutes
I0614 13:12:28.324204  2299 solver.cpp:291]     Train net output #0: loss = 0.0219881 (* 1 = 0.0219881 loss)
I0614 13:12:28.324213  2299 sgd_solver.cpp:106] Iteration 7250, lr = 1e-05
I0614 13:12:40.998054  2299 solver.cpp:270] Iteration 7300 (3.94526 iter/s, 12.6734s/50 iter), loss = 0.0183716, remaining 0 hours and 19 minutes
I0614 13:12:40.998085  2299 solver.cpp:291]     Train net output #0: loss = 0.0183716 (* 1 = 0.0183716 loss)
I0614 13:12:40.998092  2299 sgd_solver.cpp:106] Iteration 7300, lr = 1e-05
I0614 13:12:53.662700  2299 solver.cpp:270] Iteration 7350 (3.94814 iter/s, 12.6642s/50 iter), loss = 0.00603064, remaining 0 hours and 19 minutes
I0614 13:12:53.662731  2299 solver.cpp:291]     Train net output #0: loss = 0.00603063 (* 1 = 0.00603063 loss)
I0614 13:12:53.662739  2299 sgd_solver.cpp:106] Iteration 7350, lr = 1e-05
I0614 13:13:06.267189  2299 solver.cpp:270] Iteration 7400 (3.96698 iter/s, 12.604s/50 iter), loss = 0.00562506, remaining 0 hours and 19 minutes
I0614 13:13:06.267374  2299 solver.cpp:291]     Train net output #0: loss = 0.00562505 (* 1 = 0.00562505 loss)
I0614 13:13:06.267383  2299 sgd_solver.cpp:106] Iteration 7400, lr = 1e-05
I0614 13:13:18.884234  2299 solver.cpp:270] Iteration 7450 (3.96308 iter/s, 12.6165s/50 iter), loss = 0.00861916, remaining 0 hours and 18 minutes
I0614 13:13:18.884263  2299 solver.cpp:291]     Train net output #0: loss = 0.00861915 (* 1 = 0.00861915 loss)
I0614 13:13:18.884270  2299 sgd_solver.cpp:106] Iteration 7450, lr = 1e-05
I0614 13:13:31.514348  2299 solver.cpp:270] Iteration 7500 (3.95893 iter/s, 12.6297s/50 iter), loss = 0.0289427, remaining 0 hours and 18 minutes
I0614 13:13:31.514379  2299 solver.cpp:291]     Train net output #0: loss = 0.0289427 (* 1 = 0.0289427 loss)
I0614 13:13:31.514386  2299 sgd_solver.cpp:106] Iteration 7500, lr = 1e-06
I0614 13:13:44.136495  2299 solver.cpp:270] Iteration 7550 (3.96143 iter/s, 12.6217s/50 iter), loss = 0.00270985, remaining 0 hours and 18 minutes
I0614 13:13:44.136771  2299 solver.cpp:291]     Train net output #0: loss = 0.00270985 (* 1 = 0.00270985 loss)
I0614 13:13:44.136795  2299 sgd_solver.cpp:106] Iteration 7550, lr = 1e-06
I0614 13:13:56.760028  2299 solver.cpp:270] Iteration 7600 (3.96107 iter/s, 12.6228s/50 iter), loss = 0.00606326, remaining 0 hours and 18 minutes
I0614 13:13:56.760059  2299 solver.cpp:291]     Train net output #0: loss = 0.00606328 (* 1 = 0.00606328 loss)
I0614 13:13:56.760067  2299 sgd_solver.cpp:106] Iteration 7600, lr = 1e-06
I0614 13:14:09.394567  2299 solver.cpp:270] Iteration 7650 (3.95754 iter/s, 12.6341s/50 iter), loss = 0.0136237, remaining 0 hours and 18 minutes
I0614 13:14:09.394598  2299 solver.cpp:291]     Train net output #0: loss = 0.0136237 (* 1 = 0.0136237 loss)
I0614 13:14:09.394620  2299 sgd_solver.cpp:106] Iteration 7650, lr = 1e-06
I0614 13:14:22.015012  2299 solver.cpp:270] Iteration 7700 (3.96196 iter/s, 12.62s/50 iter), loss = 0.00421924, remaining 0 hours and 17 minutes
I0614 13:14:22.015259  2299 solver.cpp:291]     Train net output #0: loss = 0.00421925 (* 1 = 0.00421925 loss)
I0614 13:14:22.015267  2299 sgd_solver.cpp:106] Iteration 7700, lr = 1e-06
I0614 13:14:34.650648  2299 solver.cpp:270] Iteration 7750 (3.95727 iter/s, 12.635s/50 iter), loss = 0.0183227, remaining 0 hours and 17 minutes
I0614 13:14:34.650677  2299 solver.cpp:291]     Train net output #0: loss = 0.0183227 (* 1 = 0.0183227 loss)
I0614 13:14:34.650686  2299 sgd_solver.cpp:106] Iteration 7750, lr = 1e-06
I0614 13:14:47.286098  2299 solver.cpp:270] Iteration 7800 (3.95726 iter/s, 12.635s/50 iter), loss = 0.0159657, remaining 0 hours and 17 minutes
I0614 13:14:47.286128  2299 solver.cpp:291]     Train net output #0: loss = 0.0159657 (* 1 = 0.0159657 loss)
I0614 13:14:47.286136  2299 sgd_solver.cpp:106] Iteration 7800, lr = 1e-06
I0614 13:14:59.903475  2299 solver.cpp:270] Iteration 7850 (3.96293 iter/s, 12.6169s/50 iter), loss = 0.0225357, remaining 0 hours and 17 minutes
I0614 13:14:59.903724  2299 solver.cpp:291]     Train net output #0: loss = 0.0225357 (* 1 = 0.0225357 loss)
I0614 13:14:59.903733  2299 sgd_solver.cpp:106] Iteration 7850, lr = 1e-06
I0614 13:15:12.545950  2299 solver.cpp:270] Iteration 7900 (3.95512 iter/s, 12.6418s/50 iter), loss = 0.00700143, remaining 0 hours and 17 minutes
I0614 13:15:12.545979  2299 solver.cpp:291]     Train net output #0: loss = 0.00700144 (* 1 = 0.00700144 loss)
I0614 13:15:12.545987  2299 sgd_solver.cpp:106] Iteration 7900, lr = 1e-06
I0614 13:15:25.169972  2299 solver.cpp:270] Iteration 7950 (3.96084 iter/s, 12.6236s/50 iter), loss = 0.035884, remaining 0 hours and 16 minutes
I0614 13:15:25.170003  2299 solver.cpp:291]     Train net output #0: loss = 0.035884 (* 1 = 0.035884 loss)
I0614 13:15:25.170011  2299 sgd_solver.cpp:106] Iteration 7950, lr = 1e-06
I0614 13:15:37.551424  2299 solver.cpp:424] Iteration 8000, Testing net (#0)
I0614 13:15:39.045176  2299 solver.cpp:523]     Test net output #0: accuracy = 0.95675
I0614 13:15:39.045203  2299 solver.cpp:523]     Test net output #1: loss = 0.165024 (* 1 = 0.165024 loss)
I0614 13:15:39.045208  2299 solver.cpp:523]     Test net output #2: top-1 = 0.95675
I0614 13:15:39.292251  2299 solver.cpp:270] Iteration 8000 (3.54063 iter/s, 14.1218s/50 iter), loss = 0.00837282, remaining 0 hours and 18 minutes
I0614 13:15:39.292280  2299 solver.cpp:291]     Train net output #0: loss = 0.00837282 (* 1 = 0.00837282 loss)
I0614 13:15:39.292287  2299 sgd_solver.cpp:106] Iteration 8000, lr = 1e-06
I0614 13:15:51.914772  2299 solver.cpp:270] Iteration 8050 (3.96131 iter/s, 12.6221s/50 iter), loss = 0.0316715, remaining 0 hours and 16 minutes
I0614 13:15:51.914803  2299 solver.cpp:291]     Train net output #0: loss = 0.0316715 (* 1 = 0.0316715 loss)
I0614 13:15:51.914809  2299 sgd_solver.cpp:106] Iteration 8050, lr = 1e-06
I0614 13:16:04.540122  2299 solver.cpp:270] Iteration 8100 (3.96042 iter/s, 12.6249s/50 iter), loss = 0.0111718, remaining 0 hours and 16 minutes
I0614 13:16:04.540153  2299 solver.cpp:291]     Train net output #0: loss = 0.0111718 (* 1 = 0.0111718 loss)
I0614 13:16:04.540177  2299 sgd_solver.cpp:106] Iteration 8100, lr = 1e-06
I0614 13:16:17.161268  2299 solver.cpp:270] Iteration 8150 (3.96174 iter/s, 12.6207s/50 iter), loss = 0.0298679, remaining 0 hours and 16 minutes
I0614 13:16:17.161612  2299 solver.cpp:291]     Train net output #0: loss = 0.0298679 (* 1 = 0.0298679 loss)
I0614 13:16:17.161636  2299 sgd_solver.cpp:106] Iteration 8150, lr = 1e-06
I0614 13:16:29.792234  2299 solver.cpp:270] Iteration 8200 (3.95876 iter/s, 12.6302s/50 iter), loss = 0.00765006, remaining 0 hours and 15 minutes
I0614 13:16:29.792263  2299 solver.cpp:291]     Train net output #0: loss = 0.00765007 (* 1 = 0.00765007 loss)
I0614 13:16:29.792270  2299 sgd_solver.cpp:106] Iteration 8200, lr = 1e-06
I0614 13:16:42.517832  2299 solver.cpp:270] Iteration 8250 (3.92923 iter/s, 12.7252s/50 iter), loss = 0.0198372, remaining 0 hours and 15 minutes
I0614 13:16:42.517861  2299 solver.cpp:291]     Train net output #0: loss = 0.0198372 (* 1 = 0.0198372 loss)
I0614 13:16:42.517886  2299 sgd_solver.cpp:106] Iteration 8250, lr = 1e-06
I0614 13:16:55.227687  2299 solver.cpp:270] Iteration 8300 (3.93409 iter/s, 12.7094s/50 iter), loss = 0.00973438, remaining 0 hours and 15 minutes
I0614 13:16:55.227921  2299 solver.cpp:291]     Train net output #0: loss = 0.00973438 (* 1 = 0.00973438 loss)
I0614 13:16:55.227928  2299 sgd_solver.cpp:106] Iteration 8300, lr = 1e-06
I0614 13:17:07.924916  2299 solver.cpp:270] Iteration 8350 (3.93807 iter/s, 12.6966s/50 iter), loss = 0.0163883, remaining 0 hours and 15 minutes
I0614 13:17:07.924945  2299 solver.cpp:291]     Train net output #0: loss = 0.0163883 (* 1 = 0.0163883 loss)
I0614 13:17:07.924968  2299 sgd_solver.cpp:106] Iteration 8350, lr = 1e-06
I0614 13:17:20.581365  2299 solver.cpp:270] Iteration 8400 (3.95069 iter/s, 12.656s/50 iter), loss = 0.0218549, remaining 0 hours and 15 minutes
I0614 13:17:20.581398  2299 solver.cpp:291]     Train net output #0: loss = 0.0218549 (* 1 = 0.0218549 loss)
I0614 13:17:20.581406  2299 sgd_solver.cpp:106] Iteration 8400, lr = 1e-06
I0614 13:17:33.207082  2299 solver.cpp:270] Iteration 8450 (3.96031 iter/s, 12.6253s/50 iter), loss = 0.0144048, remaining 0 hours and 14 minutes
I0614 13:17:33.207321  2299 solver.cpp:291]     Train net output #0: loss = 0.0144048 (* 1 = 0.0144048 loss)
I0614 13:17:33.207345  2299 sgd_solver.cpp:106] Iteration 8450, lr = 1e-06
I0614 13:17:45.829030  2299 solver.cpp:270] Iteration 8500 (3.96156 iter/s, 12.6213s/50 iter), loss = 0.00808429, remaining 0 hours and 14 minutes
I0614 13:17:45.829061  2299 solver.cpp:291]     Train net output #0: loss = 0.00808428 (* 1 = 0.00808428 loss)
I0614 13:17:45.829067  2299 sgd_solver.cpp:106] Iteration 8500, lr = 1e-06
I0614 13:17:58.441474  2299 solver.cpp:270] Iteration 8550 (3.96448 iter/s, 12.612s/50 iter), loss = 0.0314783, remaining 0 hours and 14 minutes
I0614 13:17:58.441505  2299 solver.cpp:291]     Train net output #0: loss = 0.0314783 (* 1 = 0.0314783 loss)
I0614 13:17:58.441514  2299 sgd_solver.cpp:106] Iteration 8550, lr = 1e-06
I0614 13:18:11.062806  2299 solver.cpp:270] Iteration 8600 (3.96169 iter/s, 12.6209s/50 iter), loss = 0.00481807, remaining 0 hours and 14 minutes
I0614 13:18:11.063052  2299 solver.cpp:291]     Train net output #0: loss = 0.00481807 (* 1 = 0.00481807 loss)
I0614 13:18:11.063076  2299 sgd_solver.cpp:106] Iteration 8600, lr = 1e-06
I0614 13:18:23.676885  2299 solver.cpp:270] Iteration 8650 (3.96403 iter/s, 12.6134s/50 iter), loss = 0.00343088, remaining 0 hours and 13 minutes
I0614 13:18:23.676916  2299 solver.cpp:291]     Train net output #0: loss = 0.00343087 (* 1 = 0.00343087 loss)
I0614 13:18:23.676924  2299 sgd_solver.cpp:106] Iteration 8650, lr = 1e-06
I0614 13:18:36.306653  2299 solver.cpp:270] Iteration 8700 (3.95904 iter/s, 12.6293s/50 iter), loss = 0.016468, remaining 0 hours and 13 minutes
I0614 13:18:36.306682  2299 solver.cpp:291]     Train net output #0: loss = 0.016468 (* 1 = 0.016468 loss)
I0614 13:18:36.306706  2299 sgd_solver.cpp:106] Iteration 8700, lr = 1e-06
I0614 13:18:48.922261  2299 solver.cpp:270] Iteration 8750 (3.96348 iter/s, 12.6152s/50 iter), loss = 0.025288, remaining 0 hours and 13 minutes
I0614 13:18:48.922595  2299 solver.cpp:291]     Train net output #0: loss = 0.025288 (* 1 = 0.025288 loss)
I0614 13:18:48.922602  2299 sgd_solver.cpp:106] Iteration 8750, lr = 1e-06
I0614 13:19:01.559613  2299 solver.cpp:270] Iteration 8800 (3.95676 iter/s, 12.6366s/50 iter), loss = 0.0135454, remaining 0 hours and 13 minutes
I0614 13:19:01.559643  2299 solver.cpp:291]     Train net output #0: loss = 0.0135454 (* 1 = 0.0135454 loss)
I0614 13:19:01.559650  2299 sgd_solver.cpp:106] Iteration 8800, lr = 1e-06
I0614 13:19:14.191818  2299 solver.cpp:270] Iteration 8850 (3.95827 iter/s, 12.6318s/50 iter), loss = 0.00749604, remaining 0 hours and 13 minutes
I0614 13:19:14.191849  2299 solver.cpp:291]     Train net output #0: loss = 0.00749603 (* 1 = 0.00749603 loss)
I0614 13:19:14.191857  2299 sgd_solver.cpp:106] Iteration 8850, lr = 1e-06
I0614 13:19:26.824689  2299 solver.cpp:270] Iteration 8900 (3.95807 iter/s, 12.6324s/50 iter), loss = 0.0104725, remaining 0 hours and 12 minutes
I0614 13:19:26.824884  2299 solver.cpp:291]     Train net output #0: loss = 0.0104725 (* 1 = 0.0104725 loss)
I0614 13:19:26.824908  2299 sgd_solver.cpp:106] Iteration 8900, lr = 1e-06
I0614 13:19:39.444394  2299 solver.cpp:270] Iteration 8950 (3.96225 iter/s, 12.6191s/50 iter), loss = 0.00787281, remaining 0 hours and 12 minutes
I0614 13:19:39.444425  2299 solver.cpp:291]     Train net output #0: loss = 0.0078728 (* 1 = 0.0078728 loss)
I0614 13:19:39.444432  2299 sgd_solver.cpp:106] Iteration 8950, lr = 1e-06
I0614 13:19:51.809971  2299 solver.cpp:424] Iteration 9000, Testing net (#0)
I0614 13:19:53.318048  2299 solver.cpp:523]     Test net output #0: accuracy = 0.9575
I0614 13:19:53.318075  2299 solver.cpp:523]     Test net output #1: loss = 0.178486 (* 1 = 0.178486 loss)
I0614 13:19:53.318080  2299 solver.cpp:523]     Test net output #2: top-1 = 0.9575
I0614 13:19:53.564698  2299 solver.cpp:270] Iteration 9000 (3.54112 iter/s, 14.1198s/50 iter), loss = 0.0290559, remaining 0 hours and 14 minutes
I0614 13:19:53.564728  2299 solver.cpp:291]     Train net output #0: loss = 0.0290559 (* 1 = 0.0290559 loss)
I0614 13:19:53.564735  2299 sgd_solver.cpp:106] Iteration 9000, lr = 1e-06
I0614 13:20:06.220522  2299 solver.cpp:270] Iteration 9050 (3.95089 iter/s, 12.6554s/50 iter), loss = 0.00589824, remaining 0 hours and 12 minutes
I0614 13:20:06.220767  2299 solver.cpp:291]     Train net output #0: loss = 0.00589824 (* 1 = 0.00589824 loss)
I0614 13:20:06.220774  2299 sgd_solver.cpp:106] Iteration 9050, lr = 1e-06
I0614 13:20:18.847836  2299 solver.cpp:270] Iteration 9100 (3.95987 iter/s, 12.6267s/50 iter), loss = 0.0201367, remaining 0 hours and 12 minutes
I0614 13:20:18.847867  2299 solver.cpp:291]     Train net output #0: loss = 0.0201367 (* 1 = 0.0201367 loss)
I0614 13:20:18.847874  2299 sgd_solver.cpp:106] Iteration 9100, lr = 1e-06
I0614 13:20:31.475271  2299 solver.cpp:270] Iteration 9150 (3.95977 iter/s, 12.627s/50 iter), loss = 0.0105816, remaining 0 hours and 11 minutes
I0614 13:20:31.475302  2299 solver.cpp:291]     Train net output #0: loss = 0.0105816 (* 1 = 0.0105816 loss)
I0614 13:20:31.475311  2299 sgd_solver.cpp:106] Iteration 9150, lr = 1e-06
I0614 13:20:44.095161  2299 solver.cpp:270] Iteration 9200 (3.96214 iter/s, 12.6194s/50 iter), loss = 0.0315637, remaining 0 hours and 11 minutes
I0614 13:20:44.095337  2299 solver.cpp:291]     Train net output #0: loss = 0.0315637 (* 1 = 0.0315637 loss)
I0614 13:20:44.095348  2299 sgd_solver.cpp:106] Iteration 9200, lr = 1e-06
I0614 13:20:56.739499  2299 solver.cpp:270] Iteration 9250 (3.95452 iter/s, 12.6438s/50 iter), loss = 0.015623, remaining 0 hours and 11 minutes
I0614 13:20:56.739529  2299 solver.cpp:291]     Train net output #0: loss = 0.015623 (* 1 = 0.015623 loss)
I0614 13:20:56.739537  2299 sgd_solver.cpp:106] Iteration 9250, lr = 1e-06
I0614 13:21:09.365262  2299 solver.cpp:270] Iteration 9300 (3.96029 iter/s, 12.6253s/50 iter), loss = 0.0234052, remaining 0 hours and 11 minutes
I0614 13:21:09.365293  2299 solver.cpp:291]     Train net output #0: loss = 0.0234052 (* 1 = 0.0234052 loss)
I0614 13:21:09.365316  2299 sgd_solver.cpp:106] Iteration 9300, lr = 1e-06
I0614 13:21:21.987640  2299 solver.cpp:270] Iteration 9350 (3.96136 iter/s, 12.6219s/50 iter), loss = 0.019927, remaining 0 hours and 11 minutes
I0614 13:21:21.987919  2299 solver.cpp:291]     Train net output #0: loss = 0.019927 (* 1 = 0.019927 loss)
I0614 13:21:21.987943  2299 sgd_solver.cpp:106] Iteration 9350, lr = 1e-06
I0614 13:21:34.598750  2299 solver.cpp:270] Iteration 9400 (3.96497 iter/s, 12.6104s/50 iter), loss = 0.00817724, remaining 0 hours and 10 minutes
I0614 13:21:34.598779  2299 solver.cpp:291]     Train net output #0: loss = 0.00817724 (* 1 = 0.00817724 loss)
I0614 13:21:34.598803  2299 sgd_solver.cpp:106] Iteration 9400, lr = 1e-06
I0614 13:21:47.228376  2299 solver.cpp:270] Iteration 9450 (3.95908 iter/s, 12.6292s/50 iter), loss = 0.00220328, remaining 0 hours and 10 minutes
I0614 13:21:47.228407  2299 solver.cpp:291]     Train net output #0: loss = 0.00220327 (* 1 = 0.00220327 loss)
I0614 13:21:47.228415  2299 sgd_solver.cpp:106] Iteration 9450, lr = 1e-06
I0614 13:21:59.846146  2299 solver.cpp:270] Iteration 9500 (3.9628 iter/s, 12.6173s/50 iter), loss = 0.0198882, remaining 0 hours and 10 minutes
I0614 13:21:59.846352  2299 solver.cpp:291]     Train net output #0: loss = 0.0198882 (* 1 = 0.0198882 loss)
I0614 13:21:59.846361  2299 sgd_solver.cpp:106] Iteration 9500, lr = 1e-06
I0614 13:22:12.463847  2299 solver.cpp:270] Iteration 9550 (3.96288 iter/s, 12.6171s/50 iter), loss = 0.00487695, remaining 0 hours and 10 minutes
I0614 13:22:12.463876  2299 solver.cpp:291]     Train net output #0: loss = 0.00487694 (* 1 = 0.00487694 loss)
I0614 13:22:12.463884  2299 sgd_solver.cpp:106] Iteration 9550, lr = 1e-06
I0614 13:22:25.084914  2299 solver.cpp:270] Iteration 9600 (3.96177 iter/s, 12.6206s/50 iter), loss = 0.00625935, remaining 0 hours and 10 minutes
I0614 13:22:25.084945  2299 solver.cpp:291]     Train net output #0: loss = 0.00625934 (* 1 = 0.00625934 loss)
I0614 13:22:25.084954  2299 sgd_solver.cpp:106] Iteration 9600, lr = 1e-06
I0614 13:22:37.728021  2299 solver.cpp:270] Iteration 9650 (3.95486 iter/s, 12.6427s/50 iter), loss = 0.0471685, remaining 0 hours and 9 minutes
I0614 13:22:37.728204  2299 solver.cpp:291]     Train net output #0: loss = 0.0471684 (* 1 = 0.0471684 loss)
I0614 13:22:37.728214  2299 sgd_solver.cpp:106] Iteration 9650, lr = 1e-06
I0614 13:22:50.341037  2299 solver.cpp:270] Iteration 9700 (3.96434 iter/s, 12.6124s/50 iter), loss = 0.0133911, remaining 0 hours and 9 minutes
I0614 13:22:50.341065  2299 solver.cpp:291]     Train net output #0: loss = 0.0133911 (* 1 = 0.0133911 loss)
I0614 13:22:50.341073  2299 sgd_solver.cpp:106] Iteration 9700, lr = 1e-06
I0614 13:23:02.965608  2299 solver.cpp:270] Iteration 9750 (3.96067 iter/s, 12.6241s/50 iter), loss = 0.0106895, remaining 0 hours and 9 minutes
I0614 13:23:02.965639  2299 solver.cpp:291]     Train net output #0: loss = 0.0106895 (* 1 = 0.0106895 loss)
I0614 13:23:02.965647  2299 sgd_solver.cpp:106] Iteration 9750, lr = 1e-06
I0614 13:23:15.600237  2299 solver.cpp:270] Iteration 9800 (3.95752 iter/s, 12.6342s/50 iter), loss = 0.0205957, remaining 0 hours and 9 minutes
I0614 13:23:15.600488  2299 solver.cpp:291]     Train net output #0: loss = 0.0205957 (* 1 = 0.0205957 loss)
I0614 13:23:15.600512  2299 sgd_solver.cpp:106] Iteration 9800, lr = 1e-06
I0614 13:23:28.235116  2299 solver.cpp:270] Iteration 9850 (3.95751 iter/s, 12.6342s/50 iter), loss = 0.0138865, remaining 0 hours and 8 minutes
I0614 13:23:28.235146  2299 solver.cpp:291]     Train net output #0: loss = 0.0138865 (* 1 = 0.0138865 loss)
I0614 13:23:28.235154  2299 sgd_solver.cpp:106] Iteration 9850, lr = 1e-06
I0614 13:23:40.864089  2299 solver.cpp:270] Iteration 9900 (3.95929 iter/s, 12.6285s/50 iter), loss = 0.0066142, remaining 0 hours and 8 minutes
I0614 13:23:40.864120  2299 solver.cpp:291]     Train net output #0: loss = 0.00661418 (* 1 = 0.00661418 loss)
I0614 13:23:40.864127  2299 sgd_solver.cpp:106] Iteration 9900, lr = 1e-06
I0614 13:23:53.481024  2299 solver.cpp:270] Iteration 9950 (3.96307 iter/s, 12.6165s/50 iter), loss = 0.00953151, remaining 0 hours and 8 minutes
I0614 13:23:53.481345  2299 solver.cpp:291]     Train net output #0: loss = 0.00953148 (* 1 = 0.00953148 loss)
I0614 13:23:53.481353  2299 sgd_solver.cpp:106] Iteration 9950, lr = 1e-06
I0614 13:24:05.843636  2299 solver.cpp:424] Iteration 10000, Testing net (#0)
I0614 13:24:07.331799  2299 solver.cpp:523]     Test net output #0: accuracy = 0.9565
I0614 13:24:07.331828  2299 solver.cpp:523]     Test net output #1: loss = 0.187337 (* 1 = 0.187337 loss)
I0614 13:24:07.331833  2299 solver.cpp:523]     Test net output #2: top-1 = 0.9565
I0614 13:24:07.578281  2299 solver.cpp:270] Iteration 10000 (3.54698 iter/s, 14.0965s/50 iter), loss = 0.0100067, remaining 0 hours and 9 minutes
I0614 13:24:07.578310  2299 solver.cpp:291]     Train net output #0: loss = 0.0100067 (* 1 = 0.0100067 loss)
I0614 13:24:07.578320  2299 sgd_solver.cpp:106] Iteration 10000, lr = 1e-07
I0614 13:24:20.206475  2299 solver.cpp:270] Iteration 10050 (3.95953 iter/s, 12.6278s/50 iter), loss = 0.0093069, remaining 0 hours and 8 minutes
I0614 13:24:20.206506  2299 solver.cpp:291]     Train net output #0: loss = 0.00930688 (* 1 = 0.00930688 loss)
I0614 13:24:20.206512  2299 sgd_solver.cpp:106] Iteration 10050, lr = 1e-07
I0614 13:24:32.823765  2299 solver.cpp:270] Iteration 10100 (3.96295 iter/s, 12.6169s/50 iter), loss = 0.0151085, remaining 0 hours and 7 minutes
I0614 13:24:32.824028  2299 solver.cpp:291]     Train net output #0: loss = 0.0151085 (* 1 = 0.0151085 loss)
I0614 13:24:32.824038  2299 sgd_solver.cpp:106] Iteration 10100, lr = 1e-07
I0614 13:24:45.440662  2299 solver.cpp:270] Iteration 10150 (3.96315 iter/s, 12.6162s/50 iter), loss = 0.00351393, remaining 0 hours and 7 minutes
I0614 13:24:45.440690  2299 solver.cpp:291]     Train net output #0: loss = 0.00351391 (* 1 = 0.00351391 loss)
I0614 13:24:45.440697  2299 sgd_solver.cpp:106] Iteration 10150, lr = 1e-07
I0614 13:24:58.065698  2299 solver.cpp:270] Iteration 10200 (3.96052 iter/s, 12.6246s/50 iter), loss = 0.00710058, remaining 0 hours and 7 minutes
I0614 13:24:58.065729  2299 solver.cpp:291]     Train net output #0: loss = 0.00710056 (* 1 = 0.00710056 loss)
I0614 13:24:58.065737  2299 sgd_solver.cpp:106] Iteration 10200, lr = 1e-07
I0614 13:25:10.682008  2299 solver.cpp:270] Iteration 10250 (3.96326 iter/s, 12.6159s/50 iter), loss = 0.0118092, remaining 0 hours and 7 minutes
I0614 13:25:10.682255  2299 solver.cpp:291]     Train net output #0: loss = 0.0118092 (* 1 = 0.0118092 loss)
I0614 13:25:10.682265  2299 sgd_solver.cpp:106] Iteration 10250, lr = 1e-07
I0614 13:25:23.302345  2299 solver.cpp:270] Iteration 10300 (3.96207 iter/s, 12.6197s/50 iter), loss = 0.0183447, remaining 0 hours and 7 minutes
I0614 13:25:23.302383  2299 solver.cpp:291]     Train net output #0: loss = 0.0183447 (* 1 = 0.0183447 loss)
I0614 13:25:23.302408  2299 sgd_solver.cpp:106] Iteration 10300, lr = 1e-07
I0614 13:25:35.918987  2299 solver.cpp:270] Iteration 10350 (3.96316 iter/s, 12.6162s/50 iter), loss = 0.00519121, remaining 0 hours and 6 minutes
I0614 13:25:35.919018  2299 solver.cpp:291]     Train net output #0: loss = 0.0051912 (* 1 = 0.0051912 loss)
I0614 13:25:35.919024  2299 sgd_solver.cpp:106] Iteration 10350, lr = 1e-07
I0614 13:25:48.534660  2299 solver.cpp:270] Iteration 10400 (3.96346 iter/s, 12.6152s/50 iter), loss = 0.0229556, remaining 0 hours and 6 minutes
I0614 13:25:48.534857  2299 solver.cpp:291]     Train net output #0: loss = 0.0229556 (* 1 = 0.0229556 loss)
I0614 13:25:48.534883  2299 sgd_solver.cpp:106] Iteration 10400, lr = 1e-07
I0614 13:26:01.147753  2299 solver.cpp:270] Iteration 10450 (3.96433 iter/s, 12.6125s/50 iter), loss = 0.00864036, remaining 0 hours and 6 minutes
I0614 13:26:01.147784  2299 solver.cpp:291]     Train net output #0: loss = 0.00864034 (* 1 = 0.00864034 loss)
I0614 13:26:01.147795  2299 sgd_solver.cpp:106] Iteration 10450, lr = 1e-07
I0614 13:26:13.766022  2299 solver.cpp:270] Iteration 10500 (3.96265 iter/s, 12.6178s/50 iter), loss = 0.00808289, remaining 0 hours and 6 minutes
I0614 13:26:13.766052  2299 solver.cpp:291]     Train net output #0: loss = 0.00808288 (* 1 = 0.00808288 loss)
I0614 13:26:13.766075  2299 sgd_solver.cpp:106] Iteration 10500, lr = 1e-07
I0614 13:26:26.388645  2299 solver.cpp:270] Iteration 10550 (3.96128 iter/s, 12.6222s/50 iter), loss = 0.0302775, remaining 0 hours and 6 minutes
I0614 13:26:26.388964  2299 solver.cpp:291]     Train net output #0: loss = 0.0302774 (* 1 = 0.0302774 loss)
I0614 13:26:26.388973  2299 sgd_solver.cpp:106] Iteration 10550, lr = 1e-07
I0614 13:26:39.013425  2299 solver.cpp:270] Iteration 10600 (3.96069 iter/s, 12.6241s/50 iter), loss = 0.00872722, remaining 0 hours and 5 minutes
I0614 13:26:39.013456  2299 solver.cpp:291]     Train net output #0: loss = 0.00872721 (* 1 = 0.00872721 loss)
I0614 13:26:39.013464  2299 sgd_solver.cpp:106] Iteration 10600, lr = 1e-07
I0614 13:26:51.614696  2299 solver.cpp:270] Iteration 10650 (3.96799 iter/s, 12.6008s/50 iter), loss = 0.0308928, remaining 0 hours and 5 minutes
I0614 13:26:51.614725  2299 solver.cpp:291]     Train net output #0: loss = 0.0308928 (* 1 = 0.0308928 loss)
I0614 13:26:51.614749  2299 sgd_solver.cpp:106] Iteration 10650, lr = 1e-07
I0614 13:27:04.236359  2299 solver.cpp:270] Iteration 10700 (3.96158 iter/s, 12.6212s/50 iter), loss = 0.00434711, remaining 0 hours and 5 minutes
I0614 13:27:04.236531  2299 solver.cpp:291]     Train net output #0: loss = 0.0043471 (* 1 = 0.0043471 loss)
I0614 13:27:04.236557  2299 sgd_solver.cpp:106] Iteration 10700, lr = 1e-07
I0614 13:27:16.864006  2299 solver.cpp:270] Iteration 10750 (3.95975 iter/s, 12.6271s/50 iter), loss = 0.0136139, remaining 0 hours and 5 minutes
I0614 13:27:16.864038  2299 solver.cpp:291]     Train net output #0: loss = 0.0136138 (* 1 = 0.0136138 loss)
I0614 13:27:16.864061  2299 sgd_solver.cpp:106] Iteration 10750, lr = 1e-07
I0614 13:27:29.472411  2299 solver.cpp:270] Iteration 10800 (3.96575 iter/s, 12.608s/50 iter), loss = 0.0309883, remaining 0 hours and 5 minutes
I0614 13:27:29.472440  2299 solver.cpp:291]     Train net output #0: loss = 0.0309883 (* 1 = 0.0309883 loss)
I0614 13:27:29.472448  2299 sgd_solver.cpp:106] Iteration 10800, lr = 1e-07
I0614 13:27:42.091974  2299 solver.cpp:270] Iteration 10850 (3.96224 iter/s, 12.6191s/50 iter), loss = 0.0233515, remaining 0 hours and 4 minutes
I0614 13:27:42.092177  2299 solver.cpp:291]     Train net output #0: loss = 0.0233515 (* 1 = 0.0233515 loss)
I0614 13:27:42.092201  2299 sgd_solver.cpp:106] Iteration 10850, lr = 1e-07
I0614 13:27:54.728435  2299 solver.cpp:270] Iteration 10900 (3.957 iter/s, 12.6358s/50 iter), loss = 0.024012, remaining 0 hours and 4 minutes
I0614 13:27:54.728464  2299 solver.cpp:291]     Train net output #0: loss = 0.024012 (* 1 = 0.024012 loss)
I0614 13:27:54.728488  2299 sgd_solver.cpp:106] Iteration 10900, lr = 1e-07
I0614 13:28:07.365959  2299 solver.cpp:270] Iteration 10950 (3.95661 iter/s, 12.6371s/50 iter), loss = 0.0299922, remaining 0 hours and 4 minutes
I0614 13:28:07.365990  2299 solver.cpp:291]     Train net output #0: loss = 0.0299922 (* 1 = 0.0299922 loss)
I0614 13:28:07.365999  2299 sgd_solver.cpp:106] Iteration 10950, lr = 1e-07
I0614 13:28:19.750576  2299 solver.cpp:424] Iteration 11000, Testing net (#0)
I0614 13:28:21.253468  2299 solver.cpp:523]     Test net output #0: accuracy = 0.9565
I0614 13:28:21.253495  2299 solver.cpp:523]     Test net output #1: loss = 0.19212 (* 1 = 0.19212 loss)
I0614 13:28:21.253500  2299 solver.cpp:523]     Test net output #2: top-1 = 0.9565
I0614 13:28:21.500159  2299 solver.cpp:270] Iteration 11000 (3.53764 iter/s, 14.1337s/50 iter), loss = 0.022668, remaining 0 hours and 4 minutes
I0614 13:28:21.500186  2299 solver.cpp:291]     Train net output #0: loss = 0.022668 (* 1 = 0.022668 loss)
I0614 13:28:21.500211  2299 sgd_solver.cpp:106] Iteration 11000, lr = 1e-07
I0614 13:28:34.125144  2299 solver.cpp:270] Iteration 11050 (3.96054 iter/s, 12.6245s/50 iter), loss = 0.0128699, remaining 0 hours and 3 minutes
I0614 13:28:34.125173  2299 solver.cpp:291]     Train net output #0: loss = 0.0128699 (* 1 = 0.0128699 loss)
I0614 13:28:34.125181  2299 sgd_solver.cpp:106] Iteration 11050, lr = 1e-07
I0614 13:28:46.737643  2299 solver.cpp:270] Iteration 11100 (3.96446 iter/s, 12.6121s/50 iter), loss = 0.00716231, remaining 0 hours and 3 minutes
I0614 13:28:46.737674  2299 solver.cpp:291]     Train net output #0: loss = 0.0071623 (* 1 = 0.0071623 loss)
I0614 13:28:46.737682  2299 sgd_solver.cpp:106] Iteration 11100, lr = 1e-07
I0614 13:28:59.382871  2299 solver.cpp:270] Iteration 11150 (3.9542 iter/s, 12.6448s/50 iter), loss = 0.00445738, remaining 0 hours and 3 minutes
I0614 13:28:59.383194  2299 solver.cpp:291]     Train net output #0: loss = 0.00445736 (* 1 = 0.00445736 loss)
I0614 13:28:59.383203  2299 sgd_solver.cpp:106] Iteration 11150, lr = 1e-07
I0614 13:29:12.005569  2299 solver.cpp:270] Iteration 11200 (3.96135 iter/s, 12.622s/50 iter), loss = 0.00841838, remaining 0 hours and 3 minutes
I0614 13:29:12.005599  2299 solver.cpp:291]     Train net output #0: loss = 0.00841837 (* 1 = 0.00841837 loss)
I0614 13:29:12.005606  2299 sgd_solver.cpp:106] Iteration 11200, lr = 1e-07
I0614 13:29:24.626307  2299 solver.cpp:270] Iteration 11250 (3.96187 iter/s, 12.6203s/50 iter), loss = 0.0131672, remaining 0 hours and 3 minutes
I0614 13:29:24.626338  2299 solver.cpp:291]     Train net output #0: loss = 0.0131672 (* 1 = 0.0131672 loss)
I0614 13:29:24.626361  2299 sgd_solver.cpp:106] Iteration 11250, lr = 1e-07
I0614 13:29:37.254036  2299 solver.cpp:270] Iteration 11300 (3.95968 iter/s, 12.6273s/50 iter), loss = 0.0080802, remaining 0 hours and 2 minutes
I0614 13:29:37.254236  2299 solver.cpp:291]     Train net output #0: loss = 0.00808018 (* 1 = 0.00808018 loss)
I0614 13:29:37.254245  2299 sgd_solver.cpp:106] Iteration 11300, lr = 1e-07
I0614 13:29:49.881379  2299 solver.cpp:270] Iteration 11350 (3.95985 iter/s, 12.6267s/50 iter), loss = 0.00425148, remaining 0 hours and 2 minutes
I0614 13:29:49.881436  2299 solver.cpp:291]     Train net output #0: loss = 0.00425146 (* 1 = 0.00425146 loss)
I0614 13:29:49.881460  2299 sgd_solver.cpp:106] Iteration 11350, lr = 1e-07
I0614 13:30:02.520568  2299 solver.cpp:270] Iteration 11400 (3.95609 iter/s, 12.6387s/50 iter), loss = 0.0143031, remaining 0 hours and 2 minutes
I0614 13:30:02.520598  2299 solver.cpp:291]     Train net output #0: loss = 0.0143031 (* 1 = 0.0143031 loss)
I0614 13:30:02.520607  2299 sgd_solver.cpp:106] Iteration 11400, lr = 1e-07
I0614 13:30:15.133635  2299 solver.cpp:270] Iteration 11450 (3.96428 iter/s, 12.6126s/50 iter), loss = 0.00464776, remaining 0 hours and 2 minutes
I0614 13:30:15.133867  2299 solver.cpp:291]     Train net output #0: loss = 0.00464775 (* 1 = 0.00464775 loss)
I0614 13:30:15.133877  2299 sgd_solver.cpp:106] Iteration 11450, lr = 1e-07
I0614 13:30:27.753116  2299 solver.cpp:270] Iteration 11500 (3.96233 iter/s, 12.6188s/50 iter), loss = 0.0117707, remaining 0 hours and 2 minutes
I0614 13:30:27.753146  2299 solver.cpp:291]     Train net output #0: loss = 0.0117707 (* 1 = 0.0117707 loss)
I0614 13:30:27.753154  2299 sgd_solver.cpp:106] Iteration 11500, lr = 1e-07
I0614 13:30:40.369406  2299 solver.cpp:270] Iteration 11550 (3.96327 iter/s, 12.6159s/50 iter), loss = 0.0162392, remaining 0 hours and 1 minutes
I0614 13:30:40.369437  2299 solver.cpp:291]     Train net output #0: loss = 0.0162392 (* 1 = 0.0162392 loss)
I0614 13:30:40.369446  2299 sgd_solver.cpp:106] Iteration 11550, lr = 1e-07
I0614 13:30:53.004114  2299 solver.cpp:270] Iteration 11600 (3.95749 iter/s, 12.6343s/50 iter), loss = 0.00577196, remaining 0 hours and 1 minutes
I0614 13:30:53.004367  2299 solver.cpp:291]     Train net output #0: loss = 0.00577195 (* 1 = 0.00577195 loss)
I0614 13:30:53.004374  2299 sgd_solver.cpp:106] Iteration 11600, lr = 1e-07
I0614 13:31:05.638476  2299 solver.cpp:270] Iteration 11650 (3.95767 iter/s, 12.6337s/50 iter), loss = 0.0181812, remaining 0 hours and 1 minutes
I0614 13:31:05.638506  2299 solver.cpp:291]     Train net output #0: loss = 0.0181812 (* 1 = 0.0181812 loss)
I0614 13:31:05.638530  2299 sgd_solver.cpp:106] Iteration 11650, lr = 1e-07
I0614 13:31:18.278831  2299 solver.cpp:270] Iteration 11700 (3.95572 iter/s, 12.6399s/50 iter), loss = 0.00386931, remaining 0 hours and 1 minutes
I0614 13:31:18.278862  2299 solver.cpp:291]     Train net output #0: loss = 0.0038693 (* 1 = 0.0038693 loss)
I0614 13:31:18.278870  2299 sgd_solver.cpp:106] Iteration 11700, lr = 1e-07
I0614 13:31:30.906406  2299 solver.cpp:270] Iteration 11750 (3.95973 iter/s, 12.6271s/50 iter), loss = 0.0108341, remaining 0 hours and 1 minutes
I0614 13:31:30.906738  2299 solver.cpp:291]     Train net output #0: loss = 0.010834 (* 1 = 0.010834 loss)
I0614 13:31:30.906747  2299 sgd_solver.cpp:106] Iteration 11750, lr = 1e-07
I0614 13:31:43.537256  2299 solver.cpp:270] Iteration 11800 (3.95879 iter/s, 12.6301s/50 iter), loss = 0.0397503, remaining 0 hours and 0 minutes
I0614 13:31:43.537286  2299 solver.cpp:291]     Train net output #0: loss = 0.0397503 (* 1 = 0.0397503 loss)
I0614 13:31:43.537294  2299 sgd_solver.cpp:106] Iteration 11800, lr = 1e-07
I0614 13:31:56.148093  2299 solver.cpp:270] Iteration 11850 (3.96498 iter/s, 12.6104s/50 iter), loss = 0.00326019, remaining 0 hours and 0 minutes
I0614 13:31:56.148123  2299 solver.cpp:291]     Train net output #0: loss = 0.00326019 (* 1 = 0.00326019 loss)
I0614 13:31:56.148130  2299 sgd_solver.cpp:106] Iteration 11850, lr = 1e-07
I0614 13:32:08.773599  2299 solver.cpp:270] Iteration 11900 (3.96037 iter/s, 12.6251s/50 iter), loss = 0.0264394, remaining 0 hours and 0 minutes
I0614 13:32:08.773797  2299 solver.cpp:291]     Train net output #0: loss = 0.0264394 (* 1 = 0.0264394 loss)
I0614 13:32:08.773806  2299 sgd_solver.cpp:106] Iteration 11900, lr = 1e-07
I0614 13:32:21.392908  2299 solver.cpp:270] Iteration 11950 (3.96237 iter/s, 12.6187s/50 iter), loss = 0.00770023, remaining 0 hours and 0 minutes
I0614 13:32:21.392939  2299 solver.cpp:291]     Train net output #0: loss = 0.00770023 (* 1 = 0.00770023 loss)
I0614 13:32:21.392947  2299 sgd_solver.cpp:106] Iteration 11950, lr = 1e-07
I0614 13:32:33.752243  2299 solver.cpp:935] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0/snapshots/_iter_12000.caffemodel
I0614 13:32:39.642412  2299 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0/snapshots/_iter_12000.solverstate
I0614 13:32:43.403614  2299 solver.cpp:384] Iteration 12000, loss = 0.0209964
I0614 13:32:43.403640  2299 solver.cpp:424] Iteration 12000, Testing net (#0)
I0614 13:32:44.820397  2299 solver.cpp:523]     Test net output #0: accuracy = 0.9565
I0614 13:32:44.820426  2299 solver.cpp:523]     Test net output #1: loss = 0.194336 (* 1 = 0.194336 loss)
I0614 13:32:44.820432  2299 solver.cpp:523]     Test net output #2: top-1 = 0.9565
I0614 13:32:44.820436  2299 solver.cpp:392] Optimization Done (3.93981 iter/s).
I0614 13:32:44.820441  2299 caffe_interface.cpp:576] Optimization Done.
(c) Copyright 2016â2019 Xilinx, Inc. All rights reserved.

I0614 13:32:45.891496  2396 pruning_runner.cpp:234] Analysis info found.
I0614 13:32:47.555989  2396 pruning_runner.cpp:265] Start pruning, please wait...
I0614 13:32:56.616647  2396 pruning_runner.cpp:312] Compression complete 0%
I0614 13:33:05.299196  2396 pruning_runner.cpp:312] Compression complete 0%
I0614 13:33:14.175415  2396 pruning_runner.cpp:312] Compression complete 0%
I0614 13:33:22.976145  2396 pruning_runner.cpp:312] Compression complete 0%
I0614 13:33:31.323627  2396 pruning_runner.cpp:312] Compression complete 0%
I0614 13:33:40.182817  2396 pruning_runner.cpp:312] Compression complete 0%
I0614 13:33:48.941929  2396 pruning_runner.cpp:312] Compression complete 0%
I0614 13:33:57.800563  2396 pruning_runner.cpp:312] Compression complete 0%
I0614 13:34:06.912842  2396 pruning_runner.cpp:312] Compression complete 0%
I0614 13:34:15.838389  2396 pruning_runner.cpp:312] Compression complete 0%
I0614 13:34:26.944572  2396 pruning_runner.cpp:365] pruning done, output model: pruning/alexnetBNnoLRN/regular_rate_0.1/sparse.caffemodel
I0614 13:34:26.944604  2396 pruning_runner.cpp:379] summary of REGULAR compression with rate 0.1:
+-------------------------------------------------------------------+
| Item           | Baseline       | Compressed     | Delta          |
+-------------------------------------------------------------------+
| Accuracy       | 0.953499794    | 0.95724982     | 0.00375002623  |
+-------------------------------------------------------------------+
| Weights        | 3.74857903 M   | 1.15144897 M   | -69.2830582%   |
+-------------------------------------------------------------------+
| Operations     | 2.05460167 G   | 1.17685986 G   | -42.7207718%   |
+-------------------------------------------------------------------+
To fine-tune the pruned model, please run:
vai_p_caffe finetune -config /workspace/TUTORIALS/VAI2.0bash-Caffe-ML-CATSvsDOGS/files/pruning/alexnetBNnoLRN/config1.prototxt
(c) Copyright 2016â2019 Xilinx, Inc. All rights reserved.

W0614 13:34:27.122972  3451 utils.cpp:207] BVLC BatchNormLayer without ScaleLayer detected: 3, it will be converted to NVCaffe Format.
W0614 13:34:27.131781  3451 utils.cpp:207] BVLC BatchNormLayer without ScaleLayer detected: 7, it will be converted to NVCaffe Format.
W0614 13:34:27.131857  3451 utils.cpp:207] BVLC BatchNormLayer without ScaleLayer detected: 21, it will be converted to NVCaffe Format.
I0614 13:34:27.141021  3451 vai_p_caffe.cpp:287] pruning/alexnetBNnoLRN/regular_rate_0.1/net_finetune.prototxt
I0614 13:34:27.354405  3451 gpu_memory.cpp:53] GPUMemory::Manager initialized with Caching (CUB) GPU Allocator
I0614 13:34:27.354427  3451 gpu_memory.cpp:55] Total memory: 25635127296, Free: 24776736768, dev_info[0]: total=25635127296 free=24776736768
I0614 13:34:27.354547  3451 caffe_interface.cpp:539] Using GPUs 0
I0614 13:34:27.354633  3451 caffe_interface.cpp:544] GPU 0: Quadro P6000
I0614 13:34:28.006476  3451 solver.cpp:51] Initializing solver from parameters: 
test_iter: 80
test_interval: 1000
base_lr: 0.001
display: 50
max_iter: 12000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 2500
snapshot: 6000
snapshot_prefix: "pruning/alexnetBNnoLRN/regular_rate_0.1/snapshots/"
solver_mode: GPU
device_id: 0
random_seed: 1201
net: "pruning/alexnetBNnoLRN/regular_rate_0.1/net_finetune.prototxt"
type: "Adam"
I0614 13:34:28.007402  3451 solver.cpp:99] Creating training net from net file: pruning/alexnetBNnoLRN/regular_rate_0.1/net_finetune.prototxt
I0614 13:34:28.008067  3451 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0614 13:34:28.008082  3451 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0614 13:34:28.008086  3451 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy-top1
I0614 13:34:28.008091  3451 net.cpp:52] Initializing net from parameters: 
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_value: 106
    mean_value: 116
    mean_value: 124
  }
  data_param {
    source: "input/lmdb/train_lmdb"
    batch_size: 256
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 0
    kernel_size: 8
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "bn1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn2"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "bn2"
  top: "relu2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "relu6"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "drop6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn7"
  type: "BatchNorm"
  bottom: "fc7"
  top: "bn7"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "bn7"
  top: "relu7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "relu7"
  top: "drop7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "drop7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0614 13:34:28.008571  3451 layer_factory.hpp:77] Creating layer data
I0614 13:34:28.008709  3451 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0614 13:34:28.010907  3451 net.cpp:94] Creating Layer data
I0614 13:34:28.010924  3451 net.cpp:409] data -> data
I0614 13:34:28.010939  3451 net.cpp:409] data -> label
I0614 13:34:28.012524  3488 db_lmdb.cpp:35] Opened lmdb input/lmdb/train_lmdb
I0614 13:34:28.012553  3488 db_lmdb.cpp:38] Items count: 20000
I0614 13:34:28.012590  3488 data_reader.cpp:124] TRAIN: reading data using 1 channel(s)
I0614 13:34:28.012965  3451 data_layer.cpp:78] ReshapePrefetch 256, 3, 227, 227
I0614 13:34:28.013015  3451 data_layer.cpp:83] output data size: 256,3,227,227
I0614 13:34:28.532887  3451 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0614 13:34:28.533110  3451 net.cpp:144] Setting up data
I0614 13:34:28.533118  3451 net.cpp:151] Top shape: 256 3 227 227 (39574272)
I0614 13:34:28.533126  3451 net.cpp:151] Top shape: 256 (256)
I0614 13:34:28.533130  3451 net.cpp:159] Memory required for data: 158298112
I0614 13:34:28.533135  3451 layer_factory.hpp:77] Creating layer conv1
I0614 13:34:28.533146  3451 net.cpp:94] Creating Layer conv1
I0614 13:34:28.533149  3451 net.cpp:435] conv1 <- data
I0614 13:34:28.533155  3451 net.cpp:409] conv1 -> conv1
I0614 13:34:28.533515  3451 net.cpp:144] Setting up conv1
I0614 13:34:28.533522  3451 net.cpp:151] Top shape: 256 96 55 55 (74342400)
I0614 13:34:28.533529  3451 net.cpp:159] Memory required for data: 455667712
I0614 13:34:28.533538  3451 layer_factory.hpp:77] Creating layer bn1
I0614 13:34:28.533545  3451 net.cpp:94] Creating Layer bn1
I0614 13:34:28.533550  3451 net.cpp:435] bn1 <- conv1
I0614 13:34:28.533555  3451 net.cpp:409] bn1 -> bn1
I0614 13:34:28.533839  3451 net.cpp:144] Setting up bn1
I0614 13:34:28.533846  3451 net.cpp:151] Top shape: 256 96 55 55 (74342400)
I0614 13:34:28.533851  3451 net.cpp:159] Memory required for data: 753037312
I0614 13:34:28.533860  3451 layer_factory.hpp:77] Creating layer relu1
I0614 13:34:28.533866  3451 net.cpp:94] Creating Layer relu1
I0614 13:34:28.533869  3451 net.cpp:435] relu1 <- bn1
I0614 13:34:28.533874  3451 net.cpp:409] relu1 -> relu1
I0614 13:34:28.533885  3451 net.cpp:144] Setting up relu1
I0614 13:34:28.533890  3451 net.cpp:151] Top shape: 256 96 55 55 (74342400)
I0614 13:34:28.533893  3451 net.cpp:159] Memory required for data: 1050406912
I0614 13:34:28.533897  3451 layer_factory.hpp:77] Creating layer pool1
I0614 13:34:28.533902  3451 net.cpp:94] Creating Layer pool1
I0614 13:34:28.533906  3451 net.cpp:435] pool1 <- relu1
I0614 13:34:28.533910  3451 net.cpp:409] pool1 -> pool1
I0614 13:34:28.533928  3451 net.cpp:144] Setting up pool1
I0614 13:34:28.533932  3451 net.cpp:151] Top shape: 256 96 27 27 (17915904)
I0614 13:34:28.533937  3451 net.cpp:159] Memory required for data: 1122070528
I0614 13:34:28.533941  3451 layer_factory.hpp:77] Creating layer conv2
I0614 13:34:28.533946  3451 net.cpp:94] Creating Layer conv2
I0614 13:34:28.533951  3451 net.cpp:435] conv2 <- pool1
I0614 13:34:28.533955  3451 net.cpp:409] conv2 -> conv2
I0614 13:34:28.549268  3451 net.cpp:144] Setting up conv2
I0614 13:34:28.549285  3451 net.cpp:151] Top shape: 256 256 27 27 (47775744)
I0614 13:34:28.549294  3451 net.cpp:159] Memory required for data: 1313173504
I0614 13:34:28.549305  3451 layer_factory.hpp:77] Creating layer bn2
I0614 13:34:28.549314  3451 net.cpp:94] Creating Layer bn2
I0614 13:34:28.549319  3451 net.cpp:435] bn2 <- conv2
I0614 13:34:28.549327  3451 net.cpp:409] bn2 -> bn2
I0614 13:34:28.549651  3451 net.cpp:144] Setting up bn2
I0614 13:34:28.549659  3451 net.cpp:151] Top shape: 256 256 27 27 (47775744)
I0614 13:34:28.549665  3451 net.cpp:159] Memory required for data: 1504276480
I0614 13:34:28.549675  3451 layer_factory.hpp:77] Creating layer relu2
I0614 13:34:28.549681  3451 net.cpp:94] Creating Layer relu2
I0614 13:34:28.549686  3451 net.cpp:435] relu2 <- bn2
I0614 13:34:28.549691  3451 net.cpp:409] relu2 -> relu2
I0614 13:34:28.549706  3451 net.cpp:144] Setting up relu2
I0614 13:34:28.549710  3451 net.cpp:151] Top shape: 256 256 27 27 (47775744)
I0614 13:34:28.549717  3451 net.cpp:159] Memory required for data: 1695379456
I0614 13:34:28.549721  3451 layer_factory.hpp:77] Creating layer pool2
I0614 13:34:28.549728  3451 net.cpp:94] Creating Layer pool2
I0614 13:34:28.549732  3451 net.cpp:435] pool2 <- relu2
I0614 13:34:28.549738  3451 net.cpp:409] pool2 -> pool2
I0614 13:34:28.549757  3451 net.cpp:144] Setting up pool2
I0614 13:34:28.549760  3451 net.cpp:151] Top shape: 256 256 13 13 (11075584)
I0614 13:34:28.549767  3451 net.cpp:159] Memory required for data: 1739681792
I0614 13:34:28.549772  3451 layer_factory.hpp:77] Creating layer conv3
I0614 13:34:28.550338  3451 net.cpp:94] Creating Layer conv3
I0614 13:34:28.550345  3451 net.cpp:435] conv3 <- pool2
I0614 13:34:28.550354  3451 net.cpp:409] conv3 -> conv3
I0614 13:34:28.566660  3451 net.cpp:144] Setting up conv3
I0614 13:34:28.566689  3451 net.cpp:151] Top shape: 256 384 13 13 (16613376)
I0614 13:34:28.566701  3451 net.cpp:159] Memory required for data: 1806135296
I0614 13:34:28.566715  3451 layer_factory.hpp:77] Creating layer relu3
I0614 13:34:28.566725  3451 net.cpp:94] Creating Layer relu3
I0614 13:34:28.566732  3451 net.cpp:435] relu3 <- conv3
I0614 13:34:28.566741  3451 net.cpp:409] relu3 -> relu3
I0614 13:34:28.566766  3451 net.cpp:144] Setting up relu3
I0614 13:34:28.566771  3451 net.cpp:151] Top shape: 256 384 13 13 (16613376)
I0614 13:34:28.566779  3451 net.cpp:159] Memory required for data: 1872588800
I0614 13:34:28.566784  3451 layer_factory.hpp:77] Creating layer conv4
I0614 13:34:28.566797  3451 net.cpp:94] Creating Layer conv4
I0614 13:34:28.566802  3451 net.cpp:435] conv4 <- relu3
I0614 13:34:28.566810  3451 net.cpp:409] conv4 -> conv4
I0614 13:34:28.598544  3451 net.cpp:144] Setting up conv4
I0614 13:34:28.598580  3451 net.cpp:151] Top shape: 256 384 13 13 (16613376)
I0614 13:34:28.598593  3451 net.cpp:159] Memory required for data: 1939042304
I0614 13:34:28.598618  3451 layer_factory.hpp:77] Creating layer relu4
I0614 13:34:28.598629  3451 net.cpp:94] Creating Layer relu4
I0614 13:34:28.598637  3451 net.cpp:435] relu4 <- conv4
I0614 13:34:28.598647  3451 net.cpp:409] relu4 -> relu4
I0614 13:34:28.598681  3451 net.cpp:144] Setting up relu4
I0614 13:34:28.598687  3451 net.cpp:151] Top shape: 256 384 13 13 (16613376)
I0614 13:34:28.598696  3451 net.cpp:159] Memory required for data: 2005495808
I0614 13:34:28.598702  3451 layer_factory.hpp:77] Creating layer conv5
I0614 13:34:28.598716  3451 net.cpp:94] Creating Layer conv5
I0614 13:34:28.598722  3451 net.cpp:435] conv5 <- relu4
I0614 13:34:28.598731  3451 net.cpp:409] conv5 -> conv5
I0614 13:34:28.616823  3451 net.cpp:144] Setting up conv5
I0614 13:34:28.616849  3451 net.cpp:151] Top shape: 256 256 13 13 (11075584)
I0614 13:34:28.616858  3451 net.cpp:159] Memory required for data: 2049798144
I0614 13:34:28.616869  3451 layer_factory.hpp:77] Creating layer relu5
I0614 13:34:28.616878  3451 net.cpp:94] Creating Layer relu5
I0614 13:34:28.616883  3451 net.cpp:435] relu5 <- conv5
I0614 13:34:28.616890  3451 net.cpp:409] relu5 -> relu5
I0614 13:34:28.616912  3451 net.cpp:144] Setting up relu5
I0614 13:34:28.616915  3451 net.cpp:151] Top shape: 256 256 13 13 (11075584)
I0614 13:34:28.616921  3451 net.cpp:159] Memory required for data: 2094100480
I0614 13:34:28.616925  3451 layer_factory.hpp:77] Creating layer pool5
I0614 13:34:28.616931  3451 net.cpp:94] Creating Layer pool5
I0614 13:34:28.616935  3451 net.cpp:435] pool5 <- relu5
I0614 13:34:28.616940  3451 net.cpp:409] pool5 -> pool5
I0614 13:34:28.616961  3451 net.cpp:144] Setting up pool5
I0614 13:34:28.616978  3451 net.cpp:151] Top shape: 256 256 6 6 (2359296)
I0614 13:34:28.616983  3451 net.cpp:159] Memory required for data: 2103537664
I0614 13:34:28.616987  3451 layer_factory.hpp:77] Creating layer fc6
I0614 13:34:28.616995  3451 net.cpp:94] Creating Layer fc6
I0614 13:34:28.616998  3451 net.cpp:435] fc6 <- pool5
I0614 13:34:28.617003  3451 net.cpp:409] fc6 -> fc6
I0614 13:34:29.039660  3451 net.cpp:144] Setting up fc6
I0614 13:34:29.039685  3451 net.cpp:151] Top shape: 256 4096 (1048576)
I0614 13:34:29.039693  3451 net.cpp:159] Memory required for data: 2107731968
I0614 13:34:29.039717  3451 layer_factory.hpp:77] Creating layer relu6
I0614 13:34:29.039723  3451 net.cpp:94] Creating Layer relu6
I0614 13:34:29.039728  3451 net.cpp:435] relu6 <- fc6
I0614 13:34:29.039733  3451 net.cpp:409] relu6 -> relu6
I0614 13:34:29.039748  3451 net.cpp:144] Setting up relu6
I0614 13:34:29.039752  3451 net.cpp:151] Top shape: 256 4096 (1048576)
I0614 13:34:29.039755  3451 net.cpp:159] Memory required for data: 2111926272
I0614 13:34:29.039758  3451 layer_factory.hpp:77] Creating layer drop6
I0614 13:34:29.039764  3451 net.cpp:94] Creating Layer drop6
I0614 13:34:29.040181  3451 net.cpp:435] drop6 <- relu6
I0614 13:34:29.040187  3451 net.cpp:409] drop6 -> drop6
I0614 13:34:29.040203  3451 net.cpp:144] Setting up drop6
I0614 13:34:29.040207  3451 net.cpp:151] Top shape: 256 4096 (1048576)
I0614 13:34:29.040211  3451 net.cpp:159] Memory required for data: 2116120576
I0614 13:34:29.040215  3451 layer_factory.hpp:77] Creating layer fc7
I0614 13:34:29.040221  3451 net.cpp:94] Creating Layer fc7
I0614 13:34:29.040225  3451 net.cpp:435] fc7 <- drop6
I0614 13:34:29.040230  3451 net.cpp:409] fc7 -> fc7
I0614 13:34:29.201508  3451 net.cpp:144] Setting up fc7
I0614 13:34:29.201534  3451 net.cpp:151] Top shape: 256 4096 (1048576)
I0614 13:34:29.201542  3451 net.cpp:159] Memory required for data: 2120314880
I0614 13:34:29.201553  3451 layer_factory.hpp:77] Creating layer bn7
I0614 13:34:29.201562  3451 net.cpp:94] Creating Layer bn7
I0614 13:34:29.201567  3451 net.cpp:435] bn7 <- fc7
I0614 13:34:29.201573  3451 net.cpp:409] bn7 -> bn7
I0614 13:34:29.201887  3451 net.cpp:144] Setting up bn7
I0614 13:34:29.201895  3451 net.cpp:151] Top shape: 256 4096 (1048576)
I0614 13:34:29.201900  3451 net.cpp:159] Memory required for data: 2124509184
I0614 13:34:29.201908  3451 layer_factory.hpp:77] Creating layer relu7
I0614 13:34:29.201915  3451 net.cpp:94] Creating Layer relu7
I0614 13:34:29.201917  3451 net.cpp:435] relu7 <- bn7
I0614 13:34:29.201922  3451 net.cpp:409] relu7 -> relu7
I0614 13:34:29.201936  3451 net.cpp:144] Setting up relu7
I0614 13:34:29.201939  3451 net.cpp:151] Top shape: 256 4096 (1048576)
I0614 13:34:29.201943  3451 net.cpp:159] Memory required for data: 2128703488
I0614 13:34:29.201947  3451 layer_factory.hpp:77] Creating layer drop7
I0614 13:34:29.201953  3451 net.cpp:94] Creating Layer drop7
I0614 13:34:29.201956  3451 net.cpp:435] drop7 <- relu7
I0614 13:34:29.201961  3451 net.cpp:409] drop7 -> drop7
I0614 13:34:29.201977  3451 net.cpp:144] Setting up drop7
I0614 13:34:29.201982  3451 net.cpp:151] Top shape: 256 4096 (1048576)
I0614 13:34:29.201985  3451 net.cpp:159] Memory required for data: 2132897792
I0614 13:34:29.201989  3451 layer_factory.hpp:77] Creating layer fc8
I0614 13:34:29.201995  3451 net.cpp:94] Creating Layer fc8
I0614 13:34:29.201999  3451 net.cpp:435] fc8 <- drop7
I0614 13:34:29.202004  3451 net.cpp:409] fc8 -> fc8
I0614 13:34:29.202127  3451 net.cpp:144] Setting up fc8
I0614 13:34:29.202131  3451 net.cpp:151] Top shape: 256 2 (512)
I0614 13:34:29.202136  3451 net.cpp:159] Memory required for data: 2132899840
I0614 13:34:29.202140  3451 layer_factory.hpp:77] Creating layer loss
I0614 13:34:29.202145  3451 net.cpp:94] Creating Layer loss
I0614 13:34:29.202149  3451 net.cpp:435] loss <- fc8
I0614 13:34:29.202153  3451 net.cpp:435] loss <- label
I0614 13:34:29.202158  3451 net.cpp:409] loss -> loss
I0614 13:34:29.202164  3451 layer_factory.hpp:77] Creating layer loss
I0614 13:34:29.202206  3451 net.cpp:144] Setting up loss
I0614 13:34:29.202209  3451 net.cpp:151] Top shape: (1)
I0614 13:34:29.202214  3451 net.cpp:154]     with loss weight 1
I0614 13:34:29.202225  3451 net.cpp:159] Memory required for data: 2132899844
I0614 13:34:29.202229  3451 net.cpp:220] loss needs backward computation.
I0614 13:34:29.202232  3451 net.cpp:220] fc8 needs backward computation.
I0614 13:34:29.202236  3451 net.cpp:220] drop7 needs backward computation.
I0614 13:34:29.202240  3451 net.cpp:220] relu7 needs backward computation.
I0614 13:34:29.202244  3451 net.cpp:220] bn7 needs backward computation.
I0614 13:34:29.202247  3451 net.cpp:220] fc7 needs backward computation.
I0614 13:34:29.202251  3451 net.cpp:220] drop6 needs backward computation.
I0614 13:34:29.202255  3451 net.cpp:220] relu6 needs backward computation.
I0614 13:34:29.202258  3451 net.cpp:220] fc6 needs backward computation.
I0614 13:34:29.202262  3451 net.cpp:220] pool5 needs backward computation.
I0614 13:34:29.202266  3451 net.cpp:220] relu5 needs backward computation.
I0614 13:34:29.202270  3451 net.cpp:220] conv5 needs backward computation.
I0614 13:34:29.202275  3451 net.cpp:220] relu4 needs backward computation.
I0614 13:34:29.202602  3451 net.cpp:220] conv4 needs backward computation.
I0614 13:34:29.202607  3451 net.cpp:220] relu3 needs backward computation.
I0614 13:34:29.202611  3451 net.cpp:220] conv3 needs backward computation.
I0614 13:34:29.202615  3451 net.cpp:220] pool2 needs backward computation.
I0614 13:34:29.202618  3451 net.cpp:220] relu2 needs backward computation.
I0614 13:34:29.202622  3451 net.cpp:220] bn2 needs backward computation.
I0614 13:34:29.202626  3451 net.cpp:220] conv2 needs backward computation.
I0614 13:34:29.202630  3451 net.cpp:220] pool1 needs backward computation.
I0614 13:34:29.202634  3451 net.cpp:220] relu1 needs backward computation.
I0614 13:34:29.202637  3451 net.cpp:220] bn1 needs backward computation.
I0614 13:34:29.202641  3451 net.cpp:220] conv1 needs backward computation.
I0614 13:34:29.202646  3451 net.cpp:222] data does not need backward computation.
I0614 13:34:29.202649  3451 net.cpp:264] This network produces output loss
I0614 13:34:29.202669  3451 net.cpp:284] Network initialization done.
I0614 13:34:29.203497  3451 solver.cpp:189] Creating test net (#0) specified by net file: pruning/alexnetBNnoLRN/regular_rate_0.1/net_finetune.prototxt
I0614 13:34:29.203533  3451 net.cpp:323] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0614 13:34:29.203547  3451 net.cpp:52] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_value: 106
    mean_value: 116
    mean_value: 124
  }
  data_param {
    source: "input/lmdb/valid_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 0
    kernel_size: 8
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "bn1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn2"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "bn2"
  top: "relu2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "relu6"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "drop6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn7"
  type: "BatchNorm"
  bottom: "fc7"
  top: "bn7"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "bn7"
  top: "relu7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "relu7"
  top: "drop7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "drop7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy-top1"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "top-1"
  include {
    phase: TEST
  }
}
I0614 13:34:29.204030  3451 layer_factory.hpp:77] Creating layer data
I0614 13:34:29.204069  3451 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0614 13:34:29.206794  3451 net.cpp:94] Creating Layer data
I0614 13:34:29.206835  3451 net.cpp:409] data -> data
I0614 13:34:29.206861  3451 net.cpp:409] data -> label
I0614 13:34:29.207309  3518 db_lmdb.cpp:35] Opened lmdb input/lmdb/valid_lmdb
I0614 13:34:29.207345  3518 db_lmdb.cpp:38] Items count: 4000
I0614 13:34:29.207389  3518 data_reader.cpp:124] TEST: reading data using 1 channel(s)
I0614 13:34:29.207796  3451 data_layer.cpp:78] ReshapePrefetch 50, 3, 227, 227
I0614 13:34:29.207962  3451 data_layer.cpp:83] output data size: 50,3,227,227
I0614 13:34:29.331223  3451 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0614 13:34:29.331744  3451 net.cpp:144] Setting up data
I0614 13:34:29.331753  3451 net.cpp:151] Top shape: 50 3 227 227 (7729350)
I0614 13:34:29.331761  3451 net.cpp:151] Top shape: 50 (50)
I0614 13:34:29.331764  3451 net.cpp:159] Memory required for data: 30917600
I0614 13:34:29.331769  3451 layer_factory.hpp:77] Creating layer label_data_1_split
I0614 13:34:29.331794  3451 net.cpp:94] Creating Layer label_data_1_split
I0614 13:34:29.331799  3451 net.cpp:435] label_data_1_split <- label
I0614 13:34:29.331804  3451 net.cpp:409] label_data_1_split -> label_data_1_split_0
I0614 13:34:29.331813  3451 net.cpp:409] label_data_1_split -> label_data_1_split_1
I0614 13:34:29.331818  3451 net.cpp:409] label_data_1_split -> label_data_1_split_2
I0614 13:34:29.331863  3451 net.cpp:144] Setting up label_data_1_split
I0614 13:34:29.331867  3451 net.cpp:151] Top shape: 50 (50)
I0614 13:34:29.331871  3451 net.cpp:151] Top shape: 50 (50)
I0614 13:34:29.331876  3451 net.cpp:151] Top shape: 50 (50)
I0614 13:34:29.331878  3451 net.cpp:159] Memory required for data: 30918200
I0614 13:34:29.331882  3451 layer_factory.hpp:77] Creating layer conv1
I0614 13:34:29.331892  3451 net.cpp:94] Creating Layer conv1
I0614 13:34:29.331895  3451 net.cpp:435] conv1 <- data
I0614 13:34:29.331900  3451 net.cpp:409] conv1 -> conv1
I0614 13:34:29.332312  3451 net.cpp:144] Setting up conv1
I0614 13:34:29.332319  3451 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0614 13:34:29.332324  3451 net.cpp:159] Memory required for data: 88998200
I0614 13:34:29.332334  3451 layer_factory.hpp:77] Creating layer bn1
I0614 13:34:29.332340  3451 net.cpp:94] Creating Layer bn1
I0614 13:34:29.332345  3451 net.cpp:435] bn1 <- conv1
I0614 13:34:29.332350  3451 net.cpp:409] bn1 -> bn1
I0614 13:34:29.332662  3451 net.cpp:144] Setting up bn1
I0614 13:34:29.332669  3451 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0614 13:34:29.332674  3451 net.cpp:159] Memory required for data: 147078200
I0614 13:34:29.332684  3451 layer_factory.hpp:77] Creating layer relu1
I0614 13:34:29.332690  3451 net.cpp:94] Creating Layer relu1
I0614 13:34:29.332693  3451 net.cpp:435] relu1 <- bn1
I0614 13:34:29.332698  3451 net.cpp:409] relu1 -> relu1
I0614 13:34:29.332710  3451 net.cpp:144] Setting up relu1
I0614 13:34:29.332713  3451 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0614 13:34:29.332718  3451 net.cpp:159] Memory required for data: 205158200
I0614 13:34:29.332721  3451 layer_factory.hpp:77] Creating layer pool1
I0614 13:34:29.332727  3451 net.cpp:94] Creating Layer pool1
I0614 13:34:29.332731  3451 net.cpp:435] pool1 <- relu1
I0614 13:34:29.332736  3451 net.cpp:409] pool1 -> pool1
I0614 13:34:29.332751  3451 net.cpp:144] Setting up pool1
I0614 13:34:29.332756  3451 net.cpp:151] Top shape: 50 96 27 27 (3499200)
I0614 13:34:29.332760  3451 net.cpp:159] Memory required for data: 219155000
I0614 13:34:29.332763  3451 layer_factory.hpp:77] Creating layer conv2
I0614 13:34:29.332770  3451 net.cpp:94] Creating Layer conv2
I0614 13:34:29.332774  3451 net.cpp:435] conv2 <- pool1
I0614 13:34:29.332778  3451 net.cpp:409] conv2 -> conv2
I0614 13:34:29.339754  3451 net.cpp:144] Setting up conv2
I0614 13:34:29.339772  3451 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0614 13:34:29.339780  3451 net.cpp:159] Memory required for data: 256479800
I0614 13:34:29.339790  3451 layer_factory.hpp:77] Creating layer bn2
I0614 13:34:29.339798  3451 net.cpp:94] Creating Layer bn2
I0614 13:34:29.339803  3451 net.cpp:435] bn2 <- conv2
I0614 13:34:29.339809  3451 net.cpp:409] bn2 -> bn2
I0614 13:34:29.340082  3451 net.cpp:144] Setting up bn2
I0614 13:34:29.340086  3451 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0614 13:34:29.340091  3451 net.cpp:159] Memory required for data: 293804600
I0614 13:34:29.340099  3451 layer_factory.hpp:77] Creating layer relu2
I0614 13:34:29.340106  3451 net.cpp:94] Creating Layer relu2
I0614 13:34:29.340108  3451 net.cpp:435] relu2 <- bn2
I0614 13:34:29.340114  3451 net.cpp:409] relu2 -> relu2
I0614 13:34:29.340126  3451 net.cpp:144] Setting up relu2
I0614 13:34:29.340637  3451 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0614 13:34:29.340668  3451 net.cpp:159] Memory required for data: 331129400
I0614 13:34:29.340692  3451 layer_factory.hpp:77] Creating layer pool2
I0614 13:34:29.340723  3451 net.cpp:94] Creating Layer pool2
I0614 13:34:29.340736  3451 net.cpp:435] pool2 <- relu2
I0614 13:34:29.340768  3451 net.cpp:409] pool2 -> pool2
I0614 13:34:29.340891  3451 net.cpp:144] Setting up pool2
I0614 13:34:29.340911  3451 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0614 13:34:29.340935  3451 net.cpp:159] Memory required for data: 339782200
I0614 13:34:29.340952  3451 layer_factory.hpp:77] Creating layer conv3
I0614 13:34:29.340981  3451 net.cpp:94] Creating Layer conv3
I0614 13:34:29.340997  3451 net.cpp:435] conv3 <- pool2
I0614 13:34:29.341020  3451 net.cpp:409] conv3 -> conv3
I0614 13:34:29.366073  3451 net.cpp:144] Setting up conv3
I0614 13:34:29.366137  3451 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0614 13:34:29.366151  3451 net.cpp:159] Memory required for data: 352761400
I0614 13:34:29.366166  3451 layer_factory.hpp:77] Creating layer relu3
I0614 13:34:29.366178  3451 net.cpp:94] Creating Layer relu3
I0614 13:34:29.366185  3451 net.cpp:435] relu3 <- conv3
I0614 13:34:29.366195  3451 net.cpp:409] relu3 -> relu3
I0614 13:34:29.366227  3451 net.cpp:144] Setting up relu3
I0614 13:34:29.366233  3451 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0614 13:34:29.366242  3451 net.cpp:159] Memory required for data: 365740600
I0614 13:34:29.366248  3451 layer_factory.hpp:77] Creating layer conv4
I0614 13:34:29.366261  3451 net.cpp:94] Creating Layer conv4
I0614 13:34:29.366267  3451 net.cpp:435] conv4 <- relu3
I0614 13:34:29.366276  3451 net.cpp:409] conv4 -> conv4
I0614 13:34:29.385669  3451 net.cpp:144] Setting up conv4
I0614 13:34:29.385689  3451 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0614 13:34:29.385695  3451 net.cpp:159] Memory required for data: 378719800
I0614 13:34:29.385706  3451 layer_factory.hpp:77] Creating layer relu4
I0614 13:34:29.385712  3451 net.cpp:94] Creating Layer relu4
I0614 13:34:29.385720  3451 net.cpp:435] relu4 <- conv4
I0614 13:34:29.385727  3451 net.cpp:409] relu4 -> relu4
I0614 13:34:29.385774  3451 net.cpp:144] Setting up relu4
I0614 13:34:29.385779  3451 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0614 13:34:29.385787  3451 net.cpp:159] Memory required for data: 391699000
I0614 13:34:29.385792  3451 layer_factory.hpp:77] Creating layer conv5
I0614 13:34:29.385802  3451 net.cpp:94] Creating Layer conv5
I0614 13:34:29.385807  3451 net.cpp:435] conv5 <- relu4
I0614 13:34:29.385813  3451 net.cpp:409] conv5 -> conv5
I0614 13:34:29.397770  3451 net.cpp:144] Setting up conv5
I0614 13:34:29.397825  3451 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0614 13:34:29.397838  3451 net.cpp:159] Memory required for data: 400351800
I0614 13:34:29.397851  3451 layer_factory.hpp:77] Creating layer relu5
I0614 13:34:29.397861  3451 net.cpp:94] Creating Layer relu5
I0614 13:34:29.397866  3451 net.cpp:435] relu5 <- conv5
I0614 13:34:29.397889  3451 net.cpp:409] relu5 -> relu5
I0614 13:34:29.397918  3451 net.cpp:144] Setting up relu5
I0614 13:34:29.397924  3451 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0614 13:34:29.397931  3451 net.cpp:159] Memory required for data: 409004600
I0614 13:34:29.397936  3451 layer_factory.hpp:77] Creating layer pool5
I0614 13:34:29.397946  3451 net.cpp:94] Creating Layer pool5
I0614 13:34:29.397951  3451 net.cpp:435] pool5 <- relu5
I0614 13:34:29.397958  3451 net.cpp:409] pool5 -> pool5
I0614 13:34:29.398000  3451 net.cpp:144] Setting up pool5
I0614 13:34:29.398006  3451 net.cpp:151] Top shape: 50 256 6 6 (460800)
I0614 13:34:29.398013  3451 net.cpp:159] Memory required for data: 410847800
I0614 13:34:29.398020  3451 layer_factory.hpp:77] Creating layer fc6
I0614 13:34:29.398028  3451 net.cpp:94] Creating Layer fc6
I0614 13:34:29.398033  3451 net.cpp:435] fc6 <- pool5
I0614 13:34:29.398041  3451 net.cpp:409] fc6 -> fc6
I0614 13:34:29.747359  3451 net.cpp:144] Setting up fc6
I0614 13:34:29.747385  3451 net.cpp:151] Top shape: 50 4096 (204800)
I0614 13:34:29.747864  3451 net.cpp:159] Memory required for data: 411667000
I0614 13:34:29.747876  3451 layer_factory.hpp:77] Creating layer relu6
I0614 13:34:29.747884  3451 net.cpp:94] Creating Layer relu6
I0614 13:34:29.747889  3451 net.cpp:435] relu6 <- fc6
I0614 13:34:29.747895  3451 net.cpp:409] relu6 -> relu6
I0614 13:34:29.747915  3451 net.cpp:144] Setting up relu6
I0614 13:34:29.747918  3451 net.cpp:151] Top shape: 50 4096 (204800)
I0614 13:34:29.747923  3451 net.cpp:159] Memory required for data: 412486200
I0614 13:34:29.747926  3451 layer_factory.hpp:77] Creating layer drop6
I0614 13:34:29.747932  3451 net.cpp:94] Creating Layer drop6
I0614 13:34:29.747936  3451 net.cpp:435] drop6 <- relu6
I0614 13:34:29.747941  3451 net.cpp:409] drop6 -> drop6
I0614 13:34:29.747956  3451 net.cpp:144] Setting up drop6
I0614 13:34:29.747960  3451 net.cpp:151] Top shape: 50 4096 (204800)
I0614 13:34:29.747964  3451 net.cpp:159] Memory required for data: 413305400
I0614 13:34:29.747967  3451 layer_factory.hpp:77] Creating layer fc7
I0614 13:34:29.747974  3451 net.cpp:94] Creating Layer fc7
I0614 13:34:29.747978  3451 net.cpp:435] fc7 <- drop6
I0614 13:34:29.747982  3451 net.cpp:409] fc7 -> fc7
I0614 13:34:29.902961  3451 net.cpp:144] Setting up fc7
I0614 13:34:29.902983  3451 net.cpp:151] Top shape: 50 4096 (204800)
I0614 13:34:29.902992  3451 net.cpp:159] Memory required for data: 414124600
I0614 13:34:29.903002  3451 layer_factory.hpp:77] Creating layer bn7
I0614 13:34:29.903010  3451 net.cpp:94] Creating Layer bn7
I0614 13:34:29.903014  3451 net.cpp:435] bn7 <- fc7
I0614 13:34:29.903020  3451 net.cpp:409] bn7 -> bn7
I0614 13:34:29.903328  3451 net.cpp:144] Setting up bn7
I0614 13:34:29.903335  3451 net.cpp:151] Top shape: 50 4096 (204800)
I0614 13:34:29.903340  3451 net.cpp:159] Memory required for data: 414943800
I0614 13:34:29.903348  3451 layer_factory.hpp:77] Creating layer relu7
I0614 13:34:29.903353  3451 net.cpp:94] Creating Layer relu7
I0614 13:34:29.903357  3451 net.cpp:435] relu7 <- bn7
I0614 13:34:29.903362  3451 net.cpp:409] relu7 -> relu7
I0614 13:34:29.903374  3451 net.cpp:144] Setting up relu7
I0614 13:34:29.903378  3451 net.cpp:151] Top shape: 50 4096 (204800)
I0614 13:34:29.903383  3451 net.cpp:159] Memory required for data: 415763000
I0614 13:34:29.903385  3451 layer_factory.hpp:77] Creating layer drop7
I0614 13:34:29.903390  3451 net.cpp:94] Creating Layer drop7
I0614 13:34:29.903394  3451 net.cpp:435] drop7 <- relu7
I0614 13:34:29.903398  3451 net.cpp:409] drop7 -> drop7
I0614 13:34:29.903414  3451 net.cpp:144] Setting up drop7
I0614 13:34:29.903417  3451 net.cpp:151] Top shape: 50 4096 (204800)
I0614 13:34:29.903422  3451 net.cpp:159] Memory required for data: 416582200
I0614 13:34:29.903425  3451 layer_factory.hpp:77] Creating layer fc8
I0614 13:34:29.903431  3451 net.cpp:94] Creating Layer fc8
I0614 13:34:29.903435  3451 net.cpp:435] fc8 <- drop7
I0614 13:34:29.903439  3451 net.cpp:409] fc8 -> fc8
I0614 13:34:29.903560  3451 net.cpp:144] Setting up fc8
I0614 13:34:29.903564  3451 net.cpp:151] Top shape: 50 2 (100)
I0614 13:34:29.903568  3451 net.cpp:159] Memory required for data: 416582600
I0614 13:34:29.903573  3451 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0614 13:34:29.903580  3451 net.cpp:94] Creating Layer fc8_fc8_0_split
I0614 13:34:29.903584  3451 net.cpp:435] fc8_fc8_0_split <- fc8
I0614 13:34:29.903589  3451 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0614 13:34:29.903594  3451 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0614 13:34:29.903599  3451 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_2
I0614 13:34:29.903618  3451 net.cpp:144] Setting up fc8_fc8_0_split
I0614 13:34:29.903621  3451 net.cpp:151] Top shape: 50 2 (100)
I0614 13:34:29.903625  3451 net.cpp:151] Top shape: 50 2 (100)
I0614 13:34:29.903630  3451 net.cpp:151] Top shape: 50 2 (100)
I0614 13:34:29.903633  3451 net.cpp:159] Memory required for data: 416583800
I0614 13:34:29.903636  3451 layer_factory.hpp:77] Creating layer accuracy
I0614 13:34:29.903642  3451 net.cpp:94] Creating Layer accuracy
I0614 13:34:29.903968  3451 net.cpp:435] accuracy <- fc8_fc8_0_split_0
I0614 13:34:29.903973  3451 net.cpp:435] accuracy <- label_data_1_split_0
I0614 13:34:29.903978  3451 net.cpp:409] accuracy -> accuracy
I0614 13:34:29.903985  3451 net.cpp:144] Setting up accuracy
I0614 13:34:29.903990  3451 net.cpp:151] Top shape: (1)
I0614 13:34:29.903993  3451 net.cpp:159] Memory required for data: 416583804
I0614 13:34:29.903996  3451 layer_factory.hpp:77] Creating layer loss
I0614 13:34:29.904002  3451 net.cpp:94] Creating Layer loss
I0614 13:34:29.904006  3451 net.cpp:435] loss <- fc8_fc8_0_split_1
I0614 13:34:29.904011  3451 net.cpp:435] loss <- label_data_1_split_1
I0614 13:34:29.904014  3451 net.cpp:409] loss -> loss
I0614 13:34:29.904022  3451 layer_factory.hpp:77] Creating layer loss
I0614 13:34:29.904065  3451 net.cpp:144] Setting up loss
I0614 13:34:29.904069  3451 net.cpp:151] Top shape: (1)
I0614 13:34:29.904073  3451 net.cpp:154]     with loss weight 1
I0614 13:34:29.904085  3451 net.cpp:159] Memory required for data: 416583808
I0614 13:34:29.904089  3451 layer_factory.hpp:77] Creating layer accuracy-top1
I0614 13:34:29.904094  3451 net.cpp:94] Creating Layer accuracy-top1
I0614 13:34:29.904098  3451 net.cpp:435] accuracy-top1 <- fc8_fc8_0_split_2
I0614 13:34:29.904103  3451 net.cpp:435] accuracy-top1 <- label_data_1_split_2
I0614 13:34:29.904106  3451 net.cpp:409] accuracy-top1 -> top-1
I0614 13:34:29.904112  3451 net.cpp:144] Setting up accuracy-top1
I0614 13:34:29.904116  3451 net.cpp:151] Top shape: (1)
I0614 13:34:29.904120  3451 net.cpp:159] Memory required for data: 416583812
I0614 13:34:29.904124  3451 net.cpp:222] accuracy-top1 does not need backward computation.
I0614 13:34:29.904129  3451 net.cpp:220] loss needs backward computation.
I0614 13:34:29.904132  3451 net.cpp:222] accuracy does not need backward computation.
I0614 13:34:29.904136  3451 net.cpp:220] fc8_fc8_0_split needs backward computation.
I0614 13:34:29.904140  3451 net.cpp:220] fc8 needs backward computation.
I0614 13:34:29.904145  3451 net.cpp:220] drop7 needs backward computation.
I0614 13:34:29.904147  3451 net.cpp:220] relu7 needs backward computation.
I0614 13:34:29.904151  3451 net.cpp:220] bn7 needs backward computation.
I0614 13:34:29.904155  3451 net.cpp:220] fc7 needs backward computation.
I0614 13:34:29.904160  3451 net.cpp:220] drop6 needs backward computation.
I0614 13:34:29.904163  3451 net.cpp:220] relu6 needs backward computation.
I0614 13:34:29.904167  3451 net.cpp:220] fc6 needs backward computation.
I0614 13:34:29.904171  3451 net.cpp:220] pool5 needs backward computation.
I0614 13:34:29.904175  3451 net.cpp:220] relu5 needs backward computation.
I0614 13:34:29.904179  3451 net.cpp:220] conv5 needs backward computation.
I0614 13:34:29.904182  3451 net.cpp:220] relu4 needs backward computation.
I0614 13:34:29.904186  3451 net.cpp:220] conv4 needs backward computation.
I0614 13:34:29.904191  3451 net.cpp:220] relu3 needs backward computation.
I0614 13:34:29.904194  3451 net.cpp:220] conv3 needs backward computation.
I0614 13:34:29.904198  3451 net.cpp:220] pool2 needs backward computation.
I0614 13:34:29.904202  3451 net.cpp:220] relu2 needs backward computation.
I0614 13:34:29.904206  3451 net.cpp:220] bn2 needs backward computation.
I0614 13:34:29.904210  3451 net.cpp:220] conv2 needs backward computation.
I0614 13:34:29.904214  3451 net.cpp:220] pool1 needs backward computation.
I0614 13:34:29.904218  3451 net.cpp:220] relu1 needs backward computation.
I0614 13:34:29.904222  3451 net.cpp:220] bn1 needs backward computation.
I0614 13:34:29.904227  3451 net.cpp:220] conv1 needs backward computation.
I0614 13:34:29.904230  3451 net.cpp:222] label_data_1_split does not need backward computation.
I0614 13:34:29.904235  3451 net.cpp:222] data does not need backward computation.
I0614 13:34:29.904238  3451 net.cpp:264] This network produces output accuracy
I0614 13:34:29.904242  3451 net.cpp:264] This network produces output loss
I0614 13:34:29.904246  3451 net.cpp:264] This network produces output top-1
I0614 13:34:29.904584  3451 net.cpp:284] Network initialization done.
I0614 13:34:29.904654  3451 solver.cpp:63] Solver scaffolding done.
I0614 13:34:29.905210  3451 caffe_interface.cpp:139] Finetuning from pruning/alexnetBNnoLRN/regular_rate_0.1/sparse.caffemodel
I0614 13:34:32.291816  3451 caffe_interface.cpp:573] Starting Optimization
I0614 13:34:32.291838  3451 solver.cpp:341] Solving 
I0614 13:34:32.291842  3451 solver.cpp:342] Learning Rate Policy: step
I0614 13:34:32.293082  3451 solver.cpp:424] Iteration 0, Testing net (#0)
I0614 13:34:33.760732  3451 solver.cpp:523]     Test net output #0: accuracy = 0.95725
I0614 13:34:33.760763  3451 solver.cpp:523]     Test net output #1: loss = 0.193936 (* 1 = 0.193936 loss)
I0614 13:34:33.760767  3451 solver.cpp:523]     Test net output #2: top-1 = 0.95725
I0614 13:34:34.036530  3451 solver.cpp:270] Iteration 0 (0 iter/s, 1.74459s/50 iter), loss = 0.0092405, remaining 333333 hours and 20 minutes
I0614 13:34:34.036562  3451 solver.cpp:291]     Train net output #0: loss = 0.0092405 (* 1 = 0.0092405 loss)
I0614 13:34:34.036569  3451 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0614 13:34:46.409689  3451 solver.cpp:270] Iteration 50 (4.04117 iter/s, 12.3727s/50 iter), loss = 0.153974, remaining 0 hours and 49 minutes
I0614 13:34:46.409720  3451 solver.cpp:291]     Train net output #0: loss = 0.153974 (* 1 = 0.153974 loss)
I0614 13:34:46.409729  3451 sgd_solver.cpp:106] Iteration 50, lr = 0.001
I0614 13:34:58.878202  3451 solver.cpp:270] Iteration 100 (4.01026 iter/s, 12.468s/50 iter), loss = 0.0522486, remaining 0 hours and 49 minutes
I0614 13:34:58.878394  3451 solver.cpp:291]     Train net output #0: loss = 0.0522486 (* 1 = 0.0522486 loss)
I0614 13:34:58.878402  3451 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I0614 13:35:11.401566  3451 solver.cpp:270] Iteration 150 (3.99274 iter/s, 12.5227s/50 iter), loss = 0.113968, remaining 0 hours and 49 minutes
I0614 13:35:11.401598  3451 solver.cpp:291]     Train net output #0: loss = 0.113968 (* 1 = 0.113968 loss)
I0614 13:35:11.401607  3451 sgd_solver.cpp:106] Iteration 150, lr = 0.001
I0614 13:35:23.981187  3451 solver.cpp:270] Iteration 200 (3.97482 iter/s, 12.5792s/50 iter), loss = 0.0805645, remaining 0 hours and 49 minutes
I0614 13:35:23.981218  3451 solver.cpp:291]     Train net output #0: loss = 0.0805645 (* 1 = 0.0805645 loss)
I0614 13:35:23.981226  3451 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I0614 13:35:36.623636  3451 solver.cpp:270] Iteration 250 (3.95507 iter/s, 12.642s/50 iter), loss = 0.144185, remaining 0 hours and 49 minutes
I0614 13:35:36.623863  3451 solver.cpp:291]     Train net output #0: loss = 0.144185 (* 1 = 0.144185 loss)
I0614 13:35:36.623872  3451 sgd_solver.cpp:106] Iteration 250, lr = 0.001
I0614 13:35:49.254297  3451 solver.cpp:270] Iteration 300 (3.95882 iter/s, 12.63s/50 iter), loss = 0.108471, remaining 0 hours and 49 minutes
I0614 13:35:49.254328  3451 solver.cpp:291]     Train net output #0: loss = 0.108471 (* 1 = 0.108471 loss)
I0614 13:35:49.254335  3451 sgd_solver.cpp:106] Iteration 300, lr = 0.001
I0614 13:36:01.905290  3451 solver.cpp:270] Iteration 350 (3.9524 iter/s, 12.6505s/50 iter), loss = 0.0961662, remaining 0 hours and 49 minutes
I0614 13:36:01.905320  3451 solver.cpp:291]     Train net output #0: loss = 0.0961662 (* 1 = 0.0961662 loss)
I0614 13:36:01.905328  3451 sgd_solver.cpp:106] Iteration 350, lr = 0.001
I0614 13:36:14.537292  3451 solver.cpp:270] Iteration 400 (3.95834 iter/s, 12.6316s/50 iter), loss = 0.127308, remaining 0 hours and 48 minutes
I0614 13:36:14.537572  3451 solver.cpp:291]     Train net output #0: loss = 0.127308 (* 1 = 0.127308 loss)
I0614 13:36:14.537580  3451 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I0614 13:36:27.177801  3451 solver.cpp:270] Iteration 450 (3.95575 iter/s, 12.6398s/50 iter), loss = 0.108764, remaining 0 hours and 48 minutes
I0614 13:36:27.177831  3451 solver.cpp:291]     Train net output #0: loss = 0.108764 (* 1 = 0.108764 loss)
I0614 13:36:27.177839  3451 sgd_solver.cpp:106] Iteration 450, lr = 0.001
I0614 13:36:39.816977  3451 solver.cpp:270] Iteration 500 (3.95609 iter/s, 12.6387s/50 iter), loss = 0.0899664, remaining 0 hours and 48 minutes
I0614 13:36:39.817008  3451 solver.cpp:291]     Train net output #0: loss = 0.0899664 (* 1 = 0.0899664 loss)
I0614 13:36:39.817016  3451 sgd_solver.cpp:106] Iteration 500, lr = 0.001
I0614 13:36:52.441318  3451 solver.cpp:270] Iteration 550 (3.96074 iter/s, 12.6239s/50 iter), loss = 0.135187, remaining 0 hours and 47 minutes
I0614 13:36:52.441625  3451 solver.cpp:291]     Train net output #0: loss = 0.135187 (* 1 = 0.135187 loss)
I0614 13:36:52.441650  3451 sgd_solver.cpp:106] Iteration 550, lr = 0.001
I0614 13:37:05.051316  3451 solver.cpp:270] Iteration 600 (3.96533 iter/s, 12.6093s/50 iter), loss = 0.0730875, remaining 0 hours and 47 minutes
I0614 13:37:05.051347  3451 solver.cpp:291]     Train net output #0: loss = 0.0730875 (* 1 = 0.0730875 loss)
I0614 13:37:05.051353  3451 sgd_solver.cpp:106] Iteration 600, lr = 0.001
I0614 13:37:17.666322  3451 solver.cpp:270] Iteration 650 (3.96367 iter/s, 12.6146s/50 iter), loss = 0.121327, remaining 0 hours and 47 minutes
I0614 13:37:17.666353  3451 solver.cpp:291]     Train net output #0: loss = 0.121327 (* 1 = 0.121327 loss)
I0614 13:37:17.666361  3451 sgd_solver.cpp:106] Iteration 650, lr = 0.001
I0614 13:37:30.352267  3451 solver.cpp:270] Iteration 700 (3.94151 iter/s, 12.6855s/50 iter), loss = 0.0880497, remaining 0 hours and 47 minutes
I0614 13:37:30.352516  3451 solver.cpp:291]     Train net output #0: loss = 0.0880497 (* 1 = 0.0880497 loss)
I0614 13:37:30.352525  3451 sgd_solver.cpp:106] Iteration 700, lr = 0.001
I0614 13:37:43.060966  3451 solver.cpp:270] Iteration 750 (3.93452 iter/s, 12.708s/50 iter), loss = 0.131636, remaining 0 hours and 47 minutes
I0614 13:37:43.060998  3451 solver.cpp:291]     Train net output #0: loss = 0.131636 (* 1 = 0.131636 loss)
I0614 13:37:43.061005  3451 sgd_solver.cpp:106] Iteration 750, lr = 0.001
I0614 13:37:55.774879  3451 solver.cpp:270] Iteration 800 (3.93284 iter/s, 12.7135s/50 iter), loss = 0.141734, remaining 0 hours and 47 minutes
I0614 13:37:55.774911  3451 solver.cpp:291]     Train net output #0: loss = 0.141734 (* 1 = 0.141734 loss)
I0614 13:37:55.774919  3451 sgd_solver.cpp:106] Iteration 800, lr = 0.001
I0614 13:38:08.407873  3451 solver.cpp:270] Iteration 850 (3.95803 iter/s, 12.6326s/50 iter), loss = 0.0929709, remaining 0 hours and 46 minutes
I0614 13:38:08.408121  3451 solver.cpp:291]     Train net output #0: loss = 0.0929709 (* 1 = 0.0929709 loss)
I0614 13:38:08.408145  3451 sgd_solver.cpp:106] Iteration 850, lr = 0.001
I0614 13:38:21.017910  3451 solver.cpp:270] Iteration 900 (3.9653 iter/s, 12.6094s/50 iter), loss = 0.139605, remaining 0 hours and 46 minutes
I0614 13:38:21.017939  3451 solver.cpp:291]     Train net output #0: loss = 0.139605 (* 1 = 0.139605 loss)
I0614 13:38:21.017947  3451 sgd_solver.cpp:106] Iteration 900, lr = 0.001
I0614 13:38:33.642493  3451 solver.cpp:270] Iteration 950 (3.96066 iter/s, 12.6241s/50 iter), loss = 0.100102, remaining 0 hours and 46 minutes
I0614 13:38:33.642524  3451 solver.cpp:291]     Train net output #0: loss = 0.100102 (* 1 = 0.100102 loss)
I0614 13:38:33.642531  3451 sgd_solver.cpp:106] Iteration 950, lr = 0.001
I0614 13:38:46.031486  3451 solver.cpp:424] Iteration 1000, Testing net (#0)
I0614 13:38:47.537667  3451 solver.cpp:523]     Test net output #0: accuracy = 0.75325
I0614 13:38:47.537694  3451 solver.cpp:523]     Test net output #1: loss = 0.905503 (* 1 = 0.905503 loss)
I0614 13:38:47.537699  3451 solver.cpp:523]     Test net output #2: top-1 = 0.75325
I0614 13:38:47.784502  3451 solver.cpp:270] Iteration 1000 (3.53569 iter/s, 14.1415s/50 iter), loss = 0.113639, remaining 0 hours and 51 minutes
I0614 13:38:47.784531  3451 solver.cpp:291]     Train net output #0: loss = 0.113639 (* 1 = 0.113639 loss)
I0614 13:38:47.784538  3451 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I0614 13:39:00.433971  3451 solver.cpp:270] Iteration 1050 (3.95287 iter/s, 12.649s/50 iter), loss = 0.0850924, remaining 0 hours and 46 minutes
I0614 13:39:00.434005  3451 solver.cpp:291]     Train net output #0: loss = 0.0850924 (* 1 = 0.0850924 loss)
I0614 13:39:00.434015  3451 sgd_solver.cpp:106] Iteration 1050, lr = 0.001
I0614 13:39:13.050813  3451 solver.cpp:270] Iteration 1100 (3.9631 iter/s, 12.6164s/50 iter), loss = 0.115223, remaining 0 hours and 45 minutes
I0614 13:39:13.050848  3451 solver.cpp:291]     Train net output #0: loss = 0.115223 (* 1 = 0.115223 loss)
I0614 13:39:13.050854  3451 sgd_solver.cpp:106] Iteration 1100, lr = 0.001
I0614 13:39:25.672564  3451 solver.cpp:270] Iteration 1150 (3.96156 iter/s, 12.6213s/50 iter), loss = 0.112373, remaining 0 hours and 45 minutes
I0614 13:39:25.672892  3451 solver.cpp:291]     Train net output #0: loss = 0.112373 (* 1 = 0.112373 loss)
I0614 13:39:25.672900  3451 sgd_solver.cpp:106] Iteration 1150, lr = 0.001
I0614 13:39:38.303012  3451 solver.cpp:270] Iteration 1200 (3.95892 iter/s, 12.6297s/50 iter), loss = 0.117033, remaining 0 hours and 45 minutes
I0614 13:39:38.303043  3451 solver.cpp:291]     Train net output #0: loss = 0.117033 (* 1 = 0.117033 loss)
I0614 13:39:38.303051  3451 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I0614 13:39:50.936316  3451 solver.cpp:270] Iteration 1250 (3.95793 iter/s, 12.6329s/50 iter), loss = 0.146247, remaining 0 hours and 45 minutes
I0614 13:39:50.936349  3451 solver.cpp:291]     Train net output #0: loss = 0.146247 (* 1 = 0.146247 loss)
I0614 13:39:50.936357  3451 sgd_solver.cpp:106] Iteration 1250, lr = 0.001
I0614 13:40:03.574458  3451 solver.cpp:270] Iteration 1300 (3.95642 iter/s, 12.6377s/50 iter), loss = 0.0879231, remaining 0 hours and 44 minutes
I0614 13:40:03.574690  3451 solver.cpp:291]     Train net output #0: loss = 0.0879231 (* 1 = 0.0879231 loss)
I0614 13:40:03.574698  3451 sgd_solver.cpp:106] Iteration 1300, lr = 0.001
I0614 13:40:16.211580  3451 solver.cpp:270] Iteration 1350 (3.9568 iter/s, 12.6365s/50 iter), loss = 0.168216, remaining 0 hours and 44 minutes
I0614 13:40:16.211612  3451 solver.cpp:291]     Train net output #0: loss = 0.168216 (* 1 = 0.168216 loss)
I0614 13:40:16.211619  3451 sgd_solver.cpp:106] Iteration 1350, lr = 0.001
I0614 13:40:28.841804  3451 solver.cpp:270] Iteration 1400 (3.9589 iter/s, 12.6298s/50 iter), loss = 0.138139, remaining 0 hours and 44 minutes
I0614 13:40:28.841835  3451 solver.cpp:291]     Train net output #0: loss = 0.138139 (* 1 = 0.138139 loss)
I0614 13:40:28.841858  3451 sgd_solver.cpp:106] Iteration 1400, lr = 0.001
I0614 13:40:41.469017  3451 solver.cpp:270] Iteration 1450 (3.95984 iter/s, 12.6268s/50 iter), loss = 0.0609358, remaining 0 hours and 44 minutes
I0614 13:40:41.469244  3451 solver.cpp:291]     Train net output #0: loss = 0.0609358 (* 1 = 0.0609358 loss)
I0614 13:40:41.469269  3451 sgd_solver.cpp:106] Iteration 1450, lr = 0.001
I0614 13:40:54.112949  3451 solver.cpp:270] Iteration 1500 (3.95466 iter/s, 12.6433s/50 iter), loss = 0.113986, remaining 0 hours and 44 minutes
I0614 13:40:54.112982  3451 solver.cpp:291]     Train net output #0: loss = 0.113986 (* 1 = 0.113986 loss)
I0614 13:40:54.113004  3451 sgd_solver.cpp:106] Iteration 1500, lr = 0.001
I0614 13:41:06.772265  3451 solver.cpp:270] Iteration 1550 (3.9498 iter/s, 12.6589s/50 iter), loss = 0.0850346, remaining 0 hours and 44 minutes
I0614 13:41:06.772295  3451 solver.cpp:291]     Train net output #0: loss = 0.0850346 (* 1 = 0.0850346 loss)
I0614 13:41:06.772302  3451 sgd_solver.cpp:106] Iteration 1550, lr = 0.001
I0614 13:41:19.412091  3451 solver.cpp:270] Iteration 1600 (3.95589 iter/s, 12.6394s/50 iter), loss = 0.0862343, remaining 0 hours and 43 minutes
I0614 13:41:19.412307  3451 solver.cpp:291]     Train net output #0: loss = 0.0862343 (* 1 = 0.0862343 loss)
I0614 13:41:19.412331  3451 sgd_solver.cpp:106] Iteration 1600, lr = 0.001
I0614 13:41:32.035967  3451 solver.cpp:270] Iteration 1650 (3.96094 iter/s, 12.6233s/50 iter), loss = 0.0914318, remaining 0 hours and 43 minutes
I0614 13:41:32.036000  3451 solver.cpp:291]     Train net output #0: loss = 0.0914318 (* 1 = 0.0914318 loss)
I0614 13:41:32.036007  3451 sgd_solver.cpp:106] Iteration 1650, lr = 0.001
I0614 13:41:44.653400  3451 solver.cpp:270] Iteration 1700 (3.96291 iter/s, 12.617s/50 iter), loss = 0.192267, remaining 0 hours and 43 minutes
I0614 13:41:44.653431  3451 solver.cpp:291]     Train net output #0: loss = 0.192267 (* 1 = 0.192267 loss)
I0614 13:41:44.653438  3451 sgd_solver.cpp:106] Iteration 1700, lr = 0.001
I0614 13:41:57.299590  3451 solver.cpp:270] Iteration 1750 (3.9539 iter/s, 12.6457s/50 iter), loss = 0.146709, remaining 0 hours and 42 minutes
I0614 13:41:57.299914  3451 solver.cpp:291]     Train net output #0: loss = 0.146709 (* 1 = 0.146709 loss)
I0614 13:41:57.299937  3451 sgd_solver.cpp:106] Iteration 1750, lr = 0.001
I0614 13:42:09.935698  3451 solver.cpp:270] Iteration 1800 (3.95714 iter/s, 12.6354s/50 iter), loss = 0.0860813, remaining 0 hours and 42 minutes
I0614 13:42:09.935731  3451 solver.cpp:291]     Train net output #0: loss = 0.0860813 (* 1 = 0.0860813 loss)
I0614 13:42:09.935739  3451 sgd_solver.cpp:106] Iteration 1800, lr = 0.001
I0614 13:42:22.563228  3451 solver.cpp:270] Iteration 1850 (3.95974 iter/s, 12.6271s/50 iter), loss = 0.0836483, remaining 0 hours and 42 minutes
I0614 13:42:22.563261  3451 solver.cpp:291]     Train net output #0: loss = 0.0836483 (* 1 = 0.0836483 loss)
I0614 13:42:22.563268  3451 sgd_solver.cpp:106] Iteration 1850, lr = 0.001
I0614 13:42:35.186440  3451 solver.cpp:270] Iteration 1900 (3.9611 iter/s, 12.6228s/50 iter), loss = 0.137357, remaining 0 hours and 42 minutes
I0614 13:42:35.186640  3451 solver.cpp:291]     Train net output #0: loss = 0.137357 (* 1 = 0.137357 loss)
I0614 13:42:35.186648  3451 sgd_solver.cpp:106] Iteration 1900, lr = 0.001
I0614 13:42:47.803165  3451 solver.cpp:270] Iteration 1950 (3.96318 iter/s, 12.6161s/50 iter), loss = 0.0823026, remaining 0 hours and 42 minutes
I0614 13:42:47.803195  3451 solver.cpp:291]     Train net output #0: loss = 0.0823026 (* 1 = 0.0823026 loss)
I0614 13:42:47.803202  3451 sgd_solver.cpp:106] Iteration 1950, lr = 0.001
I0614 13:43:00.204458  3451 solver.cpp:424] Iteration 2000, Testing net (#0)
I0614 13:43:01.700806  3451 solver.cpp:523]     Test net output #0: accuracy = 0.92575
I0614 13:43:01.700836  3451 solver.cpp:523]     Test net output #1: loss = 0.193618 (* 1 = 0.193618 loss)
I0614 13:43:01.700840  3451 solver.cpp:523]     Test net output #2: top-1 = 0.92575
I0614 13:43:01.947937  3451 solver.cpp:270] Iteration 2000 (3.535 iter/s, 14.1443s/50 iter), loss = 0.0788557, remaining 0 hours and 46 minutes
I0614 13:43:01.947968  3451 solver.cpp:291]     Train net output #0: loss = 0.0788557 (* 1 = 0.0788557 loss)
I0614 13:43:01.947976  3451 sgd_solver.cpp:106] Iteration 2000, lr = 0.001
I0614 13:43:14.577332  3451 solver.cpp:270] Iteration 2050 (3.95916 iter/s, 12.629s/50 iter), loss = 0.127113, remaining 0 hours and 41 minutes
I0614 13:43:14.577587  3451 solver.cpp:291]     Train net output #0: loss = 0.127113 (* 1 = 0.127113 loss)
I0614 13:43:14.577595  3451 sgd_solver.cpp:106] Iteration 2050, lr = 0.001
I0614 13:43:27.207892  3451 solver.cpp:270] Iteration 2100 (3.95886 iter/s, 12.6299s/50 iter), loss = 0.0582238, remaining 0 hours and 41 minutes
I0614 13:43:27.207923  3451 solver.cpp:291]     Train net output #0: loss = 0.0582238 (* 1 = 0.0582238 loss)
I0614 13:43:27.207931  3451 sgd_solver.cpp:106] Iteration 2100, lr = 0.001
I0614 13:43:39.831188  3451 solver.cpp:270] Iteration 2150 (3.96107 iter/s, 12.6229s/50 iter), loss = 0.0826696, remaining 0 hours and 41 minutes
I0614 13:43:39.831220  3451 solver.cpp:291]     Train net output #0: loss = 0.0826696 (* 1 = 0.0826696 loss)
I0614 13:43:39.831228  3451 sgd_solver.cpp:106] Iteration 2150, lr = 0.001
I0614 13:43:52.452647  3451 solver.cpp:270] Iteration 2200 (3.96165 iter/s, 12.621s/50 iter), loss = 0.10041, remaining 0 hours and 41 minutes
I0614 13:43:52.452891  3451 solver.cpp:291]     Train net output #0: loss = 0.10041 (* 1 = 0.10041 loss)
I0614 13:43:52.452899  3451 sgd_solver.cpp:106] Iteration 2200, lr = 0.001
I0614 13:44:05.094835  3451 solver.cpp:270] Iteration 2250 (3.95522 iter/s, 12.6415s/50 iter), loss = 0.0833707, remaining 0 hours and 40 minutes
I0614 13:44:05.094866  3451 solver.cpp:291]     Train net output #0: loss = 0.0833707 (* 1 = 0.0833707 loss)
I0614 13:44:05.094872  3451 sgd_solver.cpp:106] Iteration 2250, lr = 0.001
I0614 13:44:17.722311  3451 solver.cpp:270] Iteration 2300 (3.95976 iter/s, 12.627s/50 iter), loss = 0.100926, remaining 0 hours and 40 minutes
I0614 13:44:17.722342  3451 solver.cpp:291]     Train net output #0: loss = 0.100926 (* 1 = 0.100926 loss)
I0614 13:44:17.722365  3451 sgd_solver.cpp:106] Iteration 2300, lr = 0.001
I0614 13:44:30.334913  3451 solver.cpp:270] Iteration 2350 (3.96443 iter/s, 12.6122s/50 iter), loss = 0.131295, remaining 0 hours and 40 minutes
I0614 13:44:30.335244  3451 solver.cpp:291]     Train net output #0: loss = 0.131295 (* 1 = 0.131295 loss)
I0614 13:44:30.335253  3451 sgd_solver.cpp:106] Iteration 2350, lr = 0.001
I0614 13:44:42.956784  3451 solver.cpp:270] Iteration 2400 (3.96161 iter/s, 12.6211s/50 iter), loss = 0.121419, remaining 0 hours and 40 minutes
I0614 13:44:42.956815  3451 solver.cpp:291]     Train net output #0: loss = 0.121419 (* 1 = 0.121419 loss)
I0614 13:44:42.956822  3451 sgd_solver.cpp:106] Iteration 2400, lr = 0.001
I0614 13:44:55.592705  3451 solver.cpp:270] Iteration 2450 (3.95711 iter/s, 12.6355s/50 iter), loss = 0.0947755, remaining 0 hours and 40 minutes
I0614 13:44:55.592736  3451 solver.cpp:291]     Train net output #0: loss = 0.0947755 (* 1 = 0.0947755 loss)
I0614 13:44:55.592744  3451 sgd_solver.cpp:106] Iteration 2450, lr = 0.001
I0614 13:45:08.233291  3451 solver.cpp:270] Iteration 2500 (3.95565 iter/s, 12.6401s/50 iter), loss = 0.145571, remaining 0 hours and 39 minutes
I0614 13:45:08.233538  3451 solver.cpp:291]     Train net output #0: loss = 0.145571 (* 1 = 0.145571 loss)
I0614 13:45:08.233546  3451 sgd_solver.cpp:106] Iteration 2500, lr = 0.0001
I0614 13:45:20.867027  3451 solver.cpp:270] Iteration 2550 (3.95786 iter/s, 12.6331s/50 iter), loss = 0.0886374, remaining 0 hours and 39 minutes
I0614 13:45:20.867060  3451 solver.cpp:291]     Train net output #0: loss = 0.0886374 (* 1 = 0.0886374 loss)
I0614 13:45:20.867067  3451 sgd_solver.cpp:106] Iteration 2550, lr = 0.0001
I0614 13:45:33.480180  3451 solver.cpp:270] Iteration 2600 (3.96425 iter/s, 12.6127s/50 iter), loss = 0.0586597, remaining 0 hours and 39 minutes
I0614 13:45:33.480211  3451 solver.cpp:291]     Train net output #0: loss = 0.0586597 (* 1 = 0.0586597 loss)
I0614 13:45:33.480218  3451 sgd_solver.cpp:106] Iteration 2600, lr = 0.0001
I0614 13:45:46.132604  3451 solver.cpp:270] Iteration 2650 (3.95195 iter/s, 12.652s/50 iter), loss = 0.0340577, remaining 0 hours and 39 minutes
I0614 13:45:46.132861  3451 solver.cpp:291]     Train net output #0: loss = 0.0340577 (* 1 = 0.0340577 loss)
I0614 13:45:46.132869  3451 sgd_solver.cpp:106] Iteration 2650, lr = 0.0001
I0614 13:45:58.772791  3451 solver.cpp:270] Iteration 2700 (3.95585 iter/s, 12.6395s/50 iter), loss = 0.0403588, remaining 0 hours and 39 minutes
I0614 13:45:58.772821  3451 solver.cpp:291]     Train net output #0: loss = 0.0403588 (* 1 = 0.0403588 loss)
I0614 13:45:58.772845  3451 sgd_solver.cpp:106] Iteration 2700, lr = 0.0001
I0614 13:46:11.491405  3451 solver.cpp:270] Iteration 2750 (3.93138 iter/s, 12.7182s/50 iter), loss = 0.0442328, remaining 0 hours and 39 minutes
I0614 13:46:11.491436  3451 solver.cpp:291]     Train net output #0: loss = 0.0442327 (* 1 = 0.0442327 loss)
I0614 13:46:11.491443  3451 sgd_solver.cpp:106] Iteration 2750, lr = 0.0001
I0614 13:46:24.227326  3451 solver.cpp:270] Iteration 2800 (3.92604 iter/s, 12.7355s/50 iter), loss = 0.0519178, remaining 0 hours and 38 minutes
I0614 13:46:24.227538  3451 solver.cpp:291]     Train net output #0: loss = 0.0519177 (* 1 = 0.0519177 loss)
I0614 13:46:24.227562  3451 sgd_solver.cpp:106] Iteration 2800, lr = 0.0001
I0614 13:46:36.914464  3451 solver.cpp:270] Iteration 2850 (3.94119 iter/s, 12.6865s/50 iter), loss = 0.066984, remaining 0 hours and 38 minutes
I0614 13:46:36.914495  3451 solver.cpp:291]     Train net output #0: loss = 0.066984 (* 1 = 0.066984 loss)
I0614 13:46:36.914502  3451 sgd_solver.cpp:106] Iteration 2850, lr = 0.0001
I0614 13:46:49.531710  3451 solver.cpp:270] Iteration 2900 (3.96297 iter/s, 12.6168s/50 iter), loss = 0.0224963, remaining 0 hours and 38 minutes
I0614 13:46:49.531742  3451 solver.cpp:291]     Train net output #0: loss = 0.0224963 (* 1 = 0.0224963 loss)
I0614 13:46:49.531749  3451 sgd_solver.cpp:106] Iteration 2900, lr = 0.0001
I0614 13:47:02.153942  3451 solver.cpp:270] Iteration 2950 (3.9614 iter/s, 12.6218s/50 iter), loss = 0.0485569, remaining 0 hours and 37 minutes
I0614 13:47:02.154285  3451 solver.cpp:291]     Train net output #0: loss = 0.0485569 (* 1 = 0.0485569 loss)
I0614 13:47:02.154294  3451 sgd_solver.cpp:106] Iteration 2950, lr = 0.0001
I0614 13:47:14.537362  3451 solver.cpp:424] Iteration 3000, Testing net (#0)
I0614 13:47:16.041052  3451 solver.cpp:523]     Test net output #0: accuracy = 0.95125
I0614 13:47:16.041082  3451 solver.cpp:523]     Test net output #1: loss = 0.128375 (* 1 = 0.128375 loss)
I0614 13:47:16.041087  3451 solver.cpp:523]     Test net output #2: top-1 = 0.95125
I0614 13:47:16.287981  3451 solver.cpp:270] Iteration 3000 (3.53776 iter/s, 14.1332s/50 iter), loss = 0.0330453, remaining 0 hours and 42 minutes
I0614 13:47:16.288012  3451 solver.cpp:291]     Train net output #0: loss = 0.0330453 (* 1 = 0.0330453 loss)
I0614 13:47:16.288019  3451 sgd_solver.cpp:106] Iteration 3000, lr = 0.0001
I0614 13:47:28.900264  3451 solver.cpp:270] Iteration 3050 (3.96453 iter/s, 12.6118s/50 iter), loss = 0.0845902, remaining 0 hours and 37 minutes
I0614 13:47:28.900293  3451 solver.cpp:291]     Train net output #0: loss = 0.0845901 (* 1 = 0.0845901 loss)
I0614 13:47:28.900301  3451 sgd_solver.cpp:106] Iteration 3050, lr = 0.0001
I0614 13:47:41.548229  3451 solver.cpp:270] Iteration 3100 (3.95334 iter/s, 12.6475s/50 iter), loss = 0.0195101, remaining 0 hours and 37 minutes
I0614 13:47:41.548477  3451 solver.cpp:291]     Train net output #0: loss = 0.0195101 (* 1 = 0.0195101 loss)
I0614 13:47:41.548485  3451 sgd_solver.cpp:106] Iteration 3100, lr = 0.0001
I0614 13:47:54.197068  3451 solver.cpp:270] Iteration 3150 (3.95314 iter/s, 12.6482s/50 iter), loss = 0.0643881, remaining 0 hours and 37 minutes
I0614 13:47:54.197099  3451 solver.cpp:291]     Train net output #0: loss = 0.0643881 (* 1 = 0.0643881 loss)
I0614 13:47:54.197106  3451 sgd_solver.cpp:106] Iteration 3150, lr = 0.0001
I0614 13:48:06.837455  3451 solver.cpp:270] Iteration 3200 (3.95571 iter/s, 12.6399s/50 iter), loss = 0.0151717, remaining 0 hours and 36 minutes
I0614 13:48:06.837486  3451 solver.cpp:291]     Train net output #0: loss = 0.0151717 (* 1 = 0.0151717 loss)
I0614 13:48:06.837493  3451 sgd_solver.cpp:106] Iteration 3200, lr = 0.0001
I0614 13:48:19.468294  3451 solver.cpp:270] Iteration 3250 (3.9587 iter/s, 12.6304s/50 iter), loss = 0.027211, remaining 0 hours and 36 minutes
I0614 13:48:19.468549  3451 solver.cpp:291]     Train net output #0: loss = 0.027211 (* 1 = 0.027211 loss)
I0614 13:48:19.468571  3451 sgd_solver.cpp:106] Iteration 3250, lr = 0.0001
I0614 13:48:32.083199  3451 solver.cpp:270] Iteration 3300 (3.96377 iter/s, 12.6142s/50 iter), loss = 0.0596595, remaining 0 hours and 36 minutes
I0614 13:48:32.083232  3451 solver.cpp:291]     Train net output #0: loss = 0.0596595 (* 1 = 0.0596595 loss)
I0614 13:48:32.083240  3451 sgd_solver.cpp:106] Iteration 3300, lr = 0.0001
I0614 13:48:44.705142  3451 solver.cpp:270] Iteration 3350 (3.96149 iter/s, 12.6215s/50 iter), loss = 0.0344228, remaining 0 hours and 36 minutes
I0614 13:48:44.705174  3451 solver.cpp:291]     Train net output #0: loss = 0.0344228 (* 1 = 0.0344228 loss)
I0614 13:48:44.705197  3451 sgd_solver.cpp:106] Iteration 3350, lr = 0.0001
I0614 13:48:57.320461  3451 solver.cpp:270] Iteration 3400 (3.96357 iter/s, 12.6149s/50 iter), loss = 0.0426295, remaining 0 hours and 36 minutes
I0614 13:48:57.320732  3451 solver.cpp:291]     Train net output #0: loss = 0.0426294 (* 1 = 0.0426294 loss)
I0614 13:48:57.320739  3451 sgd_solver.cpp:106] Iteration 3400, lr = 0.0001
I0614 13:49:09.962745  3451 solver.cpp:270] Iteration 3450 (3.95519 iter/s, 12.6416s/50 iter), loss = 0.063587, remaining 0 hours and 35 minutes
I0614 13:49:09.962778  3451 solver.cpp:291]     Train net output #0: loss = 0.063587 (* 1 = 0.063587 loss)
I0614 13:49:09.962785  3451 sgd_solver.cpp:106] Iteration 3450, lr = 0.0001
I0614 13:49:22.604753  3451 solver.cpp:270] Iteration 3500 (3.95521 iter/s, 12.6416s/50 iter), loss = 0.0347159, remaining 0 hours and 35 minutes
I0614 13:49:22.604784  3451 solver.cpp:291]     Train net output #0: loss = 0.0347159 (* 1 = 0.0347159 loss)
I0614 13:49:22.604791  3451 sgd_solver.cpp:106] Iteration 3500, lr = 0.0001
I0614 13:49:35.218926  3451 solver.cpp:270] Iteration 3550 (3.96393 iter/s, 12.6137s/50 iter), loss = 0.0336015, remaining 0 hours and 35 minutes
I0614 13:49:35.219185  3451 solver.cpp:291]     Train net output #0: loss = 0.0336014 (* 1 = 0.0336014 loss)
I0614 13:49:35.219193  3451 sgd_solver.cpp:106] Iteration 3550, lr = 0.0001
I0614 13:49:47.844799  3451 solver.cpp:270] Iteration 3600 (3.96033 iter/s, 12.6252s/50 iter), loss = 0.0591165, remaining 0 hours and 35 minutes
I0614 13:49:47.844830  3451 solver.cpp:291]     Train net output #0: loss = 0.0591164 (* 1 = 0.0591164 loss)
I0614 13:49:47.844836  3451 sgd_solver.cpp:106] Iteration 3600, lr = 0.0001
I0614 13:50:00.499217  3451 solver.cpp:270] Iteration 3650 (3.95133 iter/s, 12.654s/50 iter), loss = 0.030427, remaining 0 hours and 35 minutes
I0614 13:50:00.499249  3451 solver.cpp:291]     Train net output #0: loss = 0.0304269 (* 1 = 0.0304269 loss)
I0614 13:50:00.499258  3451 sgd_solver.cpp:106] Iteration 3650, lr = 0.0001
I0614 13:50:13.130175  3451 solver.cpp:270] Iteration 3700 (3.95867 iter/s, 12.6305s/50 iter), loss = 0.0308527, remaining 0 hours and 34 minutes
I0614 13:50:13.130411  3451 solver.cpp:291]     Train net output #0: loss = 0.0308526 (* 1 = 0.0308526 loss)
I0614 13:50:13.130435  3451 sgd_solver.cpp:106] Iteration 3700, lr = 0.0001
I0614 13:50:25.758046  3451 solver.cpp:270] Iteration 3750 (3.9597 iter/s, 12.6272s/50 iter), loss = 0.0310265, remaining 0 hours and 34 minutes
I0614 13:50:25.758078  3451 solver.cpp:291]     Train net output #0: loss = 0.0310264 (* 1 = 0.0310264 loss)
I0614 13:50:25.758085  3451 sgd_solver.cpp:106] Iteration 3750, lr = 0.0001
I0614 13:50:38.394425  3451 solver.cpp:270] Iteration 3800 (3.95697 iter/s, 12.6359s/50 iter), loss = 0.0424205, remaining 0 hours and 34 minutes
I0614 13:50:38.394457  3451 solver.cpp:291]     Train net output #0: loss = 0.0424204 (* 1 = 0.0424204 loss)
I0614 13:50:38.394480  3451 sgd_solver.cpp:106] Iteration 3800, lr = 0.0001
I0614 13:50:51.033960  3451 solver.cpp:270] Iteration 3850 (3.95598 iter/s, 12.6391s/50 iter), loss = 0.0344922, remaining 0 hours and 34 minutes
I0614 13:50:51.034193  3451 solver.cpp:291]     Train net output #0: loss = 0.0344922 (* 1 = 0.0344922 loss)
I0614 13:50:51.034217  3451 sgd_solver.cpp:106] Iteration 3850, lr = 0.0001
I0614 13:51:03.651896  3451 solver.cpp:270] Iteration 3900 (3.96281 iter/s, 12.6173s/50 iter), loss = 0.020852, remaining 0 hours and 34 minutes
I0614 13:51:03.651928  3451 solver.cpp:291]     Train net output #0: loss = 0.0208519 (* 1 = 0.0208519 loss)
I0614 13:51:03.651952  3451 sgd_solver.cpp:106] Iteration 3900, lr = 0.0001
I0614 13:51:16.273762  3451 solver.cpp:270] Iteration 3950 (3.96152 iter/s, 12.6214s/50 iter), loss = 0.00826473, remaining 0 hours and 33 minutes
I0614 13:51:16.273794  3451 solver.cpp:291]     Train net output #0: loss = 0.00826468 (* 1 = 0.00826468 loss)
I0614 13:51:16.273802  3451 sgd_solver.cpp:106] Iteration 3950, lr = 0.0001
I0614 13:51:28.635821  3451 solver.cpp:424] Iteration 4000, Testing net (#0)
I0614 13:51:30.125356  3451 solver.cpp:523]     Test net output #0: accuracy = 0.949249
I0614 13:51:30.125387  3451 solver.cpp:523]     Test net output #1: loss = 0.12583 (* 1 = 0.12583 loss)
I0614 13:51:30.125392  3451 solver.cpp:523]     Test net output #2: top-1 = 0.949249
I0614 13:51:30.372135  3451 solver.cpp:270] Iteration 4000 (3.54663 iter/s, 14.0979s/50 iter), loss = 0.0244596, remaining 0 hours and 37 minutes
I0614 13:51:30.372167  3451 solver.cpp:291]     Train net output #0: loss = 0.0244595 (* 1 = 0.0244595 loss)
I0614 13:51:30.372175  3451 sgd_solver.cpp:106] Iteration 4000, lr = 0.0001
I0614 13:51:42.996568  3451 solver.cpp:270] Iteration 4050 (3.96071 iter/s, 12.624s/50 iter), loss = 0.00577099, remaining 0 hours and 33 minutes
I0614 13:51:42.996601  3451 solver.cpp:291]     Train net output #0: loss = 0.00577093 (* 1 = 0.00577093 loss)
I0614 13:51:42.996609  3451 sgd_solver.cpp:106] Iteration 4050, lr = 0.0001
I0614 13:51:55.616842  3451 solver.cpp:270] Iteration 4100 (3.96202 iter/s, 12.6198s/50 iter), loss = 0.0354411, remaining 0 hours and 33 minutes
I0614 13:51:55.616873  3451 solver.cpp:291]     Train net output #0: loss = 0.035441 (* 1 = 0.035441 loss)
I0614 13:51:55.616881  3451 sgd_solver.cpp:106] Iteration 4100, lr = 0.0001
I0614 13:52:08.266377  3451 solver.cpp:270] Iteration 4150 (3.95285 iter/s, 12.6491s/50 iter), loss = 0.0354971, remaining 0 hours and 32 minutes
I0614 13:52:08.266706  3451 solver.cpp:291]     Train net output #0: loss = 0.035497 (* 1 = 0.035497 loss)
I0614 13:52:08.266731  3451 sgd_solver.cpp:106] Iteration 4150, lr = 0.0001
I0614 13:52:20.904234  3451 solver.cpp:270] Iteration 4200 (3.9566 iter/s, 12.6371s/50 iter), loss = 0.0148478, remaining 0 hours and 32 minutes
I0614 13:52:20.904266  3451 solver.cpp:291]     Train net output #0: loss = 0.0148477 (* 1 = 0.0148477 loss)
I0614 13:52:20.904289  3451 sgd_solver.cpp:106] Iteration 4200, lr = 0.0001
I0614 13:52:33.516453  3451 solver.cpp:270] Iteration 4250 (3.96455 iter/s, 12.6118s/50 iter), loss = 0.0295728, remaining 0 hours and 32 minutes
I0614 13:52:33.516482  3451 solver.cpp:291]     Train net output #0: loss = 0.0295727 (* 1 = 0.0295727 loss)
I0614 13:52:33.516490  3451 sgd_solver.cpp:106] Iteration 4250, lr = 0.0001
I0614 13:52:46.118466  3451 solver.cpp:270] Iteration 4300 (3.96776 iter/s, 12.6016s/50 iter), loss = 0.0579091, remaining 0 hours and 32 minutes
I0614 13:52:46.118714  3451 solver.cpp:291]     Train net output #0: loss = 0.0579091 (* 1 = 0.0579091 loss)
I0614 13:52:46.118738  3451 sgd_solver.cpp:106] Iteration 4300, lr = 0.0001
I0614 13:52:58.730473  3451 solver.cpp:270] Iteration 4350 (3.96468 iter/s, 12.6114s/50 iter), loss = 0.0193241, remaining 0 hours and 32 minutes
I0614 13:52:58.730504  3451 solver.cpp:291]     Train net output #0: loss = 0.0193241 (* 1 = 0.0193241 loss)
I0614 13:52:58.730511  3451 sgd_solver.cpp:106] Iteration 4350, lr = 0.0001
I0614 13:53:11.352098  3451 solver.cpp:270] Iteration 4400 (3.96159 iter/s, 12.6212s/50 iter), loss = 0.0379504, remaining 0 hours and 31 minutes
I0614 13:53:11.352129  3451 solver.cpp:291]     Train net output #0: loss = 0.0379504 (* 1 = 0.0379504 loss)
I0614 13:53:11.352136  3451 sgd_solver.cpp:106] Iteration 4400, lr = 0.0001
I0614 13:53:23.979609  3451 solver.cpp:270] Iteration 4450 (3.95975 iter/s, 12.6271s/50 iter), loss = 0.0272684, remaining 0 hours and 31 minutes
I0614 13:53:23.979861  3451 solver.cpp:291]     Train net output #0: loss = 0.0272683 (* 1 = 0.0272683 loss)
I0614 13:53:23.979868  3451 sgd_solver.cpp:106] Iteration 4450, lr = 0.0001
I0614 13:53:36.624692  3451 solver.cpp:270] Iteration 4500 (3.95431 iter/s, 12.6444s/50 iter), loss = 0.0214653, remaining 0 hours and 31 minutes
I0614 13:53:36.624723  3451 solver.cpp:291]     Train net output #0: loss = 0.0214653 (* 1 = 0.0214653 loss)
I0614 13:53:36.624730  3451 sgd_solver.cpp:106] Iteration 4500, lr = 0.0001
I0614 13:53:49.247748  3451 solver.cpp:270] Iteration 4550 (3.96114 iter/s, 12.6226s/50 iter), loss = 0.0264726, remaining 0 hours and 31 minutes
I0614 13:53:49.247781  3451 solver.cpp:291]     Train net output #0: loss = 0.0264726 (* 1 = 0.0264726 loss)
I0614 13:53:49.247789  3451 sgd_solver.cpp:106] Iteration 4550, lr = 0.0001
I0614 13:54:01.864306  3451 solver.cpp:270] Iteration 4600 (3.96318 iter/s, 12.6161s/50 iter), loss = 0.013296, remaining 0 hours and 31 minutes
I0614 13:54:01.864642  3451 solver.cpp:291]     Train net output #0: loss = 0.0132959 (* 1 = 0.0132959 loss)
I0614 13:54:01.864666  3451 sgd_solver.cpp:106] Iteration 4600, lr = 0.0001
I0614 13:54:14.508131  3451 solver.cpp:270] Iteration 4650 (3.95473 iter/s, 12.6431s/50 iter), loss = 0.0508997, remaining 0 hours and 30 minutes
I0614 13:54:14.508162  3451 solver.cpp:291]     Train net output #0: loss = 0.0508997 (* 1 = 0.0508997 loss)
I0614 13:54:14.508169  3451 sgd_solver.cpp:106] Iteration 4650, lr = 0.0001
I0614 13:54:27.123351  3451 solver.cpp:270] Iteration 4700 (3.9636 iter/s, 12.6148s/50 iter), loss = 0.0440385, remaining 0 hours and 30 minutes
I0614 13:54:27.123399  3451 solver.cpp:291]     Train net output #0: loss = 0.0440385 (* 1 = 0.0440385 loss)
I0614 13:54:27.123406  3451 sgd_solver.cpp:106] Iteration 4700, lr = 0.0001
I0614 13:54:39.755085  3451 solver.cpp:270] Iteration 4750 (3.95842 iter/s, 12.6313s/50 iter), loss = 0.00982937, remaining 0 hours and 30 minutes
I0614 13:54:39.755296  3451 solver.cpp:291]     Train net output #0: loss = 0.00982932 (* 1 = 0.00982932 loss)
I0614 13:54:39.755321  3451 sgd_solver.cpp:106] Iteration 4750, lr = 0.0001
I0614 13:54:52.480381  3451 solver.cpp:270] Iteration 4800 (3.92937 iter/s, 12.7247s/50 iter), loss = 0.0211651, remaining 0 hours and 30 minutes
I0614 13:54:52.480412  3451 solver.cpp:291]     Train net output #0: loss = 0.0211651 (* 1 = 0.0211651 loss)
I0614 13:54:52.480420  3451 sgd_solver.cpp:106] Iteration 4800, lr = 0.0001
I0614 13:55:05.204665  3451 solver.cpp:270] Iteration 4850 (3.92963 iter/s, 12.7238s/50 iter), loss = 0.0255071, remaining 0 hours and 30 minutes
I0614 13:55:05.204697  3451 solver.cpp:291]     Train net output #0: loss = 0.025507 (* 1 = 0.025507 loss)
I0614 13:55:05.204704  3451 sgd_solver.cpp:106] Iteration 4850, lr = 0.0001
I0614 13:55:17.874313  3451 solver.cpp:270] Iteration 4900 (3.94658 iter/s, 12.6692s/50 iter), loss = 0.0147466, remaining 0 hours and 29 minutes
I0614 13:55:17.874560  3451 solver.cpp:291]     Train net output #0: loss = 0.0147465 (* 1 = 0.0147465 loss)
I0614 13:55:17.874567  3451 sgd_solver.cpp:106] Iteration 4900, lr = 0.0001
I0614 13:55:30.505851  3451 solver.cpp:270] Iteration 4950 (3.95855 iter/s, 12.6309s/50 iter), loss = 0.0228358, remaining 0 hours and 29 minutes
I0614 13:55:30.505882  3451 solver.cpp:291]     Train net output #0: loss = 0.0228357 (* 1 = 0.0228357 loss)
I0614 13:55:30.505889  3451 sgd_solver.cpp:106] Iteration 4950, lr = 0.0001
I0614 13:55:42.883347  3451 solver.cpp:424] Iteration 5000, Testing net (#0)
I0614 13:55:44.389799  3451 solver.cpp:523]     Test net output #0: accuracy = 0.9565
I0614 13:55:44.389828  3451 solver.cpp:523]     Test net output #1: loss = 0.131721 (* 1 = 0.131721 loss)
I0614 13:55:44.389833  3451 solver.cpp:523]     Test net output #2: top-1 = 0.9565
I0614 13:55:44.636333  3451 solver.cpp:270] Iteration 5000 (3.53857 iter/s, 14.13s/50 iter), loss = 0.034701, remaining 0 hours and 32 minutes
I0614 13:55:44.636363  3451 solver.cpp:291]     Train net output #0: loss = 0.034701 (* 1 = 0.034701 loss)
I0614 13:55:44.636370  3451 sgd_solver.cpp:106] Iteration 5000, lr = 1e-05
I0614 13:55:57.346720  3451 solver.cpp:270] Iteration 5050 (3.93393 iter/s, 12.7099s/50 iter), loss = 0.0187448, remaining 0 hours and 29 minutes
I0614 13:55:57.346967  3451 solver.cpp:291]     Train net output #0: loss = 0.0187448 (* 1 = 0.0187448 loss)
I0614 13:55:57.346976  3451 sgd_solver.cpp:106] Iteration 5050, lr = 1e-05
I0614 13:56:10.054880  3451 solver.cpp:270] Iteration 5100 (3.93468 iter/s, 12.7075s/50 iter), loss = 0.0190893, remaining 0 hours and 29 minutes
I0614 13:56:10.054913  3451 solver.cpp:291]     Train net output #0: loss = 0.0190892 (* 1 = 0.0190892 loss)
I0614 13:56:10.054937  3451 sgd_solver.cpp:106] Iteration 5100, lr = 1e-05
I0614 13:56:22.765491  3451 solver.cpp:270] Iteration 5150 (3.93386 iter/s, 12.7102s/50 iter), loss = 0.00921751, remaining 0 hours and 28 minutes
I0614 13:56:22.765523  3451 solver.cpp:291]     Train net output #0: loss = 0.00921748 (* 1 = 0.00921748 loss)
I0614 13:56:22.765530  3451 sgd_solver.cpp:106] Iteration 5150, lr = 1e-05
I0614 13:56:35.408358  3451 solver.cpp:270] Iteration 5200 (3.95494 iter/s, 12.6424s/50 iter), loss = 0.0019355, remaining 0 hours and 28 minutes
I0614 13:56:35.408632  3451 solver.cpp:291]     Train net output #0: loss = 0.00193547 (* 1 = 0.00193547 loss)
I0614 13:56:35.408655  3451 sgd_solver.cpp:106] Iteration 5200, lr = 1e-05
I0614 13:56:48.051432  3451 solver.cpp:270] Iteration 5250 (3.95495 iter/s, 12.6424s/50 iter), loss = 0.00459425, remaining 0 hours and 28 minutes
I0614 13:56:48.051461  3451 solver.cpp:291]     Train net output #0: loss = 0.00459422 (* 1 = 0.00459422 loss)
I0614 13:56:48.051470  3451 sgd_solver.cpp:106] Iteration 5250, lr = 1e-05
I0614 13:57:00.674561  3451 solver.cpp:270] Iteration 5300 (3.96112 iter/s, 12.6227s/50 iter), loss = 0.0063503, remaining 0 hours and 28 minutes
I0614 13:57:00.674592  3451 solver.cpp:291]     Train net output #0: loss = 0.00635026 (* 1 = 0.00635026 loss)
I0614 13:57:00.674616  3451 sgd_solver.cpp:106] Iteration 5300, lr = 1e-05
I0614 13:57:13.311228  3451 solver.cpp:270] Iteration 5350 (3.95688 iter/s, 12.6362s/50 iter), loss = 0.0173195, remaining 0 hours and 27 minutes
I0614 13:57:13.311461  3451 solver.cpp:291]     Train net output #0: loss = 0.0173194 (* 1 = 0.0173194 loss)
I0614 13:57:13.311468  3451 sgd_solver.cpp:106] Iteration 5350, lr = 1e-05
I0614 13:57:25.948964  3451 solver.cpp:270] Iteration 5400 (3.95661 iter/s, 12.6371s/50 iter), loss = 0.0179057, remaining 0 hours and 27 minutes
I0614 13:57:25.948994  3451 solver.cpp:291]     Train net output #0: loss = 0.0179057 (* 1 = 0.0179057 loss)
I0614 13:57:25.949002  3451 sgd_solver.cpp:106] Iteration 5400, lr = 1e-05
I0614 13:57:38.584235  3451 solver.cpp:270] Iteration 5450 (3.95731 iter/s, 12.6348s/50 iter), loss = 0.0116559, remaining 0 hours and 27 minutes
I0614 13:57:38.584265  3451 solver.cpp:291]     Train net output #0: loss = 0.0116558 (* 1 = 0.0116558 loss)
I0614 13:57:38.584273  3451 sgd_solver.cpp:106] Iteration 5450, lr = 1e-05
I0614 13:57:51.197640  3451 solver.cpp:270] Iteration 5500 (3.96417 iter/s, 12.613s/50 iter), loss = 0.0342562, remaining 0 hours and 27 minutes
I0614 13:57:51.197898  3451 solver.cpp:291]     Train net output #0: loss = 0.0342562 (* 1 = 0.0342562 loss)
I0614 13:57:51.197908  3451 sgd_solver.cpp:106] Iteration 5500, lr = 1e-05
I0614 13:58:03.815627  3451 solver.cpp:270] Iteration 5550 (3.96281 iter/s, 12.6173s/50 iter), loss = 0.0836631, remaining 0 hours and 27 minutes
I0614 13:58:03.815658  3451 solver.cpp:291]     Train net output #0: loss = 0.0836631 (* 1 = 0.0836631 loss)
I0614 13:58:03.815666  3451 sgd_solver.cpp:106] Iteration 5550, lr = 1e-05
I0614 13:58:16.431783  3451 solver.cpp:270] Iteration 5600 (3.96331 iter/s, 12.6157s/50 iter), loss = 0.0054168, remaining 0 hours and 26 minutes
I0614 13:58:16.431813  3451 solver.cpp:291]     Train net output #0: loss = 0.00541677 (* 1 = 0.00541677 loss)
I0614 13:58:16.431821  3451 sgd_solver.cpp:106] Iteration 5600, lr = 1e-05
I0614 13:58:29.048614  3451 solver.cpp:270] Iteration 5650 (3.9631 iter/s, 12.6164s/50 iter), loss = 0.0085889, remaining 0 hours and 26 minutes
I0614 13:58:29.048866  3451 solver.cpp:291]     Train net output #0: loss = 0.00858887 (* 1 = 0.00858887 loss)
I0614 13:58:29.048892  3451 sgd_solver.cpp:106] Iteration 5650, lr = 1e-05
I0614 13:58:41.653455  3451 solver.cpp:270] Iteration 5700 (3.96694 iter/s, 12.6042s/50 iter), loss = 0.00379422, remaining 0 hours and 26 minutes
I0614 13:58:41.653486  3451 solver.cpp:291]     Train net output #0: loss = 0.00379419 (* 1 = 0.00379419 loss)
I0614 13:58:41.653494  3451 sgd_solver.cpp:106] Iteration 5700, lr = 1e-05
I0614 13:58:54.276376  3451 solver.cpp:270] Iteration 5750 (3.96119 iter/s, 12.6225s/50 iter), loss = 0.026835, remaining 0 hours and 26 minutes
I0614 13:58:54.276407  3451 solver.cpp:291]     Train net output #0: loss = 0.026835 (* 1 = 0.026835 loss)
I0614 13:58:54.276413  3451 sgd_solver.cpp:106] Iteration 5750, lr = 1e-05
I0614 13:59:06.898442  3451 solver.cpp:270] Iteration 5800 (3.96145 iter/s, 12.6216s/50 iter), loss = 0.00887892, remaining 0 hours and 26 minutes
I0614 13:59:06.898767  3451 solver.cpp:291]     Train net output #0: loss = 0.0088789 (* 1 = 0.0088789 loss)
I0614 13:59:06.898777  3451 sgd_solver.cpp:106] Iteration 5800, lr = 1e-05
I0614 13:59:19.536322  3451 solver.cpp:270] Iteration 5850 (3.95659 iter/s, 12.6371s/50 iter), loss = 0.0131151, remaining 0 hours and 25 minutes
I0614 13:59:19.536353  3451 solver.cpp:291]     Train net output #0: loss = 0.0131151 (* 1 = 0.0131151 loss)
I0614 13:59:19.536361  3451 sgd_solver.cpp:106] Iteration 5850, lr = 1e-05
I0614 13:59:32.178155  3451 solver.cpp:270] Iteration 5900 (3.95526 iter/s, 12.6414s/50 iter), loss = 0.0467224, remaining 0 hours and 25 minutes
I0614 13:59:32.178185  3451 solver.cpp:291]     Train net output #0: loss = 0.0467224 (* 1 = 0.0467224 loss)
I0614 13:59:32.178193  3451 sgd_solver.cpp:106] Iteration 5900, lr = 1e-05
I0614 13:59:44.805373  3451 solver.cpp:270] Iteration 5950 (3.95984 iter/s, 12.6268s/50 iter), loss = 0.0136515, remaining 0 hours and 25 minutes
I0614 13:59:44.805629  3451 solver.cpp:291]     Train net output #0: loss = 0.0136514 (* 1 = 0.0136514 loss)
I0614 13:59:44.805652  3451 sgd_solver.cpp:106] Iteration 5950, lr = 1e-05
I0614 13:59:57.198706  3451 solver.cpp:935] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.1/snapshots/_iter_6000.caffemodel
I0614 14:00:03.131567  3451 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.1/snapshots/_iter_6000.solverstate
I0614 14:00:06.769570  3451 solver.cpp:424] Iteration 6000, Testing net (#0)
I0614 14:00:08.184860  3451 solver.cpp:523]     Test net output #0: accuracy = 0.95825
I0614 14:00:08.184891  3451 solver.cpp:523]     Test net output #1: loss = 0.145324 (* 1 = 0.145324 loss)
I0614 14:00:08.184895  3451 solver.cpp:523]     Test net output #2: top-1 = 0.95825
I0614 14:00:08.425295  3451 solver.cpp:270] Iteration 6000 (2.11695 iter/s, 23.6189s/50 iter), loss = 0.0225217, remaining 0 hours and 47 minutes
I0614 14:00:08.425326  3451 solver.cpp:291]     Train net output #0: loss = 0.0225217 (* 1 = 0.0225217 loss)
I0614 14:00:08.425334  3451 sgd_solver.cpp:106] Iteration 6000, lr = 1e-05
I0614 14:00:20.956223  3451 solver.cpp:270] Iteration 6050 (3.99027 iter/s, 12.5305s/50 iter), loss = 0.0264913, remaining 0 hours and 24 minutes
I0614 14:00:20.956480  3451 solver.cpp:291]     Train net output #0: loss = 0.0264913 (* 1 = 0.0264913 loss)
I0614 14:00:20.956487  3451 sgd_solver.cpp:106] Iteration 6050, lr = 1e-05
I0614 14:00:33.512755  3451 solver.cpp:270] Iteration 6100 (3.9822 iter/s, 12.5559s/50 iter), loss = 0.00842432, remaining 0 hours and 24 minutes
I0614 14:00:33.512784  3451 solver.cpp:291]     Train net output #0: loss = 0.0084243 (* 1 = 0.0084243 loss)
I0614 14:00:33.512790  3451 sgd_solver.cpp:106] Iteration 6100, lr = 1e-05
I0614 14:00:46.109666  3451 solver.cpp:270] Iteration 6150 (3.96936 iter/s, 12.5965s/50 iter), loss = 0.0222216, remaining 0 hours and 24 minutes
I0614 14:00:46.109699  3451 solver.cpp:291]     Train net output #0: loss = 0.0222216 (* 1 = 0.0222216 loss)
I0614 14:00:46.109705  3451 sgd_solver.cpp:106] Iteration 6150, lr = 1e-05
I0614 14:00:58.728057  3451 solver.cpp:270] Iteration 6200 (3.96261 iter/s, 12.6179s/50 iter), loss = 0.0129877, remaining 0 hours and 24 minutes
I0614 14:00:58.728268  3451 solver.cpp:291]     Train net output #0: loss = 0.0129877 (* 1 = 0.0129877 loss)
I0614 14:00:58.728293  3451 sgd_solver.cpp:106] Iteration 6200, lr = 1e-05
I0614 14:01:11.408588  3451 solver.cpp:270] Iteration 6250 (3.94325 iter/s, 12.6799s/50 iter), loss = 0.015066, remaining 0 hours and 24 minutes
I0614 14:01:11.408619  3451 solver.cpp:291]     Train net output #0: loss = 0.015066 (* 1 = 0.015066 loss)
I0614 14:01:11.408627  3451 sgd_solver.cpp:106] Iteration 6250, lr = 1e-05
I0614 14:01:24.166363  3451 solver.cpp:270] Iteration 6300 (3.91932 iter/s, 12.7573s/50 iter), loss = 0.0081187, remaining 0 hours and 24 minutes
I0614 14:01:24.166394  3451 solver.cpp:291]     Train net output #0: loss = 0.00811867 (* 1 = 0.00811867 loss)
I0614 14:01:24.166402  3451 sgd_solver.cpp:106] Iteration 6300, lr = 1e-05
I0614 14:01:36.870216  3451 solver.cpp:270] Iteration 6350 (3.93595 iter/s, 12.7034s/50 iter), loss = 0.00918251, remaining 0 hours and 23 minutes
I0614 14:01:36.870513  3451 solver.cpp:291]     Train net output #0: loss = 0.00918248 (* 1 = 0.00918248 loss)
I0614 14:01:36.870522  3451 sgd_solver.cpp:106] Iteration 6350, lr = 1e-05
I0614 14:01:49.503103  3451 solver.cpp:270] Iteration 6400 (3.95814 iter/s, 12.6322s/50 iter), loss = 0.00159369, remaining 0 hours and 23 minutes
I0614 14:01:49.503134  3451 solver.cpp:291]     Train net output #0: loss = 0.00159364 (* 1 = 0.00159364 loss)
I0614 14:01:49.503140  3451 sgd_solver.cpp:106] Iteration 6400, lr = 1e-05
I0614 14:02:02.140790  3451 solver.cpp:270] Iteration 6450 (3.95656 iter/s, 12.6372s/50 iter), loss = 0.00200276, remaining 0 hours and 23 minutes
I0614 14:02:02.140822  3451 solver.cpp:291]     Train net output #0: loss = 0.00200272 (* 1 = 0.00200272 loss)
I0614 14:02:02.140830  3451 sgd_solver.cpp:106] Iteration 6450, lr = 1e-05
I0614 14:02:14.763006  3451 solver.cpp:270] Iteration 6500 (3.96141 iter/s, 12.6218s/50 iter), loss = 0.0128926, remaining 0 hours and 22 minutes
I0614 14:02:14.763197  3451 solver.cpp:291]     Train net output #0: loss = 0.0128926 (* 1 = 0.0128926 loss)
I0614 14:02:14.763221  3451 sgd_solver.cpp:106] Iteration 6500, lr = 1e-05
I0614 14:02:27.410086  3451 solver.cpp:270] Iteration 6550 (3.95367 iter/s, 12.6465s/50 iter), loss = 0.0058945, remaining 0 hours and 22 minutes
I0614 14:02:27.410117  3451 solver.cpp:291]     Train net output #0: loss = 0.00589446 (* 1 = 0.00589446 loss)
I0614 14:02:27.410140  3451 sgd_solver.cpp:106] Iteration 6550, lr = 1e-05
I0614 14:02:40.041105  3451 solver.cpp:270] Iteration 6600 (3.95865 iter/s, 12.6306s/50 iter), loss = 0.0256542, remaining 0 hours and 22 minutes
I0614 14:02:40.041136  3451 solver.cpp:291]     Train net output #0: loss = 0.0256542 (* 1 = 0.0256542 loss)
I0614 14:02:40.041142  3451 sgd_solver.cpp:106] Iteration 6600, lr = 1e-05
I0614 14:02:52.676473  3451 solver.cpp:270] Iteration 6650 (3.95728 iter/s, 12.6349s/50 iter), loss = 0.00596318, remaining 0 hours and 22 minutes
I0614 14:02:52.676705  3451 solver.cpp:291]     Train net output #0: loss = 0.00596314 (* 1 = 0.00596314 loss)
I0614 14:02:52.676729  3451 sgd_solver.cpp:106] Iteration 6650, lr = 1e-05
I0614 14:03:05.319173  3451 solver.cpp:270] Iteration 6700 (3.95505 iter/s, 12.6421s/50 iter), loss = 0.0311592, remaining 0 hours and 22 minutes
I0614 14:03:05.319207  3451 solver.cpp:291]     Train net output #0: loss = 0.0311592 (* 1 = 0.0311592 loss)
I0614 14:03:05.319214  3451 sgd_solver.cpp:106] Iteration 6700, lr = 1e-05
I0614 14:03:17.952306  3451 solver.cpp:270] Iteration 6750 (3.95798 iter/s, 12.6327s/50 iter), loss = 0.0164372, remaining 0 hours and 21 minutes
I0614 14:03:17.952335  3451 solver.cpp:291]     Train net output #0: loss = 0.0164372 (* 1 = 0.0164372 loss)
I0614 14:03:17.952342  3451 sgd_solver.cpp:106] Iteration 6750, lr = 1e-05
I0614 14:03:30.576155  3451 solver.cpp:270] Iteration 6800 (3.96089 iter/s, 12.6234s/50 iter), loss = 0.0172561, remaining 0 hours and 21 minutes
I0614 14:03:30.576390  3451 solver.cpp:291]     Train net output #0: loss = 0.0172561 (* 1 = 0.0172561 loss)
I0614 14:03:30.576397  3451 sgd_solver.cpp:106] Iteration 6800, lr = 1e-05
I0614 14:03:43.211756  3451 solver.cpp:270] Iteration 6850 (3.95727 iter/s, 12.635s/50 iter), loss = 0.0016785, remaining 0 hours and 21 minutes
I0614 14:03:43.211788  3451 solver.cpp:291]     Train net output #0: loss = 0.00167847 (* 1 = 0.00167847 loss)
I0614 14:03:43.211796  3451 sgd_solver.cpp:106] Iteration 6850, lr = 1e-05
I0614 14:03:55.831197  3451 solver.cpp:270] Iteration 6900 (3.96228 iter/s, 12.619s/50 iter), loss = 0.00810037, remaining 0 hours and 21 minutes
I0614 14:03:55.831230  3451 solver.cpp:291]     Train net output #0: loss = 0.00810034 (* 1 = 0.00810034 loss)
I0614 14:03:55.831254  3451 sgd_solver.cpp:106] Iteration 6900, lr = 1e-05
I0614 14:04:08.472177  3451 solver.cpp:270] Iteration 6950 (3.95553 iter/s, 12.6405s/50 iter), loss = 0.0222822, remaining 0 hours and 21 minutes
I0614 14:04:08.472498  3451 solver.cpp:291]     Train net output #0: loss = 0.0222822 (* 1 = 0.0222822 loss)
I0614 14:04:08.472506  3451 sgd_solver.cpp:106] Iteration 6950, lr = 1e-05
I0614 14:04:20.850783  3451 solver.cpp:424] Iteration 7000, Testing net (#0)
I0614 14:04:22.351002  3451 solver.cpp:523]     Test net output #0: accuracy = 0.959
I0614 14:04:22.351032  3451 solver.cpp:523]     Test net output #1: loss = 0.158511 (* 1 = 0.158511 loss)
I0614 14:04:22.351035  3451 solver.cpp:523]     Test net output #2: top-1 = 0.959
I0614 14:04:22.597430  3451 solver.cpp:270] Iteration 7000 (3.53995 iter/s, 14.1245s/50 iter), loss = 0.0073987, remaining 0 hours and 23 minutes
I0614 14:04:22.597461  3451 solver.cpp:291]     Train net output #0: loss = 0.00739866 (* 1 = 0.00739866 loss)
I0614 14:04:22.597468  3451 sgd_solver.cpp:106] Iteration 7000, lr = 1e-05
I0614 14:04:35.230787  3451 solver.cpp:270] Iteration 7050 (3.95791 iter/s, 12.6329s/50 iter), loss = 0.0240728, remaining 0 hours and 20 minutes
I0614 14:04:35.230819  3451 solver.cpp:291]     Train net output #0: loss = 0.0240728 (* 1 = 0.0240728 loss)
I0614 14:04:35.230827  3451 sgd_solver.cpp:106] Iteration 7050, lr = 1e-05
I0614 14:04:47.844244  3451 solver.cpp:270] Iteration 7100 (3.96416 iter/s, 12.613s/50 iter), loss = 0.0045485, remaining 0 hours and 20 minutes
I0614 14:04:47.844472  3451 solver.cpp:291]     Train net output #0: loss = 0.00454846 (* 1 = 0.00454846 loss)
I0614 14:04:47.844480  3451 sgd_solver.cpp:106] Iteration 7100, lr = 1e-05
I0614 14:05:00.458389  3451 solver.cpp:270] Iteration 7150 (3.964 iter/s, 12.6135s/50 iter), loss = 0.0307753, remaining 0 hours and 20 minutes
I0614 14:05:00.458421  3451 solver.cpp:291]     Train net output #0: loss = 0.0307752 (* 1 = 0.0307752 loss)
I0614 14:05:00.458429  3451 sgd_solver.cpp:106] Iteration 7150, lr = 1e-05
I0614 14:05:13.103020  3451 solver.cpp:270] Iteration 7200 (3.95439 iter/s, 12.6442s/50 iter), loss = 0.0127685, remaining 0 hours and 20 minutes
I0614 14:05:13.103052  3451 solver.cpp:291]     Train net output #0: loss = 0.0127684 (* 1 = 0.0127684 loss)
I0614 14:05:13.103060  3451 sgd_solver.cpp:106] Iteration 7200, lr = 1e-05
I0614 14:05:25.724980  3451 solver.cpp:270] Iteration 7250 (3.96149 iter/s, 12.6215s/50 iter), loss = 0.00536644, remaining 0 hours and 19 minutes
I0614 14:05:25.725215  3451 solver.cpp:291]     Train net output #0: loss = 0.0053664 (* 1 = 0.0053664 loss)
I0614 14:05:25.725239  3451 sgd_solver.cpp:106] Iteration 7250, lr = 1e-05
I0614 14:05:38.373003  3451 solver.cpp:270] Iteration 7300 (3.95339 iter/s, 12.6474s/50 iter), loss = 0.00406046, remaining 0 hours and 19 minutes
I0614 14:05:38.373032  3451 solver.cpp:291]     Train net output #0: loss = 0.00406042 (* 1 = 0.00406042 loss)
I0614 14:05:38.373040  3451 sgd_solver.cpp:106] Iteration 7300, lr = 1e-05
I0614 14:05:51.034579  3451 solver.cpp:270] Iteration 7350 (3.94909 iter/s, 12.6611s/50 iter), loss = 0.00318235, remaining 0 hours and 19 minutes
I0614 14:05:51.034611  3451 solver.cpp:291]     Train net output #0: loss = 0.0031823 (* 1 = 0.0031823 loss)
I0614 14:05:51.034619  3451 sgd_solver.cpp:106] Iteration 7350, lr = 1e-05
I0614 14:06:03.673878  3451 solver.cpp:270] Iteration 7400 (3.95605 iter/s, 12.6389s/50 iter), loss = 0.00210485, remaining 0 hours and 19 minutes
I0614 14:06:03.674129  3451 solver.cpp:291]     Train net output #0: loss = 0.0021048 (* 1 = 0.0021048 loss)
I0614 14:06:03.674137  3451 sgd_solver.cpp:106] Iteration 7400, lr = 1e-05
I0614 14:06:16.303761  3451 solver.cpp:270] Iteration 7450 (3.95907 iter/s, 12.6292s/50 iter), loss = 0.00470893, remaining 0 hours and 18 minutes
I0614 14:06:16.303793  3451 solver.cpp:291]     Train net output #0: loss = 0.00470888 (* 1 = 0.00470888 loss)
I0614 14:06:16.303802  3451 sgd_solver.cpp:106] Iteration 7450, lr = 1e-05
I0614 14:06:28.925249  3451 solver.cpp:270] Iteration 7500 (3.96164 iter/s, 12.621s/50 iter), loss = 0.00589708, remaining 0 hours and 18 minutes
I0614 14:06:28.925282  3451 solver.cpp:291]     Train net output #0: loss = 0.00589703 (* 1 = 0.00589703 loss)
I0614 14:06:28.925289  3451 sgd_solver.cpp:106] Iteration 7500, lr = 1e-06
I0614 14:06:41.543426  3451 solver.cpp:270] Iteration 7550 (3.96268 iter/s, 12.6177s/50 iter), loss = 0.00911778, remaining 0 hours and 18 minutes
I0614 14:06:41.543756  3451 solver.cpp:291]     Train net output #0: loss = 0.00911775 (* 1 = 0.00911775 loss)
I0614 14:06:41.543766  3451 sgd_solver.cpp:106] Iteration 7550, lr = 1e-06
I0614 14:06:54.166973  3451 solver.cpp:270] Iteration 7600 (3.96108 iter/s, 12.6228s/50 iter), loss = 0.00247124, remaining 0 hours and 18 minutes
I0614 14:06:54.167006  3451 solver.cpp:291]     Train net output #0: loss = 0.0024712 (* 1 = 0.0024712 loss)
I0614 14:06:54.167028  3451 sgd_solver.cpp:106] Iteration 7600, lr = 1e-06
I0614 14:07:06.777612  3451 solver.cpp:270] Iteration 7650 (3.96504 iter/s, 12.6102s/50 iter), loss = 0.0105465, remaining 0 hours and 18 minutes
I0614 14:07:06.777647  3451 solver.cpp:291]     Train net output #0: loss = 0.0105465 (* 1 = 0.0105465 loss)
I0614 14:07:06.777654  3451 sgd_solver.cpp:106] Iteration 7650, lr = 1e-06
I0614 14:07:19.385847  3451 solver.cpp:270] Iteration 7700 (3.9658 iter/s, 12.6078s/50 iter), loss = 0.00345193, remaining 0 hours and 17 minutes
I0614 14:07:19.386090  3451 solver.cpp:291]     Train net output #0: loss = 0.00345188 (* 1 = 0.00345188 loss)
I0614 14:07:19.386116  3451 sgd_solver.cpp:106] Iteration 7700, lr = 1e-06
I0614 14:07:32.030926  3451 solver.cpp:270] Iteration 7750 (3.95431 iter/s, 12.6444s/50 iter), loss = 0.00322875, remaining 0 hours and 17 minutes
I0614 14:07:32.030959  3451 solver.cpp:291]     Train net output #0: loss = 0.0032287 (* 1 = 0.0032287 loss)
I0614 14:07:32.030967  3451 sgd_solver.cpp:106] Iteration 7750, lr = 1e-06
I0614 14:07:44.682742  3451 solver.cpp:270] Iteration 7800 (3.95214 iter/s, 12.6514s/50 iter), loss = 0.00950232, remaining 0 hours and 17 minutes
I0614 14:07:44.682773  3451 solver.cpp:291]     Train net output #0: loss = 0.00950227 (* 1 = 0.00950227 loss)
I0614 14:07:44.682781  3451 sgd_solver.cpp:106] Iteration 7800, lr = 1e-06
I0614 14:07:57.302433  3451 solver.cpp:270] Iteration 7850 (3.9622 iter/s, 12.6193s/50 iter), loss = 0.011932, remaining 0 hours and 17 minutes
I0614 14:07:57.302621  3451 solver.cpp:291]     Train net output #0: loss = 0.0119319 (* 1 = 0.0119319 loss)
I0614 14:07:57.302646  3451 sgd_solver.cpp:106] Iteration 7850, lr = 1e-06
I0614 14:08:09.928200  3451 solver.cpp:270] Iteration 7900 (3.96034 iter/s, 12.6252s/50 iter), loss = 0.000920794, remaining 0 hours and 17 minutes
I0614 14:08:09.928232  3451 solver.cpp:291]     Train net output #0: loss = 0.000920742 (* 1 = 0.000920742 loss)
I0614 14:08:09.928241  3451 sgd_solver.cpp:106] Iteration 7900, lr = 1e-06
I0614 14:08:22.543058  3451 solver.cpp:270] Iteration 7950 (3.96372 iter/s, 12.6144s/50 iter), loss = 0.00540057, remaining 0 hours and 16 minutes
I0614 14:08:22.543089  3451 solver.cpp:291]     Train net output #0: loss = 0.00540052 (* 1 = 0.00540052 loss)
I0614 14:08:22.543097  3451 sgd_solver.cpp:106] Iteration 7950, lr = 1e-06
I0614 14:08:34.911818  3451 solver.cpp:424] Iteration 8000, Testing net (#0)
I0614 14:08:36.411116  3451 solver.cpp:523]     Test net output #0: accuracy = 0.95675
I0614 14:08:36.411146  3451 solver.cpp:523]     Test net output #1: loss = 0.182275 (* 1 = 0.182275 loss)
I0614 14:08:36.411150  3451 solver.cpp:523]     Test net output #2: top-1 = 0.95675
I0614 14:08:36.657411  3451 solver.cpp:270] Iteration 8000 (3.54262 iter/s, 14.1139s/50 iter), loss = 0.00294758, remaining 0 hours and 18 minutes
I0614 14:08:36.657441  3451 solver.cpp:291]     Train net output #0: loss = 0.00294753 (* 1 = 0.00294753 loss)
I0614 14:08:36.657449  3451 sgd_solver.cpp:106] Iteration 8000, lr = 1e-06
I0614 14:08:49.270182  3451 solver.cpp:270] Iteration 8050 (3.96437 iter/s, 12.6123s/50 iter), loss = 0.0288604, remaining 0 hours and 16 minutes
I0614 14:08:49.270215  3451 solver.cpp:291]     Train net output #0: loss = 0.0288604 (* 1 = 0.0288604 loss)
I0614 14:08:49.270239  3451 sgd_solver.cpp:106] Iteration 8050, lr = 1e-06
I0614 14:09:01.919437  3451 solver.cpp:270] Iteration 8100 (3.95294 iter/s, 12.6488s/50 iter), loss = 0.0102424, remaining 0 hours and 16 minutes
I0614 14:09:01.919471  3451 solver.cpp:291]     Train net output #0: loss = 0.0102424 (* 1 = 0.0102424 loss)
I0614 14:09:01.919494  3451 sgd_solver.cpp:106] Iteration 8100, lr = 1e-06
I0614 14:09:14.525625  3451 solver.cpp:270] Iteration 8150 (3.96644 iter/s, 12.6057s/50 iter), loss = 0.0116691, remaining 0 hours and 16 minutes
I0614 14:09:14.525931  3451 solver.cpp:291]     Train net output #0: loss = 0.011669 (* 1 = 0.011669 loss)
I0614 14:09:14.525939  3451 sgd_solver.cpp:106] Iteration 8150, lr = 1e-06
I0614 14:09:27.131851  3451 solver.cpp:270] Iteration 8200 (3.96652 iter/s, 12.6055s/50 iter), loss = 0.00449947, remaining 0 hours and 15 minutes
I0614 14:09:27.131883  3451 solver.cpp:291]     Train net output #0: loss = 0.00449941 (* 1 = 0.00449941 loss)
I0614 14:09:27.131907  3451 sgd_solver.cpp:106] Iteration 8200, lr = 1e-06
I0614 14:09:39.783638  3451 solver.cpp:270] Iteration 8250 (3.95215 iter/s, 12.6513s/50 iter), loss = 0.0146218, remaining 0 hours and 15 minutes
I0614 14:09:39.783668  3451 solver.cpp:291]     Train net output #0: loss = 0.0146217 (* 1 = 0.0146217 loss)
I0614 14:09:39.783676  3451 sgd_solver.cpp:106] Iteration 8250, lr = 1e-06
I0614 14:09:52.414888  3451 solver.cpp:270] Iteration 8300 (3.95857 iter/s, 12.6308s/50 iter), loss = 0.00556516, remaining 0 hours and 15 minutes
I0614 14:09:52.415139  3451 solver.cpp:291]     Train net output #0: loss = 0.00556511 (* 1 = 0.00556511 loss)
I0614 14:09:52.415148  3451 sgd_solver.cpp:106] Iteration 8300, lr = 1e-06
I0614 14:10:05.033298  3451 solver.cpp:270] Iteration 8350 (3.96267 iter/s, 12.6178s/50 iter), loss = 0.00374275, remaining 0 hours and 15 minutes
I0614 14:10:05.033331  3451 solver.cpp:291]     Train net output #0: loss = 0.00374269 (* 1 = 0.00374269 loss)
I0614 14:10:05.033339  3451 sgd_solver.cpp:106] Iteration 8350, lr = 1e-06
I0614 14:10:17.653678  3451 solver.cpp:270] Iteration 8400 (3.96198 iter/s, 12.6199s/50 iter), loss = 0.00710572, remaining 0 hours and 15 minutes
I0614 14:10:17.653709  3451 solver.cpp:291]     Train net output #0: loss = 0.00710566 (* 1 = 0.00710566 loss)
I0614 14:10:17.653717  3451 sgd_solver.cpp:106] Iteration 8400, lr = 1e-06
I0614 14:10:30.263410  3451 solver.cpp:270] Iteration 8450 (3.96533 iter/s, 12.6093s/50 iter), loss = 0.00502503, remaining 0 hours and 14 minutes
I0614 14:10:30.263670  3451 solver.cpp:291]     Train net output #0: loss = 0.00502496 (* 1 = 0.00502496 loss)
I0614 14:10:30.263679  3451 sgd_solver.cpp:106] Iteration 8450, lr = 1e-06
I0614 14:10:42.883888  3451 solver.cpp:270] Iteration 8500 (3.96203 iter/s, 12.6198s/50 iter), loss = 0.00478025, remaining 0 hours and 14 minutes
I0614 14:10:42.883919  3451 solver.cpp:291]     Train net output #0: loss = 0.00478018 (* 1 = 0.00478018 loss)
I0614 14:10:42.883926  3451 sgd_solver.cpp:106] Iteration 8500, lr = 1e-06
I0614 14:10:55.520617  3451 solver.cpp:270] Iteration 8550 (3.95686 iter/s, 12.6363s/50 iter), loss = 0.0207438, remaining 0 hours and 14 minutes
I0614 14:10:55.520648  3451 solver.cpp:291]     Train net output #0: loss = 0.0207437 (* 1 = 0.0207437 loss)
I0614 14:10:55.520656  3451 sgd_solver.cpp:106] Iteration 8550, lr = 1e-06
I0614 14:11:08.150666  3451 solver.cpp:270] Iteration 8600 (3.95895 iter/s, 12.6296s/50 iter), loss = 0.00841086, remaining 0 hours and 14 minutes
I0614 14:11:08.150923  3451 solver.cpp:291]     Train net output #0: loss = 0.00841079 (* 1 = 0.00841079 loss)
I0614 14:11:08.150949  3451 sgd_solver.cpp:106] Iteration 8600, lr = 1e-06
I0614 14:11:20.780215  3451 solver.cpp:270] Iteration 8650 (3.95918 iter/s, 12.6289s/50 iter), loss = 0.00616604, remaining 0 hours and 13 minutes
I0614 14:11:20.780246  3451 solver.cpp:291]     Train net output #0: loss = 0.00616598 (* 1 = 0.00616598 loss)
I0614 14:11:20.780253  3451 sgd_solver.cpp:106] Iteration 8650, lr = 1e-06
I0614 14:11:33.400113  3451 solver.cpp:270] Iteration 8700 (3.96213 iter/s, 12.6195s/50 iter), loss = 0.00864417, remaining 0 hours and 13 minutes
I0614 14:11:33.400144  3451 solver.cpp:291]     Train net output #0: loss = 0.00864411 (* 1 = 0.00864411 loss)
I0614 14:11:33.400152  3451 sgd_solver.cpp:106] Iteration 8700, lr = 1e-06
I0614 14:11:46.057624  3451 solver.cpp:270] Iteration 8750 (3.95036 iter/s, 12.6571s/50 iter), loss = 0.0078187, remaining 0 hours and 13 minutes
I0614 14:11:46.057895  3451 solver.cpp:291]     Train net output #0: loss = 0.00781864 (* 1 = 0.00781864 loss)
I0614 14:11:46.057904  3451 sgd_solver.cpp:106] Iteration 8750, lr = 1e-06
I0614 14:11:58.692627  3451 solver.cpp:270] Iteration 8800 (3.95747 iter/s, 12.6343s/50 iter), loss = 0.0132673, remaining 0 hours and 13 minutes
I0614 14:11:58.692657  3451 solver.cpp:291]     Train net output #0: loss = 0.0132673 (* 1 = 0.0132673 loss)
I0614 14:11:58.692682  3451 sgd_solver.cpp:106] Iteration 8800, lr = 1e-06
I0614 14:12:11.306648  3451 solver.cpp:270] Iteration 8850 (3.96398 iter/s, 12.6136s/50 iter), loss = 0.00261029, remaining 0 hours and 13 minutes
I0614 14:12:11.306679  3451 solver.cpp:291]     Train net output #0: loss = 0.00261023 (* 1 = 0.00261023 loss)
I0614 14:12:11.306686  3451 sgd_solver.cpp:106] Iteration 8850, lr = 1e-06
I0614 14:12:23.928766  3451 solver.cpp:270] Iteration 8900 (3.96144 iter/s, 12.6217s/50 iter), loss = 0.00255603, remaining 0 hours and 12 minutes
I0614 14:12:23.929010  3451 solver.cpp:291]     Train net output #0: loss = 0.00255596 (* 1 = 0.00255596 loss)
I0614 14:12:23.929034  3451 sgd_solver.cpp:106] Iteration 8900, lr = 1e-06
I0614 14:12:36.566980  3451 solver.cpp:270] Iteration 8950 (3.95646 iter/s, 12.6376s/50 iter), loss = 0.00411561, remaining 0 hours and 12 minutes
I0614 14:12:36.567011  3451 solver.cpp:291]     Train net output #0: loss = 0.00411554 (* 1 = 0.00411554 loss)
I0614 14:12:36.567019  3451 sgd_solver.cpp:106] Iteration 8950, lr = 1e-06
I0614 14:12:48.938623  3451 solver.cpp:424] Iteration 9000, Testing net (#0)
I0614 14:12:50.443217  3451 solver.cpp:523]     Test net output #0: accuracy = 0.957
I0614 14:12:50.443248  3451 solver.cpp:523]     Test net output #1: loss = 0.19853 (* 1 = 0.19853 loss)
I0614 14:12:50.443253  3451 solver.cpp:523]     Test net output #2: top-1 = 0.957
I0614 14:12:50.690845  3451 solver.cpp:270] Iteration 9000 (3.54023 iter/s, 14.1234s/50 iter), loss = 0.0334892, remaining 0 hours and 14 minutes
I0614 14:12:50.690876  3451 solver.cpp:291]     Train net output #0: loss = 0.0334891 (* 1 = 0.0334891 loss)
I0614 14:12:50.690883  3451 sgd_solver.cpp:106] Iteration 9000, lr = 1e-06
I0614 14:13:03.331833  3451 solver.cpp:270] Iteration 9050 (3.95552 iter/s, 12.6405s/50 iter), loss = 0.00435972, remaining 0 hours and 12 minutes
I0614 14:13:03.332032  3451 solver.cpp:291]     Train net output #0: loss = 0.00435965 (* 1 = 0.00435965 loss)
I0614 14:13:03.332041  3451 sgd_solver.cpp:106] Iteration 9050, lr = 1e-06
I0614 14:13:15.945165  3451 solver.cpp:270] Iteration 9100 (3.96425 iter/s, 12.6127s/50 iter), loss = 0.0136455, remaining 0 hours and 12 minutes
I0614 14:13:15.945196  3451 solver.cpp:291]     Train net output #0: loss = 0.0136454 (* 1 = 0.0136454 loss)
I0614 14:13:15.945204  3451 sgd_solver.cpp:106] Iteration 9100, lr = 1e-06
I0614 14:13:28.578416  3451 solver.cpp:270] Iteration 9150 (3.95795 iter/s, 12.6328s/50 iter), loss = 0.00251054, remaining 0 hours and 11 minutes
I0614 14:13:28.578447  3451 solver.cpp:291]     Train net output #0: loss = 0.00251047 (* 1 = 0.00251047 loss)
I0614 14:13:28.578455  3451 sgd_solver.cpp:106] Iteration 9150, lr = 1e-06
I0614 14:13:41.210187  3451 solver.cpp:270] Iteration 9200 (3.95841 iter/s, 12.6313s/50 iter), loss = 0.0349872, remaining 0 hours and 11 minutes
I0614 14:13:41.210407  3451 solver.cpp:291]     Train net output #0: loss = 0.0349871 (* 1 = 0.0349871 loss)
I0614 14:13:41.210415  3451 sgd_solver.cpp:106] Iteration 9200, lr = 1e-06
I0614 14:13:53.854144  3451 solver.cpp:270] Iteration 9250 (3.95465 iter/s, 12.6433s/50 iter), loss = 0.0245347, remaining 0 hours and 11 minutes
I0614 14:13:53.854176  3451 solver.cpp:291]     Train net output #0: loss = 0.0245346 (* 1 = 0.0245346 loss)
I0614 14:13:53.854199  3451 sgd_solver.cpp:106] Iteration 9250, lr = 1e-06
I0614 14:14:06.494112  3451 solver.cpp:270] Iteration 9300 (3.95584 iter/s, 12.6395s/50 iter), loss = 0.0252917, remaining 0 hours and 11 minutes
I0614 14:14:06.494143  3451 solver.cpp:291]     Train net output #0: loss = 0.0252917 (* 1 = 0.0252917 loss)
I0614 14:14:06.494168  3451 sgd_solver.cpp:106] Iteration 9300, lr = 1e-06
I0614 14:14:19.120038  3451 solver.cpp:270] Iteration 9350 (3.96024 iter/s, 12.6255s/50 iter), loss = 0.00196034, remaining 0 hours and 11 minutes
I0614 14:14:19.120349  3451 solver.cpp:291]     Train net output #0: loss = 0.00196026 (* 1 = 0.00196026 loss)
I0614 14:14:19.120358  3451 sgd_solver.cpp:106] Iteration 9350, lr = 1e-06
I0614 14:14:31.737576  3451 solver.cpp:270] Iteration 9400 (3.96296 iter/s, 12.6168s/50 iter), loss = 0.0131319, remaining 0 hours and 10 minutes
I0614 14:14:31.737607  3451 solver.cpp:291]     Train net output #0: loss = 0.0131318 (* 1 = 0.0131318 loss)
I0614 14:14:31.737614  3451 sgd_solver.cpp:106] Iteration 9400, lr = 1e-06
I0614 14:14:44.361861  3451 solver.cpp:270] Iteration 9450 (3.96076 iter/s, 12.6238s/50 iter), loss = 0.00147513, remaining 0 hours and 10 minutes
I0614 14:14:44.361892  3451 solver.cpp:291]     Train net output #0: loss = 0.00147505 (* 1 = 0.00147505 loss)
I0614 14:14:44.361901  3451 sgd_solver.cpp:106] Iteration 9450, lr = 1e-06
I0614 14:14:56.979140  3451 solver.cpp:270] Iteration 9500 (3.96296 iter/s, 12.6168s/50 iter), loss = 0.01267, remaining 0 hours and 10 minutes
I0614 14:14:56.979341  3451 solver.cpp:291]     Train net output #0: loss = 0.01267 (* 1 = 0.01267 loss)
I0614 14:14:56.979351  3451 sgd_solver.cpp:106] Iteration 9500, lr = 1e-06
I0614 14:15:09.600705  3451 solver.cpp:270] Iteration 9550 (3.96167 iter/s, 12.621s/50 iter), loss = 0.00214874, remaining 0 hours and 10 minutes
I0614 14:15:09.600736  3451 solver.cpp:291]     Train net output #0: loss = 0.00214866 (* 1 = 0.00214866 loss)
I0614 14:15:09.600745  3451 sgd_solver.cpp:106] Iteration 9550, lr = 1e-06
I0614 14:15:22.239157  3451 solver.cpp:270] Iteration 9600 (3.95632 iter/s, 12.638s/50 iter), loss = 0.017795, remaining 0 hours and 10 minutes
I0614 14:15:22.239190  3451 solver.cpp:291]     Train net output #0: loss = 0.0177949 (* 1 = 0.0177949 loss)
I0614 14:15:22.239214  3451 sgd_solver.cpp:106] Iteration 9600, lr = 1e-06
I0614 14:15:34.874104  3451 solver.cpp:270] Iteration 9650 (3.95742 iter/s, 12.6345s/50 iter), loss = 0.0117973, remaining 0 hours and 9 minutes
I0614 14:15:34.874334  3451 solver.cpp:291]     Train net output #0: loss = 0.0117972 (* 1 = 0.0117972 loss)
I0614 14:15:34.874358  3451 sgd_solver.cpp:106] Iteration 9650, lr = 1e-06
I0614 14:15:47.490746  3451 solver.cpp:270] Iteration 9700 (3.96322 iter/s, 12.616s/50 iter), loss = 0.00215888, remaining 0 hours and 9 minutes
I0614 14:15:47.490777  3451 solver.cpp:291]     Train net output #0: loss = 0.0021588 (* 1 = 0.0021588 loss)
I0614 14:15:47.490784  3451 sgd_solver.cpp:106] Iteration 9700, lr = 1e-06
I0614 14:16:00.112705  3451 solver.cpp:270] Iteration 9750 (3.96149 iter/s, 12.6215s/50 iter), loss = 0.00797791, remaining 0 hours and 9 minutes
I0614 14:16:00.112737  3451 solver.cpp:291]     Train net output #0: loss = 0.00797783 (* 1 = 0.00797783 loss)
I0614 14:16:00.112746  3451 sgd_solver.cpp:106] Iteration 9750, lr = 1e-06
I0614 14:16:12.754537  3451 solver.cpp:270] Iteration 9800 (3.95526 iter/s, 12.6414s/50 iter), loss = 0.00486243, remaining 0 hours and 9 minutes
I0614 14:16:12.754737  3451 solver.cpp:291]     Train net output #0: loss = 0.00486234 (* 1 = 0.00486234 loss)
I0614 14:16:12.754746  3451 sgd_solver.cpp:106] Iteration 9800, lr = 1e-06
I0614 14:16:25.367398  3451 solver.cpp:270] Iteration 9850 (3.9644 iter/s, 12.6123s/50 iter), loss = 0.0228482, remaining 0 hours and 8 minutes
I0614 14:16:25.367429  3451 solver.cpp:291]     Train net output #0: loss = 0.0228481 (* 1 = 0.0228481 loss)
I0614 14:16:25.367436  3451 sgd_solver.cpp:106] Iteration 9850, lr = 1e-06
I0614 14:16:37.996214  3451 solver.cpp:270] Iteration 9900 (3.95934 iter/s, 12.6284s/50 iter), loss = 0.00170986, remaining 0 hours and 8 minutes
I0614 14:16:37.996245  3451 solver.cpp:291]     Train net output #0: loss = 0.00170977 (* 1 = 0.00170977 loss)
I0614 14:16:37.996264  3451 sgd_solver.cpp:106] Iteration 9900, lr = 1e-06
I0614 14:16:50.607928  3451 solver.cpp:270] Iteration 9950 (3.96471 iter/s, 12.6113s/50 iter), loss = 0.00787671, remaining 0 hours and 8 minutes
I0614 14:16:50.608198  3451 solver.cpp:291]     Train net output #0: loss = 0.00787662 (* 1 = 0.00787662 loss)
I0614 14:16:50.608207  3451 sgd_solver.cpp:106] Iteration 9950, lr = 1e-06
I0614 14:17:02.981653  3451 solver.cpp:424] Iteration 10000, Testing net (#0)
I0614 14:17:04.469192  3451 solver.cpp:523]     Test net output #0: accuracy = 0.95675
I0614 14:17:04.469220  3451 solver.cpp:523]     Test net output #1: loss = 0.207217 (* 1 = 0.207217 loss)
I0614 14:17:04.469225  3451 solver.cpp:523]     Test net output #2: top-1 = 0.95675
I0614 14:17:04.715579  3451 solver.cpp:270] Iteration 10000 (3.54436 iter/s, 14.1069s/50 iter), loss = 0.00343995, remaining 0 hours and 9 minutes
I0614 14:17:04.715611  3451 solver.cpp:291]     Train net output #0: loss = 0.00343987 (* 1 = 0.00343987 loss)
I0614 14:17:04.715620  3451 sgd_solver.cpp:106] Iteration 10000, lr = 1e-07
I0614 14:17:17.339216  3451 solver.cpp:270] Iteration 10050 (3.96096 iter/s, 12.6232s/50 iter), loss = 0.00361597, remaining 0 hours and 8 minutes
I0614 14:17:17.339249  3451 solver.cpp:291]     Train net output #0: loss = 0.00361589 (* 1 = 0.00361589 loss)
I0614 14:17:17.339272  3451 sgd_solver.cpp:106] Iteration 10050, lr = 1e-07
I0614 14:17:29.965054  3451 solver.cpp:270] Iteration 10100 (3.96027 iter/s, 12.6254s/50 iter), loss = 0.00605533, remaining 0 hours and 7 minutes
I0614 14:17:29.965315  3451 solver.cpp:291]     Train net output #0: loss = 0.00605526 (* 1 = 0.00605526 loss)
I0614 14:17:29.965323  3451 sgd_solver.cpp:106] Iteration 10100, lr = 1e-07
I0614 14:17:42.603152  3451 solver.cpp:270] Iteration 10150 (3.9565 iter/s, 12.6374s/50 iter), loss = 0.000939841, remaining 0 hours and 7 minutes
I0614 14:17:42.603183  3451 solver.cpp:291]     Train net output #0: loss = 0.000939772 (* 1 = 0.000939772 loss)
I0614 14:17:42.603190  3451 sgd_solver.cpp:106] Iteration 10150, lr = 1e-07
I0614 14:17:55.236603  3451 solver.cpp:270] Iteration 10200 (3.95788 iter/s, 12.633s/50 iter), loss = 0.0051042, remaining 0 hours and 7 minutes
I0614 14:17:55.236634  3451 solver.cpp:291]     Train net output #0: loss = 0.00510413 (* 1 = 0.00510413 loss)
I0614 14:17:55.236642  3451 sgd_solver.cpp:106] Iteration 10200, lr = 1e-07
I0614 14:18:07.861289  3451 solver.cpp:270] Iteration 10250 (3.96063 iter/s, 12.6242s/50 iter), loss = 0.00820221, remaining 0 hours and 7 minutes
I0614 14:18:07.861557  3451 solver.cpp:291]     Train net output #0: loss = 0.00820215 (* 1 = 0.00820215 loss)
I0614 14:18:07.861565  3451 sgd_solver.cpp:106] Iteration 10250, lr = 1e-07
I0614 14:18:20.478341  3451 solver.cpp:270] Iteration 10300 (3.9631 iter/s, 12.6164s/50 iter), loss = 0.00611599, remaining 0 hours and 7 minutes
I0614 14:18:20.478372  3451 solver.cpp:291]     Train net output #0: loss = 0.00611592 (* 1 = 0.00611592 loss)
I0614 14:18:20.478397  3451 sgd_solver.cpp:106] Iteration 10300, lr = 1e-07
I0614 14:18:33.093096  3451 solver.cpp:270] Iteration 10350 (3.96375 iter/s, 12.6143s/50 iter), loss = 0.00357859, remaining 0 hours and 6 minutes
I0614 14:18:33.093127  3451 solver.cpp:291]     Train net output #0: loss = 0.00357852 (* 1 = 0.00357852 loss)
I0614 14:18:33.093135  3451 sgd_solver.cpp:106] Iteration 10350, lr = 1e-07
I0614 14:18:45.716450  3451 solver.cpp:270] Iteration 10400 (3.96105 iter/s, 12.6229s/50 iter), loss = 0.00499769, remaining 0 hours and 6 minutes
I0614 14:18:45.716789  3451 solver.cpp:291]     Train net output #0: loss = 0.00499763 (* 1 = 0.00499763 loss)
I0614 14:18:45.716797  3451 sgd_solver.cpp:106] Iteration 10400, lr = 1e-07
I0614 14:18:58.349591  3451 solver.cpp:270] Iteration 10450 (3.95808 iter/s, 12.6324s/50 iter), loss = 0.0134896, remaining 0 hours and 6 minutes
I0614 14:18:58.349620  3451 solver.cpp:291]     Train net output #0: loss = 0.0134896 (* 1 = 0.0134896 loss)
I0614 14:18:58.349628  3451 sgd_solver.cpp:106] Iteration 10450, lr = 1e-07
I0614 14:19:10.985172  3451 solver.cpp:270] Iteration 10500 (3.95722 iter/s, 12.6351s/50 iter), loss = 0.00521725, remaining 0 hours and 6 minutes
I0614 14:19:10.985203  3451 solver.cpp:291]     Train net output #0: loss = 0.00521719 (* 1 = 0.00521719 loss)
I0614 14:19:10.985210  3451 sgd_solver.cpp:106] Iteration 10500, lr = 1e-07
I0614 14:19:23.598903  3451 solver.cpp:270] Iteration 10550 (3.96407 iter/s, 12.6133s/50 iter), loss = 0.0513511, remaining 0 hours and 6 minutes
I0614 14:19:23.599151  3451 solver.cpp:291]     Train net output #0: loss = 0.051351 (* 1 = 0.051351 loss)
I0614 14:19:23.599159  3451 sgd_solver.cpp:106] Iteration 10550, lr = 1e-07
I0614 14:19:36.205046  3451 solver.cpp:270] Iteration 10600 (3.96653 iter/s, 12.6055s/50 iter), loss = 0.00314737, remaining 0 hours and 5 minutes
I0614 14:19:36.205078  3451 solver.cpp:291]     Train net output #0: loss = 0.0031473 (* 1 = 0.0031473 loss)
I0614 14:19:36.205087  3451 sgd_solver.cpp:106] Iteration 10600, lr = 1e-07
I0614 14:19:48.818740  3451 solver.cpp:270] Iteration 10650 (3.96408 iter/s, 12.6133s/50 iter), loss = 0.0131126, remaining 0 hours and 5 minutes
I0614 14:19:48.818773  3451 solver.cpp:291]     Train net output #0: loss = 0.0131126 (* 1 = 0.0131126 loss)
I0614 14:19:48.818780  3451 sgd_solver.cpp:106] Iteration 10650, lr = 1e-07
I0614 14:20:01.435297  3451 solver.cpp:270] Iteration 10700 (3.96318 iter/s, 12.6161s/50 iter), loss = 0.00535545, remaining 0 hours and 5 minutes
I0614 14:20:01.435528  3451 solver.cpp:291]     Train net output #0: loss = 0.00535538 (* 1 = 0.00535538 loss)
I0614 14:20:01.435536  3451 sgd_solver.cpp:106] Iteration 10700, lr = 1e-07
I0614 14:20:14.074821  3451 solver.cpp:270] Iteration 10750 (3.95605 iter/s, 12.6389s/50 iter), loss = 0.0185622, remaining 0 hours and 5 minutes
I0614 14:20:14.074852  3451 solver.cpp:291]     Train net output #0: loss = 0.0185621 (* 1 = 0.0185621 loss)
I0614 14:20:14.074860  3451 sgd_solver.cpp:106] Iteration 10750, lr = 1e-07
I0614 14:20:26.700095  3451 solver.cpp:270] Iteration 10800 (3.96045 iter/s, 12.6248s/50 iter), loss = 0.0280596, remaining 0 hours and 5 minutes
I0614 14:20:26.700126  3451 solver.cpp:291]     Train net output #0: loss = 0.0280595 (* 1 = 0.0280595 loss)
I0614 14:20:26.700134  3451 sgd_solver.cpp:106] Iteration 10800, lr = 1e-07
I0614 14:20:39.335530  3451 solver.cpp:270] Iteration 10850 (3.95726 iter/s, 12.635s/50 iter), loss = 0.0257625, remaining 0 hours and 4 minutes
I0614 14:20:39.335774  3451 solver.cpp:291]     Train net output #0: loss = 0.0257625 (* 1 = 0.0257625 loss)
I0614 14:20:39.335798  3451 sgd_solver.cpp:106] Iteration 10850, lr = 1e-07
I0614 14:20:51.950598  3451 solver.cpp:270] Iteration 10900 (3.96372 iter/s, 12.6144s/50 iter), loss = 0.0263515, remaining 0 hours and 4 minutes
I0614 14:20:51.950629  3451 solver.cpp:291]     Train net output #0: loss = 0.0263514 (* 1 = 0.0263514 loss)
I0614 14:20:51.950637  3451 sgd_solver.cpp:106] Iteration 10900, lr = 1e-07
I0614 14:21:04.563541  3451 solver.cpp:270] Iteration 10950 (3.96432 iter/s, 12.6125s/50 iter), loss = 0.013376, remaining 0 hours and 4 minutes
I0614 14:21:04.563573  3451 solver.cpp:291]     Train net output #0: loss = 0.0133759 (* 1 = 0.0133759 loss)
I0614 14:21:04.563581  3451 sgd_solver.cpp:106] Iteration 10950, lr = 1e-07
I0614 14:21:16.942931  3451 solver.cpp:424] Iteration 11000, Testing net (#0)
I0614 14:21:18.425366  3451 solver.cpp:523]     Test net output #0: accuracy = 0.95675
I0614 14:21:18.425400  3451 solver.cpp:523]     Test net output #1: loss = 0.211955 (* 1 = 0.211955 loss)
I0614 14:21:18.425405  3451 solver.cpp:523]     Test net output #2: top-1 = 0.95675
I0614 14:21:18.672351  3451 solver.cpp:270] Iteration 11000 (3.54401 iter/s, 14.1083s/50 iter), loss = 0.0266813, remaining 0 hours and 4 minutes
I0614 14:21:18.672381  3451 solver.cpp:291]     Train net output #0: loss = 0.0266812 (* 1 = 0.0266812 loss)
I0614 14:21:18.672390  3451 sgd_solver.cpp:106] Iteration 11000, lr = 1e-07
I0614 14:21:31.301426  3451 solver.cpp:270] Iteration 11050 (3.95926 iter/s, 12.6286s/50 iter), loss = 0.00480175, remaining 0 hours and 3 minutes
I0614 14:21:31.301456  3451 solver.cpp:291]     Train net output #0: loss = 0.00480168 (* 1 = 0.00480168 loss)
I0614 14:21:31.301465  3451 sgd_solver.cpp:106] Iteration 11050, lr = 1e-07
I0614 14:21:43.922122  3451 solver.cpp:270] Iteration 11100 (3.96188 iter/s, 12.6203s/50 iter), loss = 0.00484907, remaining 0 hours and 3 minutes
I0614 14:21:43.922152  3451 solver.cpp:291]     Train net output #0: loss = 0.00484901 (* 1 = 0.00484901 loss)
I0614 14:21:43.922175  3451 sgd_solver.cpp:106] Iteration 11100, lr = 1e-07
I0614 14:21:56.536814  3451 solver.cpp:270] Iteration 11150 (3.96377 iter/s, 12.6143s/50 iter), loss = 0.00161217, remaining 0 hours and 3 minutes
I0614 14:21:56.537151  3451 solver.cpp:291]     Train net output #0: loss = 0.00161211 (* 1 = 0.00161211 loss)
I0614 14:21:56.537175  3451 sgd_solver.cpp:106] Iteration 11150, lr = 1e-07
I0614 14:22:09.153864  3451 solver.cpp:270] Iteration 11200 (3.96313 iter/s, 12.6163s/50 iter), loss = 0.0112142, remaining 0 hours and 3 minutes
I0614 14:22:09.153898  3451 solver.cpp:291]     Train net output #0: loss = 0.0112141 (* 1 = 0.0112141 loss)
I0614 14:22:09.153908  3451 sgd_solver.cpp:106] Iteration 11200, lr = 1e-07
I0614 14:22:21.766227  3451 solver.cpp:270] Iteration 11250 (3.9645 iter/s, 12.6119s/50 iter), loss = 0.00651523, remaining 0 hours and 3 minutes
I0614 14:22:21.766258  3451 solver.cpp:291]     Train net output #0: loss = 0.00651517 (* 1 = 0.00651517 loss)
I0614 14:22:21.766268  3451 sgd_solver.cpp:106] Iteration 11250, lr = 1e-07
I0614 14:22:34.413491  3451 solver.cpp:270] Iteration 11300 (3.95356 iter/s, 12.6468s/50 iter), loss = 0.018842, remaining 0 hours and 2 minutes
I0614 14:22:34.413609  3451 solver.cpp:291]     Train net output #0: loss = 0.018842 (* 1 = 0.018842 loss)
I0614 14:22:34.413619  3451 sgd_solver.cpp:106] Iteration 11300, lr = 1e-07
I0614 14:22:47.045518  3451 solver.cpp:270] Iteration 11350 (3.95836 iter/s, 12.6315s/50 iter), loss = 0.00532812, remaining 0 hours and 2 minutes
I0614 14:22:47.045550  3451 solver.cpp:291]     Train net output #0: loss = 0.00532805 (* 1 = 0.00532805 loss)
I0614 14:22:47.045559  3451 sgd_solver.cpp:106] Iteration 11350, lr = 1e-07
I0614 14:22:59.678387  3451 solver.cpp:270] Iteration 11400 (3.95807 iter/s, 12.6324s/50 iter), loss = 0.00108625, remaining 0 hours and 2 minutes
I0614 14:22:59.678417  3451 solver.cpp:291]     Train net output #0: loss = 0.00108618 (* 1 = 0.00108618 loss)
I0614 14:22:59.678426  3451 sgd_solver.cpp:106] Iteration 11400, lr = 1e-07
I0614 14:23:12.309394  3451 solver.cpp:270] Iteration 11450 (3.95865 iter/s, 12.6306s/50 iter), loss = 0.00254184, remaining 0 hours and 2 minutes
I0614 14:23:12.309531  3451 solver.cpp:291]     Train net output #0: loss = 0.00254178 (* 1 = 0.00254178 loss)
I0614 14:23:12.309541  3451 sgd_solver.cpp:106] Iteration 11450, lr = 1e-07
I0614 14:23:24.936106  3451 solver.cpp:270] Iteration 11500 (3.96003 iter/s, 12.6262s/50 iter), loss = 0.0135886, remaining 0 hours and 2 minutes
I0614 14:23:24.936137  3451 solver.cpp:291]     Train net output #0: loss = 0.0135885 (* 1 = 0.0135885 loss)
I0614 14:23:24.936146  3451 sgd_solver.cpp:106] Iteration 11500, lr = 1e-07
I0614 14:23:37.568257  3451 solver.cpp:270] Iteration 11550 (3.95829 iter/s, 12.6317s/50 iter), loss = 0.010149, remaining 0 hours and 1 minutes
I0614 14:23:37.568289  3451 solver.cpp:291]     Train net output #0: loss = 0.0101489 (* 1 = 0.0101489 loss)
I0614 14:23:37.568296  3451 sgd_solver.cpp:106] Iteration 11550, lr = 1e-07
I0614 14:23:50.186357  3451 solver.cpp:270] Iteration 11600 (3.9627 iter/s, 12.6177s/50 iter), loss = 0.000761447, remaining 0 hours and 1 minutes
I0614 14:23:50.186645  3451 solver.cpp:291]     Train net output #0: loss = 0.00076138 (* 1 = 0.00076138 loss)
I0614 14:23:50.186654  3451 sgd_solver.cpp:106] Iteration 11600, lr = 1e-07
I0614 14:24:02.806816  3451 solver.cpp:270] Iteration 11650 (3.96204 iter/s, 12.6198s/50 iter), loss = 0.0244046, remaining 0 hours and 1 minutes
I0614 14:24:02.806847  3451 solver.cpp:291]     Train net output #0: loss = 0.0244045 (* 1 = 0.0244045 loss)
I0614 14:24:02.806855  3451 sgd_solver.cpp:106] Iteration 11650, lr = 1e-07
I0614 14:24:15.448345  3451 solver.cpp:270] Iteration 11700 (3.95536 iter/s, 12.6411s/50 iter), loss = 0.0086473, remaining 0 hours and 1 minutes
I0614 14:24:15.448377  3451 solver.cpp:291]     Train net output #0: loss = 0.00864724 (* 1 = 0.00864724 loss)
I0614 14:24:15.448386  3451 sgd_solver.cpp:106] Iteration 11700, lr = 1e-07
I0614 14:24:28.073173  3451 solver.cpp:270] Iteration 11750 (3.96059 iter/s, 12.6244s/50 iter), loss = 0.00728708, remaining 0 hours and 1 minutes
I0614 14:24:28.073287  3451 solver.cpp:291]     Train net output #0: loss = 0.00728701 (* 1 = 0.00728701 loss)
I0614 14:24:28.073295  3451 sgd_solver.cpp:106] Iteration 11750, lr = 1e-07
I0614 14:24:40.697934  3451 solver.cpp:270] Iteration 11800 (3.96063 iter/s, 12.6242s/50 iter), loss = 0.0281022, remaining 0 hours and 0 minutes
I0614 14:24:40.697968  3451 solver.cpp:291]     Train net output #0: loss = 0.0281021 (* 1 = 0.0281021 loss)
I0614 14:24:40.697976  3451 sgd_solver.cpp:106] Iteration 11800, lr = 1e-07
I0614 14:24:53.338503  3451 solver.cpp:270] Iteration 11850 (3.95566 iter/s, 12.6401s/50 iter), loss = 0.00224744, remaining 0 hours and 0 minutes
I0614 14:24:53.338546  3451 solver.cpp:291]     Train net output #0: loss = 0.00224736 (* 1 = 0.00224736 loss)
I0614 14:24:53.338554  3451 sgd_solver.cpp:106] Iteration 11850, lr = 1e-07
I0614 14:25:05.988216  3451 solver.cpp:270] Iteration 11900 (3.9528 iter/s, 12.6493s/50 iter), loss = 0.0202936, remaining 0 hours and 0 minutes
I0614 14:25:05.988335  3451 solver.cpp:291]     Train net output #0: loss = 0.0202935 (* 1 = 0.0202935 loss)
I0614 14:25:05.988344  3451 sgd_solver.cpp:106] Iteration 11900, lr = 1e-07
I0614 14:25:18.606086  3451 solver.cpp:270] Iteration 11950 (3.9628 iter/s, 12.6173s/50 iter), loss = 0.00342966, remaining 0 hours and 0 minutes
I0614 14:25:18.606117  3451 solver.cpp:291]     Train net output #0: loss = 0.00342958 (* 1 = 0.00342958 loss)
I0614 14:25:18.606124  3451 sgd_solver.cpp:106] Iteration 11950, lr = 1e-07
I0614 14:25:31.007529  3451 solver.cpp:935] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.1/snapshots/_iter_12000.caffemodel
I0614 14:25:37.203111  3451 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.1/snapshots/_iter_12000.solverstate
I0614 14:25:40.938705  3451 solver.cpp:384] Iteration 12000, loss = 0.0122584
I0614 14:25:40.938731  3451 solver.cpp:424] Iteration 12000, Testing net (#0)
I0614 14:25:42.367942  3451 solver.cpp:523]     Test net output #0: accuracy = 0.9565
I0614 14:25:42.367971  3451 solver.cpp:523]     Test net output #1: loss = 0.214232 (* 1 = 0.214232 loss)
I0614 14:25:42.367977  3451 solver.cpp:523]     Test net output #2: top-1 = 0.9565
I0614 14:25:42.367982  3451 solver.cpp:392] Optimization Done (3.93935 iter/s).
I0614 14:25:42.367986  3451 caffe_interface.cpp:576] Optimization Done.
(c) Copyright 2016â2019 Xilinx, Inc. All rights reserved.

I0614 14:25:43.251410  3548 pruning_runner.cpp:234] Analysis info found.
I0614 14:25:44.970801  3548 pruning_runner.cpp:265] Start pruning, please wait...
I0614 14:25:54.421794  3548 pruning_runner.cpp:312] Compression complete 0%
I0614 14:26:03.997987  3548 pruning_runner.cpp:312] Compression complete 0%
I0614 14:26:13.631327  3548 pruning_runner.cpp:312] Compression complete 0%
I0614 14:26:22.956358  3548 pruning_runner.cpp:312] Compression complete 0%
I0614 14:26:32.204602  3548 pruning_runner.cpp:312] Compression complete 0%
I0614 14:26:41.848429  3548 pruning_runner.cpp:312] Compression complete 0%
I0614 14:26:51.008813  3548 pruning_runner.cpp:312] Compression complete 0%
I0614 14:27:00.295926  3548 pruning_runner.cpp:312] Compression complete 0%
I0614 14:27:09.697368  3548 pruning_runner.cpp:312] Compression complete 0%
I0614 14:27:19.054220  3548 pruning_runner.cpp:312] Compression complete 0%
I0614 14:27:30.688382  3548 pruning_runner.cpp:365] pruning done, output model: pruning/alexnetBNnoLRN/regular_rate_0.2/sparse.caffemodel
I0614 14:27:30.688524  3548 pruning_runner.cpp:379] summary of REGULAR compression with rate 0.2:
+-------------------------------------------------------------------+
| Item           | Baseline       | Compressed     | Delta          |
+-------------------------------------------------------------------+
| Accuracy       | 0.953499794    | 0.956499696    | 0.00299990177  |
+-------------------------------------------------------------------+
| Weights        | 3.74857903 M   | 1.15144897 M   | -69.2830582%   |
+-------------------------------------------------------------------+
| Operations     | 2.05460167 G   | 1.17685986 G   | -42.7207718%   |
+-------------------------------------------------------------------+
To fine-tune the pruned model, please run:
vai_p_caffe finetune -config /workspace/TUTORIALS/VAI2.0bash-Caffe-ML-CATSvsDOGS/files/pruning/alexnetBNnoLRN/config2.prototxt
(c) Copyright 2016â2019 Xilinx, Inc. All rights reserved.

W0614 14:27:31.237673  4603 utils.cpp:207] BVLC BatchNormLayer without ScaleLayer detected: 3, it will be converted to NVCaffe Format.
W0614 14:27:31.270560  4603 utils.cpp:207] BVLC BatchNormLayer without ScaleLayer detected: 7, it will be converted to NVCaffe Format.
W0614 14:27:31.270658  4603 utils.cpp:207] BVLC BatchNormLayer without ScaleLayer detected: 21, it will be converted to NVCaffe Format.
I0614 14:27:31.283097  4603 vai_p_caffe.cpp:287] pruning/alexnetBNnoLRN/regular_rate_0.2/net_finetune.prototxt
I0614 14:27:31.502979  4603 gpu_memory.cpp:53] GPUMemory::Manager initialized with Caching (CUB) GPU Allocator
I0614 14:27:31.502998  4603 gpu_memory.cpp:55] Total memory: 25635127296, Free: 24702615552, dev_info[0]: total=25635127296 free=24702615552
I0614 14:27:31.503129  4603 caffe_interface.cpp:539] Using GPUs 0
I0614 14:27:31.503223  4603 caffe_interface.cpp:544] GPU 0: Quadro P6000
I0614 14:27:32.182386  4603 solver.cpp:51] Initializing solver from parameters: 
test_iter: 80
test_interval: 1000
base_lr: 0.001
display: 50
max_iter: 12000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 2500
snapshot: 6000
snapshot_prefix: "pruning/alexnetBNnoLRN/regular_rate_0.2/snapshots/"
solver_mode: GPU
device_id: 0
random_seed: 1201
net: "pruning/alexnetBNnoLRN/regular_rate_0.2/net_finetune.prototxt"
type: "Adam"
I0614 14:27:32.183625  4603 solver.cpp:99] Creating training net from net file: pruning/alexnetBNnoLRN/regular_rate_0.2/net_finetune.prototxt
I0614 14:27:32.184413  4603 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0614 14:27:32.184429  4603 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0614 14:27:32.184434  4603 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy-top1
I0614 14:27:32.184442  4603 net.cpp:52] Initializing net from parameters: 
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_value: 106
    mean_value: 116
    mean_value: 124
  }
  data_param {
    source: "input/lmdb/train_lmdb"
    batch_size: 256
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 0
    kernel_size: 8
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "bn1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn2"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "bn2"
  top: "relu2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "relu6"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "drop6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn7"
  type: "BatchNorm"
  bottom: "fc7"
  top: "bn7"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "bn7"
  top: "relu7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "relu7"
  top: "drop7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "drop7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0614 14:27:32.185075  4603 layer_factory.hpp:77] Creating layer data
I0614 14:27:32.185272  4603 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0614 14:27:32.188279  4603 net.cpp:94] Creating Layer data
I0614 14:27:32.188319  4603 net.cpp:409] data -> data
I0614 14:27:32.188349  4603 net.cpp:409] data -> label
I0614 14:27:32.189738  4640 db_lmdb.cpp:35] Opened lmdb input/lmdb/train_lmdb
I0614 14:27:32.189776  4640 db_lmdb.cpp:38] Items count: 20000
I0614 14:27:32.189826  4640 data_reader.cpp:124] TRAIN: reading data using 1 channel(s)
I0614 14:27:32.190268  4603 data_layer.cpp:78] ReshapePrefetch 256, 3, 227, 227
I0614 14:27:32.190465  4603 data_layer.cpp:83] output data size: 256,3,227,227
I0614 14:27:32.738158  4603 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0614 14:27:32.738394  4603 net.cpp:144] Setting up data
I0614 14:27:32.738402  4603 net.cpp:151] Top shape: 256 3 227 227 (39574272)
I0614 14:27:32.738411  4603 net.cpp:151] Top shape: 256 (256)
I0614 14:27:32.738416  4603 net.cpp:159] Memory required for data: 158298112
I0614 14:27:32.738421  4603 layer_factory.hpp:77] Creating layer conv1
I0614 14:27:32.738433  4603 net.cpp:94] Creating Layer conv1
I0614 14:27:32.738437  4603 net.cpp:435] conv1 <- data
I0614 14:27:32.738445  4603 net.cpp:409] conv1 -> conv1
I0614 14:27:32.738824  4603 net.cpp:144] Setting up conv1
I0614 14:27:32.738833  4603 net.cpp:151] Top shape: 256 96 55 55 (74342400)
I0614 14:27:32.738839  4603 net.cpp:159] Memory required for data: 455667712
I0614 14:27:32.738849  4603 layer_factory.hpp:77] Creating layer bn1
I0614 14:27:32.738857  4603 net.cpp:94] Creating Layer bn1
I0614 14:27:32.738863  4603 net.cpp:435] bn1 <- conv1
I0614 14:27:32.738869  4603 net.cpp:409] bn1 -> bn1
I0614 14:27:32.739188  4603 net.cpp:144] Setting up bn1
I0614 14:27:32.739197  4603 net.cpp:151] Top shape: 256 96 55 55 (74342400)
I0614 14:27:32.739202  4603 net.cpp:159] Memory required for data: 753037312
I0614 14:27:32.739213  4603 layer_factory.hpp:77] Creating layer relu1
I0614 14:27:32.739219  4603 net.cpp:94] Creating Layer relu1
I0614 14:27:32.739223  4603 net.cpp:435] relu1 <- bn1
I0614 14:27:32.739228  4603 net.cpp:409] relu1 -> relu1
I0614 14:27:32.739240  4603 net.cpp:144] Setting up relu1
I0614 14:27:32.739244  4603 net.cpp:151] Top shape: 256 96 55 55 (74342400)
I0614 14:27:32.739249  4603 net.cpp:159] Memory required for data: 1050406912
I0614 14:27:32.739253  4603 layer_factory.hpp:77] Creating layer pool1
I0614 14:27:32.739259  4603 net.cpp:94] Creating Layer pool1
I0614 14:27:32.739262  4603 net.cpp:435] pool1 <- relu1
I0614 14:27:32.739267  4603 net.cpp:409] pool1 -> pool1
I0614 14:27:32.739289  4603 net.cpp:144] Setting up pool1
I0614 14:27:32.739292  4603 net.cpp:151] Top shape: 256 96 27 27 (17915904)
I0614 14:27:32.739297  4603 net.cpp:159] Memory required for data: 1122070528
I0614 14:27:32.739301  4603 layer_factory.hpp:77] Creating layer conv2
I0614 14:27:32.739308  4603 net.cpp:94] Creating Layer conv2
I0614 14:27:32.739312  4603 net.cpp:435] conv2 <- pool1
I0614 14:27:32.739318  4603 net.cpp:409] conv2 -> conv2
I0614 14:27:32.755796  4603 net.cpp:144] Setting up conv2
I0614 14:27:32.755815  4603 net.cpp:151] Top shape: 256 256 27 27 (47775744)
I0614 14:27:32.755825  4603 net.cpp:159] Memory required for data: 1313173504
I0614 14:27:32.755836  4603 layer_factory.hpp:77] Creating layer bn2
I0614 14:27:32.755847  4603 net.cpp:94] Creating Layer bn2
I0614 14:27:32.755852  4603 net.cpp:435] bn2 <- conv2
I0614 14:27:32.755877  4603 net.cpp:409] bn2 -> bn2
I0614 14:27:32.756217  4603 net.cpp:144] Setting up bn2
I0614 14:27:32.756227  4603 net.cpp:151] Top shape: 256 256 27 27 (47775744)
I0614 14:27:32.756235  4603 net.cpp:159] Memory required for data: 1504276480
I0614 14:27:32.756247  4603 layer_factory.hpp:77] Creating layer relu2
I0614 14:27:32.756255  4603 net.cpp:94] Creating Layer relu2
I0614 14:27:32.756260  4603 net.cpp:435] relu2 <- bn2
I0614 14:27:32.756268  4603 net.cpp:409] relu2 -> relu2
I0614 14:27:32.756283  4603 net.cpp:144] Setting up relu2
I0614 14:27:32.756289  4603 net.cpp:151] Top shape: 256 256 27 27 (47775744)
I0614 14:27:32.756296  4603 net.cpp:159] Memory required for data: 1695379456
I0614 14:27:32.756301  4603 layer_factory.hpp:77] Creating layer pool2
I0614 14:27:32.756309  4603 net.cpp:94] Creating Layer pool2
I0614 14:27:32.756314  4603 net.cpp:435] pool2 <- relu2
I0614 14:27:32.756320  4603 net.cpp:409] pool2 -> pool2
I0614 14:27:32.756340  4603 net.cpp:144] Setting up pool2
I0614 14:27:32.756345  4603 net.cpp:151] Top shape: 256 256 13 13 (11075584)
I0614 14:27:32.756352  4603 net.cpp:159] Memory required for data: 1739681792
I0614 14:27:32.756357  4603 layer_factory.hpp:77] Creating layer conv3
I0614 14:27:32.756801  4603 net.cpp:94] Creating Layer conv3
I0614 14:27:32.756814  4603 net.cpp:435] conv3 <- pool2
I0614 14:27:32.756821  4603 net.cpp:409] conv3 -> conv3
I0614 14:27:32.773582  4603 net.cpp:144] Setting up conv3
I0614 14:27:32.773607  4603 net.cpp:151] Top shape: 256 384 13 13 (16613376)
I0614 14:27:32.773617  4603 net.cpp:159] Memory required for data: 1806135296
I0614 14:27:32.773630  4603 layer_factory.hpp:77] Creating layer relu3
I0614 14:27:32.773639  4603 net.cpp:94] Creating Layer relu3
I0614 14:27:32.773646  4603 net.cpp:435] relu3 <- conv3
I0614 14:27:32.773655  4603 net.cpp:409] relu3 -> relu3
I0614 14:27:32.773679  4603 net.cpp:144] Setting up relu3
I0614 14:27:32.773684  4603 net.cpp:151] Top shape: 256 384 13 13 (16613376)
I0614 14:27:32.773691  4603 net.cpp:159] Memory required for data: 1872588800
I0614 14:27:32.773696  4603 layer_factory.hpp:77] Creating layer conv4
I0614 14:27:32.773707  4603 net.cpp:94] Creating Layer conv4
I0614 14:27:32.773712  4603 net.cpp:435] conv4 <- relu3
I0614 14:27:32.773720  4603 net.cpp:409] conv4 -> conv4
I0614 14:27:32.806489  4603 net.cpp:144] Setting up conv4
I0614 14:27:32.806519  4603 net.cpp:151] Top shape: 256 384 13 13 (16613376)
I0614 14:27:32.806531  4603 net.cpp:159] Memory required for data: 1939042304
I0614 14:27:32.806550  4603 layer_factory.hpp:77] Creating layer relu4
I0614 14:27:32.806561  4603 net.cpp:94] Creating Layer relu4
I0614 14:27:32.806567  4603 net.cpp:435] relu4 <- conv4
I0614 14:27:32.806576  4603 net.cpp:409] relu4 -> relu4
I0614 14:27:32.806607  4603 net.cpp:144] Setting up relu4
I0614 14:27:32.806612  4603 net.cpp:151] Top shape: 256 384 13 13 (16613376)
I0614 14:27:32.806618  4603 net.cpp:159] Memory required for data: 2005495808
I0614 14:27:32.806624  4603 layer_factory.hpp:77] Creating layer conv5
I0614 14:27:32.806634  4603 net.cpp:94] Creating Layer conv5
I0614 14:27:32.806640  4603 net.cpp:435] conv5 <- relu4
I0614 14:27:32.806649  4603 net.cpp:409] conv5 -> conv5
I0614 14:27:32.824592  4603 net.cpp:144] Setting up conv5
I0614 14:27:32.824616  4603 net.cpp:151] Top shape: 256 256 13 13 (11075584)
I0614 14:27:32.824625  4603 net.cpp:159] Memory required for data: 2049798144
I0614 14:27:32.824635  4603 layer_factory.hpp:77] Creating layer relu5
I0614 14:27:32.824645  4603 net.cpp:94] Creating Layer relu5
I0614 14:27:32.824649  4603 net.cpp:435] relu5 <- conv5
I0614 14:27:32.824656  4603 net.cpp:409] relu5 -> relu5
I0614 14:27:32.824679  4603 net.cpp:144] Setting up relu5
I0614 14:27:32.824683  4603 net.cpp:151] Top shape: 256 256 13 13 (11075584)
I0614 14:27:32.824688  4603 net.cpp:159] Memory required for data: 2094100480
I0614 14:27:32.824692  4603 layer_factory.hpp:77] Creating layer pool5
I0614 14:27:32.824698  4603 net.cpp:94] Creating Layer pool5
I0614 14:27:32.824702  4603 net.cpp:435] pool5 <- relu5
I0614 14:27:32.824707  4603 net.cpp:409] pool5 -> pool5
I0614 14:27:32.824740  4603 net.cpp:144] Setting up pool5
I0614 14:27:32.824746  4603 net.cpp:151] Top shape: 256 256 6 6 (2359296)
I0614 14:27:32.824751  4603 net.cpp:159] Memory required for data: 2103537664
I0614 14:27:32.824755  4603 layer_factory.hpp:77] Creating layer fc6
I0614 14:27:32.824764  4603 net.cpp:94] Creating Layer fc6
I0614 14:27:32.824767  4603 net.cpp:435] fc6 <- pool5
I0614 14:27:32.824774  4603 net.cpp:409] fc6 -> fc6
I0614 14:27:33.254655  4603 net.cpp:144] Setting up fc6
I0614 14:27:33.254678  4603 net.cpp:151] Top shape: 256 4096 (1048576)
I0614 14:27:33.254686  4603 net.cpp:159] Memory required for data: 2107731968
I0614 14:27:33.254695  4603 layer_factory.hpp:77] Creating layer relu6
I0614 14:27:33.254703  4603 net.cpp:94] Creating Layer relu6
I0614 14:27:33.254707  4603 net.cpp:435] relu6 <- fc6
I0614 14:27:33.254714  4603 net.cpp:409] relu6 -> relu6
I0614 14:27:33.254727  4603 net.cpp:144] Setting up relu6
I0614 14:27:33.254730  4603 net.cpp:151] Top shape: 256 4096 (1048576)
I0614 14:27:33.254734  4603 net.cpp:159] Memory required for data: 2111926272
I0614 14:27:33.254737  4603 layer_factory.hpp:77] Creating layer drop6
I0614 14:27:33.254742  4603 net.cpp:94] Creating Layer drop6
I0614 14:27:33.255198  4603 net.cpp:435] drop6 <- relu6
I0614 14:27:33.255206  4603 net.cpp:409] drop6 -> drop6
I0614 14:27:33.255228  4603 net.cpp:144] Setting up drop6
I0614 14:27:33.255230  4603 net.cpp:151] Top shape: 256 4096 (1048576)
I0614 14:27:33.255235  4603 net.cpp:159] Memory required for data: 2116120576
I0614 14:27:33.255239  4603 layer_factory.hpp:77] Creating layer fc7
I0614 14:27:33.255246  4603 net.cpp:94] Creating Layer fc7
I0614 14:27:33.255250  4603 net.cpp:435] fc7 <- drop6
I0614 14:27:33.255255  4603 net.cpp:409] fc7 -> fc7
I0614 14:27:33.415405  4603 net.cpp:144] Setting up fc7
I0614 14:27:33.415426  4603 net.cpp:151] Top shape: 256 4096 (1048576)
I0614 14:27:33.415434  4603 net.cpp:159] Memory required for data: 2120314880
I0614 14:27:33.415443  4603 layer_factory.hpp:77] Creating layer bn7
I0614 14:27:33.415452  4603 net.cpp:94] Creating Layer bn7
I0614 14:27:33.415457  4603 net.cpp:435] bn7 <- fc7
I0614 14:27:33.415462  4603 net.cpp:409] bn7 -> bn7
I0614 14:27:33.415751  4603 net.cpp:144] Setting up bn7
I0614 14:27:33.415760  4603 net.cpp:151] Top shape: 256 4096 (1048576)
I0614 14:27:33.415767  4603 net.cpp:159] Memory required for data: 2124509184
I0614 14:27:33.415777  4603 layer_factory.hpp:77] Creating layer relu7
I0614 14:27:33.415784  4603 net.cpp:94] Creating Layer relu7
I0614 14:27:33.415788  4603 net.cpp:435] relu7 <- bn7
I0614 14:27:33.415793  4603 net.cpp:409] relu7 -> relu7
I0614 14:27:33.415808  4603 net.cpp:144] Setting up relu7
I0614 14:27:33.415812  4603 net.cpp:151] Top shape: 256 4096 (1048576)
I0614 14:27:33.415817  4603 net.cpp:159] Memory required for data: 2128703488
I0614 14:27:33.415820  4603 layer_factory.hpp:77] Creating layer drop7
I0614 14:27:33.415827  4603 net.cpp:94] Creating Layer drop7
I0614 14:27:33.415832  4603 net.cpp:435] drop7 <- relu7
I0614 14:27:33.415836  4603 net.cpp:409] drop7 -> drop7
I0614 14:27:33.415853  4603 net.cpp:144] Setting up drop7
I0614 14:27:33.415858  4603 net.cpp:151] Top shape: 256 4096 (1048576)
I0614 14:27:33.415861  4603 net.cpp:159] Memory required for data: 2132897792
I0614 14:27:33.415865  4603 layer_factory.hpp:77] Creating layer fc8
I0614 14:27:33.415871  4603 net.cpp:94] Creating Layer fc8
I0614 14:27:33.415875  4603 net.cpp:435] fc8 <- drop7
I0614 14:27:33.415881  4603 net.cpp:409] fc8 -> fc8
I0614 14:27:33.416033  4603 net.cpp:144] Setting up fc8
I0614 14:27:33.416038  4603 net.cpp:151] Top shape: 256 2 (512)
I0614 14:27:33.416041  4603 net.cpp:159] Memory required for data: 2132899840
I0614 14:27:33.416046  4603 layer_factory.hpp:77] Creating layer loss
I0614 14:27:33.416054  4603 net.cpp:94] Creating Layer loss
I0614 14:27:33.416057  4603 net.cpp:435] loss <- fc8
I0614 14:27:33.416061  4603 net.cpp:435] loss <- label
I0614 14:27:33.416066  4603 net.cpp:409] loss -> loss
I0614 14:27:33.416074  4603 layer_factory.hpp:77] Creating layer loss
I0614 14:27:33.416118  4603 net.cpp:144] Setting up loss
I0614 14:27:33.416122  4603 net.cpp:151] Top shape: (1)
I0614 14:27:33.416127  4603 net.cpp:154]     with loss weight 1
I0614 14:27:33.416139  4603 net.cpp:159] Memory required for data: 2132899844
I0614 14:27:33.416143  4603 net.cpp:220] loss needs backward computation.
I0614 14:27:33.416148  4603 net.cpp:220] fc8 needs backward computation.
I0614 14:27:33.416152  4603 net.cpp:220] drop7 needs backward computation.
I0614 14:27:33.416155  4603 net.cpp:220] relu7 needs backward computation.
I0614 14:27:33.416159  4603 net.cpp:220] bn7 needs backward computation.
I0614 14:27:33.416163  4603 net.cpp:220] fc7 needs backward computation.
I0614 14:27:33.416167  4603 net.cpp:220] drop6 needs backward computation.
I0614 14:27:33.416172  4603 net.cpp:220] relu6 needs backward computation.
I0614 14:27:33.416175  4603 net.cpp:220] fc6 needs backward computation.
I0614 14:27:33.416179  4603 net.cpp:220] pool5 needs backward computation.
I0614 14:27:33.416184  4603 net.cpp:220] relu5 needs backward computation.
I0614 14:27:33.416189  4603 net.cpp:220] conv5 needs backward computation.
I0614 14:27:33.416195  4603 net.cpp:220] relu4 needs backward computation.
I0614 14:27:33.416595  4603 net.cpp:220] conv4 needs backward computation.
I0614 14:27:33.416600  4603 net.cpp:220] relu3 needs backward computation.
I0614 14:27:33.416605  4603 net.cpp:220] conv3 needs backward computation.
I0614 14:27:33.416608  4603 net.cpp:220] pool2 needs backward computation.
I0614 14:27:33.416612  4603 net.cpp:220] relu2 needs backward computation.
I0614 14:27:33.416617  4603 net.cpp:220] bn2 needs backward computation.
I0614 14:27:33.416621  4603 net.cpp:220] conv2 needs backward computation.
I0614 14:27:33.416625  4603 net.cpp:220] pool1 needs backward computation.
I0614 14:27:33.416628  4603 net.cpp:220] relu1 needs backward computation.
I0614 14:27:33.416632  4603 net.cpp:220] bn1 needs backward computation.
I0614 14:27:33.416636  4603 net.cpp:220] conv1 needs backward computation.
I0614 14:27:33.416641  4603 net.cpp:222] data does not need backward computation.
I0614 14:27:33.416646  4603 net.cpp:264] This network produces output loss
I0614 14:27:33.416667  4603 net.cpp:284] Network initialization done.
I0614 14:27:33.418062  4603 solver.cpp:189] Creating test net (#0) specified by net file: pruning/alexnetBNnoLRN/regular_rate_0.2/net_finetune.prototxt
I0614 14:27:33.418099  4603 net.cpp:323] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0614 14:27:33.418114  4603 net.cpp:52] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_value: 106
    mean_value: 116
    mean_value: 124
  }
  data_param {
    source: "input/lmdb/valid_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 0
    kernel_size: 8
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "bn1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn2"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "bn2"
  top: "relu2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "relu6"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "drop6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn7"
  type: "BatchNorm"
  bottom: "fc7"
  top: "bn7"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "bn7"
  top: "relu7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "relu7"
  top: "drop7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "drop7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy-top1"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "top-1"
  include {
    phase: TEST
  }
}
I0614 14:27:33.418746  4603 layer_factory.hpp:77] Creating layer data
I0614 14:27:33.418798  4603 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0614 14:27:33.421173  4603 net.cpp:94] Creating Layer data
I0614 14:27:33.421221  4603 net.cpp:409] data -> data
I0614 14:27:33.421248  4603 net.cpp:409] data -> label
I0614 14:27:33.423651  4670 db_lmdb.cpp:35] Opened lmdb input/lmdb/valid_lmdb
I0614 14:27:33.423682  4670 db_lmdb.cpp:38] Items count: 4000
I0614 14:27:33.423727  4670 data_reader.cpp:124] TEST: reading data using 1 channel(s)
I0614 14:27:33.424360  4603 data_layer.cpp:78] ReshapePrefetch 50, 3, 227, 227
I0614 14:27:33.424569  4603 data_layer.cpp:83] output data size: 50,3,227,227
I0614 14:27:33.552701  4603 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0614 14:27:33.552920  4603 net.cpp:144] Setting up data
I0614 14:27:33.552927  4603 net.cpp:151] Top shape: 50 3 227 227 (7729350)
I0614 14:27:33.552935  4603 net.cpp:151] Top shape: 50 (50)
I0614 14:27:33.552939  4603 net.cpp:159] Memory required for data: 30917600
I0614 14:27:33.552944  4603 layer_factory.hpp:77] Creating layer label_data_1_split
I0614 14:27:33.552953  4603 net.cpp:94] Creating Layer label_data_1_split
I0614 14:27:33.552956  4603 net.cpp:435] label_data_1_split <- label
I0614 14:27:33.552963  4603 net.cpp:409] label_data_1_split -> label_data_1_split_0
I0614 14:27:33.552971  4603 net.cpp:409] label_data_1_split -> label_data_1_split_1
I0614 14:27:33.552975  4603 net.cpp:409] label_data_1_split -> label_data_1_split_2
I0614 14:27:33.553014  4603 net.cpp:144] Setting up label_data_1_split
I0614 14:27:33.553033  4603 net.cpp:151] Top shape: 50 (50)
I0614 14:27:33.553037  4603 net.cpp:151] Top shape: 50 (50)
I0614 14:27:33.553041  4603 net.cpp:151] Top shape: 50 (50)
I0614 14:27:33.553045  4603 net.cpp:159] Memory required for data: 30918200
I0614 14:27:33.553050  4603 layer_factory.hpp:77] Creating layer conv1
I0614 14:27:33.553059  4603 net.cpp:94] Creating Layer conv1
I0614 14:27:33.553063  4603 net.cpp:435] conv1 <- data
I0614 14:27:33.553068  4603 net.cpp:409] conv1 -> conv1
I0614 14:27:33.553493  4603 net.cpp:144] Setting up conv1
I0614 14:27:33.553501  4603 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0614 14:27:33.553506  4603 net.cpp:159] Memory required for data: 88998200
I0614 14:27:33.553519  4603 layer_factory.hpp:77] Creating layer bn1
I0614 14:27:33.553525  4603 net.cpp:94] Creating Layer bn1
I0614 14:27:33.553529  4603 net.cpp:435] bn1 <- conv1
I0614 14:27:33.553534  4603 net.cpp:409] bn1 -> bn1
I0614 14:27:33.553880  4603 net.cpp:144] Setting up bn1
I0614 14:27:33.553886  4603 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0614 14:27:33.553892  4603 net.cpp:159] Memory required for data: 147078200
I0614 14:27:33.553902  4603 layer_factory.hpp:77] Creating layer relu1
I0614 14:27:33.553908  4603 net.cpp:94] Creating Layer relu1
I0614 14:27:33.553912  4603 net.cpp:435] relu1 <- bn1
I0614 14:27:33.553917  4603 net.cpp:409] relu1 -> relu1
I0614 14:27:33.553930  4603 net.cpp:144] Setting up relu1
I0614 14:27:33.553934  4603 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0614 14:27:33.553939  4603 net.cpp:159] Memory required for data: 205158200
I0614 14:27:33.553943  4603 layer_factory.hpp:77] Creating layer pool1
I0614 14:27:33.553948  4603 net.cpp:94] Creating Layer pool1
I0614 14:27:33.553952  4603 net.cpp:435] pool1 <- relu1
I0614 14:27:33.553959  4603 net.cpp:409] pool1 -> pool1
I0614 14:27:33.553982  4603 net.cpp:144] Setting up pool1
I0614 14:27:33.553987  4603 net.cpp:151] Top shape: 50 96 27 27 (3499200)
I0614 14:27:33.553995  4603 net.cpp:159] Memory required for data: 219155000
I0614 14:27:33.553999  4603 layer_factory.hpp:77] Creating layer conv2
I0614 14:27:33.554006  4603 net.cpp:94] Creating Layer conv2
I0614 14:27:33.554009  4603 net.cpp:435] conv2 <- pool1
I0614 14:27:33.554015  4603 net.cpp:409] conv2 -> conv2
I0614 14:27:33.560782  4603 net.cpp:144] Setting up conv2
I0614 14:27:33.560801  4603 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0614 14:27:33.560812  4603 net.cpp:159] Memory required for data: 256479800
I0614 14:27:33.560824  4603 layer_factory.hpp:77] Creating layer bn2
I0614 14:27:33.560834  4603 net.cpp:94] Creating Layer bn2
I0614 14:27:33.560840  4603 net.cpp:435] bn2 <- conv2
I0614 14:27:33.560848  4603 net.cpp:409] bn2 -> bn2
I0614 14:27:33.561455  4603 net.cpp:144] Setting up bn2
I0614 14:27:33.561465  4603 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0614 14:27:33.561472  4603 net.cpp:159] Memory required for data: 293804600
I0614 14:27:33.561483  4603 layer_factory.hpp:77] Creating layer relu2
I0614 14:27:33.561491  4603 net.cpp:94] Creating Layer relu2
I0614 14:27:33.561494  4603 net.cpp:435] relu2 <- bn2
I0614 14:27:33.561501  4603 net.cpp:409] relu2 -> relu2
I0614 14:27:33.561514  4603 net.cpp:144] Setting up relu2
I0614 14:27:33.561899  4603 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0614 14:27:33.561909  4603 net.cpp:159] Memory required for data: 331129400
I0614 14:27:33.561914  4603 layer_factory.hpp:77] Creating layer pool2
I0614 14:27:33.561921  4603 net.cpp:94] Creating Layer pool2
I0614 14:27:33.561928  4603 net.cpp:435] pool2 <- relu2
I0614 14:27:33.561934  4603 net.cpp:409] pool2 -> pool2
I0614 14:27:33.562019  4603 net.cpp:144] Setting up pool2
I0614 14:27:33.562024  4603 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0614 14:27:33.562031  4603 net.cpp:159] Memory required for data: 339782200
I0614 14:27:33.562036  4603 layer_factory.hpp:77] Creating layer conv3
I0614 14:27:33.562047  4603 net.cpp:94] Creating Layer conv3
I0614 14:27:33.562052  4603 net.cpp:435] conv3 <- pool2
I0614 14:27:33.562059  4603 net.cpp:409] conv3 -> conv3
I0614 14:27:33.575687  4603 net.cpp:144] Setting up conv3
I0614 14:27:33.575706  4603 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0614 14:27:33.575713  4603 net.cpp:159] Memory required for data: 352761400
I0614 14:27:33.575722  4603 layer_factory.hpp:77] Creating layer relu3
I0614 14:27:33.575731  4603 net.cpp:94] Creating Layer relu3
I0614 14:27:33.575734  4603 net.cpp:435] relu3 <- conv3
I0614 14:27:33.575742  4603 net.cpp:409] relu3 -> relu3
I0614 14:27:33.575760  4603 net.cpp:144] Setting up relu3
I0614 14:27:33.575764  4603 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0614 14:27:33.575769  4603 net.cpp:159] Memory required for data: 365740600
I0614 14:27:33.575773  4603 layer_factory.hpp:77] Creating layer conv4
I0614 14:27:33.575780  4603 net.cpp:94] Creating Layer conv4
I0614 14:27:33.575784  4603 net.cpp:435] conv4 <- relu3
I0614 14:27:33.575789  4603 net.cpp:409] conv4 -> conv4
I0614 14:27:33.593298  4603 net.cpp:144] Setting up conv4
I0614 14:27:33.593319  4603 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0614 14:27:33.593331  4603 net.cpp:159] Memory required for data: 378719800
I0614 14:27:33.593346  4603 layer_factory.hpp:77] Creating layer relu4
I0614 14:27:33.593354  4603 net.cpp:94] Creating Layer relu4
I0614 14:27:33.593358  4603 net.cpp:435] relu4 <- conv4
I0614 14:27:33.593365  4603 net.cpp:409] relu4 -> relu4
I0614 14:27:33.593400  4603 net.cpp:144] Setting up relu4
I0614 14:27:33.593405  4603 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0614 14:27:33.593410  4603 net.cpp:159] Memory required for data: 391699000
I0614 14:27:33.593415  4603 layer_factory.hpp:77] Creating layer conv5
I0614 14:27:33.593423  4603 net.cpp:94] Creating Layer conv5
I0614 14:27:33.593427  4603 net.cpp:435] conv5 <- relu4
I0614 14:27:33.593432  4603 net.cpp:409] conv5 -> conv5
I0614 14:27:33.608357  4603 net.cpp:144] Setting up conv5
I0614 14:27:33.608379  4603 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0614 14:27:33.608392  4603 net.cpp:159] Memory required for data: 400351800
I0614 14:27:33.608405  4603 layer_factory.hpp:77] Creating layer relu5
I0614 14:27:33.608417  4603 net.cpp:94] Creating Layer relu5
I0614 14:27:33.608424  4603 net.cpp:435] relu5 <- conv5
I0614 14:27:33.608433  4603 net.cpp:409] relu5 -> relu5
I0614 14:27:33.608458  4603 net.cpp:144] Setting up relu5
I0614 14:27:33.608464  4603 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0614 14:27:33.608470  4603 net.cpp:159] Memory required for data: 409004600
I0614 14:27:33.608475  4603 layer_factory.hpp:77] Creating layer pool5
I0614 14:27:33.608486  4603 net.cpp:94] Creating Layer pool5
I0614 14:27:33.608491  4603 net.cpp:435] pool5 <- relu5
I0614 14:27:33.608498  4603 net.cpp:409] pool5 -> pool5
I0614 14:27:33.608525  4603 net.cpp:144] Setting up pool5
I0614 14:27:33.608529  4603 net.cpp:151] Top shape: 50 256 6 6 (460800)
I0614 14:27:33.608536  4603 net.cpp:159] Memory required for data: 410847800
I0614 14:27:33.608541  4603 layer_factory.hpp:77] Creating layer fc6
I0614 14:27:33.608551  4603 net.cpp:94] Creating Layer fc6
I0614 14:27:33.608556  4603 net.cpp:435] fc6 <- pool5
I0614 14:27:33.608563  4603 net.cpp:409] fc6 -> fc6
I0614 14:27:33.980108  4603 net.cpp:144] Setting up fc6
I0614 14:27:33.980130  4603 net.cpp:151] Top shape: 50 4096 (204800)
I0614 14:27:33.980527  4603 net.cpp:159] Memory required for data: 411667000
I0614 14:27:33.980538  4603 layer_factory.hpp:77] Creating layer relu6
I0614 14:27:33.980549  4603 net.cpp:94] Creating Layer relu6
I0614 14:27:33.980556  4603 net.cpp:435] relu6 <- fc6
I0614 14:27:33.980563  4603 net.cpp:409] relu6 -> relu6
I0614 14:27:33.980590  4603 net.cpp:144] Setting up relu6
I0614 14:27:33.980595  4603 net.cpp:151] Top shape: 50 4096 (204800)
I0614 14:27:33.980602  4603 net.cpp:159] Memory required for data: 412486200
I0614 14:27:33.980605  4603 layer_factory.hpp:77] Creating layer drop6
I0614 14:27:33.980613  4603 net.cpp:94] Creating Layer drop6
I0614 14:27:33.980618  4603 net.cpp:435] drop6 <- relu6
I0614 14:27:33.980621  4603 net.cpp:409] drop6 -> drop6
I0614 14:27:33.980640  4603 net.cpp:144] Setting up drop6
I0614 14:27:33.980644  4603 net.cpp:151] Top shape: 50 4096 (204800)
I0614 14:27:33.980648  4603 net.cpp:159] Memory required for data: 413305400
I0614 14:27:33.980652  4603 layer_factory.hpp:77] Creating layer fc7
I0614 14:27:33.980659  4603 net.cpp:94] Creating Layer fc7
I0614 14:27:33.980662  4603 net.cpp:435] fc7 <- drop6
I0614 14:27:33.980667  4603 net.cpp:409] fc7 -> fc7
I0614 14:27:34.148330  4603 net.cpp:144] Setting up fc7
I0614 14:27:34.148350  4603 net.cpp:151] Top shape: 50 4096 (204800)
I0614 14:27:34.148358  4603 net.cpp:159] Memory required for data: 414124600
I0614 14:27:34.148383  4603 layer_factory.hpp:77] Creating layer bn7
I0614 14:27:34.148393  4603 net.cpp:94] Creating Layer bn7
I0614 14:27:34.148397  4603 net.cpp:435] bn7 <- fc7
I0614 14:27:34.148406  4603 net.cpp:409] bn7 -> bn7
I0614 14:27:34.148774  4603 net.cpp:144] Setting up bn7
I0614 14:27:34.148787  4603 net.cpp:151] Top shape: 50 4096 (204800)
I0614 14:27:34.148792  4603 net.cpp:159] Memory required for data: 414943800
I0614 14:27:34.148802  4603 layer_factory.hpp:77] Creating layer relu7
I0614 14:27:34.148808  4603 net.cpp:94] Creating Layer relu7
I0614 14:27:34.148811  4603 net.cpp:435] relu7 <- bn7
I0614 14:27:34.148818  4603 net.cpp:409] relu7 -> relu7
I0614 14:27:34.148834  4603 net.cpp:144] Setting up relu7
I0614 14:27:34.148838  4603 net.cpp:151] Top shape: 50 4096 (204800)
I0614 14:27:34.148842  4603 net.cpp:159] Memory required for data: 415763000
I0614 14:27:34.148846  4603 layer_factory.hpp:77] Creating layer drop7
I0614 14:27:34.148852  4603 net.cpp:94] Creating Layer drop7
I0614 14:27:34.148856  4603 net.cpp:435] drop7 <- relu7
I0614 14:27:34.148860  4603 net.cpp:409] drop7 -> drop7
I0614 14:27:34.148878  4603 net.cpp:144] Setting up drop7
I0614 14:27:34.148882  4603 net.cpp:151] Top shape: 50 4096 (204800)
I0614 14:27:34.148887  4603 net.cpp:159] Memory required for data: 416582200
I0614 14:27:34.148890  4603 layer_factory.hpp:77] Creating layer fc8
I0614 14:27:34.148900  4603 net.cpp:94] Creating Layer fc8
I0614 14:27:34.148903  4603 net.cpp:435] fc8 <- drop7
I0614 14:27:34.148908  4603 net.cpp:409] fc8 -> fc8
I0614 14:27:34.149063  4603 net.cpp:144] Setting up fc8
I0614 14:27:34.149070  4603 net.cpp:151] Top shape: 50 2 (100)
I0614 14:27:34.149076  4603 net.cpp:159] Memory required for data: 416582600
I0614 14:27:34.149084  4603 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0614 14:27:34.149092  4603 net.cpp:94] Creating Layer fc8_fc8_0_split
I0614 14:27:34.149098  4603 net.cpp:435] fc8_fc8_0_split <- fc8
I0614 14:27:34.149106  4603 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0614 14:27:34.149116  4603 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0614 14:27:34.149125  4603 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_2
I0614 14:27:34.149163  4603 net.cpp:144] Setting up fc8_fc8_0_split
I0614 14:27:34.149168  4603 net.cpp:151] Top shape: 50 2 (100)
I0614 14:27:34.149173  4603 net.cpp:151] Top shape: 50 2 (100)
I0614 14:27:34.149178  4603 net.cpp:151] Top shape: 50 2 (100)
I0614 14:27:34.149181  4603 net.cpp:159] Memory required for data: 416583800
I0614 14:27:34.149185  4603 layer_factory.hpp:77] Creating layer accuracy
I0614 14:27:34.149199  4603 net.cpp:94] Creating Layer accuracy
I0614 14:27:34.149529  4603 net.cpp:435] accuracy <- fc8_fc8_0_split_0
I0614 14:27:34.149535  4603 net.cpp:435] accuracy <- label_data_1_split_0
I0614 14:27:34.149544  4603 net.cpp:409] accuracy -> accuracy
I0614 14:27:34.149552  4603 net.cpp:144] Setting up accuracy
I0614 14:27:34.149555  4603 net.cpp:151] Top shape: (1)
I0614 14:27:34.149559  4603 net.cpp:159] Memory required for data: 416583804
I0614 14:27:34.149564  4603 layer_factory.hpp:77] Creating layer loss
I0614 14:27:34.149569  4603 net.cpp:94] Creating Layer loss
I0614 14:27:34.149574  4603 net.cpp:435] loss <- fc8_fc8_0_split_1
I0614 14:27:34.149577  4603 net.cpp:435] loss <- label_data_1_split_1
I0614 14:27:34.149585  4603 net.cpp:409] loss -> loss
I0614 14:27:34.149593  4603 layer_factory.hpp:77] Creating layer loss
I0614 14:27:34.149654  4603 net.cpp:144] Setting up loss
I0614 14:27:34.149662  4603 net.cpp:151] Top shape: (1)
I0614 14:27:34.149667  4603 net.cpp:154]     with loss weight 1
I0614 14:27:34.149684  4603 net.cpp:159] Memory required for data: 416583808
I0614 14:27:34.149689  4603 layer_factory.hpp:77] Creating layer accuracy-top1
I0614 14:27:34.149698  4603 net.cpp:94] Creating Layer accuracy-top1
I0614 14:27:34.149703  4603 net.cpp:435] accuracy-top1 <- fc8_fc8_0_split_2
I0614 14:27:34.149708  4603 net.cpp:435] accuracy-top1 <- label_data_1_split_2
I0614 14:27:34.149713  4603 net.cpp:409] accuracy-top1 -> top-1
I0614 14:27:34.149718  4603 net.cpp:144] Setting up accuracy-top1
I0614 14:27:34.149722  4603 net.cpp:151] Top shape: (1)
I0614 14:27:34.149726  4603 net.cpp:159] Memory required for data: 416583812
I0614 14:27:34.149730  4603 net.cpp:222] accuracy-top1 does not need backward computation.
I0614 14:27:34.149735  4603 net.cpp:220] loss needs backward computation.
I0614 14:27:34.149739  4603 net.cpp:222] accuracy does not need backward computation.
I0614 14:27:34.149744  4603 net.cpp:220] fc8_fc8_0_split needs backward computation.
I0614 14:27:34.149749  4603 net.cpp:220] fc8 needs backward computation.
I0614 14:27:34.149751  4603 net.cpp:220] drop7 needs backward computation.
I0614 14:27:34.149756  4603 net.cpp:220] relu7 needs backward computation.
I0614 14:27:34.149760  4603 net.cpp:220] bn7 needs backward computation.
I0614 14:27:34.149765  4603 net.cpp:220] fc7 needs backward computation.
I0614 14:27:34.149768  4603 net.cpp:220] drop6 needs backward computation.
I0614 14:27:34.149773  4603 net.cpp:220] relu6 needs backward computation.
I0614 14:27:34.149777  4603 net.cpp:220] fc6 needs backward computation.
I0614 14:27:34.149781  4603 net.cpp:220] pool5 needs backward computation.
I0614 14:27:34.149785  4603 net.cpp:220] relu5 needs backward computation.
I0614 14:27:34.149789  4603 net.cpp:220] conv5 needs backward computation.
I0614 14:27:34.149793  4603 net.cpp:220] relu4 needs backward computation.
I0614 14:27:34.149798  4603 net.cpp:220] conv4 needs backward computation.
I0614 14:27:34.149802  4603 net.cpp:220] relu3 needs backward computation.
I0614 14:27:34.149806  4603 net.cpp:220] conv3 needs backward computation.
I0614 14:27:34.149811  4603 net.cpp:220] pool2 needs backward computation.
I0614 14:27:34.149816  4603 net.cpp:220] relu2 needs backward computation.
I0614 14:27:34.149821  4603 net.cpp:220] bn2 needs backward computation.
I0614 14:27:34.149824  4603 net.cpp:220] conv2 needs backward computation.
I0614 14:27:34.149828  4603 net.cpp:220] pool1 needs backward computation.
I0614 14:27:34.149832  4603 net.cpp:220] relu1 needs backward computation.
I0614 14:27:34.149837  4603 net.cpp:220] bn1 needs backward computation.
I0614 14:27:34.149840  4603 net.cpp:220] conv1 needs backward computation.
I0614 14:27:34.149845  4603 net.cpp:222] label_data_1_split does not need backward computation.
I0614 14:27:34.149850  4603 net.cpp:222] data does not need backward computation.
I0614 14:27:34.149854  4603 net.cpp:264] This network produces output accuracy
I0614 14:27:34.149857  4603 net.cpp:264] This network produces output loss
I0614 14:27:34.149861  4603 net.cpp:264] This network produces output top-1
I0614 14:27:34.150130  4603 net.cpp:284] Network initialization done.
I0614 14:27:34.150197  4603 solver.cpp:63] Solver scaffolding done.
I0614 14:27:34.150884  4603 caffe_interface.cpp:139] Finetuning from pruning/alexnetBNnoLRN/regular_rate_0.2/sparse.caffemodel
I0614 14:27:36.651151  4603 caffe_interface.cpp:573] Starting Optimization
I0614 14:27:36.651173  4603 solver.cpp:341] Solving 
I0614 14:27:36.651177  4603 solver.cpp:342] Learning Rate Policy: step
I0614 14:27:36.652426  4603 solver.cpp:424] Iteration 0, Testing net (#0)
I0614 14:27:38.125322  4603 solver.cpp:523]     Test net output #0: accuracy = 0.9565
I0614 14:27:38.125355  4603 solver.cpp:523]     Test net output #1: loss = 0.214232 (* 1 = 0.214232 loss)
I0614 14:27:38.125360  4603 solver.cpp:523]     Test net output #2: top-1 = 0.9565
I0614 14:27:38.384357  4603 solver.cpp:270] Iteration 0 (0 iter/s, 1.73306s/50 iter), loss = 0.00579027, remaining 333333 hours and 20 minutes
I0614 14:27:38.384387  4603 solver.cpp:291]     Train net output #0: loss = 0.00579027 (* 1 = 0.00579027 loss)
I0614 14:27:38.384395  4603 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0614 14:27:50.823652  4603 solver.cpp:270] Iteration 50 (4.01968 iter/s, 12.4388s/50 iter), loss = 0.149024, remaining 0 hours and 49 minutes
I0614 14:27:50.823683  4603 solver.cpp:291]     Train net output #0: loss = 0.149024 (* 1 = 0.149024 loss)
I0614 14:27:50.823691  4603 sgd_solver.cpp:106] Iteration 50, lr = 0.001
I0614 14:28:03.366739  4603 solver.cpp:270] Iteration 100 (3.98642 iter/s, 12.5426s/50 iter), loss = 0.109259, remaining 0 hours and 49 minutes
I0614 14:28:03.366854  4603 solver.cpp:291]     Train net output #0: loss = 0.109259 (* 1 = 0.109259 loss)
I0614 14:28:03.366863  4603 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I0614 14:28:15.937037  4603 solver.cpp:270] Iteration 150 (3.9778 iter/s, 12.5698s/50 iter), loss = 0.0904364, remaining 0 hours and 49 minutes
I0614 14:28:15.937069  4603 solver.cpp:291]     Train net output #0: loss = 0.0904364 (* 1 = 0.0904364 loss)
I0614 14:28:15.937093  4603 sgd_solver.cpp:106] Iteration 150, lr = 0.001
I0614 14:28:28.596031  4603 solver.cpp:270] Iteration 200 (3.94989 iter/s, 12.6586s/50 iter), loss = 0.0678198, remaining 0 hours and 49 minutes
I0614 14:28:28.596064  4603 solver.cpp:291]     Train net output #0: loss = 0.0678199 (* 1 = 0.0678199 loss)
I0614 14:28:28.596072  4603 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I0614 14:28:41.313737  4603 solver.cpp:270] Iteration 250 (3.93166 iter/s, 12.7173s/50 iter), loss = 0.0892075, remaining 0 hours and 49 minutes
I0614 14:28:41.313853  4603 solver.cpp:291]     Train net output #0: loss = 0.0892076 (* 1 = 0.0892076 loss)
I0614 14:28:41.313860  4603 sgd_solver.cpp:106] Iteration 250, lr = 0.001
I0614 14:28:54.087198  4603 solver.cpp:270] Iteration 300 (3.91453 iter/s, 12.7729s/50 iter), loss = 0.0936046, remaining 0 hours and 49 minutes
I0614 14:28:54.087230  4603 solver.cpp:291]     Train net output #0: loss = 0.0936046 (* 1 = 0.0936046 loss)
I0614 14:28:54.087239  4603 sgd_solver.cpp:106] Iteration 300, lr = 0.001
I0614 14:29:06.816825  4603 solver.cpp:270] Iteration 350 (3.92798 iter/s, 12.7292s/50 iter), loss = 0.0883189, remaining 0 hours and 49 minutes
I0614 14:29:06.816859  4603 solver.cpp:291]     Train net output #0: loss = 0.0883189 (* 1 = 0.0883189 loss)
I0614 14:29:06.816882  4603 sgd_solver.cpp:106] Iteration 350, lr = 0.001
I0614 14:29:19.543838  4603 solver.cpp:270] Iteration 400 (3.92879 iter/s, 12.7266s/50 iter), loss = 0.0837819, remaining 0 hours and 49 minutes
I0614 14:29:19.543953  4603 solver.cpp:291]     Train net output #0: loss = 0.0837819 (* 1 = 0.0837819 loss)
I0614 14:29:19.543978  4603 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I0614 14:29:32.247754  4603 solver.cpp:270] Iteration 450 (3.93596 iter/s, 12.7034s/50 iter), loss = 0.0982162, remaining 0 hours and 48 minutes
I0614 14:29:32.247788  4603 solver.cpp:291]     Train net output #0: loss = 0.0982162 (* 1 = 0.0982162 loss)
I0614 14:29:32.247797  4603 sgd_solver.cpp:106] Iteration 450, lr = 0.001
I0614 14:29:44.928709  4603 solver.cpp:270] Iteration 500 (3.94306 iter/s, 12.6805s/50 iter), loss = 0.105656, remaining 0 hours and 48 minutes
I0614 14:29:44.928743  4603 solver.cpp:291]     Train net output #0: loss = 0.105656 (* 1 = 0.105656 loss)
I0614 14:29:44.928750  4603 sgd_solver.cpp:106] Iteration 500, lr = 0.001
I0614 14:29:57.650863  4603 solver.cpp:270] Iteration 550 (3.93029 iter/s, 12.7217s/50 iter), loss = 0.165628, remaining 0 hours and 48 minutes
I0614 14:29:57.651034  4603 solver.cpp:291]     Train net output #0: loss = 0.165628 (* 1 = 0.165628 loss)
I0614 14:29:57.651043  4603 sgd_solver.cpp:106] Iteration 550, lr = 0.001
I0614 14:30:10.354818  4603 solver.cpp:270] Iteration 600 (3.93596 iter/s, 12.7034s/50 iter), loss = 0.0947798, remaining 0 hours and 48 minutes
I0614 14:30:10.354852  4603 solver.cpp:291]     Train net output #0: loss = 0.0947798 (* 1 = 0.0947798 loss)
I0614 14:30:10.354862  4603 sgd_solver.cpp:106] Iteration 600, lr = 0.001
I0614 14:30:23.051746  4603 solver.cpp:270] Iteration 650 (3.9381 iter/s, 12.6965s/50 iter), loss = 0.0907134, remaining 0 hours and 47 minutes
I0614 14:30:23.051779  4603 solver.cpp:291]     Train net output #0: loss = 0.0907134 (* 1 = 0.0907134 loss)
I0614 14:30:23.051787  4603 sgd_solver.cpp:106] Iteration 650, lr = 0.001
I0614 14:30:35.759189  4603 solver.cpp:270] Iteration 700 (3.93484 iter/s, 12.707s/50 iter), loss = 0.0996638, remaining 0 hours and 47 minutes
I0614 14:30:35.759407  4603 solver.cpp:291]     Train net output #0: loss = 0.0996638 (* 1 = 0.0996638 loss)
I0614 14:30:35.759414  4603 sgd_solver.cpp:106] Iteration 700, lr = 0.001
I0614 14:30:48.478018  4603 solver.cpp:270] Iteration 750 (3.93137 iter/s, 12.7182s/50 iter), loss = 0.101343, remaining 0 hours and 47 minutes
I0614 14:30:48.478051  4603 solver.cpp:291]     Train net output #0: loss = 0.101343 (* 1 = 0.101343 loss)
I0614 14:30:48.478060  4603 sgd_solver.cpp:106] Iteration 750, lr = 0.001
I0614 14:31:01.183521  4603 solver.cpp:270] Iteration 800 (3.93544 iter/s, 12.7051s/50 iter), loss = 0.0865595, remaining 0 hours and 47 minutes
I0614 14:31:01.183555  4603 solver.cpp:291]     Train net output #0: loss = 0.0865595 (* 1 = 0.0865595 loss)
I0614 14:31:01.183563  4603 sgd_solver.cpp:106] Iteration 800, lr = 0.001
I0614 14:31:13.878855  4603 solver.cpp:270] Iteration 850 (3.93859 iter/s, 12.6949s/50 iter), loss = 0.0788916, remaining 0 hours and 46 minutes
I0614 14:31:13.878970  4603 solver.cpp:291]     Train net output #0: loss = 0.0788916 (* 1 = 0.0788916 loss)
I0614 14:31:13.878978  4603 sgd_solver.cpp:106] Iteration 850, lr = 0.001
I0614 14:31:26.585176  4603 solver.cpp:270] Iteration 900 (3.93521 iter/s, 12.7058s/50 iter), loss = 0.125854, remaining 0 hours and 47 minutes
I0614 14:31:26.585207  4603 solver.cpp:291]     Train net output #0: loss = 0.125854 (* 1 = 0.125854 loss)
I0614 14:31:26.585215  4603 sgd_solver.cpp:106] Iteration 900, lr = 0.001
I0614 14:31:39.267122  4603 solver.cpp:270] Iteration 950 (3.94275 iter/s, 12.6815s/50 iter), loss = 0.0970965, remaining 0 hours and 46 minutes
I0614 14:31:39.267154  4603 solver.cpp:291]     Train net output #0: loss = 0.0970965 (* 1 = 0.0970965 loss)
I0614 14:31:39.267164  4603 sgd_solver.cpp:106] Iteration 950, lr = 0.001
I0614 14:31:51.734902  4603 solver.cpp:424] Iteration 1000, Testing net (#0)
I0614 14:31:53.255764  4603 solver.cpp:523]     Test net output #0: accuracy = 0.89825
I0614 14:31:53.255791  4603 solver.cpp:523]     Test net output #1: loss = 0.375431 (* 1 = 0.375431 loss)
I0614 14:31:53.255796  4603 solver.cpp:523]     Test net output #2: top-1 = 0.89825
I0614 14:31:53.506919  4603 solver.cpp:270] Iteration 1000 (3.51141 iter/s, 14.2393s/50 iter), loss = 0.100581, remaining 0 hours and 52 minutes
I0614 14:31:53.506950  4603 solver.cpp:291]     Train net output #0: loss = 0.100581 (* 1 = 0.100581 loss)
I0614 14:31:53.506959  4603 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I0614 14:32:06.209889  4603 solver.cpp:270] Iteration 1050 (3.93622 iter/s, 12.7025s/50 iter), loss = 0.0806336, remaining 0 hours and 46 minutes
I0614 14:32:06.209921  4603 solver.cpp:291]     Train net output #0: loss = 0.0806337 (* 1 = 0.0806337 loss)
I0614 14:32:06.209929  4603 sgd_solver.cpp:106] Iteration 1050, lr = 0.001
I0614 14:32:18.887518  4603 solver.cpp:270] Iteration 1100 (3.94409 iter/s, 12.6772s/50 iter), loss = 0.125194, remaining 0 hours and 45 minutes
I0614 14:32:18.887550  4603 solver.cpp:291]     Train net output #0: loss = 0.125194 (* 1 = 0.125194 loss)
I0614 14:32:18.887558  4603 sgd_solver.cpp:106] Iteration 1100, lr = 0.001
I0614 14:32:31.575282  4603 solver.cpp:270] Iteration 1150 (3.94094 iter/s, 12.6873s/50 iter), loss = 0.101422, remaining 0 hours and 45 minutes
I0614 14:32:31.575464  4603 solver.cpp:291]     Train net output #0: loss = 0.101422 (* 1 = 0.101422 loss)
I0614 14:32:31.575489  4603 sgd_solver.cpp:106] Iteration 1150, lr = 0.001
I0614 14:32:44.263104  4603 solver.cpp:270] Iteration 1200 (3.94097 iter/s, 12.6872s/50 iter), loss = 0.125159, remaining 0 hours and 45 minutes
I0614 14:32:44.263139  4603 solver.cpp:291]     Train net output #0: loss = 0.125159 (* 1 = 0.125159 loss)
I0614 14:32:44.263149  4603 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I0614 14:32:56.948009  4603 solver.cpp:270] Iteration 1250 (3.94183 iter/s, 12.6845s/50 iter), loss = 0.148879, remaining 0 hours and 45 minutes
I0614 14:32:56.948041  4603 solver.cpp:291]     Train net output #0: loss = 0.148879 (* 1 = 0.148879 loss)
I0614 14:32:56.948065  4603 sgd_solver.cpp:106] Iteration 1250, lr = 0.001
I0614 14:33:09.655720  4603 solver.cpp:270] Iteration 1300 (3.93476 iter/s, 12.7073s/50 iter), loss = 0.0654007, remaining 0 hours and 45 minutes
I0614 14:33:09.655843  4603 solver.cpp:291]     Train net output #0: loss = 0.0654007 (* 1 = 0.0654007 loss)
I0614 14:33:09.655851  4603 sgd_solver.cpp:106] Iteration 1300, lr = 0.001
I0614 14:33:22.329164  4603 solver.cpp:270] Iteration 1350 (3.94542 iter/s, 12.6729s/50 iter), loss = 0.0864012, remaining 0 hours and 44 minutes
I0614 14:33:22.329196  4603 solver.cpp:291]     Train net output #0: loss = 0.0864012 (* 1 = 0.0864012 loss)
I0614 14:33:22.329205  4603 sgd_solver.cpp:106] Iteration 1350, lr = 0.001
I0614 14:33:35.049001  4603 solver.cpp:270] Iteration 1400 (3.931 iter/s, 12.7194s/50 iter), loss = 0.096532, remaining 0 hours and 44 minutes
I0614 14:33:35.049033  4603 solver.cpp:291]     Train net output #0: loss = 0.096532 (* 1 = 0.096532 loss)
I0614 14:33:35.049041  4603 sgd_solver.cpp:106] Iteration 1400, lr = 0.001
I0614 14:33:47.760131  4603 solver.cpp:270] Iteration 1450 (3.9337 iter/s, 12.7107s/50 iter), loss = 0.0888727, remaining 0 hours and 44 minutes
I0614 14:33:47.760349  4603 solver.cpp:291]     Train net output #0: loss = 0.0888728 (* 1 = 0.0888728 loss)
I0614 14:33:47.760358  4603 sgd_solver.cpp:106] Iteration 1450, lr = 0.001
I0614 14:34:00.429632  4603 solver.cpp:270] Iteration 1500 (3.94668 iter/s, 12.6689s/50 iter), loss = 0.0714966, remaining 0 hours and 44 minutes
I0614 14:34:00.429664  4603 solver.cpp:291]     Train net output #0: loss = 0.0714966 (* 1 = 0.0714966 loss)
I0614 14:34:00.429688  4603 sgd_solver.cpp:106] Iteration 1500, lr = 0.001
I0614 14:34:13.128916  4603 solver.cpp:270] Iteration 1550 (3.93737 iter/s, 12.6988s/50 iter), loss = 0.103438, remaining 0 hours and 44 minutes
I0614 14:34:13.128948  4603 solver.cpp:291]     Train net output #0: loss = 0.103438 (* 1 = 0.103438 loss)
I0614 14:34:13.128955  4603 sgd_solver.cpp:106] Iteration 1550, lr = 0.001
I0614 14:34:25.837558  4603 solver.cpp:270] Iteration 1600 (3.93447 iter/s, 12.7082s/50 iter), loss = 0.0582672, remaining 0 hours and 43 minutes
I0614 14:34:25.837673  4603 solver.cpp:291]     Train net output #0: loss = 0.0582672 (* 1 = 0.0582672 loss)
I0614 14:34:25.837697  4603 sgd_solver.cpp:106] Iteration 1600, lr = 0.001
I0614 14:34:38.560458  4603 solver.cpp:270] Iteration 1650 (3.93008 iter/s, 12.7224s/50 iter), loss = 0.0574587, remaining 0 hours and 43 minutes
I0614 14:34:38.560492  4603 solver.cpp:291]     Train net output #0: loss = 0.0574588 (* 1 = 0.0574588 loss)
I0614 14:34:38.560503  4603 sgd_solver.cpp:106] Iteration 1650, lr = 0.001
I0614 14:34:51.281482  4603 solver.cpp:270] Iteration 1700 (3.93064 iter/s, 12.7206s/50 iter), loss = 0.117548, remaining 0 hours and 43 minutes
I0614 14:34:51.281514  4603 solver.cpp:291]     Train net output #0: loss = 0.117548 (* 1 = 0.117548 loss)
I0614 14:34:51.281538  4603 sgd_solver.cpp:106] Iteration 1700, lr = 0.001
I0614 14:35:03.981289  4603 solver.cpp:270] Iteration 1750 (3.9372 iter/s, 12.6994s/50 iter), loss = 0.0851156, remaining 0 hours and 43 minutes
I0614 14:35:03.981472  4603 solver.cpp:291]     Train net output #0: loss = 0.0851157 (* 1 = 0.0851157 loss)
I0614 14:35:03.981479  4603 sgd_solver.cpp:106] Iteration 1750, lr = 0.001
I0614 14:35:16.677588  4603 solver.cpp:270] Iteration 1800 (3.93834 iter/s, 12.6957s/50 iter), loss = 0.110619, remaining 0 hours and 43 minutes
I0614 14:35:16.677620  4603 solver.cpp:291]     Train net output #0: loss = 0.110619 (* 1 = 0.110619 loss)
I0614 14:35:16.677628  4603 sgd_solver.cpp:106] Iteration 1800, lr = 0.001
I0614 14:35:29.377164  4603 solver.cpp:270] Iteration 1850 (3.93728 iter/s, 12.6991s/50 iter), loss = 0.122212, remaining 0 hours and 42 minutes
I0614 14:35:29.377197  4603 solver.cpp:291]     Train net output #0: loss = 0.122212 (* 1 = 0.122212 loss)
I0614 14:35:29.377204  4603 sgd_solver.cpp:106] Iteration 1850, lr = 0.001
I0614 14:35:42.077625  4603 solver.cpp:270] Iteration 1900 (3.937 iter/s, 12.7s/50 iter), loss = 0.109568, remaining 0 hours and 42 minutes
I0614 14:35:42.077744  4603 solver.cpp:291]     Train net output #0: loss = 0.109568 (* 1 = 0.109568 loss)
I0614 14:35:42.077754  4603 sgd_solver.cpp:106] Iteration 1900, lr = 0.001
I0614 14:35:54.771518  4603 solver.cpp:270] Iteration 1950 (3.93907 iter/s, 12.6934s/50 iter), loss = 0.0555289, remaining 0 hours and 42 minutes
I0614 14:35:54.771551  4603 solver.cpp:291]     Train net output #0: loss = 0.055529 (* 1 = 0.055529 loss)
I0614 14:35:54.771575  4603 sgd_solver.cpp:106] Iteration 1950, lr = 0.001
I0614 14:36:07.183326  4603 solver.cpp:424] Iteration 2000, Testing net (#0)
I0614 14:36:08.700817  4603 solver.cpp:523]     Test net output #0: accuracy = 0.93475
I0614 14:36:08.700847  4603 solver.cpp:523]     Test net output #1: loss = 0.197542 (* 1 = 0.197542 loss)
I0614 14:36:08.700851  4603 solver.cpp:523]     Test net output #2: top-1 = 0.93475
I0614 14:36:08.951858  4603 solver.cpp:270] Iteration 2000 (3.52613 iter/s, 14.1798s/50 iter), loss = 0.0761406, remaining 0 hours and 47 minutes
I0614 14:36:08.951890  4603 solver.cpp:291]     Train net output #0: loss = 0.0761406 (* 1 = 0.0761406 loss)
I0614 14:36:08.951898  4603 sgd_solver.cpp:106] Iteration 2000, lr = 0.001
I0614 14:36:22.010794  4603 solver.cpp:270] Iteration 2050 (3.82893 iter/s, 13.0585s/50 iter), loss = 0.140261, remaining 0 hours and 43 minutes
I0614 14:36:22.010944  4603 solver.cpp:291]     Train net output #0: loss = 0.140261 (* 1 = 0.140261 loss)
I0614 14:36:22.010952  4603 sgd_solver.cpp:106] Iteration 2050, lr = 0.001
I0614 14:36:34.730792  4603 solver.cpp:270] Iteration 2100 (3.93099 iter/s, 12.7194s/50 iter), loss = 0.0891442, remaining 0 hours and 41 minutes
I0614 14:36:34.730823  4603 solver.cpp:291]     Train net output #0: loss = 0.0891442 (* 1 = 0.0891442 loss)
I0614 14:36:34.730831  4603 sgd_solver.cpp:106] Iteration 2100, lr = 0.001
I0614 14:36:47.344177  4603 solver.cpp:270] Iteration 2150 (3.96418 iter/s, 12.6129s/50 iter), loss = 0.0705101, remaining 0 hours and 41 minutes
I0614 14:36:47.344210  4603 solver.cpp:291]     Train net output #0: loss = 0.0705102 (* 1 = 0.0705102 loss)
I0614 14:36:47.344219  4603 sgd_solver.cpp:106] Iteration 2150, lr = 0.001
I0614 14:37:00.005125  4603 solver.cpp:270] Iteration 2200 (3.94929 iter/s, 12.6605s/50 iter), loss = 0.103292, remaining 0 hours and 41 minutes
I0614 14:37:00.005348  4603 solver.cpp:291]     Train net output #0: loss = 0.103292 (* 1 = 0.103292 loss)
I0614 14:37:00.005357  4603 sgd_solver.cpp:106] Iteration 2200, lr = 0.001
I0614 14:37:12.628628  4603 solver.cpp:270] Iteration 2250 (3.96106 iter/s, 12.6229s/50 iter), loss = 0.0754412, remaining 0 hours and 40 minutes
I0614 14:37:12.628660  4603 solver.cpp:291]     Train net output #0: loss = 0.0754413 (* 1 = 0.0754413 loss)
I0614 14:37:12.628669  4603 sgd_solver.cpp:106] Iteration 2250, lr = 0.001
I0614 14:37:25.239012  4603 solver.cpp:270] Iteration 2300 (3.96512 iter/s, 12.6099s/50 iter), loss = 0.0866436, remaining 0 hours and 40 minutes
I0614 14:37:25.239045  4603 solver.cpp:291]     Train net output #0: loss = 0.0866436 (* 1 = 0.0866436 loss)
I0614 14:37:25.239053  4603 sgd_solver.cpp:106] Iteration 2300, lr = 0.001
I0614 14:37:37.864382  4603 solver.cpp:270] Iteration 2350 (3.96042 iter/s, 12.6249s/50 iter), loss = 0.181014, remaining 0 hours and 40 minutes
I0614 14:37:37.864552  4603 solver.cpp:291]     Train net output #0: loss = 0.181014 (* 1 = 0.181014 loss)
I0614 14:37:37.864562  4603 sgd_solver.cpp:106] Iteration 2350, lr = 0.001
I0614 14:37:50.514856  4603 solver.cpp:270] Iteration 2400 (3.9526 iter/s, 12.6499s/50 iter), loss = 0.0713794, remaining 0 hours and 40 minutes
I0614 14:37:50.514889  4603 solver.cpp:291]     Train net output #0: loss = 0.0713794 (* 1 = 0.0713794 loss)
I0614 14:37:50.514896  4603 sgd_solver.cpp:106] Iteration 2400, lr = 0.001
I0614 14:38:03.141371  4603 solver.cpp:270] Iteration 2450 (3.96006 iter/s, 12.6261s/50 iter), loss = 0.100367, remaining 0 hours and 40 minutes
I0614 14:38:03.141404  4603 solver.cpp:291]     Train net output #0: loss = 0.100367 (* 1 = 0.100367 loss)
I0614 14:38:03.141412  4603 sgd_solver.cpp:106] Iteration 2450, lr = 0.001
I0614 14:38:15.788237  4603 solver.cpp:270] Iteration 2500 (3.95369 iter/s, 12.6464s/50 iter), loss = 0.121364, remaining 0 hours and 39 minutes
I0614 14:38:15.788352  4603 solver.cpp:291]     Train net output #0: loss = 0.121364 (* 1 = 0.121364 loss)
I0614 14:38:15.788375  4603 sgd_solver.cpp:106] Iteration 2500, lr = 0.0001
I0614 14:38:28.426486  4603 solver.cpp:270] Iteration 2550 (3.95641 iter/s, 12.6377s/50 iter), loss = 0.0678792, remaining 0 hours and 39 minutes
I0614 14:38:28.426517  4603 solver.cpp:291]     Train net output #0: loss = 0.0678792 (* 1 = 0.0678792 loss)
I0614 14:38:28.426524  4603 sgd_solver.cpp:106] Iteration 2550, lr = 0.0001
I0614 14:38:41.054026  4603 solver.cpp:270] Iteration 2600 (3.95974 iter/s, 12.6271s/50 iter), loss = 0.0654784, remaining 0 hours and 39 minutes
I0614 14:38:41.054059  4603 solver.cpp:291]     Train net output #0: loss = 0.0654784 (* 1 = 0.0654784 loss)
I0614 14:38:41.054066  4603 sgd_solver.cpp:106] Iteration 2600, lr = 0.0001
I0614 14:38:53.790141  4603 solver.cpp:270] Iteration 2650 (3.92598 iter/s, 12.7357s/50 iter), loss = 0.0401526, remaining 0 hours and 39 minutes
I0614 14:38:53.790251  4603 solver.cpp:291]     Train net output #0: loss = 0.0401526 (* 1 = 0.0401526 loss)
I0614 14:38:53.790259  4603 sgd_solver.cpp:106] Iteration 2650, lr = 0.0001
I0614 14:39:06.475067  4603 solver.cpp:270] Iteration 2700 (3.94185 iter/s, 12.6844s/50 iter), loss = 0.0312532, remaining 0 hours and 39 minutes
I0614 14:39:06.475100  4603 solver.cpp:291]     Train net output #0: loss = 0.0312532 (* 1 = 0.0312532 loss)
I0614 14:39:06.475107  4603 sgd_solver.cpp:106] Iteration 2700, lr = 0.0001
I0614 14:39:19.192456  4603 solver.cpp:270] Iteration 2750 (3.93176 iter/s, 12.7169s/50 iter), loss = 0.0510298, remaining 0 hours and 39 minutes
I0614 14:39:19.192489  4603 solver.cpp:291]     Train net output #0: loss = 0.0510299 (* 1 = 0.0510299 loss)
I0614 14:39:19.192497  4603 sgd_solver.cpp:106] Iteration 2750, lr = 0.0001
I0614 14:39:31.829030  4603 solver.cpp:270] Iteration 2800 (3.95691 iter/s, 12.6361s/50 iter), loss = 0.0449869, remaining 0 hours and 38 minutes
I0614 14:39:31.829144  4603 solver.cpp:291]     Train net output #0: loss = 0.0449869 (* 1 = 0.0449869 loss)
I0614 14:39:31.829151  4603 sgd_solver.cpp:106] Iteration 2800, lr = 0.0001
I0614 14:39:44.485646  4603 solver.cpp:270] Iteration 2850 (3.95067 iter/s, 12.6561s/50 iter), loss = 0.0696989, remaining 0 hours and 38 minutes
I0614 14:39:44.485680  4603 solver.cpp:291]     Train net output #0: loss = 0.069699 (* 1 = 0.069699 loss)
I0614 14:39:44.485688  4603 sgd_solver.cpp:106] Iteration 2850, lr = 0.0001
I0614 14:39:57.118508  4603 solver.cpp:270] Iteration 2900 (3.95807 iter/s, 12.6324s/50 iter), loss = 0.0599458, remaining 0 hours and 38 minutes
I0614 14:39:57.118542  4603 solver.cpp:291]     Train net output #0: loss = 0.0599458 (* 1 = 0.0599458 loss)
I0614 14:39:57.118551  4603 sgd_solver.cpp:106] Iteration 2900, lr = 0.0001
I0614 14:40:09.757345  4603 solver.cpp:270] Iteration 2950 (3.9562 iter/s, 12.6384s/50 iter), loss = 0.0359843, remaining 0 hours and 37 minutes
I0614 14:40:09.757597  4603 solver.cpp:291]     Train net output #0: loss = 0.0359843 (* 1 = 0.0359843 loss)
I0614 14:40:09.757604  4603 sgd_solver.cpp:106] Iteration 2950, lr = 0.0001
I0614 14:40:22.138947  4603 solver.cpp:424] Iteration 3000, Testing net (#0)
I0614 14:40:23.658529  4603 solver.cpp:523]     Test net output #0: accuracy = 0.9545
I0614 14:40:23.658555  4603 solver.cpp:523]     Test net output #1: loss = 0.132242 (* 1 = 0.132242 loss)
I0614 14:40:23.658560  4603 solver.cpp:523]     Test net output #2: top-1 = 0.9545
I0614 14:40:23.905035  4603 solver.cpp:270] Iteration 3000 (3.53432 iter/s, 14.147s/50 iter), loss = 0.0206529, remaining 0 hours and 42 minutes
I0614 14:40:23.905069  4603 solver.cpp:291]     Train net output #0: loss = 0.0206529 (* 1 = 0.0206529 loss)
I0614 14:40:23.905077  4603 sgd_solver.cpp:106] Iteration 3000, lr = 0.0001
I0614 14:40:36.545771  4603 solver.cpp:270] Iteration 3050 (3.9556 iter/s, 12.6403s/50 iter), loss = 0.0917709, remaining 0 hours and 37 minutes
I0614 14:40:36.545802  4603 solver.cpp:291]     Train net output #0: loss = 0.0917709 (* 1 = 0.0917709 loss)
I0614 14:40:36.545810  4603 sgd_solver.cpp:106] Iteration 3050, lr = 0.0001
I0614 14:40:49.176539  4603 solver.cpp:270] Iteration 3100 (3.95872 iter/s, 12.6303s/50 iter), loss = 0.0190973, remaining 0 hours and 37 minutes
I0614 14:40:49.176774  4603 solver.cpp:291]     Train net output #0: loss = 0.0190973 (* 1 = 0.0190973 loss)
I0614 14:40:49.176781  4603 sgd_solver.cpp:106] Iteration 3100, lr = 0.0001
I0614 14:41:01.824900  4603 solver.cpp:270] Iteration 3150 (3.95328 iter/s, 12.6477s/50 iter), loss = 0.0617632, remaining 0 hours and 37 minutes
I0614 14:41:01.824931  4603 solver.cpp:291]     Train net output #0: loss = 0.0617632 (* 1 = 0.0617632 loss)
I0614 14:41:01.824939  4603 sgd_solver.cpp:106] Iteration 3150, lr = 0.0001
I0614 14:41:14.444830  4603 solver.cpp:270] Iteration 3200 (3.96212 iter/s, 12.6195s/50 iter), loss = 0.0318213, remaining 0 hours and 36 minutes
I0614 14:41:14.444862  4603 solver.cpp:291]     Train net output #0: loss = 0.0318213 (* 1 = 0.0318213 loss)
I0614 14:41:14.444870  4603 sgd_solver.cpp:106] Iteration 3200, lr = 0.0001
I0614 14:41:27.082513  4603 solver.cpp:270] Iteration 3250 (3.95656 iter/s, 12.6372s/50 iter), loss = 0.0274844, remaining 0 hours and 36 minutes
I0614 14:41:27.082628  4603 solver.cpp:291]     Train net output #0: loss = 0.0274844 (* 1 = 0.0274844 loss)
I0614 14:41:27.082635  4603 sgd_solver.cpp:106] Iteration 3250, lr = 0.0001
I0614 14:41:39.703644  4603 solver.cpp:270] Iteration 3300 (3.96177 iter/s, 12.6206s/50 iter), loss = 0.0460982, remaining 0 hours and 36 minutes
I0614 14:41:39.703675  4603 solver.cpp:291]     Train net output #0: loss = 0.0460982 (* 1 = 0.0460982 loss)
I0614 14:41:39.703684  4603 sgd_solver.cpp:106] Iteration 3300, lr = 0.0001
I0614 14:41:52.341086  4603 solver.cpp:270] Iteration 3350 (3.95663 iter/s, 12.637s/50 iter), loss = 0.0301343, remaining 0 hours and 36 minutes
I0614 14:41:52.341117  4603 solver.cpp:291]     Train net output #0: loss = 0.0301343 (* 1 = 0.0301343 loss)
I0614 14:41:52.341125  4603 sgd_solver.cpp:106] Iteration 3350, lr = 0.0001
I0614 14:42:04.979300  4603 solver.cpp:270] Iteration 3400 (3.95639 iter/s, 12.6378s/50 iter), loss = 0.0406941, remaining 0 hours and 36 minutes
I0614 14:42:04.979467  4603 solver.cpp:291]     Train net output #0: loss = 0.0406941 (* 1 = 0.0406941 loss)
I0614 14:42:04.979475  4603 sgd_solver.cpp:106] Iteration 3400, lr = 0.0001
I0614 14:42:17.627049  4603 solver.cpp:270] Iteration 3450 (3.95345 iter/s, 12.6472s/50 iter), loss = 0.0278153, remaining 0 hours and 35 minutes
I0614 14:42:17.627081  4603 solver.cpp:291]     Train net output #0: loss = 0.0278153 (* 1 = 0.0278153 loss)
I0614 14:42:17.627089  4603 sgd_solver.cpp:106] Iteration 3450, lr = 0.0001
I0614 14:42:30.251004  4603 solver.cpp:270] Iteration 3500 (3.96086 iter/s, 12.6235s/50 iter), loss = 0.0154962, remaining 0 hours and 35 minutes
I0614 14:42:30.251037  4603 solver.cpp:291]     Train net output #0: loss = 0.0154962 (* 1 = 0.0154962 loss)
I0614 14:42:30.251045  4603 sgd_solver.cpp:106] Iteration 3500, lr = 0.0001
I0614 14:42:42.886869  4603 solver.cpp:270] Iteration 3550 (3.95713 iter/s, 12.6354s/50 iter), loss = 0.0451363, remaining 0 hours and 35 minutes
I0614 14:42:42.886987  4603 solver.cpp:291]     Train net output #0: loss = 0.0451363 (* 1 = 0.0451363 loss)
I0614 14:42:42.886996  4603 sgd_solver.cpp:106] Iteration 3550, lr = 0.0001
I0614 14:42:55.524374  4603 solver.cpp:270] Iteration 3600 (3.95664 iter/s, 12.637s/50 iter), loss = 0.0270136, remaining 0 hours and 35 minutes
I0614 14:42:55.524406  4603 solver.cpp:291]     Train net output #0: loss = 0.0270136 (* 1 = 0.0270136 loss)
I0614 14:42:55.524415  4603 sgd_solver.cpp:106] Iteration 3600, lr = 0.0001
I0614 14:43:08.143261  4603 solver.cpp:270] Iteration 3650 (3.96245 iter/s, 12.6184s/50 iter), loss = 0.0260718, remaining 0 hours and 35 minutes
I0614 14:43:08.143293  4603 solver.cpp:291]     Train net output #0: loss = 0.0260718 (* 1 = 0.0260718 loss)
I0614 14:43:08.143302  4603 sgd_solver.cpp:106] Iteration 3650, lr = 0.0001
I0614 14:43:20.769687  4603 solver.cpp:270] Iteration 3700 (3.96009 iter/s, 12.626s/50 iter), loss = 0.01313, remaining 0 hours and 34 minutes
I0614 14:43:20.769804  4603 solver.cpp:291]     Train net output #0: loss = 0.01313 (* 1 = 0.01313 loss)
I0614 14:43:20.769815  4603 sgd_solver.cpp:106] Iteration 3700, lr = 0.0001
I0614 14:43:33.413997  4603 solver.cpp:270] Iteration 3750 (3.95451 iter/s, 12.6438s/50 iter), loss = 0.0246473, remaining 0 hours and 34 minutes
I0614 14:43:33.414031  4603 solver.cpp:291]     Train net output #0: loss = 0.0246473 (* 1 = 0.0246473 loss)
I0614 14:43:33.414037  4603 sgd_solver.cpp:106] Iteration 3750, lr = 0.0001
I0614 14:43:46.069974  4603 solver.cpp:270] Iteration 3800 (3.95084 iter/s, 12.6555s/50 iter), loss = 0.0283899, remaining 0 hours and 34 minutes
I0614 14:43:46.070008  4603 solver.cpp:291]     Train net output #0: loss = 0.0283899 (* 1 = 0.0283899 loss)
I0614 14:43:46.070016  4603 sgd_solver.cpp:106] Iteration 3800, lr = 0.0001
I0614 14:43:58.685001  4603 solver.cpp:270] Iteration 3850 (3.96367 iter/s, 12.6146s/50 iter), loss = 0.00934903, remaining 0 hours and 34 minutes
I0614 14:43:58.685189  4603 solver.cpp:291]     Train net output #0: loss = 0.00934902 (* 1 = 0.00934902 loss)
I0614 14:43:58.685197  4603 sgd_solver.cpp:106] Iteration 3850, lr = 0.0001
I0614 14:44:11.297991  4603 solver.cpp:270] Iteration 3900 (3.96435 iter/s, 12.6124s/50 iter), loss = 0.0169654, remaining 0 hours and 34 minutes
I0614 14:44:11.298025  4603 solver.cpp:291]     Train net output #0: loss = 0.0169654 (* 1 = 0.0169654 loss)
I0614 14:44:11.298033  4603 sgd_solver.cpp:106] Iteration 3900, lr = 0.0001
I0614 14:44:23.935356  4603 solver.cpp:270] Iteration 3950 (3.95666 iter/s, 12.6369s/50 iter), loss = 0.00768513, remaining 0 hours and 33 minutes
I0614 14:44:23.935389  4603 solver.cpp:291]     Train net output #0: loss = 0.00768511 (* 1 = 0.00768511 loss)
I0614 14:44:23.935400  4603 sgd_solver.cpp:106] Iteration 3950, lr = 0.0001
I0614 14:44:36.307210  4603 solver.cpp:424] Iteration 4000, Testing net (#0)
I0614 14:44:37.820194  4603 solver.cpp:523]     Test net output #0: accuracy = 0.9495
I0614 14:44:37.820220  4603 solver.cpp:523]     Test net output #1: loss = 0.124743 (* 1 = 0.124743 loss)
I0614 14:44:37.820225  4603 solver.cpp:523]     Test net output #2: top-1 = 0.9495
I0614 14:44:38.066366  4603 solver.cpp:270] Iteration 4000 (3.53844 iter/s, 14.1305s/50 iter), loss = 0.0139857, remaining 0 hours and 37 minutes
I0614 14:44:38.066398  4603 solver.cpp:291]     Train net output #0: loss = 0.0139857 (* 1 = 0.0139857 loss)
I0614 14:44:38.066406  4603 sgd_solver.cpp:106] Iteration 4000, lr = 0.0001
I0614 14:44:50.703864  4603 solver.cpp:270] Iteration 4050 (3.95662 iter/s, 12.6371s/50 iter), loss = 0.011976, remaining 0 hours and 33 minutes
I0614 14:44:50.703896  4603 solver.cpp:291]     Train net output #0: loss = 0.011976 (* 1 = 0.011976 loss)
I0614 14:44:50.703904  4603 sgd_solver.cpp:106] Iteration 4050, lr = 0.0001
I0614 14:45:03.340554  4603 solver.cpp:270] Iteration 4100 (3.95687 iter/s, 12.6362s/50 iter), loss = 0.0253115, remaining 0 hours and 33 minutes
I0614 14:45:03.340590  4603 solver.cpp:291]     Train net output #0: loss = 0.0253115 (* 1 = 0.0253115 loss)
I0614 14:45:03.340597  4603 sgd_solver.cpp:106] Iteration 4100, lr = 0.0001
I0614 14:45:15.956477  4603 solver.cpp:270] Iteration 4150 (3.96338 iter/s, 12.6155s/50 iter), loss = 0.0210505, remaining 0 hours and 32 minutes
I0614 14:45:15.956642  4603 solver.cpp:291]     Train net output #0: loss = 0.0210505 (* 1 = 0.0210505 loss)
I0614 14:45:15.956651  4603 sgd_solver.cpp:106] Iteration 4150, lr = 0.0001
I0614 14:45:28.685869  4603 solver.cpp:270] Iteration 4200 (3.92809 iter/s, 12.7288s/50 iter), loss = 0.0112465, remaining 0 hours and 33 minutes
I0614 14:45:28.685901  4603 solver.cpp:291]     Train net output #0: loss = 0.0112465 (* 1 = 0.0112465 loss)
I0614 14:45:28.685909  4603 sgd_solver.cpp:106] Iteration 4200, lr = 0.0001
I0614 14:45:41.412529  4603 solver.cpp:270] Iteration 4250 (3.9289 iter/s, 12.7262s/50 iter), loss = 0.0173608, remaining 0 hours and 32 minutes
I0614 14:45:41.412562  4603 solver.cpp:291]     Train net output #0: loss = 0.0173608 (* 1 = 0.0173608 loss)
I0614 14:45:41.412569  4603 sgd_solver.cpp:106] Iteration 4250, lr = 0.0001
I0614 14:45:54.093537  4603 solver.cpp:270] Iteration 4300 (3.94304 iter/s, 12.6806s/50 iter), loss = 0.0411314, remaining 0 hours and 32 minutes
I0614 14:45:54.093753  4603 solver.cpp:291]     Train net output #0: loss = 0.0411314 (* 1 = 0.0411314 loss)
I0614 14:45:54.093761  4603 sgd_solver.cpp:106] Iteration 4300, lr = 0.0001
I0614 14:46:06.721508  4603 solver.cpp:270] Iteration 4350 (3.95966 iter/s, 12.6273s/50 iter), loss = 0.032226, remaining 0 hours and 32 minutes
I0614 14:46:06.721540  4603 solver.cpp:291]     Train net output #0: loss = 0.032226 (* 1 = 0.032226 loss)
I0614 14:46:06.721549  4603 sgd_solver.cpp:106] Iteration 4350, lr = 0.0001
I0614 14:46:19.363831  4603 solver.cpp:270] Iteration 4400 (3.95511 iter/s, 12.6419s/50 iter), loss = 0.0158736, remaining 0 hours and 31 minutes
I0614 14:46:19.363862  4603 solver.cpp:291]     Train net output #0: loss = 0.0158736 (* 1 = 0.0158736 loss)
I0614 14:46:19.363870  4603 sgd_solver.cpp:106] Iteration 4400, lr = 0.0001
I0614 14:46:32.003985  4603 solver.cpp:270] Iteration 4450 (3.95579 iter/s, 12.6397s/50 iter), loss = 0.0130541, remaining 0 hours and 31 minutes
I0614 14:46:32.004103  4603 solver.cpp:291]     Train net output #0: loss = 0.0130541 (* 1 = 0.0130541 loss)
I0614 14:46:32.004112  4603 sgd_solver.cpp:106] Iteration 4450, lr = 0.0001
I0614 14:46:44.651988  4603 solver.cpp:270] Iteration 4500 (3.95336 iter/s, 12.6475s/50 iter), loss = 0.02328, remaining 0 hours and 31 minutes
I0614 14:46:44.652020  4603 solver.cpp:291]     Train net output #0: loss = 0.02328 (* 1 = 0.02328 loss)
I0614 14:46:44.652043  4603 sgd_solver.cpp:106] Iteration 4500, lr = 0.0001
I0614 14:46:57.296344  4603 solver.cpp:270] Iteration 4550 (3.95447 iter/s, 12.6439s/50 iter), loss = 0.0143505, remaining 0 hours and 31 minutes
I0614 14:46:57.296375  4603 solver.cpp:291]     Train net output #0: loss = 0.0143505 (* 1 = 0.0143505 loss)
I0614 14:46:57.296383  4603 sgd_solver.cpp:106] Iteration 4550, lr = 0.0001
I0614 14:47:09.907349  4603 solver.cpp:270] Iteration 4600 (3.96493 iter/s, 12.6106s/50 iter), loss = 0.0225377, remaining 0 hours and 31 minutes
I0614 14:47:09.907519  4603 solver.cpp:291]     Train net output #0: loss = 0.0225377 (* 1 = 0.0225377 loss)
I0614 14:47:09.907527  4603 sgd_solver.cpp:106] Iteration 4600, lr = 0.0001
I0614 14:47:22.527190  4603 solver.cpp:270] Iteration 4650 (3.9622 iter/s, 12.6193s/50 iter), loss = 0.0383179, remaining 0 hours and 30 minutes
I0614 14:47:22.527221  4603 solver.cpp:291]     Train net output #0: loss = 0.0383178 (* 1 = 0.0383178 loss)
I0614 14:47:22.527230  4603 sgd_solver.cpp:106] Iteration 4650, lr = 0.0001
I0614 14:47:35.150094  4603 solver.cpp:270] Iteration 4700 (3.96119 iter/s, 12.6225s/50 iter), loss = 0.0518363, remaining 0 hours and 30 minutes
I0614 14:47:35.150126  4603 solver.cpp:291]     Train net output #0: loss = 0.0518363 (* 1 = 0.0518363 loss)
I0614 14:47:35.150135  4603 sgd_solver.cpp:106] Iteration 4700, lr = 0.0001
I0614 14:47:47.787405  4603 solver.cpp:270] Iteration 4750 (3.95668 iter/s, 12.6369s/50 iter), loss = 0.0149633, remaining 0 hours and 30 minutes
I0614 14:47:47.787523  4603 solver.cpp:291]     Train net output #0: loss = 0.0149633 (* 1 = 0.0149633 loss)
I0614 14:47:47.787531  4603 sgd_solver.cpp:106] Iteration 4750, lr = 0.0001
I0614 14:48:00.436483  4603 solver.cpp:270] Iteration 4800 (3.95302 iter/s, 12.6486s/50 iter), loss = 0.0180537, remaining 0 hours and 30 minutes
I0614 14:48:00.436515  4603 solver.cpp:291]     Train net output #0: loss = 0.0180537 (* 1 = 0.0180537 loss)
I0614 14:48:00.436522  4603 sgd_solver.cpp:106] Iteration 4800, lr = 0.0001
I0614 14:48:13.062451  4603 solver.cpp:270] Iteration 4850 (3.96023 iter/s, 12.6255s/50 iter), loss = 0.0129714, remaining 0 hours and 30 minutes
I0614 14:48:13.062482  4603 solver.cpp:291]     Train net output #0: loss = 0.0129714 (* 1 = 0.0129714 loss)
I0614 14:48:13.062491  4603 sgd_solver.cpp:106] Iteration 4850, lr = 0.0001
I0614 14:48:25.706812  4603 solver.cpp:270] Iteration 4900 (3.95447 iter/s, 12.6439s/50 iter), loss = 0.005288, remaining 0 hours and 29 minutes
I0614 14:48:25.706930  4603 solver.cpp:291]     Train net output #0: loss = 0.00528797 (* 1 = 0.00528797 loss)
I0614 14:48:25.706954  4603 sgd_solver.cpp:106] Iteration 4900, lr = 0.0001
I0614 14:48:38.348609  4603 solver.cpp:270] Iteration 4950 (3.9553 iter/s, 12.6413s/50 iter), loss = 0.0148081, remaining 0 hours and 29 minutes
I0614 14:48:38.348642  4603 solver.cpp:291]     Train net output #0: loss = 0.0148081 (* 1 = 0.0148081 loss)
I0614 14:48:38.348650  4603 sgd_solver.cpp:106] Iteration 4950, lr = 0.0001
I0614 14:48:50.709717  4603 solver.cpp:424] Iteration 5000, Testing net (#0)
I0614 14:48:52.223062  4603 solver.cpp:523]     Test net output #0: accuracy = 0.955
I0614 14:48:52.223090  4603 solver.cpp:523]     Test net output #1: loss = 0.130618 (* 1 = 0.130618 loss)
I0614 14:48:52.223094  4603 solver.cpp:523]     Test net output #2: top-1 = 0.955
I0614 14:48:52.469408  4603 solver.cpp:270] Iteration 5000 (3.541 iter/s, 14.1203s/50 iter), loss = 0.00518491, remaining 0 hours and 32 minutes
I0614 14:48:52.469439  4603 solver.cpp:291]     Train net output #0: loss = 0.00518489 (* 1 = 0.00518489 loss)
I0614 14:48:52.469446  4603 sgd_solver.cpp:106] Iteration 5000, lr = 1e-05
I0614 14:49:05.099289  4603 solver.cpp:270] Iteration 5050 (3.959 iter/s, 12.6294s/50 iter), loss = 0.0162114, remaining 0 hours and 29 minutes
I0614 14:49:05.099413  4603 solver.cpp:291]     Train net output #0: loss = 0.0162114 (* 1 = 0.0162114 loss)
I0614 14:49:05.099421  4603 sgd_solver.cpp:106] Iteration 5050, lr = 1e-05
I0614 14:49:17.710953  4603 solver.cpp:270] Iteration 5100 (3.96475 iter/s, 12.6111s/50 iter), loss = 0.00560156, remaining 0 hours and 29 minutes
I0614 14:49:17.710985  4603 solver.cpp:291]     Train net output #0: loss = 0.00560154 (* 1 = 0.00560154 loss)
I0614 14:49:17.710994  4603 sgd_solver.cpp:106] Iteration 5100, lr = 1e-05
I0614 14:49:30.327888  4603 solver.cpp:270] Iteration 5150 (3.96307 iter/s, 12.6165s/50 iter), loss = 0.010358, remaining 0 hours and 28 minutes
I0614 14:49:30.327921  4603 solver.cpp:291]     Train net output #0: loss = 0.010358 (* 1 = 0.010358 loss)
I0614 14:49:30.327945  4603 sgd_solver.cpp:106] Iteration 5150, lr = 1e-05
I0614 14:49:42.962376  4603 solver.cpp:270] Iteration 5200 (3.95756 iter/s, 12.634s/50 iter), loss = 0.0019276, remaining 0 hours and 28 minutes
I0614 14:49:42.962704  4603 solver.cpp:291]     Train net output #0: loss = 0.00192758 (* 1 = 0.00192758 loss)
I0614 14:49:42.962713  4603 sgd_solver.cpp:106] Iteration 5200, lr = 1e-05
I0614 14:49:55.594533  4603 solver.cpp:270] Iteration 5250 (3.95838 iter/s, 12.6314s/50 iter), loss = 0.0221432, remaining 0 hours and 28 minutes
I0614 14:49:55.594566  4603 solver.cpp:291]     Train net output #0: loss = 0.0221432 (* 1 = 0.0221432 loss)
I0614 14:49:55.594573  4603 sgd_solver.cpp:106] Iteration 5250, lr = 1e-05
I0614 14:50:08.218186  4603 solver.cpp:270] Iteration 5300 (3.96096 iter/s, 12.6232s/50 iter), loss = 0.0202665, remaining 0 hours and 28 minutes
I0614 14:50:08.218220  4603 solver.cpp:291]     Train net output #0: loss = 0.0202664 (* 1 = 0.0202664 loss)
I0614 14:50:08.218230  4603 sgd_solver.cpp:106] Iteration 5300, lr = 1e-05
I0614 14:50:20.843211  4603 solver.cpp:270] Iteration 5350 (3.96053 iter/s, 12.6246s/50 iter), loss = 0.00979558, remaining 0 hours and 27 minutes
I0614 14:50:20.843324  4603 solver.cpp:291]     Train net output #0: loss = 0.00979556 (* 1 = 0.00979556 loss)
I0614 14:50:20.843333  4603 sgd_solver.cpp:106] Iteration 5350, lr = 1e-05
I0614 14:50:33.453991  4603 solver.cpp:270] Iteration 5400 (3.96502 iter/s, 12.6103s/50 iter), loss = 0.0110588, remaining 0 hours and 27 minutes
I0614 14:50:33.454023  4603 solver.cpp:291]     Train net output #0: loss = 0.0110588 (* 1 = 0.0110588 loss)
I0614 14:50:33.454031  4603 sgd_solver.cpp:106] Iteration 5400, lr = 1e-05
I0614 14:50:46.086279  4603 solver.cpp:270] Iteration 5450 (3.95825 iter/s, 12.6318s/50 iter), loss = 0.00846745, remaining 0 hours and 27 minutes
I0614 14:50:46.086311  4603 solver.cpp:291]     Train net output #0: loss = 0.00846742 (* 1 = 0.00846742 loss)
I0614 14:50:46.086319  4603 sgd_solver.cpp:106] Iteration 5450, lr = 1e-05
I0614 14:50:58.721215  4603 solver.cpp:270] Iteration 5500 (3.95742 iter/s, 12.6345s/50 iter), loss = 0.0125903, remaining 0 hours and 27 minutes
I0614 14:50:58.721335  4603 solver.cpp:291]     Train net output #0: loss = 0.0125903 (* 1 = 0.0125903 loss)
I0614 14:50:58.721345  4603 sgd_solver.cpp:106] Iteration 5500, lr = 1e-05
I0614 14:51:11.345749  4603 solver.cpp:270] Iteration 5550 (3.96071 iter/s, 12.624s/50 iter), loss = 0.074261, remaining 0 hours and 27 minutes
I0614 14:51:11.345779  4603 solver.cpp:291]     Train net output #0: loss = 0.0742609 (* 1 = 0.0742609 loss)
I0614 14:51:11.345788  4603 sgd_solver.cpp:106] Iteration 5550, lr = 1e-05
I0614 14:51:23.965584  4603 solver.cpp:270] Iteration 5600 (3.96215 iter/s, 12.6194s/50 iter), loss = 0.0043692, remaining 0 hours and 26 minutes
I0614 14:51:23.965617  4603 solver.cpp:291]     Train net output #0: loss = 0.00436916 (* 1 = 0.00436916 loss)
I0614 14:51:23.965624  4603 sgd_solver.cpp:106] Iteration 5600, lr = 1e-05
I0614 14:51:36.594079  4603 solver.cpp:270] Iteration 5650 (3.95944 iter/s, 12.6281s/50 iter), loss = 0.0109217, remaining 0 hours and 26 minutes
I0614 14:51:36.594200  4603 solver.cpp:291]     Train net output #0: loss = 0.0109217 (* 1 = 0.0109217 loss)
I0614 14:51:36.594209  4603 sgd_solver.cpp:106] Iteration 5650, lr = 1e-05
I0614 14:51:49.225579  4603 solver.cpp:270] Iteration 5700 (3.95852 iter/s, 12.631s/50 iter), loss = 0.0043453, remaining 0 hours and 26 minutes
I0614 14:51:49.225611  4603 solver.cpp:291]     Train net output #0: loss = 0.00434527 (* 1 = 0.00434527 loss)
I0614 14:51:49.225620  4603 sgd_solver.cpp:106] Iteration 5700, lr = 1e-05
I0614 14:52:01.868808  4603 solver.cpp:270] Iteration 5750 (3.95482 iter/s, 12.6428s/50 iter), loss = 0.0232728, remaining 0 hours and 26 minutes
I0614 14:52:01.868840  4603 solver.cpp:291]     Train net output #0: loss = 0.0232728 (* 1 = 0.0232728 loss)
I0614 14:52:01.868849  4603 sgd_solver.cpp:106] Iteration 5750, lr = 1e-05
I0614 14:52:14.508021  4603 solver.cpp:270] Iteration 5800 (3.95608 iter/s, 12.6388s/50 iter), loss = 0.00744926, remaining 0 hours and 26 minutes
I0614 14:52:14.508195  4603 solver.cpp:291]     Train net output #0: loss = 0.00744924 (* 1 = 0.00744924 loss)
I0614 14:52:14.508204  4603 sgd_solver.cpp:106] Iteration 5800, lr = 1e-05
I0614 14:52:27.156422  4603 solver.cpp:270] Iteration 5850 (3.95325 iter/s, 12.6478s/50 iter), loss = 0.00630439, remaining 0 hours and 25 minutes
I0614 14:52:27.156455  4603 solver.cpp:291]     Train net output #0: loss = 0.00630436 (* 1 = 0.00630436 loss)
I0614 14:52:27.156463  4603 sgd_solver.cpp:106] Iteration 5850, lr = 1e-05
I0614 14:52:39.807090  4603 solver.cpp:270] Iteration 5900 (3.9525 iter/s, 12.6502s/50 iter), loss = 0.0170176, remaining 0 hours and 25 minutes
I0614 14:52:39.807121  4603 solver.cpp:291]     Train net output #0: loss = 0.0170176 (* 1 = 0.0170176 loss)
I0614 14:52:39.807129  4603 sgd_solver.cpp:106] Iteration 5900, lr = 1e-05
I0614 14:52:52.444092  4603 solver.cpp:270] Iteration 5950 (3.95677 iter/s, 12.6366s/50 iter), loss = 0.0247761, remaining 0 hours and 25 minutes
I0614 14:52:52.444208  4603 solver.cpp:291]     Train net output #0: loss = 0.0247761 (* 1 = 0.0247761 loss)
I0614 14:52:52.444216  4603 sgd_solver.cpp:106] Iteration 5950, lr = 1e-05
I0614 14:53:04.817744  4603 solver.cpp:935] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.2/snapshots/_iter_6000.caffemodel
I0614 14:53:10.997913  4603 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.2/snapshots/_iter_6000.solverstate
I0614 14:53:14.944530  4603 solver.cpp:424] Iteration 6000, Testing net (#0)
I0614 14:53:16.369266  4603 solver.cpp:523]     Test net output #0: accuracy = 0.9595
I0614 14:53:16.369293  4603 solver.cpp:523]     Test net output #1: loss = 0.139939 (* 1 = 0.139939 loss)
I0614 14:53:16.369298  4603 solver.cpp:523]     Test net output #2: top-1 = 0.9595
I0614 14:53:16.604190  4603 solver.cpp:270] Iteration 6000 (2.0696 iter/s, 24.1592s/50 iter), loss = 0.0229264, remaining 0 hours and 48 minutes
I0614 14:53:16.604223  4603 solver.cpp:291]     Train net output #0: loss = 0.0229263 (* 1 = 0.0229263 loss)
I0614 14:53:16.604230  4603 sgd_solver.cpp:106] Iteration 6000, lr = 1e-05
I0614 14:53:29.132814  4603 solver.cpp:270] Iteration 6050 (3.991 iter/s, 12.5282s/50 iter), loss = 0.0254712, remaining 0 hours and 24 minutes
I0614 14:53:29.132931  4603 solver.cpp:291]     Train net output #0: loss = 0.0254712 (* 1 = 0.0254712 loss)
I0614 14:53:29.132939  4603 sgd_solver.cpp:106] Iteration 6050, lr = 1e-05
I0614 14:53:41.689363  4603 solver.cpp:270] Iteration 6100 (3.98215 iter/s, 12.556s/50 iter), loss = 0.0122279, remaining 0 hours and 24 minutes
I0614 14:53:41.689399  4603 solver.cpp:291]     Train net output #0: loss = 0.0122278 (* 1 = 0.0122278 loss)
I0614 14:53:41.689406  4603 sgd_solver.cpp:106] Iteration 6100, lr = 1e-05
I0614 14:53:54.309660  4603 solver.cpp:270] Iteration 6150 (3.96201 iter/s, 12.6199s/50 iter), loss = 0.0274954, remaining 0 hours and 24 minutes
I0614 14:53:54.309693  4603 solver.cpp:291]     Train net output #0: loss = 0.0274953 (* 1 = 0.0274953 loss)
I0614 14:53:54.309702  4603 sgd_solver.cpp:106] Iteration 6150, lr = 1e-05
I0614 14:54:06.925786  4603 solver.cpp:270] Iteration 6200 (3.96332 iter/s, 12.6157s/50 iter), loss = 0.0154233, remaining 0 hours and 24 minutes
I0614 14:54:06.925905  4603 solver.cpp:291]     Train net output #0: loss = 0.0154233 (* 1 = 0.0154233 loss)
I0614 14:54:06.925915  4603 sgd_solver.cpp:106] Iteration 6200, lr = 1e-05
I0614 14:54:19.541932  4603 solver.cpp:270] Iteration 6250 (3.96334 iter/s, 12.6156s/50 iter), loss = 0.00746106, remaining 0 hours and 23 minutes
I0614 14:54:19.541963  4603 solver.cpp:291]     Train net output #0: loss = 0.00746102 (* 1 = 0.00746102 loss)
I0614 14:54:19.541970  4603 sgd_solver.cpp:106] Iteration 6250, lr = 1e-05
I0614 14:54:32.191624  4603 solver.cpp:270] Iteration 6300 (3.9528 iter/s, 12.6493s/50 iter), loss = 0.00289436, remaining 0 hours and 24 minutes
I0614 14:54:32.191656  4603 solver.cpp:291]     Train net output #0: loss = 0.00289431 (* 1 = 0.00289431 loss)
I0614 14:54:32.191664  4603 sgd_solver.cpp:106] Iteration 6300, lr = 1e-05
I0614 14:54:44.832839  4603 solver.cpp:270] Iteration 6350 (3.95545 iter/s, 12.6408s/50 iter), loss = 0.00277872, remaining 0 hours and 23 minutes
I0614 14:54:44.833146  4603 solver.cpp:291]     Train net output #0: loss = 0.00277867 (* 1 = 0.00277867 loss)
I0614 14:54:44.833154  4603 sgd_solver.cpp:106] Iteration 6350, lr = 1e-05
I0614 14:54:57.448025  4603 solver.cpp:270] Iteration 6400 (3.9637 iter/s, 12.6145s/50 iter), loss = 0.00346615, remaining 0 hours and 23 minutes
I0614 14:54:57.448056  4603 solver.cpp:291]     Train net output #0: loss = 0.0034661 (* 1 = 0.0034661 loss)
I0614 14:54:57.448063  4603 sgd_solver.cpp:106] Iteration 6400, lr = 1e-05
I0614 14:55:10.100008  4603 solver.cpp:270] Iteration 6450 (3.95209 iter/s, 12.6515s/50 iter), loss = 0.000750754, remaining 0 hours and 23 minutes
I0614 14:55:10.100039  4603 solver.cpp:291]     Train net output #0: loss = 0.000750706 (* 1 = 0.000750706 loss)
I0614 14:55:10.100046  4603 sgd_solver.cpp:106] Iteration 6450, lr = 1e-05
I0614 14:55:22.747750  4603 solver.cpp:270] Iteration 6500 (3.95341 iter/s, 12.6473s/50 iter), loss = 0.0188559, remaining 0 hours and 23 minutes
I0614 14:55:22.747867  4603 solver.cpp:291]     Train net output #0: loss = 0.0188558 (* 1 = 0.0188558 loss)
I0614 14:55:22.747876  4603 sgd_solver.cpp:106] Iteration 6500, lr = 1e-05
I0614 14:55:35.404956  4603 solver.cpp:270] Iteration 6550 (3.95048 iter/s, 12.6567s/50 iter), loss = 0.0134487, remaining 0 hours and 22 minutes
I0614 14:55:35.404989  4603 solver.cpp:291]     Train net output #0: loss = 0.0134486 (* 1 = 0.0134486 loss)
I0614 14:55:35.404997  4603 sgd_solver.cpp:106] Iteration 6550, lr = 1e-05
I0614 14:55:48.029021  4603 solver.cpp:270] Iteration 6600 (3.96083 iter/s, 12.6236s/50 iter), loss = 0.0103617, remaining 0 hours and 22 minutes
I0614 14:55:48.029052  4603 solver.cpp:291]     Train net output #0: loss = 0.0103616 (* 1 = 0.0103616 loss)
I0614 14:55:48.029060  4603 sgd_solver.cpp:106] Iteration 6600, lr = 1e-05
I0614 14:56:00.677742  4603 solver.cpp:270] Iteration 6650 (3.95311 iter/s, 12.6483s/50 iter), loss = 0.00817909, remaining 0 hours and 22 minutes
I0614 14:56:00.677858  4603 solver.cpp:291]     Train net output #0: loss = 0.00817904 (* 1 = 0.00817904 loss)
I0614 14:56:00.677867  4603 sgd_solver.cpp:106] Iteration 6650, lr = 1e-05
I0614 14:56:13.329020  4603 solver.cpp:270] Iteration 6700 (3.95233 iter/s, 12.6508s/50 iter), loss = 0.00599209, remaining 0 hours and 22 minutes
I0614 14:56:13.329051  4603 solver.cpp:291]     Train net output #0: loss = 0.00599205 (* 1 = 0.00599205 loss)
I0614 14:56:13.329061  4603 sgd_solver.cpp:106] Iteration 6700, lr = 1e-05
I0614 14:56:25.944401  4603 solver.cpp:270] Iteration 6750 (3.96355 iter/s, 12.6149s/50 iter), loss = 0.0117776, remaining 0 hours and 21 minutes
I0614 14:56:25.944433  4603 solver.cpp:291]     Train net output #0: loss = 0.0117775 (* 1 = 0.0117775 loss)
I0614 14:56:25.944442  4603 sgd_solver.cpp:106] Iteration 6750, lr = 1e-05
I0614 14:56:38.562438  4603 solver.cpp:270] Iteration 6800 (3.96272 iter/s, 12.6176s/50 iter), loss = 0.00808289, remaining 0 hours and 21 minutes
I0614 14:56:38.562554  4603 solver.cpp:291]     Train net output #0: loss = 0.00808285 (* 1 = 0.00808285 loss)
I0614 14:56:38.562562  4603 sgd_solver.cpp:106] Iteration 6800, lr = 1e-05
I0614 14:56:51.169068  4603 solver.cpp:270] Iteration 6850 (3.96633 iter/s, 12.6061s/50 iter), loss = 0.000466511, remaining 0 hours and 21 minutes
I0614 14:56:51.169101  4603 solver.cpp:291]     Train net output #0: loss = 0.000466461 (* 1 = 0.000466461 loss)
I0614 14:56:51.169126  4603 sgd_solver.cpp:106] Iteration 6850, lr = 1e-05
I0614 14:57:03.784349  4603 solver.cpp:270] Iteration 6900 (3.96359 iter/s, 12.6148s/50 iter), loss = 0.010723, remaining 0 hours and 21 minutes
I0614 14:57:03.784382  4603 solver.cpp:291]     Train net output #0: loss = 0.0107229 (* 1 = 0.0107229 loss)
I0614 14:57:03.784405  4603 sgd_solver.cpp:106] Iteration 6900, lr = 1e-05
I0614 14:57:16.416762  4603 solver.cpp:270] Iteration 6950 (3.95821 iter/s, 12.632s/50 iter), loss = 0.0148139, remaining 0 hours and 21 minutes
I0614 14:57:16.416937  4603 solver.cpp:291]     Train net output #0: loss = 0.0148139 (* 1 = 0.0148139 loss)
I0614 14:57:16.416961  4603 sgd_solver.cpp:106] Iteration 6950, lr = 1e-05
I0614 14:57:28.793154  4603 solver.cpp:424] Iteration 7000, Testing net (#0)
I0614 14:57:30.300693  4603 solver.cpp:523]     Test net output #0: accuracy = 0.95825
I0614 14:57:30.300720  4603 solver.cpp:523]     Test net output #1: loss = 0.163624 (* 1 = 0.163624 loss)
I0614 14:57:30.300725  4603 solver.cpp:523]     Test net output #2: top-1 = 0.95825
I0614 14:57:30.547257  4603 solver.cpp:270] Iteration 7000 (3.5386 iter/s, 14.1299s/50 iter), loss = 0.0166215, remaining 0 hours and 23 minutes
I0614 14:57:30.547288  4603 solver.cpp:291]     Train net output #0: loss = 0.0166214 (* 1 = 0.0166214 loss)
I0614 14:57:30.547297  4603 sgd_solver.cpp:106] Iteration 7000, lr = 1e-05
I0614 14:57:43.187762  4603 solver.cpp:270] Iteration 7050 (3.95568 iter/s, 12.6401s/50 iter), loss = 0.0104945, remaining 0 hours and 20 minutes
I0614 14:57:43.187793  4603 solver.cpp:291]     Train net output #0: loss = 0.0104944 (* 1 = 0.0104944 loss)
I0614 14:57:43.187801  4603 sgd_solver.cpp:106] Iteration 7050, lr = 1e-05
I0614 14:57:55.795781  4603 solver.cpp:270] Iteration 7100 (3.96587 iter/s, 12.6076s/50 iter), loss = 0.00333298, remaining 0 hours and 20 minutes
I0614 14:57:55.795898  4603 solver.cpp:291]     Train net output #0: loss = 0.00333294 (* 1 = 0.00333294 loss)
I0614 14:57:55.795907  4603 sgd_solver.cpp:106] Iteration 7100, lr = 1e-05
I0614 14:58:08.413563  4603 solver.cpp:270] Iteration 7150 (3.96283 iter/s, 12.6173s/50 iter), loss = 0.0207204, remaining 0 hours and 20 minutes
I0614 14:58:08.413595  4603 solver.cpp:291]     Train net output #0: loss = 0.0207204 (* 1 = 0.0207204 loss)
I0614 14:58:08.413619  4603 sgd_solver.cpp:106] Iteration 7150, lr = 1e-05
I0614 14:58:21.029333  4603 solver.cpp:270] Iteration 7200 (3.96343 iter/s, 12.6153s/50 iter), loss = 0.00339819, remaining 0 hours and 20 minutes
I0614 14:58:21.029367  4603 solver.cpp:291]     Train net output #0: loss = 0.00339815 (* 1 = 0.00339815 loss)
I0614 14:58:21.029395  4603 sgd_solver.cpp:106] Iteration 7200, lr = 1e-05
I0614 14:58:33.648540  4603 solver.cpp:270] Iteration 7250 (3.96235 iter/s, 12.6188s/50 iter), loss = 0.00880384, remaining 0 hours and 19 minutes
I0614 14:58:33.648655  4603 solver.cpp:291]     Train net output #0: loss = 0.0088038 (* 1 = 0.0088038 loss)
I0614 14:58:33.648664  4603 sgd_solver.cpp:106] Iteration 7250, lr = 1e-05
I0614 14:58:46.265878  4603 solver.cpp:270] Iteration 7300 (3.96296 iter/s, 12.6168s/50 iter), loss = 0.00514047, remaining 0 hours and 19 minutes
I0614 14:58:46.265909  4603 solver.cpp:291]     Train net output #0: loss = 0.00514044 (* 1 = 0.00514044 loss)
I0614 14:58:46.265918  4603 sgd_solver.cpp:106] Iteration 7300, lr = 1e-05
I0614 14:58:58.879369  4603 solver.cpp:270] Iteration 7350 (3.96415 iter/s, 12.6131s/50 iter), loss = 0.00993392, remaining 0 hours and 19 minutes
I0614 14:58:58.879403  4603 solver.cpp:291]     Train net output #0: loss = 0.00993389 (* 1 = 0.00993389 loss)
I0614 14:58:58.879411  4603 sgd_solver.cpp:106] Iteration 7350, lr = 1e-05
I0614 14:59:11.488608  4603 solver.cpp:270] Iteration 7400 (3.96548 iter/s, 12.6088s/50 iter), loss = 0.00513577, remaining 0 hours and 19 minutes
I0614 14:59:11.488750  4603 solver.cpp:291]     Train net output #0: loss = 0.00513573 (* 1 = 0.00513573 loss)
I0614 14:59:11.488759  4603 sgd_solver.cpp:106] Iteration 7400, lr = 1e-05
I0614 14:59:24.095957  4603 solver.cpp:270] Iteration 7450 (3.96611 iter/s, 12.6068s/50 iter), loss = 0.0368393, remaining 0 hours and 18 minutes
I0614 14:59:24.095989  4603 solver.cpp:291]     Train net output #0: loss = 0.0368393 (* 1 = 0.0368393 loss)
I0614 14:59:24.095997  4603 sgd_solver.cpp:106] Iteration 7450, lr = 1e-05
I0614 14:59:36.718056  4603 solver.cpp:270] Iteration 7500 (3.96144 iter/s, 12.6217s/50 iter), loss = 0.00246076, remaining 0 hours and 18 minutes
I0614 14:59:36.718089  4603 solver.cpp:291]     Train net output #0: loss = 0.00246072 (* 1 = 0.00246072 loss)
I0614 14:59:36.718098  4603 sgd_solver.cpp:106] Iteration 7500, lr = 1e-06
I0614 14:59:49.347393  4603 solver.cpp:270] Iteration 7550 (3.95917 iter/s, 12.6289s/50 iter), loss = 0.0112103, remaining 0 hours and 18 minutes
I0614 14:59:49.347561  4603 solver.cpp:291]     Train net output #0: loss = 0.0112102 (* 1 = 0.0112102 loss)
I0614 14:59:49.347571  4603 sgd_solver.cpp:106] Iteration 7550, lr = 1e-06
I0614 15:00:01.980489  4603 solver.cpp:270] Iteration 7600 (3.95804 iter/s, 12.6325s/50 iter), loss = 0.00318327, remaining 0 hours and 18 minutes
I0614 15:00:01.980522  4603 solver.cpp:291]     Train net output #0: loss = 0.00318323 (* 1 = 0.00318323 loss)
I0614 15:00:01.980531  4603 sgd_solver.cpp:106] Iteration 7600, lr = 1e-06
I0614 15:00:14.620692  4603 solver.cpp:270] Iteration 7650 (3.95577 iter/s, 12.6398s/50 iter), loss = 0.00770409, remaining 0 hours and 18 minutes
I0614 15:00:14.620726  4603 solver.cpp:291]     Train net output #0: loss = 0.00770404 (* 1 = 0.00770404 loss)
I0614 15:00:14.620736  4603 sgd_solver.cpp:106] Iteration 7650, lr = 1e-06
I0614 15:00:27.238871  4603 solver.cpp:270] Iteration 7700 (3.96268 iter/s, 12.6177s/50 iter), loss = 0.00164549, remaining 0 hours and 17 minutes
I0614 15:00:27.238986  4603 solver.cpp:291]     Train net output #0: loss = 0.00164544 (* 1 = 0.00164544 loss)
I0614 15:00:27.239012  4603 sgd_solver.cpp:106] Iteration 7700, lr = 1e-06
I0614 15:00:39.860425  4603 solver.cpp:270] Iteration 7750 (3.96164 iter/s, 12.621s/50 iter), loss = 0.0120309, remaining 0 hours and 17 minutes
I0614 15:00:39.860457  4603 solver.cpp:291]     Train net output #0: loss = 0.0120309 (* 1 = 0.0120309 loss)
I0614 15:00:39.860466  4603 sgd_solver.cpp:106] Iteration 7750, lr = 1e-06
I0614 15:00:52.509528  4603 solver.cpp:270] Iteration 7800 (3.95299 iter/s, 12.6487s/50 iter), loss = 0.00596689, remaining 0 hours and 17 minutes
I0614 15:00:52.509560  4603 solver.cpp:291]     Train net output #0: loss = 0.00596683 (* 1 = 0.00596683 loss)
I0614 15:00:52.509568  4603 sgd_solver.cpp:106] Iteration 7800, lr = 1e-06
I0614 15:01:05.150679  4603 solver.cpp:270] Iteration 7850 (3.95547 iter/s, 12.6407s/50 iter), loss = 0.0218594, remaining 0 hours and 17 minutes
I0614 15:01:05.150794  4603 solver.cpp:291]     Train net output #0: loss = 0.0218594 (* 1 = 0.0218594 loss)
I0614 15:01:05.150804  4603 sgd_solver.cpp:106] Iteration 7850, lr = 1e-06
I0614 15:01:17.777438  4603 solver.cpp:270] Iteration 7900 (3.96001 iter/s, 12.6262s/50 iter), loss = 0.00270253, remaining 0 hours and 17 minutes
I0614 15:01:17.777470  4603 solver.cpp:291]     Train net output #0: loss = 0.00270248 (* 1 = 0.00270248 loss)
I0614 15:01:17.777479  4603 sgd_solver.cpp:106] Iteration 7900, lr = 1e-06
I0614 15:01:30.429527  4603 solver.cpp:270] Iteration 7950 (3.95205 iter/s, 12.6516s/50 iter), loss = 0.0120025, remaining 0 hours and 16 minutes
I0614 15:01:30.429560  4603 solver.cpp:291]     Train net output #0: loss = 0.0120024 (* 1 = 0.0120024 loss)
I0614 15:01:30.429569  4603 sgd_solver.cpp:106] Iteration 7950, lr = 1e-06
I0614 15:01:42.811010  4603 solver.cpp:424] Iteration 8000, Testing net (#0)
I0614 15:01:44.322902  4603 solver.cpp:523]     Test net output #0: accuracy = 0.95775
I0614 15:01:44.322930  4603 solver.cpp:523]     Test net output #1: loss = 0.184922 (* 1 = 0.184922 loss)
I0614 15:01:44.322934  4603 solver.cpp:523]     Test net output #2: top-1 = 0.95775
I0614 15:01:44.569435  4603 solver.cpp:270] Iteration 8000 (3.53621 iter/s, 14.1394s/50 iter), loss = 0.00165323, remaining 0 hours and 18 minutes
I0614 15:01:44.569468  4603 solver.cpp:291]     Train net output #0: loss = 0.00165317 (* 1 = 0.00165317 loss)
I0614 15:01:44.569478  4603 sgd_solver.cpp:106] Iteration 8000, lr = 1e-06
I0614 15:01:57.208556  4603 solver.cpp:270] Iteration 8050 (3.95611 iter/s, 12.6387s/50 iter), loss = 0.0333605, remaining 0 hours and 16 minutes
I0614 15:01:57.208588  4603 solver.cpp:291]     Train net output #0: loss = 0.0333605 (* 1 = 0.0333605 loss)
I0614 15:01:57.208597  4603 sgd_solver.cpp:106] Iteration 8050, lr = 1e-06
I0614 15:02:09.826709  4603 solver.cpp:270] Iteration 8100 (3.96268 iter/s, 12.6177s/50 iter), loss = 0.00963269, remaining 0 hours and 16 minutes
I0614 15:02:09.826741  4603 solver.cpp:291]     Train net output #0: loss = 0.00963263 (* 1 = 0.00963263 loss)
I0614 15:02:09.826750  4603 sgd_solver.cpp:106] Iteration 8100, lr = 1e-06
I0614 15:02:22.458703  4603 solver.cpp:270] Iteration 8150 (3.95834 iter/s, 12.6316s/50 iter), loss = 0.0217387, remaining 0 hours and 16 minutes
I0614 15:02:22.458873  4603 solver.cpp:291]     Train net output #0: loss = 0.0217386 (* 1 = 0.0217386 loss)
I0614 15:02:22.458897  4603 sgd_solver.cpp:106] Iteration 8150, lr = 1e-06
I0614 15:02:35.104326  4603 solver.cpp:270] Iteration 8200 (3.95412 iter/s, 12.645s/50 iter), loss = 0.00292596, remaining 0 hours and 15 minutes
I0614 15:02:35.104360  4603 solver.cpp:291]     Train net output #0: loss = 0.00292589 (* 1 = 0.00292589 loss)
I0614 15:02:35.104372  4603 sgd_solver.cpp:106] Iteration 8200, lr = 1e-06
I0614 15:02:47.760339  4603 solver.cpp:270] Iteration 8250 (3.95083 iter/s, 12.6556s/50 iter), loss = 0.00520851, remaining 0 hours and 15 minutes
I0614 15:02:47.760371  4603 solver.cpp:291]     Train net output #0: loss = 0.00520844 (* 1 = 0.00520844 loss)
I0614 15:02:47.760380  4603 sgd_solver.cpp:106] Iteration 8250, lr = 1e-06
I0614 15:03:00.487946  4603 solver.cpp:270] Iteration 8300 (3.9286 iter/s, 12.7272s/50 iter), loss = 0.00334332, remaining 0 hours and 15 minutes
I0614 15:03:00.488060  4603 solver.cpp:291]     Train net output #0: loss = 0.00334326 (* 1 = 0.00334326 loss)
I0614 15:03:00.488071  4603 sgd_solver.cpp:106] Iteration 8300, lr = 1e-06
I0614 15:03:13.218008  4603 solver.cpp:270] Iteration 8350 (3.92787 iter/s, 12.7295s/50 iter), loss = 0.015082, remaining 0 hours and 15 minutes
I0614 15:03:13.218039  4603 solver.cpp:291]     Train net output #0: loss = 0.0150819 (* 1 = 0.0150819 loss)
I0614 15:03:13.218050  4603 sgd_solver.cpp:106] Iteration 8350, lr = 1e-06
I0614 15:03:25.850347  4603 solver.cpp:270] Iteration 8400 (3.95823 iter/s, 12.6319s/50 iter), loss = 0.00441917, remaining 0 hours and 15 minutes
I0614 15:03:25.850380  4603 solver.cpp:291]     Train net output #0: loss = 0.0044191 (* 1 = 0.0044191 loss)
I0614 15:03:25.850389  4603 sgd_solver.cpp:106] Iteration 8400, lr = 1e-06
I0614 15:03:38.471491  4603 solver.cpp:270] Iteration 8450 (3.96174 iter/s, 12.6207s/50 iter), loss = 0.00241256, remaining 0 hours and 14 minutes
I0614 15:03:38.471606  4603 solver.cpp:291]     Train net output #0: loss = 0.00241248 (* 1 = 0.00241248 loss)
I0614 15:03:38.471617  4603 sgd_solver.cpp:106] Iteration 8450, lr = 1e-06
I0614 15:03:51.115550  4603 solver.cpp:270] Iteration 8500 (3.95459 iter/s, 12.6435s/50 iter), loss = 0.0167526, remaining 0 hours and 14 minutes
I0614 15:03:51.115584  4603 solver.cpp:291]     Train net output #0: loss = 0.0167525 (* 1 = 0.0167525 loss)
I0614 15:03:51.115593  4603 sgd_solver.cpp:106] Iteration 8500, lr = 1e-06
I0614 15:04:03.764344  4603 solver.cpp:270] Iteration 8550 (3.95308 iter/s, 12.6484s/50 iter), loss = 0.0184932, remaining 0 hours and 14 minutes
I0614 15:04:03.764377  4603 solver.cpp:291]     Train net output #0: loss = 0.0184931 (* 1 = 0.0184931 loss)
I0614 15:04:03.764386  4603 sgd_solver.cpp:106] Iteration 8550, lr = 1e-06
I0614 15:04:16.406430  4603 solver.cpp:270] Iteration 8600 (3.95518 iter/s, 12.6416s/50 iter), loss = 0.0134109, remaining 0 hours and 14 minutes
I0614 15:04:16.406541  4603 solver.cpp:291]     Train net output #0: loss = 0.0134108 (* 1 = 0.0134108 loss)
I0614 15:04:16.406550  4603 sgd_solver.cpp:106] Iteration 8600, lr = 1e-06
I0614 15:04:29.042425  4603 solver.cpp:270] Iteration 8650 (3.95711 iter/s, 12.6355s/50 iter), loss = 0.00507628, remaining 0 hours and 13 minutes
I0614 15:04:29.042457  4603 solver.cpp:291]     Train net output #0: loss = 0.0050762 (* 1 = 0.0050762 loss)
I0614 15:04:29.042465  4603 sgd_solver.cpp:106] Iteration 8650, lr = 1e-06
I0614 15:04:41.659404  4603 solver.cpp:270] Iteration 8700 (3.96305 iter/s, 12.6165s/50 iter), loss = 0.0138041, remaining 0 hours and 13 minutes
I0614 15:04:41.659435  4603 solver.cpp:291]     Train net output #0: loss = 0.013804 (* 1 = 0.013804 loss)
I0614 15:04:41.659442  4603 sgd_solver.cpp:106] Iteration 8700, lr = 1e-06
I0614 15:04:54.272861  4603 solver.cpp:270] Iteration 8750 (3.96416 iter/s, 12.613s/50 iter), loss = 0.00858412, remaining 0 hours and 13 minutes
I0614 15:04:54.273034  4603 solver.cpp:291]     Train net output #0: loss = 0.00858404 (* 1 = 0.00858404 loss)
I0614 15:04:54.273043  4603 sgd_solver.cpp:106] Iteration 8750, lr = 1e-06
I0614 15:05:06.884656  4603 solver.cpp:270] Iteration 8800 (3.96472 iter/s, 12.6112s/50 iter), loss = 0.0140506, remaining 0 hours and 13 minutes
I0614 15:05:06.884687  4603 solver.cpp:291]     Train net output #0: loss = 0.0140505 (* 1 = 0.0140505 loss)
I0614 15:05:06.884696  4603 sgd_solver.cpp:106] Iteration 8800, lr = 1e-06
I0614 15:05:19.501433  4603 solver.cpp:270] Iteration 8850 (3.96311 iter/s, 12.6163s/50 iter), loss = 0.0112231, remaining 0 hours and 13 minutes
I0614 15:05:19.501464  4603 solver.cpp:291]     Train net output #0: loss = 0.0112231 (* 1 = 0.0112231 loss)
I0614 15:05:19.501473  4603 sgd_solver.cpp:106] Iteration 8850, lr = 1e-06
I0614 15:05:32.129478  4603 solver.cpp:270] Iteration 8900 (3.95958 iter/s, 12.6276s/50 iter), loss = 0.00344782, remaining 0 hours and 12 minutes
I0614 15:05:32.129696  4603 solver.cpp:291]     Train net output #0: loss = 0.00344775 (* 1 = 0.00344775 loss)
I0614 15:05:32.129705  4603 sgd_solver.cpp:106] Iteration 8900, lr = 1e-06
I0614 15:05:44.750856  4603 solver.cpp:270] Iteration 8950 (3.96173 iter/s, 12.6208s/50 iter), loss = 0.00409855, remaining 0 hours and 12 minutes
I0614 15:05:44.750890  4603 solver.cpp:291]     Train net output #0: loss = 0.00409848 (* 1 = 0.00409848 loss)
I0614 15:05:44.750897  4603 sgd_solver.cpp:106] Iteration 8950, lr = 1e-06
I0614 15:05:57.130390  4603 solver.cpp:424] Iteration 9000, Testing net (#0)
I0614 15:05:58.640962  4603 solver.cpp:523]     Test net output #0: accuracy = 0.95875
I0614 15:05:58.640990  4603 solver.cpp:523]     Test net output #1: loss = 0.201814 (* 1 = 0.201814 loss)
I0614 15:05:58.640995  4603 solver.cpp:523]     Test net output #2: top-1 = 0.95875
I0614 15:05:58.887699  4603 solver.cpp:270] Iteration 9000 (3.53698 iter/s, 14.1364s/50 iter), loss = 0.0173792, remaining 0 hours and 14 minutes
I0614 15:05:58.887732  4603 solver.cpp:291]     Train net output #0: loss = 0.0173791 (* 1 = 0.0173791 loss)
I0614 15:05:58.887740  4603 sgd_solver.cpp:106] Iteration 9000, lr = 1e-06
I0614 15:06:11.523643  4603 solver.cpp:270] Iteration 9050 (3.9571 iter/s, 12.6355s/50 iter), loss = 0.00547372, remaining 0 hours and 12 minutes
I0614 15:06:11.523761  4603 solver.cpp:291]     Train net output #0: loss = 0.00547365 (* 1 = 0.00547365 loss)
I0614 15:06:11.523785  4603 sgd_solver.cpp:106] Iteration 9050, lr = 1e-06
I0614 15:06:24.150697  4603 solver.cpp:270] Iteration 9100 (3.95992 iter/s, 12.6265s/50 iter), loss = 0.0200696, remaining 0 hours and 12 minutes
I0614 15:06:24.150730  4603 solver.cpp:291]     Train net output #0: loss = 0.0200696 (* 1 = 0.0200696 loss)
I0614 15:06:24.150738  4603 sgd_solver.cpp:106] Iteration 9100, lr = 1e-06
I0614 15:06:36.781738  4603 solver.cpp:270] Iteration 9150 (3.95864 iter/s, 12.6306s/50 iter), loss = 0.00164048, remaining 0 hours and 11 minutes
I0614 15:06:36.781770  4603 solver.cpp:291]     Train net output #0: loss = 0.00164042 (* 1 = 0.00164042 loss)
I0614 15:06:36.781795  4603 sgd_solver.cpp:106] Iteration 9150, lr = 1e-06
I0614 15:06:49.415880  4603 solver.cpp:270] Iteration 9200 (3.95767 iter/s, 12.6337s/50 iter), loss = 0.0188276, remaining 0 hours and 11 minutes
I0614 15:06:49.416028  4603 solver.cpp:291]     Train net output #0: loss = 0.0188275 (* 1 = 0.0188275 loss)
I0614 15:06:49.416036  4603 sgd_solver.cpp:106] Iteration 9200, lr = 1e-06
I0614 15:07:02.045316  4603 solver.cpp:270] Iteration 9250 (3.95918 iter/s, 12.6289s/50 iter), loss = 0.00520434, remaining 0 hours and 11 minutes
I0614 15:07:02.045347  4603 solver.cpp:291]     Train net output #0: loss = 0.00520428 (* 1 = 0.00520428 loss)
I0614 15:07:02.045356  4603 sgd_solver.cpp:106] Iteration 9250, lr = 1e-06
I0614 15:07:14.662411  4603 solver.cpp:270] Iteration 9300 (3.96302 iter/s, 12.6167s/50 iter), loss = 0.0434173, remaining 0 hours and 11 minutes
I0614 15:07:14.662446  4603 solver.cpp:291]     Train net output #0: loss = 0.0434173 (* 1 = 0.0434173 loss)
I0614 15:07:14.662469  4603 sgd_solver.cpp:106] Iteration 9300, lr = 1e-06
I0614 15:07:27.282442  4603 solver.cpp:270] Iteration 9350 (3.96209 iter/s, 12.6196s/50 iter), loss = 0.00724032, remaining 0 hours and 11 minutes
I0614 15:07:27.282615  4603 solver.cpp:291]     Train net output #0: loss = 0.00724025 (* 1 = 0.00724025 loss)
I0614 15:07:27.282625  4603 sgd_solver.cpp:106] Iteration 9350, lr = 1e-06
I0614 15:07:39.904668  4603 solver.cpp:270] Iteration 9400 (3.96145 iter/s, 12.6216s/50 iter), loss = 0.010695, remaining 0 hours and 10 minutes
I0614 15:07:39.904700  4603 solver.cpp:291]     Train net output #0: loss = 0.010695 (* 1 = 0.010695 loss)
I0614 15:07:39.904709  4603 sgd_solver.cpp:106] Iteration 9400, lr = 1e-06
I0614 15:07:52.531288  4603 solver.cpp:270] Iteration 9450 (3.96003 iter/s, 12.6262s/50 iter), loss = 0.0015523, remaining 0 hours and 10 minutes
I0614 15:07:52.531320  4603 solver.cpp:291]     Train net output #0: loss = 0.00155223 (* 1 = 0.00155223 loss)
I0614 15:07:52.531328  4603 sgd_solver.cpp:106] Iteration 9450, lr = 1e-06
I0614 15:08:05.178396  4603 solver.cpp:270] Iteration 9500 (3.95361 iter/s, 12.6467s/50 iter), loss = 0.0105361, remaining 0 hours and 10 minutes
I0614 15:08:05.178515  4603 solver.cpp:291]     Train net output #0: loss = 0.010536 (* 1 = 0.010536 loss)
I0614 15:08:05.178525  4603 sgd_solver.cpp:106] Iteration 9500, lr = 1e-06
I0614 15:08:17.807181  4603 solver.cpp:270] Iteration 9550 (3.95937 iter/s, 12.6283s/50 iter), loss = 0.000827329, remaining 0 hours and 10 minutes
I0614 15:08:17.807214  4603 solver.cpp:291]     Train net output #0: loss = 0.000827262 (* 1 = 0.000827262 loss)
I0614 15:08:17.807222  4603 sgd_solver.cpp:106] Iteration 9550, lr = 1e-06
I0614 15:08:30.427979  4603 solver.cpp:270] Iteration 9600 (3.96185 iter/s, 12.6204s/50 iter), loss = 0.0033628, remaining 0 hours and 10 minutes
I0614 15:08:30.428012  4603 solver.cpp:291]     Train net output #0: loss = 0.00336274 (* 1 = 0.00336274 loss)
I0614 15:08:30.428021  4603 sgd_solver.cpp:106] Iteration 9600, lr = 1e-06
I0614 15:08:43.062546  4603 solver.cpp:270] Iteration 9650 (3.95754 iter/s, 12.6341s/50 iter), loss = 0.00660492, remaining 0 hours and 9 minutes
I0614 15:08:43.062665  4603 solver.cpp:291]     Train net output #0: loss = 0.00660485 (* 1 = 0.00660485 loss)
I0614 15:08:43.062674  4603 sgd_solver.cpp:106] Iteration 9650, lr = 1e-06
I0614 15:08:55.697074  4603 solver.cpp:270] Iteration 9700 (3.95757 iter/s, 12.634s/50 iter), loss = 0.00361096, remaining 0 hours and 9 minutes
I0614 15:08:55.697106  4603 solver.cpp:291]     Train net output #0: loss = 0.0036109 (* 1 = 0.0036109 loss)
I0614 15:08:55.697115  4603 sgd_solver.cpp:106] Iteration 9700, lr = 1e-06
I0614 15:09:08.323354  4603 solver.cpp:270] Iteration 9750 (3.96013 iter/s, 12.6258s/50 iter), loss = 0.00738562, remaining 0 hours and 9 minutes
I0614 15:09:08.323401  4603 solver.cpp:291]     Train net output #0: loss = 0.00738555 (* 1 = 0.00738555 loss)
I0614 15:09:08.323411  4603 sgd_solver.cpp:106] Iteration 9750, lr = 1e-06
I0614 15:09:20.964157  4603 solver.cpp:270] Iteration 9800 (3.95559 iter/s, 12.6403s/50 iter), loss = 0.00328609, remaining 0 hours and 9 minutes
I0614 15:09:20.964345  4603 solver.cpp:291]     Train net output #0: loss = 0.00328602 (* 1 = 0.00328602 loss)
I0614 15:09:20.964354  4603 sgd_solver.cpp:106] Iteration 9800, lr = 1e-06
I0614 15:09:33.601279  4603 solver.cpp:270] Iteration 9850 (3.95678 iter/s, 12.6365s/50 iter), loss = 0.0189936, remaining 0 hours and 8 minutes
I0614 15:09:33.601312  4603 solver.cpp:291]     Train net output #0: loss = 0.0189935 (* 1 = 0.0189935 loss)
I0614 15:09:33.601321  4603 sgd_solver.cpp:106] Iteration 9850, lr = 1e-06
I0614 15:09:46.248644  4603 solver.cpp:270] Iteration 9900 (3.95353 iter/s, 12.6469s/50 iter), loss = 0.00322041, remaining 0 hours and 8 minutes
I0614 15:09:46.248678  4603 solver.cpp:291]     Train net output #0: loss = 0.00322034 (* 1 = 0.00322034 loss)
I0614 15:09:46.248687  4603 sgd_solver.cpp:106] Iteration 9900, lr = 1e-06
I0614 15:09:58.881343  4603 solver.cpp:270] Iteration 9950 (3.95812 iter/s, 12.6323s/50 iter), loss = 0.00334096, remaining 0 hours and 8 minutes
I0614 15:09:58.881772  4603 solver.cpp:291]     Train net output #0: loss = 0.00334089 (* 1 = 0.00334089 loss)
I0614 15:09:58.881798  4603 sgd_solver.cpp:106] Iteration 9950, lr = 1e-06
I0614 15:10:11.250247  4603 solver.cpp:424] Iteration 10000, Testing net (#0)
I0614 15:10:12.748123  4603 solver.cpp:523]     Test net output #0: accuracy = 0.9585
I0614 15:10:12.748152  4603 solver.cpp:523]     Test net output #1: loss = 0.211447 (* 1 = 0.211447 loss)
I0614 15:10:12.748157  4603 solver.cpp:523]     Test net output #2: top-1 = 0.9585
I0614 15:10:12.994237  4603 solver.cpp:270] Iteration 10000 (3.54308 iter/s, 14.112s/50 iter), loss = 0.00928999, remaining 0 hours and 9 minutes
I0614 15:10:12.994269  4603 solver.cpp:291]     Train net output #0: loss = 0.00928992 (* 1 = 0.00928992 loss)
I0614 15:10:12.994278  4603 sgd_solver.cpp:106] Iteration 10000, lr = 1e-07
I0614 15:10:25.613881  4603 solver.cpp:270] Iteration 10050 (3.96221 iter/s, 12.6192s/50 iter), loss = 0.00147348, remaining 0 hours and 8 minutes
I0614 15:10:25.613914  4603 solver.cpp:291]     Train net output #0: loss = 0.0014734 (* 1 = 0.0014734 loss)
I0614 15:10:25.613924  4603 sgd_solver.cpp:106] Iteration 10050, lr = 1e-07
I0614 15:10:38.237604  4603 solver.cpp:270] Iteration 10100 (3.96093 iter/s, 12.6233s/50 iter), loss = 0.0025071, remaining 0 hours and 7 minutes
I0614 15:10:38.237721  4603 solver.cpp:291]     Train net output #0: loss = 0.00250703 (* 1 = 0.00250703 loss)
I0614 15:10:38.237746  4603 sgd_solver.cpp:106] Iteration 10100, lr = 1e-07
I0614 15:10:50.849133  4603 solver.cpp:270] Iteration 10150 (3.96479 iter/s, 12.611s/50 iter), loss = 0.00475289, remaining 0 hours and 7 minutes
I0614 15:10:50.849166  4603 solver.cpp:291]     Train net output #0: loss = 0.00475282 (* 1 = 0.00475282 loss)
I0614 15:10:50.849174  4603 sgd_solver.cpp:106] Iteration 10150, lr = 1e-07
I0614 15:11:03.481106  4603 solver.cpp:270] Iteration 10200 (3.95835 iter/s, 12.6315s/50 iter), loss = 0.00826572, remaining 0 hours and 7 minutes
I0614 15:11:03.481138  4603 solver.cpp:291]     Train net output #0: loss = 0.00826565 (* 1 = 0.00826565 loss)
I0614 15:11:03.481148  4603 sgd_solver.cpp:106] Iteration 10200, lr = 1e-07
I0614 15:11:16.096673  4603 solver.cpp:270] Iteration 10250 (3.9635 iter/s, 12.6151s/50 iter), loss = 0.00559568, remaining 0 hours and 7 minutes
I0614 15:11:16.096848  4603 solver.cpp:291]     Train net output #0: loss = 0.00559561 (* 1 = 0.00559561 loss)
I0614 15:11:16.096874  4603 sgd_solver.cpp:106] Iteration 10250, lr = 1e-07
I0614 15:11:28.722959  4603 solver.cpp:270] Iteration 10300 (3.96018 iter/s, 12.6257s/50 iter), loss = 0.00745854, remaining 0 hours and 7 minutes
I0614 15:11:28.722990  4603 solver.cpp:291]     Train net output #0: loss = 0.00745847 (* 1 = 0.00745847 loss)
I0614 15:11:28.722998  4603 sgd_solver.cpp:106] Iteration 10300, lr = 1e-07
I0614 15:11:41.351948  4603 solver.cpp:270] Iteration 10350 (3.95928 iter/s, 12.6285s/50 iter), loss = 0.00250516, remaining 0 hours and 6 minutes
I0614 15:11:41.351984  4603 solver.cpp:291]     Train net output #0: loss = 0.00250509 (* 1 = 0.00250509 loss)
I0614 15:11:41.351994  4603 sgd_solver.cpp:106] Iteration 10350, lr = 1e-07
I0614 15:11:53.964098  4603 solver.cpp:270] Iteration 10400 (3.96457 iter/s, 12.6117s/50 iter), loss = 0.000769353, remaining 0 hours and 6 minutes
I0614 15:11:53.964459  4603 solver.cpp:291]     Train net output #0: loss = 0.000769286 (* 1 = 0.000769286 loss)
I0614 15:11:53.964468  4603 sgd_solver.cpp:106] Iteration 10400, lr = 1e-07
I0614 15:12:06.590843  4603 solver.cpp:270] Iteration 10450 (3.96009 iter/s, 12.626s/50 iter), loss = 0.00846651, remaining 0 hours and 6 minutes
I0614 15:12:06.590876  4603 solver.cpp:291]     Train net output #0: loss = 0.00846644 (* 1 = 0.00846644 loss)
I0614 15:12:06.590884  4603 sgd_solver.cpp:106] Iteration 10450, lr = 1e-07
I0614 15:12:19.231324  4603 solver.cpp:270] Iteration 10500 (3.95568 iter/s, 12.64s/50 iter), loss = 0.00264035, remaining 0 hours and 6 minutes
I0614 15:12:19.231355  4603 solver.cpp:291]     Train net output #0: loss = 0.00264029 (* 1 = 0.00264029 loss)
I0614 15:12:19.231364  4603 sgd_solver.cpp:106] Iteration 10500, lr = 1e-07
I0614 15:12:31.867547  4603 solver.cpp:270] Iteration 10550 (3.95702 iter/s, 12.6358s/50 iter), loss = 0.0502275, remaining 0 hours and 6 minutes
I0614 15:12:31.867808  4603 solver.cpp:291]     Train net output #0: loss = 0.0502274 (* 1 = 0.0502274 loss)
I0614 15:12:31.867816  4603 sgd_solver.cpp:106] Iteration 10550, lr = 1e-07
I0614 15:12:44.493643  4603 solver.cpp:270] Iteration 10600 (3.96026 iter/s, 12.6254s/50 iter), loss = 0.00100413, remaining 0 hours and 5 minutes
I0614 15:12:44.493675  4603 solver.cpp:291]     Train net output #0: loss = 0.00100406 (* 1 = 0.00100406 loss)
I0614 15:12:44.493683  4603 sgd_solver.cpp:106] Iteration 10600, lr = 1e-07
I0614 15:12:57.119274  4603 solver.cpp:270] Iteration 10650 (3.96034 iter/s, 12.6252s/50 iter), loss = 0.00366316, remaining 0 hours and 5 minutes
I0614 15:12:57.119307  4603 solver.cpp:291]     Train net output #0: loss = 0.00366309 (* 1 = 0.00366309 loss)
I0614 15:12:57.119331  4603 sgd_solver.cpp:106] Iteration 10650, lr = 1e-07
I0614 15:13:09.732142  4603 solver.cpp:270] Iteration 10700 (3.96434 iter/s, 12.6124s/50 iter), loss = 0.0025512, remaining 0 hours and 5 minutes
I0614 15:13:09.732401  4603 solver.cpp:291]     Train net output #0: loss = 0.00255113 (* 1 = 0.00255113 loss)
I0614 15:13:09.732410  4603 sgd_solver.cpp:106] Iteration 10700, lr = 1e-07
I0614 15:13:22.377332  4603 solver.cpp:270] Iteration 10750 (3.95428 iter/s, 12.6445s/50 iter), loss = 0.0327219, remaining 0 hours and 5 minutes
I0614 15:13:22.377362  4603 solver.cpp:291]     Train net output #0: loss = 0.0327218 (* 1 = 0.0327218 loss)
I0614 15:13:22.377370  4603 sgd_solver.cpp:106] Iteration 10750, lr = 1e-07
I0614 15:13:35.005925  4603 solver.cpp:270] Iteration 10800 (3.95941 iter/s, 12.6282s/50 iter), loss = 0.0112865, remaining 0 hours and 5 minutes
I0614 15:13:35.005957  4603 solver.cpp:291]     Train net output #0: loss = 0.0112864 (* 1 = 0.0112864 loss)
I0614 15:13:35.005965  4603 sgd_solver.cpp:106] Iteration 10800, lr = 1e-07
I0614 15:13:47.644352  4603 solver.cpp:270] Iteration 10850 (3.95633 iter/s, 12.638s/50 iter), loss = 0.0293587, remaining 0 hours and 4 minutes
I0614 15:13:47.644559  4603 solver.cpp:291]     Train net output #0: loss = 0.0293586 (* 1 = 0.0293586 loss)
I0614 15:13:47.644568  4603 sgd_solver.cpp:106] Iteration 10850, lr = 1e-07
I0614 15:14:00.264554  4603 solver.cpp:270] Iteration 10900 (3.96209 iter/s, 12.6196s/50 iter), loss = 0.0238834, remaining 0 hours and 4 minutes
I0614 15:14:00.264585  4603 solver.cpp:291]     Train net output #0: loss = 0.0238833 (* 1 = 0.0238833 loss)
I0614 15:14:00.264593  4603 sgd_solver.cpp:106] Iteration 10900, lr = 1e-07
I0614 15:14:12.886127  4603 solver.cpp:270] Iteration 10950 (3.96161 iter/s, 12.6211s/50 iter), loss = 0.0114142, remaining 0 hours and 4 minutes
I0614 15:14:12.886159  4603 solver.cpp:291]     Train net output #0: loss = 0.0114141 (* 1 = 0.0114141 loss)
I0614 15:14:12.886168  4603 sgd_solver.cpp:106] Iteration 10950, lr = 1e-07
I0614 15:14:25.259183  4603 solver.cpp:424] Iteration 11000, Testing net (#0)
I0614 15:14:26.763434  4603 solver.cpp:523]     Test net output #0: accuracy = 0.95825
I0614 15:14:26.763463  4603 solver.cpp:523]     Test net output #1: loss = 0.21616 (* 1 = 0.21616 loss)
I0614 15:14:26.763468  4603 solver.cpp:523]     Test net output #2: top-1 = 0.95825
I0614 15:14:27.009851  4603 solver.cpp:270] Iteration 11000 (3.54026 iter/s, 14.1232s/50 iter), loss = 0.0189324, remaining 0 hours and 4 minutes
I0614 15:14:27.009883  4603 solver.cpp:291]     Train net output #0: loss = 0.0189323 (* 1 = 0.0189323 loss)
I0614 15:14:27.009892  4603 sgd_solver.cpp:106] Iteration 11000, lr = 1e-07
I0614 15:14:39.633764  4603 solver.cpp:270] Iteration 11050 (3.96088 iter/s, 12.6235s/50 iter), loss = 0.00624643, remaining 0 hours and 3 minutes
I0614 15:14:39.633795  4603 solver.cpp:291]     Train net output #0: loss = 0.00624636 (* 1 = 0.00624636 loss)
I0614 15:14:39.633817  4603 sgd_solver.cpp:106] Iteration 11050, lr = 1e-07
I0614 15:14:52.263039  4603 solver.cpp:270] Iteration 11100 (3.95919 iter/s, 12.6288s/50 iter), loss = 0.012198, remaining 0 hours and 3 minutes
I0614 15:14:52.263070  4603 solver.cpp:291]     Train net output #0: loss = 0.012198 (* 1 = 0.012198 loss)
I0614 15:14:52.263079  4603 sgd_solver.cpp:106] Iteration 11100, lr = 1e-07
I0614 15:15:04.884907  4603 solver.cpp:270] Iteration 11150 (3.96152 iter/s, 12.6214s/50 iter), loss = 0.00138885, remaining 0 hours and 3 minutes
I0614 15:15:04.885212  4603 solver.cpp:291]     Train net output #0: loss = 0.00138878 (* 1 = 0.00138878 loss)
I0614 15:15:04.885236  4603 sgd_solver.cpp:106] Iteration 11150, lr = 1e-07
I0614 15:15:17.501142  4603 solver.cpp:270] Iteration 11200 (3.96337 iter/s, 12.6155s/50 iter), loss = 0.00432818, remaining 0 hours and 3 minutes
I0614 15:15:17.501171  4603 solver.cpp:291]     Train net output #0: loss = 0.00432812 (* 1 = 0.00432812 loss)
I0614 15:15:17.501179  4603 sgd_solver.cpp:106] Iteration 11200, lr = 1e-07
I0614 15:15:30.125128  4603 solver.cpp:270] Iteration 11250 (3.96085 iter/s, 12.6236s/50 iter), loss = 0.003033, remaining 0 hours and 3 minutes
I0614 15:15:30.125161  4603 solver.cpp:291]     Train net output #0: loss = 0.00303294 (* 1 = 0.00303294 loss)
I0614 15:15:30.125169  4603 sgd_solver.cpp:106] Iteration 11250, lr = 1e-07
I0614 15:15:42.773911  4603 solver.cpp:270] Iteration 11300 (3.95309 iter/s, 12.6483s/50 iter), loss = 0.00487594, remaining 0 hours and 2 minutes
I0614 15:15:42.774159  4603 solver.cpp:291]     Train net output #0: loss = 0.00487587 (* 1 = 0.00487587 loss)
I0614 15:15:42.774184  4603 sgd_solver.cpp:106] Iteration 11300, lr = 1e-07
I0614 15:15:55.396277  4603 solver.cpp:270] Iteration 11350 (3.96143 iter/s, 12.6217s/50 iter), loss = 0.00267739, remaining 0 hours and 2 minutes
I0614 15:15:55.396307  4603 solver.cpp:291]     Train net output #0: loss = 0.00267732 (* 1 = 0.00267732 loss)
I0614 15:15:55.396330  4603 sgd_solver.cpp:106] Iteration 11350, lr = 1e-07
I0614 15:16:08.022833  4603 solver.cpp:270] Iteration 11400 (3.96005 iter/s, 12.6261s/50 iter), loss = 0.00218894, remaining 0 hours and 2 minutes
I0614 15:16:08.022866  4603 solver.cpp:291]     Train net output #0: loss = 0.00218888 (* 1 = 0.00218888 loss)
I0614 15:16:08.022873  4603 sgd_solver.cpp:106] Iteration 11400, lr = 1e-07
I0614 15:16:20.635996  4603 solver.cpp:270] Iteration 11450 (3.96425 iter/s, 12.6127s/50 iter), loss = 0.00217317, remaining 0 hours and 2 minutes
I0614 15:16:20.636253  4603 solver.cpp:291]     Train net output #0: loss = 0.00217311 (* 1 = 0.00217311 loss)
I0614 15:16:20.636262  4603 sgd_solver.cpp:106] Iteration 11450, lr = 1e-07
I0614 15:16:33.259243  4603 solver.cpp:270] Iteration 11500 (3.96115 iter/s, 12.6226s/50 iter), loss = 0.0122471, remaining 0 hours and 2 minutes
I0614 15:16:33.259274  4603 solver.cpp:291]     Train net output #0: loss = 0.012247 (* 1 = 0.012247 loss)
I0614 15:16:33.259282  4603 sgd_solver.cpp:106] Iteration 11500, lr = 1e-07
I0614 15:16:45.881336  4603 solver.cpp:270] Iteration 11550 (3.96144 iter/s, 12.6217s/50 iter), loss = 0.00539529, remaining 0 hours and 1 minutes
I0614 15:16:45.881366  4603 solver.cpp:291]     Train net output #0: loss = 0.00539522 (* 1 = 0.00539522 loss)
I0614 15:16:45.881374  4603 sgd_solver.cpp:106] Iteration 11550, lr = 1e-07
I0614 15:16:58.487334  4603 solver.cpp:270] Iteration 11600 (3.9665 iter/s, 12.6056s/50 iter), loss = 0.00576386, remaining 0 hours and 1 minutes
I0614 15:16:58.487681  4603 solver.cpp:291]     Train net output #0: loss = 0.00576379 (* 1 = 0.00576379 loss)
I0614 15:16:58.487705  4603 sgd_solver.cpp:106] Iteration 11600, lr = 1e-07
I0614 15:17:11.130398  4603 solver.cpp:270] Iteration 11650 (3.95497 iter/s, 12.6423s/50 iter), loss = 0.021611, remaining 0 hours and 1 minutes
I0614 15:17:11.130430  4603 solver.cpp:291]     Train net output #0: loss = 0.021611 (* 1 = 0.021611 loss)
I0614 15:17:11.130439  4603 sgd_solver.cpp:106] Iteration 11650, lr = 1e-07
I0614 15:17:23.750205  4603 solver.cpp:270] Iteration 11700 (3.96216 iter/s, 12.6194s/50 iter), loss = 0.00170697, remaining 0 hours and 1 minutes
I0614 15:17:23.750236  4603 solver.cpp:291]     Train net output #0: loss = 0.0017069 (* 1 = 0.0017069 loss)
I0614 15:17:23.750245  4603 sgd_solver.cpp:106] Iteration 11700, lr = 1e-07
I0614 15:17:36.385378  4603 solver.cpp:270] Iteration 11750 (3.95735 iter/s, 12.6347s/50 iter), loss = 0.00149652, remaining 0 hours and 1 minutes
I0614 15:17:36.385629  4603 solver.cpp:291]     Train net output #0: loss = 0.00149646 (* 1 = 0.00149646 loss)
I0614 15:17:36.385654  4603 sgd_solver.cpp:106] Iteration 11750, lr = 1e-07
I0614 15:17:48.996434  4603 solver.cpp:270] Iteration 11800 (3.96498 iter/s, 12.6104s/50 iter), loss = 0.0301605, remaining 0 hours and 0 minutes
I0614 15:17:48.996467  4603 solver.cpp:291]     Train net output #0: loss = 0.0301604 (* 1 = 0.0301604 loss)
I0614 15:17:48.996491  4603 sgd_solver.cpp:106] Iteration 11800, lr = 1e-07
I0614 15:18:01.617139  4603 solver.cpp:270] Iteration 11850 (3.96188 iter/s, 12.6203s/50 iter), loss = 0.00455596, remaining 0 hours and 0 minutes
I0614 15:18:01.617169  4603 solver.cpp:291]     Train net output #0: loss = 0.0045559 (* 1 = 0.0045559 loss)
I0614 15:18:01.617177  4603 sgd_solver.cpp:106] Iteration 11850, lr = 1e-07
I0614 15:18:14.231674  4603 solver.cpp:270] Iteration 11900 (3.96382 iter/s, 12.6141s/50 iter), loss = 0.0216268, remaining 0 hours and 0 minutes
I0614 15:18:14.231946  4603 solver.cpp:291]     Train net output #0: loss = 0.0216268 (* 1 = 0.0216268 loss)
I0614 15:18:14.231956  4603 sgd_solver.cpp:106] Iteration 11900, lr = 1e-07
I0614 15:18:26.843991  4603 solver.cpp:270] Iteration 11950 (3.96459 iter/s, 12.6116s/50 iter), loss = 0.00456041, remaining 0 hours and 0 minutes
I0614 15:18:26.844023  4603 solver.cpp:291]     Train net output #0: loss = 0.00456035 (* 1 = 0.00456035 loss)
I0614 15:18:26.844031  4603 sgd_solver.cpp:106] Iteration 11950, lr = 1e-07
I0614 15:18:39.243501  4603 solver.cpp:935] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.2/snapshots/_iter_12000.caffemodel
I0614 15:18:45.143982  4603 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.2/snapshots/_iter_12000.solverstate
I0614 15:18:48.707412  4603 solver.cpp:384] Iteration 12000, loss = 0.00483227
I0614 15:18:48.707435  4603 solver.cpp:424] Iteration 12000, Testing net (#0)
I0614 15:18:50.114997  4603 solver.cpp:523]     Test net output #0: accuracy = 0.95825
I0614 15:18:50.115026  4603 solver.cpp:523]     Test net output #1: loss = 0.218328 (* 1 = 0.218328 loss)
I0614 15:18:50.115031  4603 solver.cpp:523]     Test net output #2: top-1 = 0.95825
I0614 15:18:50.115036  4603 solver.cpp:392] Optimization Done (3.93433 iter/s).
I0614 15:18:50.115039  4603 caffe_interface.cpp:576] Optimization Done.
(c) Copyright 2016â2019 Xilinx, Inc. All rights reserved.

I0614 15:18:51.230435  4700 pruning_runner.cpp:234] Analysis info found.
I0614 15:18:52.940284  4700 pruning_runner.cpp:265] Start pruning, please wait...
I0614 15:19:02.021103  4700 pruning_runner.cpp:312] Compression complete 0%
I0614 15:19:11.120595  4700 pruning_runner.cpp:312] Compression complete 0%
I0614 15:19:20.046316  4700 pruning_runner.cpp:312] Compression complete 0%
I0614 15:19:28.883374  4700 pruning_runner.cpp:312] Compression complete 0%
I0614 15:19:37.967010  4700 pruning_runner.cpp:312] Compression complete 0%
I0614 15:19:48.714169  4700 pruning_runner.cpp:312] Compression complete 0%
I0614 15:19:57.859637  4700 pruning_runner.cpp:312] Compression complete 0%
I0614 15:20:07.194736  4700 pruning_runner.cpp:312] Compression complete 0%
I0614 15:20:16.442387  4700 pruning_runner.cpp:312] Compression complete 0%
I0614 15:20:25.278466  4700 pruning_runner.cpp:312] Compression complete 0%
I0614 15:20:36.437609  4700 pruning_runner.cpp:365] pruning done, output model: pruning/alexnetBNnoLRN/regular_rate_0.3/sparse.caffemodel
I0614 15:20:36.437640  4700 pruning_runner.cpp:379] summary of REGULAR compression with rate 0.3:
+-------------------------------------------------------------------+
| Item           | Baseline       | Compressed     | Delta          |
+-------------------------------------------------------------------+
| Accuracy       | 0.953499794    | 0.958249748    | 0.00474995375  |
+-------------------------------------------------------------------+
| Weights        | 3.74857903 M   | 1.15144897 M   | -69.2830582%   |
+-------------------------------------------------------------------+
| Operations     | 2.05460167 G   | 1.17685986 G   | -42.7207718%   |
+-------------------------------------------------------------------+
To fine-tune the pruned model, please run:
vai_p_caffe finetune -config /workspace/TUTORIALS/VAI2.0bash-Caffe-ML-CATSvsDOGS/files/pruning/alexnetBNnoLRN/config3.prototxt
(c) Copyright 2016â2019 Xilinx, Inc. All rights reserved.

W0614 15:20:36.984388  5755 utils.cpp:207] BVLC BatchNormLayer without ScaleLayer detected: 3, it will be converted to NVCaffe Format.
W0614 15:20:36.986052  5755 utils.cpp:207] BVLC BatchNormLayer without ScaleLayer detected: 7, it will be converted to NVCaffe Format.
W0614 15:20:36.986122  5755 utils.cpp:207] BVLC BatchNormLayer without ScaleLayer detected: 21, it will be converted to NVCaffe Format.
I0614 15:20:36.996277  5755 vai_p_caffe.cpp:287] pruning/alexnetBNnoLRN/regular_rate_0.3/net_finetune.prototxt
I0614 15:20:37.214303  5755 gpu_memory.cpp:53] GPUMemory::Manager initialized with Caching (CUB) GPU Allocator
I0614 15:20:37.214323  5755 gpu_memory.cpp:55] Total memory: 25635127296, Free: 24705433600, dev_info[0]: total=25635127296 free=24705433600
I0614 15:20:37.214459  5755 caffe_interface.cpp:539] Using GPUs 0
I0614 15:20:37.214546  5755 caffe_interface.cpp:544] GPU 0: Quadro P6000
I0614 15:20:37.884258  5755 solver.cpp:51] Initializing solver from parameters: 
test_iter: 80
test_interval: 1000
base_lr: 0.001
display: 50
max_iter: 12000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 2500
snapshot: 6000
snapshot_prefix: "pruning/alexnetBNnoLRN/regular_rate_0.3/snapshots/"
solver_mode: GPU
device_id: 0
random_seed: 1201
net: "pruning/alexnetBNnoLRN/regular_rate_0.3/net_finetune.prototxt"
type: "Adam"
I0614 15:20:37.885231  5755 solver.cpp:99] Creating training net from net file: pruning/alexnetBNnoLRN/regular_rate_0.3/net_finetune.prototxt
I0614 15:20:37.886004  5755 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0614 15:20:37.886019  5755 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0614 15:20:37.886023  5755 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy-top1
I0614 15:20:37.886031  5755 net.cpp:52] Initializing net from parameters: 
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_value: 106
    mean_value: 116
    mean_value: 124
  }
  data_param {
    source: "input/lmdb/train_lmdb"
    batch_size: 256
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 0
    kernel_size: 8
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "bn1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn2"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "bn2"
  top: "relu2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "relu6"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "drop6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn7"
  type: "BatchNorm"
  bottom: "fc7"
  top: "bn7"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "bn7"
  top: "relu7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "relu7"
  top: "drop7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "drop7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0614 15:20:37.886636  5755 layer_factory.hpp:77] Creating layer data
I0614 15:20:37.886787  5755 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0614 15:20:37.888938  5755 net.cpp:94] Creating Layer data
I0614 15:20:37.888954  5755 net.cpp:409] data -> data
I0614 15:20:37.888970  5755 net.cpp:409] data -> label
I0614 15:20:37.891216  5792 db_lmdb.cpp:35] Opened lmdb input/lmdb/train_lmdb
I0614 15:20:37.891254  5792 db_lmdb.cpp:38] Items count: 20000
I0614 15:20:37.891294  5792 data_reader.cpp:124] TRAIN: reading data using 1 channel(s)
I0614 15:20:37.891670  5755 data_layer.cpp:78] ReshapePrefetch 256, 3, 227, 227
I0614 15:20:37.891721  5755 data_layer.cpp:83] output data size: 256,3,227,227
I0614 15:20:38.423135  5755 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0614 15:20:38.423285  5755 net.cpp:144] Setting up data
I0614 15:20:38.423290  5755 net.cpp:151] Top shape: 256 3 227 227 (39574272)
I0614 15:20:38.423300  5755 net.cpp:151] Top shape: 256 (256)
I0614 15:20:38.423303  5755 net.cpp:159] Memory required for data: 158298112
I0614 15:20:38.423307  5755 layer_factory.hpp:77] Creating layer conv1
I0614 15:20:38.423319  5755 net.cpp:94] Creating Layer conv1
I0614 15:20:38.423322  5755 net.cpp:435] conv1 <- data
I0614 15:20:38.423328  5755 net.cpp:409] conv1 -> conv1
I0614 15:20:38.423811  5755 net.cpp:144] Setting up conv1
I0614 15:20:38.423820  5755 net.cpp:151] Top shape: 256 96 55 55 (74342400)
I0614 15:20:38.423825  5755 net.cpp:159] Memory required for data: 455667712
I0614 15:20:38.423835  5755 layer_factory.hpp:77] Creating layer bn1
I0614 15:20:38.423842  5755 net.cpp:94] Creating Layer bn1
I0614 15:20:38.423846  5755 net.cpp:435] bn1 <- conv1
I0614 15:20:38.423851  5755 net.cpp:409] bn1 -> bn1
I0614 15:20:38.424140  5755 net.cpp:144] Setting up bn1
I0614 15:20:38.424146  5755 net.cpp:151] Top shape: 256 96 55 55 (74342400)
I0614 15:20:38.424151  5755 net.cpp:159] Memory required for data: 753037312
I0614 15:20:38.424161  5755 layer_factory.hpp:77] Creating layer relu1
I0614 15:20:38.424166  5755 net.cpp:94] Creating Layer relu1
I0614 15:20:38.424170  5755 net.cpp:435] relu1 <- bn1
I0614 15:20:38.424175  5755 net.cpp:409] relu1 -> relu1
I0614 15:20:38.424186  5755 net.cpp:144] Setting up relu1
I0614 15:20:38.424190  5755 net.cpp:151] Top shape: 256 96 55 55 (74342400)
I0614 15:20:38.424196  5755 net.cpp:159] Memory required for data: 1050406912
I0614 15:20:38.424198  5755 layer_factory.hpp:77] Creating layer pool1
I0614 15:20:38.424218  5755 net.cpp:94] Creating Layer pool1
I0614 15:20:38.424222  5755 net.cpp:435] pool1 <- relu1
I0614 15:20:38.424227  5755 net.cpp:409] pool1 -> pool1
I0614 15:20:38.424245  5755 net.cpp:144] Setting up pool1
I0614 15:20:38.424249  5755 net.cpp:151] Top shape: 256 96 27 27 (17915904)
I0614 15:20:38.424253  5755 net.cpp:159] Memory required for data: 1122070528
I0614 15:20:38.424257  5755 layer_factory.hpp:77] Creating layer conv2
I0614 15:20:38.424264  5755 net.cpp:94] Creating Layer conv2
I0614 15:20:38.424268  5755 net.cpp:435] conv2 <- pool1
I0614 15:20:38.424273  5755 net.cpp:409] conv2 -> conv2
I0614 15:20:38.440855  5755 net.cpp:144] Setting up conv2
I0614 15:20:38.440873  5755 net.cpp:151] Top shape: 256 256 27 27 (47775744)
I0614 15:20:38.440882  5755 net.cpp:159] Memory required for data: 1313173504
I0614 15:20:38.440893  5755 layer_factory.hpp:77] Creating layer bn2
I0614 15:20:38.440903  5755 net.cpp:94] Creating Layer bn2
I0614 15:20:38.440908  5755 net.cpp:435] bn2 <- conv2
I0614 15:20:38.440917  5755 net.cpp:409] bn2 -> bn2
I0614 15:20:38.441239  5755 net.cpp:144] Setting up bn2
I0614 15:20:38.441249  5755 net.cpp:151] Top shape: 256 256 27 27 (47775744)
I0614 15:20:38.441256  5755 net.cpp:159] Memory required for data: 1504276480
I0614 15:20:38.441267  5755 layer_factory.hpp:77] Creating layer relu2
I0614 15:20:38.441274  5755 net.cpp:94] Creating Layer relu2
I0614 15:20:38.441279  5755 net.cpp:435] relu2 <- bn2
I0614 15:20:38.441284  5755 net.cpp:409] relu2 -> relu2
I0614 15:20:38.441303  5755 net.cpp:144] Setting up relu2
I0614 15:20:38.441308  5755 net.cpp:151] Top shape: 256 256 27 27 (47775744)
I0614 15:20:38.441316  5755 net.cpp:159] Memory required for data: 1695379456
I0614 15:20:38.441323  5755 layer_factory.hpp:77] Creating layer pool2
I0614 15:20:38.441330  5755 net.cpp:94] Creating Layer pool2
I0614 15:20:38.441335  5755 net.cpp:435] pool2 <- relu2
I0614 15:20:38.441341  5755 net.cpp:409] pool2 -> pool2
I0614 15:20:38.441359  5755 net.cpp:144] Setting up pool2
I0614 15:20:38.441365  5755 net.cpp:151] Top shape: 256 256 13 13 (11075584)
I0614 15:20:38.441372  5755 net.cpp:159] Memory required for data: 1739681792
I0614 15:20:38.441386  5755 layer_factory.hpp:77] Creating layer conv3
I0614 15:20:38.441769  5755 net.cpp:94] Creating Layer conv3
I0614 15:20:38.441797  5755 net.cpp:435] conv3 <- pool2
I0614 15:20:38.441817  5755 net.cpp:409] conv3 -> conv3
I0614 15:20:38.475056  5755 net.cpp:144] Setting up conv3
I0614 15:20:38.475078  5755 net.cpp:151] Top shape: 256 384 13 13 (16613376)
I0614 15:20:38.475090  5755 net.cpp:159] Memory required for data: 1806135296
I0614 15:20:38.475101  5755 layer_factory.hpp:77] Creating layer relu3
I0614 15:20:38.475111  5755 net.cpp:94] Creating Layer relu3
I0614 15:20:38.475116  5755 net.cpp:435] relu3 <- conv3
I0614 15:20:38.475124  5755 net.cpp:409] relu3 -> relu3
I0614 15:20:38.475145  5755 net.cpp:144] Setting up relu3
I0614 15:20:38.475150  5755 net.cpp:151] Top shape: 256 384 13 13 (16613376)
I0614 15:20:38.475157  5755 net.cpp:159] Memory required for data: 1872588800
I0614 15:20:38.475163  5755 layer_factory.hpp:77] Creating layer conv4
I0614 15:20:38.475178  5755 net.cpp:94] Creating Layer conv4
I0614 15:20:38.475183  5755 net.cpp:435] conv4 <- relu3
I0614 15:20:38.475189  5755 net.cpp:409] conv4 -> conv4
I0614 15:20:38.493592  5755 net.cpp:144] Setting up conv4
I0614 15:20:38.493657  5755 net.cpp:151] Top shape: 256 384 13 13 (16613376)
I0614 15:20:38.493670  5755 net.cpp:159] Memory required for data: 1939042304
I0614 15:20:38.493692  5755 layer_factory.hpp:77] Creating layer relu4
I0614 15:20:38.493702  5755 net.cpp:94] Creating Layer relu4
I0614 15:20:38.493708  5755 net.cpp:435] relu4 <- conv4
I0614 15:20:38.493731  5755 net.cpp:409] relu4 -> relu4
I0614 15:20:38.493767  5755 net.cpp:144] Setting up relu4
I0614 15:20:38.493772  5755 net.cpp:151] Top shape: 256 384 13 13 (16613376)
I0614 15:20:38.493779  5755 net.cpp:159] Memory required for data: 2005495808
I0614 15:20:38.493785  5755 layer_factory.hpp:77] Creating layer conv5
I0614 15:20:38.493796  5755 net.cpp:94] Creating Layer conv5
I0614 15:20:38.493801  5755 net.cpp:435] conv5 <- relu4
I0614 15:20:38.493808  5755 net.cpp:409] conv5 -> conv5
I0614 15:20:38.531550  5755 net.cpp:144] Setting up conv5
I0614 15:20:38.531574  5755 net.cpp:151] Top shape: 256 256 13 13 (11075584)
I0614 15:20:38.531585  5755 net.cpp:159] Memory required for data: 2049798144
I0614 15:20:38.531615  5755 layer_factory.hpp:77] Creating layer relu5
I0614 15:20:38.531623  5755 net.cpp:94] Creating Layer relu5
I0614 15:20:38.531628  5755 net.cpp:435] relu5 <- conv5
I0614 15:20:38.531636  5755 net.cpp:409] relu5 -> relu5
I0614 15:20:38.531658  5755 net.cpp:144] Setting up relu5
I0614 15:20:38.531662  5755 net.cpp:151] Top shape: 256 256 13 13 (11075584)
I0614 15:20:38.531667  5755 net.cpp:159] Memory required for data: 2094100480
I0614 15:20:38.531672  5755 layer_factory.hpp:77] Creating layer pool5
I0614 15:20:38.531677  5755 net.cpp:94] Creating Layer pool5
I0614 15:20:38.531682  5755 net.cpp:435] pool5 <- relu5
I0614 15:20:38.531687  5755 net.cpp:409] pool5 -> pool5
I0614 15:20:38.531711  5755 net.cpp:144] Setting up pool5
I0614 15:20:38.531718  5755 net.cpp:151] Top shape: 256 256 6 6 (2359296)
I0614 15:20:38.531723  5755 net.cpp:159] Memory required for data: 2103537664
I0614 15:20:38.531728  5755 layer_factory.hpp:77] Creating layer fc6
I0614 15:20:38.531739  5755 net.cpp:94] Creating Layer fc6
I0614 15:20:38.531744  5755 net.cpp:435] fc6 <- pool5
I0614 15:20:38.531749  5755 net.cpp:409] fc6 -> fc6
I0614 15:20:38.954598  5755 net.cpp:144] Setting up fc6
I0614 15:20:38.954625  5755 net.cpp:151] Top shape: 256 4096 (1048576)
I0614 15:20:38.954634  5755 net.cpp:159] Memory required for data: 2107731968
I0614 15:20:38.954659  5755 layer_factory.hpp:77] Creating layer relu6
I0614 15:20:38.954666  5755 net.cpp:94] Creating Layer relu6
I0614 15:20:38.954670  5755 net.cpp:435] relu6 <- fc6
I0614 15:20:38.954676  5755 net.cpp:409] relu6 -> relu6
I0614 15:20:38.954691  5755 net.cpp:144] Setting up relu6
I0614 15:20:38.954694  5755 net.cpp:151] Top shape: 256 4096 (1048576)
I0614 15:20:38.954699  5755 net.cpp:159] Memory required for data: 2111926272
I0614 15:20:38.954701  5755 layer_factory.hpp:77] Creating layer drop6
I0614 15:20:38.954707  5755 net.cpp:94] Creating Layer drop6
I0614 15:20:38.955195  5755 net.cpp:435] drop6 <- relu6
I0614 15:20:38.955205  5755 net.cpp:409] drop6 -> drop6
I0614 15:20:38.955231  5755 net.cpp:144] Setting up drop6
I0614 15:20:38.955236  5755 net.cpp:151] Top shape: 256 4096 (1048576)
I0614 15:20:38.955242  5755 net.cpp:159] Memory required for data: 2116120576
I0614 15:20:38.955247  5755 layer_factory.hpp:77] Creating layer fc7
I0614 15:20:38.955256  5755 net.cpp:94] Creating Layer fc7
I0614 15:20:38.955260  5755 net.cpp:435] fc7 <- drop6
I0614 15:20:38.955264  5755 net.cpp:409] fc7 -> fc7
I0614 15:20:39.113294  5755 net.cpp:144] Setting up fc7
I0614 15:20:39.113322  5755 net.cpp:151] Top shape: 256 4096 (1048576)
I0614 15:20:39.113329  5755 net.cpp:159] Memory required for data: 2120314880
I0614 15:20:39.113338  5755 layer_factory.hpp:77] Creating layer bn7
I0614 15:20:39.113348  5755 net.cpp:94] Creating Layer bn7
I0614 15:20:39.113353  5755 net.cpp:435] bn7 <- fc7
I0614 15:20:39.113358  5755 net.cpp:409] bn7 -> bn7
I0614 15:20:39.113641  5755 net.cpp:144] Setting up bn7
I0614 15:20:39.113646  5755 net.cpp:151] Top shape: 256 4096 (1048576)
I0614 15:20:39.113651  5755 net.cpp:159] Memory required for data: 2124509184
I0614 15:20:39.113657  5755 layer_factory.hpp:77] Creating layer relu7
I0614 15:20:39.113663  5755 net.cpp:94] Creating Layer relu7
I0614 15:20:39.113667  5755 net.cpp:435] relu7 <- bn7
I0614 15:20:39.113672  5755 net.cpp:409] relu7 -> relu7
I0614 15:20:39.113683  5755 net.cpp:144] Setting up relu7
I0614 15:20:39.113687  5755 net.cpp:151] Top shape: 256 4096 (1048576)
I0614 15:20:39.113691  5755 net.cpp:159] Memory required for data: 2128703488
I0614 15:20:39.113710  5755 layer_factory.hpp:77] Creating layer drop7
I0614 15:20:39.113716  5755 net.cpp:94] Creating Layer drop7
I0614 15:20:39.113719  5755 net.cpp:435] drop7 <- relu7
I0614 15:20:39.113725  5755 net.cpp:409] drop7 -> drop7
I0614 15:20:39.113741  5755 net.cpp:144] Setting up drop7
I0614 15:20:39.113744  5755 net.cpp:151] Top shape: 256 4096 (1048576)
I0614 15:20:39.113749  5755 net.cpp:159] Memory required for data: 2132897792
I0614 15:20:39.113752  5755 layer_factory.hpp:77] Creating layer fc8
I0614 15:20:39.113759  5755 net.cpp:94] Creating Layer fc8
I0614 15:20:39.113765  5755 net.cpp:435] fc8 <- drop7
I0614 15:20:39.113771  5755 net.cpp:409] fc8 -> fc8
I0614 15:20:39.113936  5755 net.cpp:144] Setting up fc8
I0614 15:20:39.113945  5755 net.cpp:151] Top shape: 256 2 (512)
I0614 15:20:39.113948  5755 net.cpp:159] Memory required for data: 2132899840
I0614 15:20:39.113955  5755 layer_factory.hpp:77] Creating layer loss
I0614 15:20:39.113961  5755 net.cpp:94] Creating Layer loss
I0614 15:20:39.113965  5755 net.cpp:435] loss <- fc8
I0614 15:20:39.113970  5755 net.cpp:435] loss <- label
I0614 15:20:39.113974  5755 net.cpp:409] loss -> loss
I0614 15:20:39.113983  5755 layer_factory.hpp:77] Creating layer loss
I0614 15:20:39.114027  5755 net.cpp:144] Setting up loss
I0614 15:20:39.114030  5755 net.cpp:151] Top shape: (1)
I0614 15:20:39.114034  5755 net.cpp:154]     with loss weight 1
I0614 15:20:39.114048  5755 net.cpp:159] Memory required for data: 2132899844
I0614 15:20:39.114051  5755 net.cpp:220] loss needs backward computation.
I0614 15:20:39.114055  5755 net.cpp:220] fc8 needs backward computation.
I0614 15:20:39.114059  5755 net.cpp:220] drop7 needs backward computation.
I0614 15:20:39.114063  5755 net.cpp:220] relu7 needs backward computation.
I0614 15:20:39.114066  5755 net.cpp:220] bn7 needs backward computation.
I0614 15:20:39.114070  5755 net.cpp:220] fc7 needs backward computation.
I0614 15:20:39.114074  5755 net.cpp:220] drop6 needs backward computation.
I0614 15:20:39.114078  5755 net.cpp:220] relu6 needs backward computation.
I0614 15:20:39.114082  5755 net.cpp:220] fc6 needs backward computation.
I0614 15:20:39.114086  5755 net.cpp:220] pool5 needs backward computation.
I0614 15:20:39.114090  5755 net.cpp:220] relu5 needs backward computation.
I0614 15:20:39.114094  5755 net.cpp:220] conv5 needs backward computation.
I0614 15:20:39.114099  5755 net.cpp:220] relu4 needs backward computation.
I0614 15:20:39.114423  5755 net.cpp:220] conv4 needs backward computation.
I0614 15:20:39.114428  5755 net.cpp:220] relu3 needs backward computation.
I0614 15:20:39.114432  5755 net.cpp:220] conv3 needs backward computation.
I0614 15:20:39.114436  5755 net.cpp:220] pool2 needs backward computation.
I0614 15:20:39.114440  5755 net.cpp:220] relu2 needs backward computation.
I0614 15:20:39.114444  5755 net.cpp:220] bn2 needs backward computation.
I0614 15:20:39.114449  5755 net.cpp:220] conv2 needs backward computation.
I0614 15:20:39.114454  5755 net.cpp:220] pool1 needs backward computation.
I0614 15:20:39.114457  5755 net.cpp:220] relu1 needs backward computation.
I0614 15:20:39.114461  5755 net.cpp:220] bn1 needs backward computation.
I0614 15:20:39.114464  5755 net.cpp:220] conv1 needs backward computation.
I0614 15:20:39.114470  5755 net.cpp:222] data does not need backward computation.
I0614 15:20:39.114475  5755 net.cpp:264] This network produces output loss
I0614 15:20:39.114498  5755 net.cpp:284] Network initialization done.
I0614 15:20:39.115556  5755 solver.cpp:189] Creating test net (#0) specified by net file: pruning/alexnetBNnoLRN/regular_rate_0.3/net_finetune.prototxt
I0614 15:20:39.115603  5755 net.cpp:323] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0614 15:20:39.115619  5755 net.cpp:52] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_value: 106
    mean_value: 116
    mean_value: 124
  }
  data_param {
    source: "input/lmdb/valid_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 0
    kernel_size: 8
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "bn1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn2"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "bn2"
  top: "relu2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "relu6"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "drop6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn7"
  type: "BatchNorm"
  bottom: "fc7"
  top: "bn7"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "bn7"
  top: "relu7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "relu7"
  top: "drop7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "drop7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy-top1"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "top-1"
  include {
    phase: TEST
  }
}
I0614 15:20:39.116115  5755 layer_factory.hpp:77] Creating layer data
I0614 15:20:39.116168  5755 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0614 15:20:39.119436  5755 net.cpp:94] Creating Layer data
I0614 15:20:39.119474  5755 net.cpp:409] data -> data
I0614 15:20:39.119500  5755 net.cpp:409] data -> label
I0614 15:20:39.120537  5822 db_lmdb.cpp:35] Opened lmdb input/lmdb/valid_lmdb
I0614 15:20:39.120568  5822 db_lmdb.cpp:38] Items count: 4000
I0614 15:20:39.120615  5822 data_reader.cpp:124] TEST: reading data using 1 channel(s)
I0614 15:20:39.121084  5755 data_layer.cpp:78] ReshapePrefetch 50, 3, 227, 227
I0614 15:20:39.121263  5755 data_layer.cpp:83] output data size: 50,3,227,227
I0614 15:20:39.241147  5755 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0614 15:20:39.241725  5755 net.cpp:144] Setting up data
I0614 15:20:39.241732  5755 net.cpp:151] Top shape: 50 3 227 227 (7729350)
I0614 15:20:39.241741  5755 net.cpp:151] Top shape: 50 (50)
I0614 15:20:39.241745  5755 net.cpp:159] Memory required for data: 30917600
I0614 15:20:39.241750  5755 layer_factory.hpp:77] Creating layer label_data_1_split
I0614 15:20:39.241758  5755 net.cpp:94] Creating Layer label_data_1_split
I0614 15:20:39.241762  5755 net.cpp:435] label_data_1_split <- label
I0614 15:20:39.241767  5755 net.cpp:409] label_data_1_split -> label_data_1_split_0
I0614 15:20:39.241775  5755 net.cpp:409] label_data_1_split -> label_data_1_split_1
I0614 15:20:39.241780  5755 net.cpp:409] label_data_1_split -> label_data_1_split_2
I0614 15:20:39.241839  5755 net.cpp:144] Setting up label_data_1_split
I0614 15:20:39.241844  5755 net.cpp:151] Top shape: 50 (50)
I0614 15:20:39.241848  5755 net.cpp:151] Top shape: 50 (50)
I0614 15:20:39.241852  5755 net.cpp:151] Top shape: 50 (50)
I0614 15:20:39.241856  5755 net.cpp:159] Memory required for data: 30918200
I0614 15:20:39.241860  5755 layer_factory.hpp:77] Creating layer conv1
I0614 15:20:39.241869  5755 net.cpp:94] Creating Layer conv1
I0614 15:20:39.241873  5755 net.cpp:435] conv1 <- data
I0614 15:20:39.241878  5755 net.cpp:409] conv1 -> conv1
I0614 15:20:39.242219  5755 net.cpp:144] Setting up conv1
I0614 15:20:39.242225  5755 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0614 15:20:39.242231  5755 net.cpp:159] Memory required for data: 88998200
I0614 15:20:39.242241  5755 layer_factory.hpp:77] Creating layer bn1
I0614 15:20:39.242247  5755 net.cpp:94] Creating Layer bn1
I0614 15:20:39.242251  5755 net.cpp:435] bn1 <- conv1
I0614 15:20:39.242256  5755 net.cpp:409] bn1 -> bn1
I0614 15:20:39.242564  5755 net.cpp:144] Setting up bn1
I0614 15:20:39.242570  5755 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0614 15:20:39.242575  5755 net.cpp:159] Memory required for data: 147078200
I0614 15:20:39.242585  5755 layer_factory.hpp:77] Creating layer relu1
I0614 15:20:39.242591  5755 net.cpp:94] Creating Layer relu1
I0614 15:20:39.242595  5755 net.cpp:435] relu1 <- bn1
I0614 15:20:39.242599  5755 net.cpp:409] relu1 -> relu1
I0614 15:20:39.242610  5755 net.cpp:144] Setting up relu1
I0614 15:20:39.242614  5755 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0614 15:20:39.242619  5755 net.cpp:159] Memory required for data: 205158200
I0614 15:20:39.242622  5755 layer_factory.hpp:77] Creating layer pool1
I0614 15:20:39.242628  5755 net.cpp:94] Creating Layer pool1
I0614 15:20:39.242631  5755 net.cpp:435] pool1 <- relu1
I0614 15:20:39.242636  5755 net.cpp:409] pool1 -> pool1
I0614 15:20:39.242652  5755 net.cpp:144] Setting up pool1
I0614 15:20:39.242655  5755 net.cpp:151] Top shape: 50 96 27 27 (3499200)
I0614 15:20:39.242660  5755 net.cpp:159] Memory required for data: 219155000
I0614 15:20:39.242664  5755 layer_factory.hpp:77] Creating layer conv2
I0614 15:20:39.242671  5755 net.cpp:94] Creating Layer conv2
I0614 15:20:39.242674  5755 net.cpp:435] conv2 <- pool1
I0614 15:20:39.242679  5755 net.cpp:409] conv2 -> conv2
I0614 15:20:39.250241  5755 net.cpp:144] Setting up conv2
I0614 15:20:39.250255  5755 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0614 15:20:39.250262  5755 net.cpp:159] Memory required for data: 256479800
I0614 15:20:39.250272  5755 layer_factory.hpp:77] Creating layer bn2
I0614 15:20:39.250279  5755 net.cpp:94] Creating Layer bn2
I0614 15:20:39.250284  5755 net.cpp:435] bn2 <- conv2
I0614 15:20:39.250290  5755 net.cpp:409] bn2 -> bn2
I0614 15:20:39.250562  5755 net.cpp:144] Setting up bn2
I0614 15:20:39.250569  5755 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0614 15:20:39.250574  5755 net.cpp:159] Memory required for data: 293804600
I0614 15:20:39.250582  5755 layer_factory.hpp:77] Creating layer relu2
I0614 15:20:39.250588  5755 net.cpp:94] Creating Layer relu2
I0614 15:20:39.250592  5755 net.cpp:435] relu2 <- bn2
I0614 15:20:39.250597  5755 net.cpp:409] relu2 -> relu2
I0614 15:20:39.250608  5755 net.cpp:144] Setting up relu2
I0614 15:20:39.250911  5755 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0614 15:20:39.250917  5755 net.cpp:159] Memory required for data: 331129400
I0614 15:20:39.250921  5755 layer_factory.hpp:77] Creating layer pool2
I0614 15:20:39.250926  5755 net.cpp:94] Creating Layer pool2
I0614 15:20:39.250931  5755 net.cpp:435] pool2 <- relu2
I0614 15:20:39.250936  5755 net.cpp:409] pool2 -> pool2
I0614 15:20:39.250952  5755 net.cpp:144] Setting up pool2
I0614 15:20:39.250955  5755 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0614 15:20:39.250960  5755 net.cpp:159] Memory required for data: 339782200
I0614 15:20:39.250963  5755 layer_factory.hpp:77] Creating layer conv3
I0614 15:20:39.250972  5755 net.cpp:94] Creating Layer conv3
I0614 15:20:39.250975  5755 net.cpp:435] conv3 <- pool2
I0614 15:20:39.250979  5755 net.cpp:409] conv3 -> conv3
I0614 15:20:39.264654  5755 net.cpp:144] Setting up conv3
I0614 15:20:39.264676  5755 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0614 15:20:39.264684  5755 net.cpp:159] Memory required for data: 352761400
I0614 15:20:39.264693  5755 layer_factory.hpp:77] Creating layer relu3
I0614 15:20:39.264701  5755 net.cpp:94] Creating Layer relu3
I0614 15:20:39.264706  5755 net.cpp:435] relu3 <- conv3
I0614 15:20:39.264712  5755 net.cpp:409] relu3 -> relu3
I0614 15:20:39.264730  5755 net.cpp:144] Setting up relu3
I0614 15:20:39.264734  5755 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0614 15:20:39.264739  5755 net.cpp:159] Memory required for data: 365740600
I0614 15:20:39.264744  5755 layer_factory.hpp:77] Creating layer conv4
I0614 15:20:39.264752  5755 net.cpp:94] Creating Layer conv4
I0614 15:20:39.264756  5755 net.cpp:435] conv4 <- relu3
I0614 15:20:39.264761  5755 net.cpp:409] conv4 -> conv4
I0614 15:20:39.282040  5755 net.cpp:144] Setting up conv4
I0614 15:20:39.282064  5755 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0614 15:20:39.282076  5755 net.cpp:159] Memory required for data: 378719800
I0614 15:20:39.282091  5755 layer_factory.hpp:77] Creating layer relu4
I0614 15:20:39.282099  5755 net.cpp:94] Creating Layer relu4
I0614 15:20:39.282104  5755 net.cpp:435] relu4 <- conv4
I0614 15:20:39.282110  5755 net.cpp:409] relu4 -> relu4
I0614 15:20:39.282130  5755 net.cpp:144] Setting up relu4
I0614 15:20:39.282135  5755 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0614 15:20:39.282140  5755 net.cpp:159] Memory required for data: 391699000
I0614 15:20:39.282145  5755 layer_factory.hpp:77] Creating layer conv5
I0614 15:20:39.282153  5755 net.cpp:94] Creating Layer conv5
I0614 15:20:39.282157  5755 net.cpp:435] conv5 <- relu4
I0614 15:20:39.282162  5755 net.cpp:409] conv5 -> conv5
I0614 15:20:39.297112  5755 net.cpp:144] Setting up conv5
I0614 15:20:39.297140  5755 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0614 15:20:39.297152  5755 net.cpp:159] Memory required for data: 400351800
I0614 15:20:39.297164  5755 layer_factory.hpp:77] Creating layer relu5
I0614 15:20:39.297174  5755 net.cpp:94] Creating Layer relu5
I0614 15:20:39.297181  5755 net.cpp:435] relu5 <- conv5
I0614 15:20:39.297190  5755 net.cpp:409] relu5 -> relu5
I0614 15:20:39.297217  5755 net.cpp:144] Setting up relu5
I0614 15:20:39.297222  5755 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0614 15:20:39.297230  5755 net.cpp:159] Memory required for data: 409004600
I0614 15:20:39.297235  5755 layer_factory.hpp:77] Creating layer pool5
I0614 15:20:39.297245  5755 net.cpp:94] Creating Layer pool5
I0614 15:20:39.297250  5755 net.cpp:435] pool5 <- relu5
I0614 15:20:39.297256  5755 net.cpp:409] pool5 -> pool5
I0614 15:20:39.297281  5755 net.cpp:144] Setting up pool5
I0614 15:20:39.297286  5755 net.cpp:151] Top shape: 50 256 6 6 (460800)
I0614 15:20:39.297293  5755 net.cpp:159] Memory required for data: 410847800
I0614 15:20:39.297297  5755 layer_factory.hpp:77] Creating layer fc6
I0614 15:20:39.297307  5755 net.cpp:94] Creating Layer fc6
I0614 15:20:39.297312  5755 net.cpp:435] fc6 <- pool5
I0614 15:20:39.297319  5755 net.cpp:409] fc6 -> fc6
I0614 15:20:39.658601  5755 net.cpp:144] Setting up fc6
I0614 15:20:39.658624  5755 net.cpp:151] Top shape: 50 4096 (204800)
I0614 15:20:39.658864  5755 net.cpp:159] Memory required for data: 411667000
I0614 15:20:39.658874  5755 layer_factory.hpp:77] Creating layer relu6
I0614 15:20:39.658897  5755 net.cpp:94] Creating Layer relu6
I0614 15:20:39.658902  5755 net.cpp:435] relu6 <- fc6
I0614 15:20:39.658908  5755 net.cpp:409] relu6 -> relu6
I0614 15:20:39.658929  5755 net.cpp:144] Setting up relu6
I0614 15:20:39.658933  5755 net.cpp:151] Top shape: 50 4096 (204800)
I0614 15:20:39.658938  5755 net.cpp:159] Memory required for data: 412486200
I0614 15:20:39.658941  5755 layer_factory.hpp:77] Creating layer drop6
I0614 15:20:39.658947  5755 net.cpp:94] Creating Layer drop6
I0614 15:20:39.658951  5755 net.cpp:435] drop6 <- relu6
I0614 15:20:39.658957  5755 net.cpp:409] drop6 -> drop6
I0614 15:20:39.658972  5755 net.cpp:144] Setting up drop6
I0614 15:20:39.658975  5755 net.cpp:151] Top shape: 50 4096 (204800)
I0614 15:20:39.658979  5755 net.cpp:159] Memory required for data: 413305400
I0614 15:20:39.658982  5755 layer_factory.hpp:77] Creating layer fc7
I0614 15:20:39.658989  5755 net.cpp:94] Creating Layer fc7
I0614 15:20:39.658993  5755 net.cpp:435] fc7 <- drop6
I0614 15:20:39.658998  5755 net.cpp:409] fc7 -> fc7
I0614 15:20:39.816263  5755 net.cpp:144] Setting up fc7
I0614 15:20:39.816284  5755 net.cpp:151] Top shape: 50 4096 (204800)
I0614 15:20:39.816293  5755 net.cpp:159] Memory required for data: 414124600
I0614 15:20:39.816301  5755 layer_factory.hpp:77] Creating layer bn7
I0614 15:20:39.816311  5755 net.cpp:94] Creating Layer bn7
I0614 15:20:39.816315  5755 net.cpp:435] bn7 <- fc7
I0614 15:20:39.816320  5755 net.cpp:409] bn7 -> bn7
I0614 15:20:39.816601  5755 net.cpp:144] Setting up bn7
I0614 15:20:39.816604  5755 net.cpp:151] Top shape: 50 4096 (204800)
I0614 15:20:39.816609  5755 net.cpp:159] Memory required for data: 414943800
I0614 15:20:39.816615  5755 layer_factory.hpp:77] Creating layer relu7
I0614 15:20:39.816637  5755 net.cpp:94] Creating Layer relu7
I0614 15:20:39.816640  5755 net.cpp:435] relu7 <- bn7
I0614 15:20:39.816644  5755 net.cpp:409] relu7 -> relu7
I0614 15:20:39.816656  5755 net.cpp:144] Setting up relu7
I0614 15:20:39.816660  5755 net.cpp:151] Top shape: 50 4096 (204800)
I0614 15:20:39.816664  5755 net.cpp:159] Memory required for data: 415763000
I0614 15:20:39.816668  5755 layer_factory.hpp:77] Creating layer drop7
I0614 15:20:39.816673  5755 net.cpp:94] Creating Layer drop7
I0614 15:20:39.816676  5755 net.cpp:435] drop7 <- relu7
I0614 15:20:39.816681  5755 net.cpp:409] drop7 -> drop7
I0614 15:20:39.816696  5755 net.cpp:144] Setting up drop7
I0614 15:20:39.816700  5755 net.cpp:151] Top shape: 50 4096 (204800)
I0614 15:20:39.816704  5755 net.cpp:159] Memory required for data: 416582200
I0614 15:20:39.816707  5755 layer_factory.hpp:77] Creating layer fc8
I0614 15:20:39.816713  5755 net.cpp:94] Creating Layer fc8
I0614 15:20:39.816717  5755 net.cpp:435] fc8 <- drop7
I0614 15:20:39.816722  5755 net.cpp:409] fc8 -> fc8
I0614 15:20:39.816862  5755 net.cpp:144] Setting up fc8
I0614 15:20:39.816866  5755 net.cpp:151] Top shape: 50 2 (100)
I0614 15:20:39.816870  5755 net.cpp:159] Memory required for data: 416582600
I0614 15:20:39.816876  5755 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0614 15:20:39.816881  5755 net.cpp:94] Creating Layer fc8_fc8_0_split
I0614 15:20:39.816885  5755 net.cpp:435] fc8_fc8_0_split <- fc8
I0614 15:20:39.816890  5755 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0614 15:20:39.816895  5755 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0614 15:20:39.816901  5755 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_2
I0614 15:20:39.816920  5755 net.cpp:144] Setting up fc8_fc8_0_split
I0614 15:20:39.816923  5755 net.cpp:151] Top shape: 50 2 (100)
I0614 15:20:39.816928  5755 net.cpp:151] Top shape: 50 2 (100)
I0614 15:20:39.816932  5755 net.cpp:151] Top shape: 50 2 (100)
I0614 15:20:39.816936  5755 net.cpp:159] Memory required for data: 416583800
I0614 15:20:39.816939  5755 layer_factory.hpp:77] Creating layer accuracy
I0614 15:20:39.816946  5755 net.cpp:94] Creating Layer accuracy
I0614 15:20:39.817234  5755 net.cpp:435] accuracy <- fc8_fc8_0_split_0
I0614 15:20:39.817239  5755 net.cpp:435] accuracy <- label_data_1_split_0
I0614 15:20:39.817245  5755 net.cpp:409] accuracy -> accuracy
I0614 15:20:39.817251  5755 net.cpp:144] Setting up accuracy
I0614 15:20:39.817255  5755 net.cpp:151] Top shape: (1)
I0614 15:20:39.817260  5755 net.cpp:159] Memory required for data: 416583804
I0614 15:20:39.817262  5755 layer_factory.hpp:77] Creating layer loss
I0614 15:20:39.817268  5755 net.cpp:94] Creating Layer loss
I0614 15:20:39.817271  5755 net.cpp:435] loss <- fc8_fc8_0_split_1
I0614 15:20:39.817276  5755 net.cpp:435] loss <- label_data_1_split_1
I0614 15:20:39.817281  5755 net.cpp:409] loss -> loss
I0614 15:20:39.817289  5755 layer_factory.hpp:77] Creating layer loss
I0614 15:20:39.817330  5755 net.cpp:144] Setting up loss
I0614 15:20:39.817334  5755 net.cpp:151] Top shape: (1)
I0614 15:20:39.817338  5755 net.cpp:154]     with loss weight 1
I0614 15:20:39.817351  5755 net.cpp:159] Memory required for data: 416583808
I0614 15:20:39.817354  5755 layer_factory.hpp:77] Creating layer accuracy-top1
I0614 15:20:39.817360  5755 net.cpp:94] Creating Layer accuracy-top1
I0614 15:20:39.817363  5755 net.cpp:435] accuracy-top1 <- fc8_fc8_0_split_2
I0614 15:20:39.817368  5755 net.cpp:435] accuracy-top1 <- label_data_1_split_2
I0614 15:20:39.817373  5755 net.cpp:409] accuracy-top1 -> top-1
I0614 15:20:39.817384  5755 net.cpp:144] Setting up accuracy-top1
I0614 15:20:39.817389  5755 net.cpp:151] Top shape: (1)
I0614 15:20:39.817392  5755 net.cpp:159] Memory required for data: 416583812
I0614 15:20:39.817396  5755 net.cpp:222] accuracy-top1 does not need backward computation.
I0614 15:20:39.817400  5755 net.cpp:220] loss needs backward computation.
I0614 15:20:39.817405  5755 net.cpp:222] accuracy does not need backward computation.
I0614 15:20:39.817409  5755 net.cpp:220] fc8_fc8_0_split needs backward computation.
I0614 15:20:39.817413  5755 net.cpp:220] fc8 needs backward computation.
I0614 15:20:39.817416  5755 net.cpp:220] drop7 needs backward computation.
I0614 15:20:39.817420  5755 net.cpp:220] relu7 needs backward computation.
I0614 15:20:39.817425  5755 net.cpp:220] bn7 needs backward computation.
I0614 15:20:39.817428  5755 net.cpp:220] fc7 needs backward computation.
I0614 15:20:39.817431  5755 net.cpp:220] drop6 needs backward computation.
I0614 15:20:39.817435  5755 net.cpp:220] relu6 needs backward computation.
I0614 15:20:39.817440  5755 net.cpp:220] fc6 needs backward computation.
I0614 15:20:39.817443  5755 net.cpp:220] pool5 needs backward computation.
I0614 15:20:39.817447  5755 net.cpp:220] relu5 needs backward computation.
I0614 15:20:39.817451  5755 net.cpp:220] conv5 needs backward computation.
I0614 15:20:39.817456  5755 net.cpp:220] relu4 needs backward computation.
I0614 15:20:39.817461  5755 net.cpp:220] conv4 needs backward computation.
I0614 15:20:39.817464  5755 net.cpp:220] relu3 needs backward computation.
I0614 15:20:39.817468  5755 net.cpp:220] conv3 needs backward computation.
I0614 15:20:39.817472  5755 net.cpp:220] pool2 needs backward computation.
I0614 15:20:39.817476  5755 net.cpp:220] relu2 needs backward computation.
I0614 15:20:39.817481  5755 net.cpp:220] bn2 needs backward computation.
I0614 15:20:39.817483  5755 net.cpp:220] conv2 needs backward computation.
I0614 15:20:39.817487  5755 net.cpp:220] pool1 needs backward computation.
I0614 15:20:39.817492  5755 net.cpp:220] relu1 needs backward computation.
I0614 15:20:39.817495  5755 net.cpp:220] bn1 needs backward computation.
I0614 15:20:39.817499  5755 net.cpp:220] conv1 needs backward computation.
I0614 15:20:39.817504  5755 net.cpp:222] label_data_1_split does not need backward computation.
I0614 15:20:39.817508  5755 net.cpp:222] data does not need backward computation.
I0614 15:20:39.817512  5755 net.cpp:264] This network produces output accuracy
I0614 15:20:39.817515  5755 net.cpp:264] This network produces output loss
I0614 15:20:39.817519  5755 net.cpp:264] This network produces output top-1
I0614 15:20:39.817832  5755 net.cpp:284] Network initialization done.
I0614 15:20:39.817905  5755 solver.cpp:63] Solver scaffolding done.
I0614 15:20:39.818439  5755 caffe_interface.cpp:139] Finetuning from pruning/alexnetBNnoLRN/regular_rate_0.3/sparse.caffemodel
I0614 15:20:42.243959  5755 caffe_interface.cpp:573] Starting Optimization
I0614 15:20:42.243983  5755 solver.cpp:341] Solving 
I0614 15:20:42.243986  5755 solver.cpp:342] Learning Rate Policy: step
I0614 15:20:42.245178  5755 solver.cpp:424] Iteration 0, Testing net (#0)
I0614 15:20:43.714726  5755 solver.cpp:523]     Test net output #0: accuracy = 0.95825
I0614 15:20:43.714759  5755 solver.cpp:523]     Test net output #1: loss = 0.218328 (* 1 = 0.218328 loss)
I0614 15:20:43.714763  5755 solver.cpp:523]     Test net output #2: top-1 = 0.95825
I0614 15:20:43.998409  5755 solver.cpp:270] Iteration 0 (0 iter/s, 1.75432s/50 iter), loss = 0.00152872, remaining 333333 hours and 20 minutes
I0614 15:20:43.998440  5755 solver.cpp:291]     Train net output #0: loss = 0.00152872 (* 1 = 0.00152872 loss)
I0614 15:20:43.998466  5755 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0614 15:20:56.626621  5755 solver.cpp:270] Iteration 50 (3.95955 iter/s, 12.6277s/50 iter), loss = 0.0953581, remaining 0 hours and 50 minutes
I0614 15:20:56.626653  5755 solver.cpp:291]     Train net output #0: loss = 0.0953581 (* 1 = 0.0953581 loss)
I0614 15:20:56.626660  5755 sgd_solver.cpp:106] Iteration 50, lr = 0.001
I0614 15:21:09.330291  5755 solver.cpp:270] Iteration 100 (3.93603 iter/s, 12.7032s/50 iter), loss = 0.0545206, remaining 0 hours and 50 minutes
I0614 15:21:09.333130  5755 solver.cpp:291]     Train net output #0: loss = 0.0545206 (* 1 = 0.0545206 loss)
I0614 15:21:09.333154  5755 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I0614 15:21:22.139313  5755 solver.cpp:270] Iteration 150 (3.90449 iter/s, 12.8058s/50 iter), loss = 0.0699005, remaining 0 hours and 50 minutes
I0614 15:21:22.139349  5755 solver.cpp:291]     Train net output #0: loss = 0.0699005 (* 1 = 0.0699005 loss)
I0614 15:21:22.139358  5755 sgd_solver.cpp:106] Iteration 150, lr = 0.001
I0614 15:21:35.025818  5755 solver.cpp:270] Iteration 200 (3.88016 iter/s, 12.8861s/50 iter), loss = 0.051915, remaining 0 hours and 50 minutes
I0614 15:21:35.025854  5755 solver.cpp:291]     Train net output #0: loss = 0.051915 (* 1 = 0.051915 loss)
I0614 15:21:35.025862  5755 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I0614 15:21:47.911408  5755 solver.cpp:270] Iteration 250 (3.88044 iter/s, 12.8851s/50 iter), loss = 0.088465, remaining 0 hours and 50 minutes
I0614 15:21:47.914671  5755 solver.cpp:291]     Train net output #0: loss = 0.088465 (* 1 = 0.088465 loss)
I0614 15:21:47.914680  5755 sgd_solver.cpp:106] Iteration 250, lr = 0.001
I0614 15:22:00.630636  5755 solver.cpp:270] Iteration 300 (3.93219 iter/s, 12.7155s/50 iter), loss = 0.0974243, remaining 0 hours and 49 minutes
I0614 15:22:00.630676  5755 solver.cpp:291]     Train net output #0: loss = 0.0974243 (* 1 = 0.0974243 loss)
I0614 15:22:00.630686  5755 sgd_solver.cpp:106] Iteration 300, lr = 0.001
I0614 15:22:13.377074  5755 solver.cpp:270] Iteration 350 (3.9228 iter/s, 12.746s/50 iter), loss = 0.0890793, remaining 0 hours and 49 minutes
I0614 15:22:13.377113  5755 solver.cpp:291]     Train net output #0: loss = 0.0890793 (* 1 = 0.0890793 loss)
I0614 15:22:13.377123  5755 sgd_solver.cpp:106] Iteration 350, lr = 0.001
I0614 15:22:26.070752  5755 solver.cpp:270] Iteration 400 (3.93911 iter/s, 12.6932s/50 iter), loss = 0.0906422, remaining 0 hours and 48 minutes
I0614 15:22:26.074491  5755 solver.cpp:291]     Train net output #0: loss = 0.0906422 (* 1 = 0.0906422 loss)
I0614 15:22:26.074501  5755 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I0614 15:22:38.772174  5755 solver.cpp:270] Iteration 450 (3.93785 iter/s, 12.6973s/50 iter), loss = 0.0974248, remaining 0 hours and 48 minutes
I0614 15:22:38.772209  5755 solver.cpp:291]     Train net output #0: loss = 0.0974248 (* 1 = 0.0974248 loss)
I0614 15:22:38.772217  5755 sgd_solver.cpp:106] Iteration 450, lr = 0.001
I0614 15:22:51.498718  5755 solver.cpp:270] Iteration 500 (3.92894 iter/s, 12.7261s/50 iter), loss = 0.0802046, remaining 0 hours and 48 minutes
I0614 15:22:51.498754  5755 solver.cpp:291]     Train net output #0: loss = 0.0802046 (* 1 = 0.0802046 loss)
I0614 15:22:51.498762  5755 sgd_solver.cpp:106] Iteration 500, lr = 0.001
I0614 15:23:04.209810  5755 solver.cpp:270] Iteration 550 (3.93371 iter/s, 12.7106s/50 iter), loss = 0.103611, remaining 0 hours and 48 minutes
I0614 15:23:04.214087  5755 solver.cpp:291]     Train net output #0: loss = 0.103611 (* 1 = 0.103611 loss)
I0614 15:23:04.214100  5755 sgd_solver.cpp:106] Iteration 550, lr = 0.001
I0614 15:23:16.929508  5755 solver.cpp:270] Iteration 600 (3.93236 iter/s, 12.715s/50 iter), loss = 0.0889672, remaining 0 hours and 48 minutes
I0614 15:23:16.929544  5755 solver.cpp:291]     Train net output #0: loss = 0.0889672 (* 1 = 0.0889672 loss)
I0614 15:23:16.929553  5755 sgd_solver.cpp:106] Iteration 600, lr = 0.001
I0614 15:23:29.615504  5755 solver.cpp:270] Iteration 650 (3.94149 iter/s, 12.6855s/50 iter), loss = 0.0963369, remaining 0 hours and 47 minutes
I0614 15:23:29.615540  5755 solver.cpp:291]     Train net output #0: loss = 0.0963369 (* 1 = 0.0963369 loss)
I0614 15:23:29.615564  5755 sgd_solver.cpp:106] Iteration 650, lr = 0.001
I0614 15:23:42.315323  5755 solver.cpp:270] Iteration 700 (3.9372 iter/s, 12.6994s/50 iter), loss = 0.114426, remaining 0 hours and 47 minutes
I0614 15:23:42.318933  5755 solver.cpp:291]     Train net output #0: loss = 0.114426 (* 1 = 0.114426 loss)
I0614 15:23:42.318949  5755 sgd_solver.cpp:106] Iteration 700, lr = 0.001
I0614 15:23:55.041913  5755 solver.cpp:270] Iteration 750 (3.93002 iter/s, 12.7226s/50 iter), loss = 0.0607481, remaining 0 hours and 47 minutes
I0614 15:23:55.041949  5755 solver.cpp:291]     Train net output #0: loss = 0.0607481 (* 1 = 0.0607481 loss)
I0614 15:23:55.041956  5755 sgd_solver.cpp:106] Iteration 750, lr = 0.001
I0614 15:24:07.727527  5755 solver.cpp:270] Iteration 800 (3.94161 iter/s, 12.6852s/50 iter), loss = 0.0652091, remaining 0 hours and 47 minutes
I0614 15:24:07.727563  5755 solver.cpp:291]     Train net output #0: loss = 0.0652091 (* 1 = 0.0652091 loss)
I0614 15:24:07.727572  5755 sgd_solver.cpp:106] Iteration 800, lr = 0.001
I0614 15:24:20.409731  5755 solver.cpp:270] Iteration 850 (3.94267 iter/s, 12.6818s/50 iter), loss = 0.100254, remaining 0 hours and 46 minutes
I0614 15:24:20.416011  5755 solver.cpp:291]     Train net output #0: loss = 0.100254 (* 1 = 0.100254 loss)
I0614 15:24:20.416020  5755 sgd_solver.cpp:106] Iteration 850, lr = 0.001
I0614 15:24:33.123697  5755 solver.cpp:270] Iteration 900 (3.93475 iter/s, 12.7073s/50 iter), loss = 0.0954386, remaining 0 hours and 47 minutes
I0614 15:24:33.123733  5755 solver.cpp:291]     Train net output #0: loss = 0.0954386 (* 1 = 0.0954386 loss)
I0614 15:24:33.123740  5755 sgd_solver.cpp:106] Iteration 900, lr = 0.001
I0614 15:24:45.844815  5755 solver.cpp:270] Iteration 950 (3.93061 iter/s, 12.7207s/50 iter), loss = 0.0826775, remaining 0 hours and 46 minutes
I0614 15:24:45.844846  5755 solver.cpp:291]     Train net output #0: loss = 0.0826775 (* 1 = 0.0826775 loss)
I0614 15:24:45.844852  5755 sgd_solver.cpp:106] Iteration 950, lr = 0.001
I0614 15:24:58.399765  5755 solver.cpp:424] Iteration 1000, Testing net (#0)
I0614 15:24:59.896394  5755 solver.cpp:523]     Test net output #0: accuracy = 0.9195
I0614 15:24:59.896425  5755 solver.cpp:523]     Test net output #1: loss = 0.283441 (* 1 = 0.283441 loss)
I0614 15:24:59.896430  5755 solver.cpp:523]     Test net output #2: top-1 = 0.9195
I0614 15:25:00.150496  5755 solver.cpp:270] Iteration 1000 (3.49524 iter/s, 14.3052s/50 iter), loss = 0.111885, remaining 0 hours and 52 minutes
I0614 15:25:00.150527  5755 solver.cpp:291]     Train net output #0: loss = 0.111885 (* 1 = 0.111885 loss)
I0614 15:25:00.150550  5755 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I0614 15:25:12.916750  5755 solver.cpp:270] Iteration 1050 (3.91671 iter/s, 12.7658s/50 iter), loss = 0.0611205, remaining 0 hours and 46 minutes
I0614 15:25:12.916781  5755 solver.cpp:291]     Train net output #0: loss = 0.0611205 (* 1 = 0.0611205 loss)
I0614 15:25:12.916790  5755 sgd_solver.cpp:106] Iteration 1050, lr = 0.001
I0614 15:25:25.859127  5755 solver.cpp:270] Iteration 1100 (3.86341 iter/s, 12.9419s/50 iter), loss = 0.107801, remaining 0 hours and 46 minutes
I0614 15:25:25.859158  5755 solver.cpp:291]     Train net output #0: loss = 0.107801 (* 1 = 0.107801 loss)
I0614 15:25:25.859166  5755 sgd_solver.cpp:106] Iteration 1100, lr = 0.001
I0614 15:25:38.687963  5755 solver.cpp:270] Iteration 1150 (3.89761 iter/s, 12.8284s/50 iter), loss = 0.109261, remaining 0 hours and 46 minutes
I0614 15:25:38.688258  5755 solver.cpp:291]     Train net output #0: loss = 0.109261 (* 1 = 0.109261 loss)
I0614 15:25:38.688266  5755 sgd_solver.cpp:106] Iteration 1150, lr = 0.001
I0614 15:25:51.435778  5755 solver.cpp:270] Iteration 1200 (3.92246 iter/s, 12.7471s/50 iter), loss = 0.0890649, remaining 0 hours and 45 minutes
I0614 15:25:51.435808  5755 solver.cpp:291]     Train net output #0: loss = 0.089065 (* 1 = 0.089065 loss)
I0614 15:25:51.435832  5755 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I0614 15:26:04.135823  5755 solver.cpp:270] Iteration 1250 (3.93713 iter/s, 12.6996s/50 iter), loss = 0.105209, remaining 0 hours and 45 minutes
I0614 15:26:04.135852  5755 solver.cpp:291]     Train net output #0: loss = 0.105209 (* 1 = 0.105209 loss)
I0614 15:26:04.135860  5755 sgd_solver.cpp:106] Iteration 1250, lr = 0.001
I0614 15:26:16.786145  5755 solver.cpp:270] Iteration 1300 (3.95261 iter/s, 12.6499s/50 iter), loss = 0.124734, remaining 0 hours and 45 minutes
I0614 15:26:16.786401  5755 solver.cpp:291]     Train net output #0: loss = 0.124734 (* 1 = 0.124734 loss)
I0614 15:26:16.786408  5755 sgd_solver.cpp:106] Iteration 1300, lr = 0.001
I0614 15:26:29.436781  5755 solver.cpp:270] Iteration 1350 (3.95258 iter/s, 12.65s/50 iter), loss = 0.106016, remaining 0 hours and 44 minutes
I0614 15:26:29.436812  5755 solver.cpp:291]     Train net output #0: loss = 0.106016 (* 1 = 0.106016 loss)
I0614 15:26:29.436820  5755 sgd_solver.cpp:106] Iteration 1350, lr = 0.001
I0614 15:26:42.102105  5755 solver.cpp:270] Iteration 1400 (3.94792 iter/s, 12.6649s/50 iter), loss = 0.106878, remaining 0 hours and 44 minutes
I0614 15:26:42.102136  5755 solver.cpp:291]     Train net output #0: loss = 0.106878 (* 1 = 0.106878 loss)
I0614 15:26:42.102144  5755 sgd_solver.cpp:106] Iteration 1400, lr = 0.001
I0614 15:26:54.771723  5755 solver.cpp:270] Iteration 1450 (3.94659 iter/s, 12.6692s/50 iter), loss = 0.0893241, remaining 0 hours and 44 minutes
I0614 15:26:54.771931  5755 solver.cpp:291]     Train net output #0: loss = 0.0893242 (* 1 = 0.0893242 loss)
I0614 15:26:54.771955  5755 sgd_solver.cpp:106] Iteration 1450, lr = 0.001
I0614 15:27:07.443817  5755 solver.cpp:270] Iteration 1500 (3.94587 iter/s, 12.6715s/50 iter), loss = 0.111781, remaining 0 hours and 44 minutes
I0614 15:27:07.443850  5755 solver.cpp:291]     Train net output #0: loss = 0.111781 (* 1 = 0.111781 loss)
I0614 15:27:07.443858  5755 sgd_solver.cpp:106] Iteration 1500, lr = 0.001
I0614 15:27:20.092623  5755 solver.cpp:270] Iteration 1550 (3.95308 iter/s, 12.6484s/50 iter), loss = 0.0950496, remaining 0 hours and 44 minutes
I0614 15:27:20.092654  5755 solver.cpp:291]     Train net output #0: loss = 0.0950496 (* 1 = 0.0950496 loss)
I0614 15:27:20.092662  5755 sgd_solver.cpp:106] Iteration 1550, lr = 0.001
I0614 15:27:32.748558  5755 solver.cpp:270] Iteration 1600 (3.95085 iter/s, 12.6555s/50 iter), loss = 0.0618388, remaining 0 hours and 43 minutes
I0614 15:27:32.748792  5755 solver.cpp:291]     Train net output #0: loss = 0.0618388 (* 1 = 0.0618388 loss)
I0614 15:27:32.748801  5755 sgd_solver.cpp:106] Iteration 1600, lr = 0.001
I0614 15:27:45.403595  5755 solver.cpp:270] Iteration 1650 (3.9512 iter/s, 12.6544s/50 iter), loss = 0.0828662, remaining 0 hours and 43 minutes
I0614 15:27:45.403627  5755 solver.cpp:291]     Train net output #0: loss = 0.0828662 (* 1 = 0.0828662 loss)
I0614 15:27:45.403635  5755 sgd_solver.cpp:106] Iteration 1650, lr = 0.001
I0614 15:27:58.068220  5755 solver.cpp:270] Iteration 1700 (3.94814 iter/s, 12.6642s/50 iter), loss = 0.113478, remaining 0 hours and 43 minutes
I0614 15:27:58.068253  5755 solver.cpp:291]     Train net output #0: loss = 0.113478 (* 1 = 0.113478 loss)
I0614 15:27:58.068261  5755 sgd_solver.cpp:106] Iteration 1700, lr = 0.001
I0614 15:28:10.725332  5755 solver.cpp:270] Iteration 1750 (3.95049 iter/s, 12.6567s/50 iter), loss = 0.098376, remaining 0 hours and 43 minutes
I0614 15:28:10.725656  5755 solver.cpp:291]     Train net output #0: loss = 0.098376 (* 1 = 0.098376 loss)
I0614 15:28:10.725679  5755 sgd_solver.cpp:106] Iteration 1750, lr = 0.001
I0614 15:28:23.367063  5755 solver.cpp:270] Iteration 1800 (3.95538 iter/s, 12.641s/50 iter), loss = 0.101758, remaining 0 hours and 42 minutes
I0614 15:28:23.367094  5755 solver.cpp:291]     Train net output #0: loss = 0.101758 (* 1 = 0.101758 loss)
I0614 15:28:23.367101  5755 sgd_solver.cpp:106] Iteration 1800, lr = 0.001
I0614 15:28:36.015367  5755 solver.cpp:270] Iteration 1850 (3.95324 iter/s, 12.6479s/50 iter), loss = 0.0679694, remaining 0 hours and 42 minutes
I0614 15:28:36.015400  5755 solver.cpp:291]     Train net output #0: loss = 0.0679694 (* 1 = 0.0679694 loss)
I0614 15:28:36.015408  5755 sgd_solver.cpp:106] Iteration 1850, lr = 0.001
I0614 15:28:48.676743  5755 solver.cpp:270] Iteration 1900 (3.94916 iter/s, 12.6609s/50 iter), loss = 0.147916, remaining 0 hours and 42 minutes
I0614 15:28:48.676996  5755 solver.cpp:291]     Train net output #0: loss = 0.147916 (* 1 = 0.147916 loss)
I0614 15:28:48.677022  5755 sgd_solver.cpp:106] Iteration 1900, lr = 0.001
I0614 15:29:01.340539  5755 solver.cpp:270] Iteration 1950 (3.94847 iter/s, 12.6631s/50 iter), loss = 0.0821953, remaining 0 hours and 42 minutes
I0614 15:29:01.340569  5755 solver.cpp:291]     Train net output #0: loss = 0.0821953 (* 1 = 0.0821953 loss)
I0614 15:29:01.340576  5755 sgd_solver.cpp:106] Iteration 1950, lr = 0.001
I0614 15:29:13.745328  5755 solver.cpp:424] Iteration 2000, Testing net (#0)
I0614 15:29:15.254290  5755 solver.cpp:523]     Test net output #0: accuracy = 0.93275
I0614 15:29:15.254320  5755 solver.cpp:523]     Test net output #1: loss = 0.207656 (* 1 = 0.207656 loss)
I0614 15:29:15.254325  5755 solver.cpp:523]     Test net output #2: top-1 = 0.93275
I0614 15:29:15.505642  5755 solver.cpp:270] Iteration 2000 (3.52992 iter/s, 14.1646s/50 iter), loss = 0.0450213, remaining 0 hours and 47 minutes
I0614 15:29:15.505672  5755 solver.cpp:291]     Train net output #0: loss = 0.0450213 (* 1 = 0.0450213 loss)
I0614 15:29:15.505679  5755 sgd_solver.cpp:106] Iteration 2000, lr = 0.001
I0614 15:29:28.162822  5755 solver.cpp:270] Iteration 2050 (3.95046 iter/s, 12.6567s/50 iter), loss = 0.102706, remaining 0 hours and 41 minutes
I0614 15:29:28.163075  5755 solver.cpp:291]     Train net output #0: loss = 0.102706 (* 1 = 0.102706 loss)
I0614 15:29:28.163084  5755 sgd_solver.cpp:106] Iteration 2050, lr = 0.001
I0614 15:29:40.816095  5755 solver.cpp:270] Iteration 2100 (3.95175 iter/s, 12.6526s/50 iter), loss = 0.0527053, remaining 0 hours and 41 minutes
I0614 15:29:40.816128  5755 solver.cpp:291]     Train net output #0: loss = 0.0527053 (* 1 = 0.0527053 loss)
I0614 15:29:40.816134  5755 sgd_solver.cpp:106] Iteration 2100, lr = 0.001
I0614 15:29:53.458457  5755 solver.cpp:270] Iteration 2150 (3.95509 iter/s, 12.6419s/50 iter), loss = 0.0946107, remaining 0 hours and 41 minutes
I0614 15:29:53.458488  5755 solver.cpp:291]     Train net output #0: loss = 0.0946107 (* 1 = 0.0946107 loss)
I0614 15:29:53.458495  5755 sgd_solver.cpp:106] Iteration 2150, lr = 0.001
I0614 15:30:06.097488  5755 solver.cpp:270] Iteration 2200 (3.95614 iter/s, 12.6386s/50 iter), loss = 0.113295, remaining 0 hours and 41 minutes
I0614 15:30:06.097728  5755 solver.cpp:291]     Train net output #0: loss = 0.113295 (* 1 = 0.113295 loss)
I0614 15:30:06.097752  5755 sgd_solver.cpp:106] Iteration 2200, lr = 0.001
I0614 15:30:18.758498  5755 solver.cpp:270] Iteration 2250 (3.94933 iter/s, 12.6604s/50 iter), loss = 0.0589509, remaining 0 hours and 41 minutes
I0614 15:30:18.758530  5755 solver.cpp:291]     Train net output #0: loss = 0.0589509 (* 1 = 0.0589509 loss)
I0614 15:30:18.758538  5755 sgd_solver.cpp:106] Iteration 2250, lr = 0.001
I0614 15:30:31.419384  5755 solver.cpp:270] Iteration 2300 (3.94931 iter/s, 12.6604s/50 iter), loss = 0.072505, remaining 0 hours and 40 minutes
I0614 15:30:31.419414  5755 solver.cpp:291]     Train net output #0: loss = 0.072505 (* 1 = 0.072505 loss)
I0614 15:30:31.419423  5755 sgd_solver.cpp:106] Iteration 2300, lr = 0.001
I0614 15:30:44.078886  5755 solver.cpp:270] Iteration 2350 (3.94974 iter/s, 12.6591s/50 iter), loss = 0.0962601, remaining 0 hours and 40 minutes
I0614 15:30:44.079219  5755 solver.cpp:291]     Train net output #0: loss = 0.0962601 (* 1 = 0.0962601 loss)
I0614 15:30:44.079243  5755 sgd_solver.cpp:106] Iteration 2350, lr = 0.001
I0614 15:30:56.731211  5755 solver.cpp:270] Iteration 2400 (3.95207 iter/s, 12.6516s/50 iter), loss = 0.0760887, remaining 0 hours and 40 minutes
I0614 15:30:56.731241  5755 solver.cpp:291]     Train net output #0: loss = 0.0760887 (* 1 = 0.0760887 loss)
I0614 15:30:56.731248  5755 sgd_solver.cpp:106] Iteration 2400, lr = 0.001
I0614 15:31:09.392190  5755 solver.cpp:270] Iteration 2450 (3.94928 iter/s, 12.6605s/50 iter), loss = 0.0791961, remaining 0 hours and 40 minutes
I0614 15:31:09.392221  5755 solver.cpp:291]     Train net output #0: loss = 0.0791961 (* 1 = 0.0791961 loss)
I0614 15:31:09.392244  5755 sgd_solver.cpp:106] Iteration 2450, lr = 0.001
I0614 15:31:22.057267  5755 solver.cpp:270] Iteration 2500 (3.948 iter/s, 12.6646s/50 iter), loss = 0.188948, remaining 0 hours and 40 minutes
I0614 15:31:22.057541  5755 solver.cpp:291]     Train net output #0: loss = 0.188948 (* 1 = 0.188948 loss)
I0614 15:31:22.057550  5755 sgd_solver.cpp:106] Iteration 2500, lr = 0.0001
I0614 15:31:34.696496  5755 solver.cpp:270] Iteration 2550 (3.95615 iter/s, 12.6385s/50 iter), loss = 0.0668675, remaining 0 hours and 39 minutes
I0614 15:31:34.696527  5755 solver.cpp:291]     Train net output #0: loss = 0.0668675 (* 1 = 0.0668675 loss)
I0614 15:31:34.696534  5755 sgd_solver.cpp:106] Iteration 2550, lr = 0.0001
I0614 15:31:47.357933  5755 solver.cpp:270] Iteration 2600 (3.94914 iter/s, 12.661s/50 iter), loss = 0.0729963, remaining 0 hours and 39 minutes
I0614 15:31:47.357965  5755 solver.cpp:291]     Train net output #0: loss = 0.0729963 (* 1 = 0.0729963 loss)
I0614 15:31:47.357972  5755 sgd_solver.cpp:106] Iteration 2600, lr = 0.0001
I0614 15:31:59.986841  5755 solver.cpp:270] Iteration 2650 (3.95931 iter/s, 12.6285s/50 iter), loss = 0.0293048, remaining 0 hours and 39 minutes
I0614 15:31:59.987100  5755 solver.cpp:291]     Train net output #0: loss = 0.0293048 (* 1 = 0.0293048 loss)
I0614 15:31:59.987110  5755 sgd_solver.cpp:106] Iteration 2650, lr = 0.0001
I0614 15:32:12.650995  5755 solver.cpp:270] Iteration 2700 (3.94836 iter/s, 12.6635s/50 iter), loss = 0.0267799, remaining 0 hours and 39 minutes
I0614 15:32:12.651027  5755 solver.cpp:291]     Train net output #0: loss = 0.0267799 (* 1 = 0.0267799 loss)
I0614 15:32:12.651034  5755 sgd_solver.cpp:106] Iteration 2700, lr = 0.0001
I0614 15:32:25.303928  5755 solver.cpp:270] Iteration 2750 (3.95179 iter/s, 12.6525s/50 iter), loss = 0.0426434, remaining 0 hours and 38 minutes
I0614 15:32:25.303961  5755 solver.cpp:291]     Train net output #0: loss = 0.0426434 (* 1 = 0.0426434 loss)
I0614 15:32:25.303967  5755 sgd_solver.cpp:106] Iteration 2750, lr = 0.0001
I0614 15:32:37.927198  5755 solver.cpp:270] Iteration 2800 (3.96108 iter/s, 12.6228s/50 iter), loss = 0.0255015, remaining 0 hours and 38 minutes
I0614 15:32:37.927428  5755 solver.cpp:291]     Train net output #0: loss = 0.0255015 (* 1 = 0.0255015 loss)
I0614 15:32:37.927450  5755 sgd_solver.cpp:106] Iteration 2800, lr = 0.0001
I0614 15:32:50.579821  5755 solver.cpp:270] Iteration 2850 (3.95195 iter/s, 12.652s/50 iter), loss = 0.0605466, remaining 0 hours and 38 minutes
I0614 15:32:50.579852  5755 solver.cpp:291]     Train net output #0: loss = 0.0605466 (* 1 = 0.0605466 loss)
I0614 15:32:50.579859  5755 sgd_solver.cpp:106] Iteration 2850, lr = 0.0001
I0614 15:33:03.237829  5755 solver.cpp:270] Iteration 2900 (3.95021 iter/s, 12.6576s/50 iter), loss = 0.0466424, remaining 0 hours and 38 minutes
I0614 15:33:03.237861  5755 solver.cpp:291]     Train net output #0: loss = 0.0466424 (* 1 = 0.0466424 loss)
I0614 15:33:03.237884  5755 sgd_solver.cpp:106] Iteration 2900, lr = 0.0001
I0614 15:33:15.889315  5755 solver.cpp:270] Iteration 2950 (3.95224 iter/s, 12.651s/50 iter), loss = 0.0445431, remaining 0 hours and 37 minutes
I0614 15:33:15.889605  5755 solver.cpp:291]     Train net output #0: loss = 0.0445431 (* 1 = 0.0445431 loss)
I0614 15:33:15.889613  5755 sgd_solver.cpp:106] Iteration 2950, lr = 0.0001
I0614 15:33:28.309661  5755 solver.cpp:424] Iteration 3000, Testing net (#0)
I0614 15:33:29.824524  5755 solver.cpp:523]     Test net output #0: accuracy = 0.95175
I0614 15:33:29.824553  5755 solver.cpp:523]     Test net output #1: loss = 0.120229 (* 1 = 0.120229 loss)
I0614 15:33:29.824556  5755 solver.cpp:523]     Test net output #2: top-1 = 0.95175
I0614 15:33:30.075210  5755 solver.cpp:270] Iteration 3000 (3.52481 iter/s, 14.1851s/50 iter), loss = 0.0386637, remaining 0 hours and 42 minutes
I0614 15:33:30.075240  5755 solver.cpp:291]     Train net output #0: loss = 0.0386637 (* 1 = 0.0386637 loss)
I0614 15:33:30.075264  5755 sgd_solver.cpp:106] Iteration 3000, lr = 0.0001
I0614 15:33:42.740211  5755 solver.cpp:270] Iteration 3050 (3.94802 iter/s, 12.6646s/50 iter), loss = 0.0792072, remaining 0 hours and 37 minutes
I0614 15:33:42.740242  5755 solver.cpp:291]     Train net output #0: loss = 0.0792072 (* 1 = 0.0792072 loss)
I0614 15:33:42.740249  5755 sgd_solver.cpp:106] Iteration 3050, lr = 0.0001
I0614 15:33:55.380604  5755 solver.cpp:270] Iteration 3100 (3.95571 iter/s, 12.64s/50 iter), loss = 0.0114977, remaining 0 hours and 37 minutes
I0614 15:33:55.380857  5755 solver.cpp:291]     Train net output #0: loss = 0.0114977 (* 1 = 0.0114977 loss)
I0614 15:33:55.380882  5755 sgd_solver.cpp:106] Iteration 3100, lr = 0.0001
I0614 15:34:08.047065  5755 solver.cpp:270] Iteration 3150 (3.94764 iter/s, 12.6658s/50 iter), loss = 0.0774169, remaining 0 hours and 37 minutes
I0614 15:34:08.047097  5755 solver.cpp:291]     Train net output #0: loss = 0.077417 (* 1 = 0.077417 loss)
I0614 15:34:08.047120  5755 sgd_solver.cpp:106] Iteration 3150, lr = 0.0001
I0614 15:34:20.693912  5755 solver.cpp:270] Iteration 3200 (3.95369 iter/s, 12.6464s/50 iter), loss = 0.0122491, remaining 0 hours and 36 minutes
I0614 15:34:20.693943  5755 solver.cpp:291]     Train net output #0: loss = 0.0122491 (* 1 = 0.0122491 loss)
I0614 15:34:20.693949  5755 sgd_solver.cpp:106] Iteration 3200, lr = 0.0001
I0614 15:34:33.349170  5755 solver.cpp:270] Iteration 3250 (3.95106 iter/s, 12.6548s/50 iter), loss = 0.0187784, remaining 0 hours and 36 minutes
I0614 15:34:33.349393  5755 solver.cpp:291]     Train net output #0: loss = 0.0187784 (* 1 = 0.0187784 loss)
I0614 15:34:33.349401  5755 sgd_solver.cpp:106] Iteration 3250, lr = 0.0001
I0614 15:34:45.999725  5755 solver.cpp:270] Iteration 3300 (3.95259 iter/s, 12.6499s/50 iter), loss = 0.0562223, remaining 0 hours and 36 minutes
I0614 15:34:45.999755  5755 solver.cpp:291]     Train net output #0: loss = 0.0562223 (* 1 = 0.0562223 loss)
I0614 15:34:45.999763  5755 sgd_solver.cpp:106] Iteration 3300, lr = 0.0001
I0614 15:34:58.640966  5755 solver.cpp:270] Iteration 3350 (3.95545 iter/s, 12.6408s/50 iter), loss = 0.0291342, remaining 0 hours and 36 minutes
I0614 15:34:58.640998  5755 solver.cpp:291]     Train net output #0: loss = 0.0291342 (* 1 = 0.0291342 loss)
I0614 15:34:58.641005  5755 sgd_solver.cpp:106] Iteration 3350, lr = 0.0001
I0614 15:35:11.296208  5755 solver.cpp:270] Iteration 3400 (3.95107 iter/s, 12.6548s/50 iter), loss = 0.0343357, remaining 0 hours and 36 minutes
I0614 15:35:11.296425  5755 solver.cpp:291]     Train net output #0: loss = 0.0343357 (* 1 = 0.0343357 loss)
I0614 15:35:11.296433  5755 sgd_solver.cpp:106] Iteration 3400, lr = 0.0001
I0614 15:35:23.960314  5755 solver.cpp:270] Iteration 3450 (3.94836 iter/s, 12.6635s/50 iter), loss = 0.0287846, remaining 0 hours and 35 minutes
I0614 15:35:23.960345  5755 solver.cpp:291]     Train net output #0: loss = 0.0287846 (* 1 = 0.0287846 loss)
I0614 15:35:23.960352  5755 sgd_solver.cpp:106] Iteration 3450, lr = 0.0001
I0614 15:35:36.608364  5755 solver.cpp:270] Iteration 3500 (3.95332 iter/s, 12.6476s/50 iter), loss = 0.0341328, remaining 0 hours and 35 minutes
I0614 15:35:36.608397  5755 solver.cpp:291]     Train net output #0: loss = 0.0341328 (* 1 = 0.0341328 loss)
I0614 15:35:36.608420  5755 sgd_solver.cpp:106] Iteration 3500, lr = 0.0001
I0614 15:35:49.278079  5755 solver.cpp:270] Iteration 3550 (3.94656 iter/s, 12.6693s/50 iter), loss = 0.0340333, remaining 0 hours and 35 minutes
I0614 15:35:49.278327  5755 solver.cpp:291]     Train net output #0: loss = 0.0340333 (* 1 = 0.0340333 loss)
I0614 15:35:49.278335  5755 sgd_solver.cpp:106] Iteration 3550, lr = 0.0001
I0614 15:36:01.912827  5755 solver.cpp:270] Iteration 3600 (3.95755 iter/s, 12.6341s/50 iter), loss = 0.0362313, remaining 0 hours and 35 minutes
I0614 15:36:01.912858  5755 solver.cpp:291]     Train net output #0: loss = 0.0362313 (* 1 = 0.0362313 loss)
I0614 15:36:01.912865  5755 sgd_solver.cpp:106] Iteration 3600, lr = 0.0001
I0614 15:36:14.577790  5755 solver.cpp:270] Iteration 3650 (3.94804 iter/s, 12.6645s/50 iter), loss = 0.0336776, remaining 0 hours and 35 minutes
I0614 15:36:14.577823  5755 solver.cpp:291]     Train net output #0: loss = 0.0336777 (* 1 = 0.0336777 loss)
I0614 15:36:14.577831  5755 sgd_solver.cpp:106] Iteration 3650, lr = 0.0001
I0614 15:36:27.243391  5755 solver.cpp:270] Iteration 3700 (3.94784 iter/s, 12.6652s/50 iter), loss = 0.0120071, remaining 0 hours and 34 minutes
I0614 15:36:27.243647  5755 solver.cpp:291]     Train net output #0: loss = 0.0120071 (* 1 = 0.0120071 loss)
I0614 15:36:27.243655  5755 sgd_solver.cpp:106] Iteration 3700, lr = 0.0001
I0614 15:36:39.905853  5755 solver.cpp:270] Iteration 3750 (3.94889 iter/s, 12.6618s/50 iter), loss = 0.0295018, remaining 0 hours and 34 minutes
I0614 15:36:39.905884  5755 solver.cpp:291]     Train net output #0: loss = 0.0295018 (* 1 = 0.0295018 loss)
I0614 15:36:39.905890  5755 sgd_solver.cpp:106] Iteration 3750, lr = 0.0001
I0614 15:36:52.556844  5755 solver.cpp:270] Iteration 3800 (3.9524 iter/s, 12.6506s/50 iter), loss = 0.0274216, remaining 0 hours and 34 minutes
I0614 15:36:52.556875  5755 solver.cpp:291]     Train net output #0: loss = 0.0274216 (* 1 = 0.0274216 loss)
I0614 15:36:52.556883  5755 sgd_solver.cpp:106] Iteration 3800, lr = 0.0001
I0614 15:37:05.205336  5755 solver.cpp:270] Iteration 3850 (3.95318 iter/s, 12.6481s/50 iter), loss = 0.0123853, remaining 0 hours and 34 minutes
I0614 15:37:05.205514  5755 solver.cpp:291]     Train net output #0: loss = 0.0123853 (* 1 = 0.0123853 loss)
I0614 15:37:05.205538  5755 sgd_solver.cpp:106] Iteration 3850, lr = 0.0001
I0614 15:37:17.868072  5755 solver.cpp:270] Iteration 3900 (3.94878 iter/s, 12.6622s/50 iter), loss = 0.00683106, remaining 0 hours and 34 minutes
I0614 15:37:17.868105  5755 solver.cpp:291]     Train net output #0: loss = 0.00683107 (* 1 = 0.00683107 loss)
I0614 15:37:17.868129  5755 sgd_solver.cpp:106] Iteration 3900, lr = 0.0001
I0614 15:37:30.499660  5755 solver.cpp:270] Iteration 3950 (3.95847 iter/s, 12.6311s/50 iter), loss = 0.0164655, remaining 0 hours and 33 minutes
I0614 15:37:30.499691  5755 solver.cpp:291]     Train net output #0: loss = 0.0164655 (* 1 = 0.0164655 loss)
I0614 15:37:30.499698  5755 sgd_solver.cpp:106] Iteration 3950, lr = 0.0001
I0614 15:37:42.908233  5755 solver.cpp:424] Iteration 4000, Testing net (#0)
I0614 15:37:44.419488  5755 solver.cpp:523]     Test net output #0: accuracy = 0.95325
I0614 15:37:44.419517  5755 solver.cpp:523]     Test net output #1: loss = 0.116358 (* 1 = 0.116358 loss)
I0614 15:37:44.419521  5755 solver.cpp:523]     Test net output #2: top-1 = 0.95325
I0614 15:37:44.671087  5755 solver.cpp:270] Iteration 4000 (3.52835 iter/s, 14.1709s/50 iter), loss = 0.0199144, remaining 0 hours and 37 minutes
I0614 15:37:44.671118  5755 solver.cpp:291]     Train net output #0: loss = 0.0199145 (* 1 = 0.0199145 loss)
I0614 15:37:44.671126  5755 sgd_solver.cpp:106] Iteration 4000, lr = 0.0001
I0614 15:37:57.331327  5755 solver.cpp:270] Iteration 4050 (3.94951 iter/s, 12.6598s/50 iter), loss = 0.0149045, remaining 0 hours and 33 minutes
I0614 15:37:57.331360  5755 solver.cpp:291]     Train net output #0: loss = 0.0149045 (* 1 = 0.0149045 loss)
I0614 15:37:57.331384  5755 sgd_solver.cpp:106] Iteration 4050, lr = 0.0001
I0614 15:38:10.018285  5755 solver.cpp:270] Iteration 4100 (3.94119 iter/s, 12.6865s/50 iter), loss = 0.0174367, remaining 0 hours and 33 minutes
I0614 15:38:10.018316  5755 solver.cpp:291]     Train net output #0: loss = 0.0174367 (* 1 = 0.0174367 loss)
I0614 15:38:10.018323  5755 sgd_solver.cpp:106] Iteration 4100, lr = 0.0001
I0614 15:38:22.683666  5755 solver.cpp:270] Iteration 4150 (3.94791 iter/s, 12.6649s/50 iter), loss = 0.0341086, remaining 0 hours and 32 minutes
I0614 15:38:22.683987  5755 solver.cpp:291]     Train net output #0: loss = 0.0341087 (* 1 = 0.0341087 loss)
I0614 15:38:22.683995  5755 sgd_solver.cpp:106] Iteration 4150, lr = 0.0001
I0614 15:38:35.348898  5755 solver.cpp:270] Iteration 4200 (3.94804 iter/s, 12.6645s/50 iter), loss = 0.0263069, remaining 0 hours and 32 minutes
I0614 15:38:35.348932  5755 solver.cpp:291]     Train net output #0: loss = 0.0263069 (* 1 = 0.0263069 loss)
I0614 15:38:35.348939  5755 sgd_solver.cpp:106] Iteration 4200, lr = 0.0001
I0614 15:38:47.978930  5755 solver.cpp:270] Iteration 4250 (3.95896 iter/s, 12.6296s/50 iter), loss = 0.00600921, remaining 0 hours and 32 minutes
I0614 15:38:47.978961  5755 solver.cpp:291]     Train net output #0: loss = 0.00600925 (* 1 = 0.00600925 loss)
I0614 15:38:47.978968  5755 sgd_solver.cpp:106] Iteration 4250, lr = 0.0001
I0614 15:39:00.637743  5755 solver.cpp:270] Iteration 4300 (3.94995 iter/s, 12.6584s/50 iter), loss = 0.052258, remaining 0 hours and 32 minutes
I0614 15:39:00.637986  5755 solver.cpp:291]     Train net output #0: loss = 0.0522581 (* 1 = 0.0522581 loss)
I0614 15:39:00.638010  5755 sgd_solver.cpp:106] Iteration 4300, lr = 0.0001
I0614 15:39:13.281252  5755 solver.cpp:270] Iteration 4350 (3.9548 iter/s, 12.6429s/50 iter), loss = 0.0134053, remaining 0 hours and 32 minutes
I0614 15:39:13.281283  5755 solver.cpp:291]     Train net output #0: loss = 0.0134053 (* 1 = 0.0134053 loss)
I0614 15:39:13.281307  5755 sgd_solver.cpp:106] Iteration 4350, lr = 0.0001
I0614 15:39:25.906805  5755 solver.cpp:270] Iteration 4400 (3.96036 iter/s, 12.6251s/50 iter), loss = 0.0342382, remaining 0 hours and 31 minutes
I0614 15:39:25.906836  5755 solver.cpp:291]     Train net output #0: loss = 0.0342382 (* 1 = 0.0342382 loss)
I0614 15:39:25.906844  5755 sgd_solver.cpp:106] Iteration 4400, lr = 0.0001
I0614 15:39:38.547848  5755 solver.cpp:270] Iteration 4450 (3.95551 iter/s, 12.6406s/50 iter), loss = 0.0136018, remaining 0 hours and 31 minutes
I0614 15:39:38.548092  5755 solver.cpp:291]     Train net output #0: loss = 0.0136019 (* 1 = 0.0136019 loss)
I0614 15:39:38.548100  5755 sgd_solver.cpp:106] Iteration 4450, lr = 0.0001
I0614 15:39:51.206089  5755 solver.cpp:270] Iteration 4500 (3.9502 iter/s, 12.6576s/50 iter), loss = 0.0226655, remaining 0 hours and 31 minutes
I0614 15:39:51.206121  5755 solver.cpp:291]     Train net output #0: loss = 0.0226656 (* 1 = 0.0226656 loss)
I0614 15:39:51.206130  5755 sgd_solver.cpp:106] Iteration 4500, lr = 0.0001
I0614 15:40:03.857501  5755 solver.cpp:270] Iteration 4550 (3.95227 iter/s, 12.651s/50 iter), loss = 0.0280999, remaining 0 hours and 31 minutes
I0614 15:40:03.857532  5755 solver.cpp:291]     Train net output #0: loss = 0.0280999 (* 1 = 0.0280999 loss)
I0614 15:40:03.857539  5755 sgd_solver.cpp:106] Iteration 4550, lr = 0.0001
I0614 15:40:16.501222  5755 solver.cpp:270] Iteration 4600 (3.95467 iter/s, 12.6433s/50 iter), loss = 0.00998438, remaining 0 hours and 31 minutes
I0614 15:40:16.501567  5755 solver.cpp:291]     Train net output #0: loss = 0.00998441 (* 1 = 0.00998441 loss)
I0614 15:40:16.501590  5755 sgd_solver.cpp:106] Iteration 4600, lr = 0.0001
I0614 15:40:29.133774  5755 solver.cpp:270] Iteration 4650 (3.95826 iter/s, 12.6318s/50 iter), loss = 0.0377119, remaining 0 hours and 30 minutes
I0614 15:40:29.133806  5755 solver.cpp:291]     Train net output #0: loss = 0.037712 (* 1 = 0.037712 loss)
I0614 15:40:29.133813  5755 sgd_solver.cpp:106] Iteration 4650, lr = 0.0001
I0614 15:40:41.790539  5755 solver.cpp:270] Iteration 4700 (3.95059 iter/s, 12.6563s/50 iter), loss = 0.0338067, remaining 0 hours and 30 minutes
I0614 15:40:41.790570  5755 solver.cpp:291]     Train net output #0: loss = 0.0338067 (* 1 = 0.0338067 loss)
I0614 15:40:41.790578  5755 sgd_solver.cpp:106] Iteration 4700, lr = 0.0001
I0614 15:40:54.434307  5755 solver.cpp:270] Iteration 4750 (3.95465 iter/s, 12.6433s/50 iter), loss = 0.0158702, remaining 0 hours and 30 minutes
I0614 15:40:54.434540  5755 solver.cpp:291]     Train net output #0: loss = 0.0158703 (* 1 = 0.0158703 loss)
I0614 15:40:54.434563  5755 sgd_solver.cpp:106] Iteration 4750, lr = 0.0001
I0614 15:41:07.205011  5755 solver.cpp:270] Iteration 4800 (3.91541 iter/s, 12.7701s/50 iter), loss = 0.0290168, remaining 0 hours and 30 minutes
I0614 15:41:07.205045  5755 solver.cpp:291]     Train net output #0: loss = 0.0290168 (* 1 = 0.0290168 loss)
I0614 15:41:07.205053  5755 sgd_solver.cpp:106] Iteration 4800, lr = 0.0001
I0614 15:41:20.374908  5755 solver.cpp:270] Iteration 4850 (3.79667 iter/s, 13.1694s/50 iter), loss = 0.0210993, remaining 0 hours and 31 minutes
I0614 15:41:20.374939  5755 solver.cpp:291]     Train net output #0: loss = 0.0210994 (* 1 = 0.0210994 loss)
I0614 15:41:20.374946  5755 sgd_solver.cpp:106] Iteration 4850, lr = 0.0001
I0614 15:41:33.224138  5755 solver.cpp:270] Iteration 4900 (3.89142 iter/s, 12.8488s/50 iter), loss = 0.0149586, remaining 0 hours and 30 minutes
I0614 15:41:33.224315  5755 solver.cpp:291]     Train net output #0: loss = 0.0149586 (* 1 = 0.0149586 loss)
I0614 15:41:33.224323  5755 sgd_solver.cpp:106] Iteration 4900, lr = 0.0001
I0614 15:41:45.881953  5755 solver.cpp:270] Iteration 4950 (3.95031 iter/s, 12.6572s/50 iter), loss = 0.0123575, remaining 0 hours and 29 minutes
I0614 15:41:45.881984  5755 solver.cpp:291]     Train net output #0: loss = 0.0123576 (* 1 = 0.0123576 loss)
I0614 15:41:45.882009  5755 sgd_solver.cpp:106] Iteration 4950, lr = 0.0001
I0614 15:41:58.286587  5755 solver.cpp:424] Iteration 5000, Testing net (#0)
I0614 15:41:59.798637  5755 solver.cpp:523]     Test net output #0: accuracy = 0.954
I0614 15:41:59.798666  5755 solver.cpp:523]     Test net output #1: loss = 0.132829 (* 1 = 0.132829 loss)
I0614 15:41:59.798671  5755 solver.cpp:523]     Test net output #2: top-1 = 0.954
I0614 15:42:00.051615  5755 solver.cpp:270] Iteration 5000 (3.52879 iter/s, 14.1692s/50 iter), loss = 0.0141329, remaining 0 hours and 32 minutes
I0614 15:42:00.051645  5755 solver.cpp:291]     Train net output #0: loss = 0.0141329 (* 1 = 0.0141329 loss)
I0614 15:42:00.051651  5755 sgd_solver.cpp:106] Iteration 5000, lr = 1e-05
I0614 15:42:12.703778  5755 solver.cpp:270] Iteration 5050 (3.95203 iter/s, 12.6517s/50 iter), loss = 0.0131108, remaining 0 hours and 29 minutes
I0614 15:42:12.704033  5755 solver.cpp:291]     Train net output #0: loss = 0.0131108 (* 1 = 0.0131108 loss)
I0614 15:42:12.704042  5755 sgd_solver.cpp:106] Iteration 5050, lr = 1e-05
I0614 15:42:25.365540  5755 solver.cpp:270] Iteration 5100 (3.9491 iter/s, 12.6611s/50 iter), loss = 0.00364794, remaining 0 hours and 29 minutes
I0614 15:42:25.365572  5755 solver.cpp:291]     Train net output #0: loss = 0.00364798 (* 1 = 0.00364798 loss)
I0614 15:42:25.365581  5755 sgd_solver.cpp:106] Iteration 5100, lr = 1e-05
I0614 15:42:38.004734  5755 solver.cpp:270] Iteration 5150 (3.95609 iter/s, 12.6388s/50 iter), loss = 0.0129481, remaining 0 hours and 28 minutes
I0614 15:42:38.004765  5755 solver.cpp:291]     Train net output #0: loss = 0.0129481 (* 1 = 0.0129481 loss)
I0614 15:42:38.004773  5755 sgd_solver.cpp:106] Iteration 5150, lr = 1e-05
I0614 15:42:50.648880  5755 solver.cpp:270] Iteration 5200 (3.95454 iter/s, 12.6437s/50 iter), loss = 0.00110045, remaining 0 hours and 28 minutes
I0614 15:42:50.649211  5755 solver.cpp:291]     Train net output #0: loss = 0.00110049 (* 1 = 0.00110049 loss)
I0614 15:42:50.649219  5755 sgd_solver.cpp:106] Iteration 5200, lr = 1e-05
I0614 15:43:03.311564  5755 solver.cpp:270] Iteration 5250 (3.94884 iter/s, 12.6619s/50 iter), loss = 0.0168656, remaining 0 hours and 28 minutes
I0614 15:43:03.311594  5755 solver.cpp:291]     Train net output #0: loss = 0.0168657 (* 1 = 0.0168657 loss)
I0614 15:43:03.311600  5755 sgd_solver.cpp:106] Iteration 5250, lr = 1e-05
I0614 15:43:15.980607  5755 solver.cpp:270] Iteration 5300 (3.94676 iter/s, 12.6686s/50 iter), loss = 0.00725081, remaining 0 hours and 28 minutes
I0614 15:43:15.980639  5755 solver.cpp:291]     Train net output #0: loss = 0.00725085 (* 1 = 0.00725085 loss)
I0614 15:43:15.980646  5755 sgd_solver.cpp:106] Iteration 5300, lr = 1e-05
I0614 15:43:28.625222  5755 solver.cpp:270] Iteration 5350 (3.95439 iter/s, 12.6442s/50 iter), loss = 0.0136994, remaining 0 hours and 27 minutes
I0614 15:43:28.625495  5755 solver.cpp:291]     Train net output #0: loss = 0.0136994 (* 1 = 0.0136994 loss)
I0614 15:43:28.625520  5755 sgd_solver.cpp:106] Iteration 5350, lr = 1e-05
I0614 15:43:41.285836  5755 solver.cpp:270] Iteration 5400 (3.94947 iter/s, 12.6599s/50 iter), loss = 0.00243573, remaining 0 hours and 27 minutes
I0614 15:43:41.285867  5755 solver.cpp:291]     Train net output #0: loss = 0.00243578 (* 1 = 0.00243578 loss)
I0614 15:43:41.285876  5755 sgd_solver.cpp:106] Iteration 5400, lr = 1e-05
I0614 15:43:53.923760  5755 solver.cpp:270] Iteration 5450 (3.95648 iter/s, 12.6375s/50 iter), loss = 0.013476, remaining 0 hours and 27 minutes
I0614 15:43:53.923794  5755 solver.cpp:291]     Train net output #0: loss = 0.0134761 (* 1 = 0.0134761 loss)
I0614 15:43:53.923800  5755 sgd_solver.cpp:106] Iteration 5450, lr = 1e-05
I0614 15:44:06.593466  5755 solver.cpp:270] Iteration 5500 (3.94656 iter/s, 12.6693s/50 iter), loss = 0.0117584, remaining 0 hours and 27 minutes
I0614 15:44:06.593700  5755 solver.cpp:291]     Train net output #0: loss = 0.0117585 (* 1 = 0.0117585 loss)
I0614 15:44:06.593725  5755 sgd_solver.cpp:106] Iteration 5500, lr = 1e-05
I0614 15:44:19.246614  5755 solver.cpp:270] Iteration 5550 (3.95179 iter/s, 12.6525s/50 iter), loss = 0.0446021, remaining 0 hours and 27 minutes
I0614 15:44:19.246646  5755 solver.cpp:291]     Train net output #0: loss = 0.0446022 (* 1 = 0.0446022 loss)
I0614 15:44:19.246654  5755 sgd_solver.cpp:106] Iteration 5550, lr = 1e-05
I0614 15:44:31.899194  5755 solver.cpp:270] Iteration 5600 (3.9519 iter/s, 12.6521s/50 iter), loss = 0.0193975, remaining 0 hours and 26 minutes
I0614 15:44:31.899228  5755 solver.cpp:291]     Train net output #0: loss = 0.0193976 (* 1 = 0.0193976 loss)
I0614 15:44:31.899237  5755 sgd_solver.cpp:106] Iteration 5600, lr = 1e-05
I0614 15:44:44.564738  5755 solver.cpp:270] Iteration 5650 (3.94786 iter/s, 12.6651s/50 iter), loss = 0.0130315, remaining 0 hours and 26 minutes
I0614 15:44:44.564983  5755 solver.cpp:291]     Train net output #0: loss = 0.0130315 (* 1 = 0.0130315 loss)
I0614 15:44:44.565007  5755 sgd_solver.cpp:106] Iteration 5650, lr = 1e-05
I0614 15:44:57.226049  5755 solver.cpp:270] Iteration 5700 (3.94924 iter/s, 12.6607s/50 iter), loss = 0.00109062, remaining 0 hours and 26 minutes
I0614 15:44:57.226083  5755 solver.cpp:291]     Train net output #0: loss = 0.00109067 (* 1 = 0.00109067 loss)
I0614 15:44:57.226089  5755 sgd_solver.cpp:106] Iteration 5700, lr = 1e-05
I0614 15:45:09.881399  5755 solver.cpp:270] Iteration 5750 (3.95104 iter/s, 12.6549s/50 iter), loss = 0.0148426, remaining 0 hours and 26 minutes
I0614 15:45:09.881431  5755 solver.cpp:291]     Train net output #0: loss = 0.0148427 (* 1 = 0.0148427 loss)
I0614 15:45:09.881455  5755 sgd_solver.cpp:106] Iteration 5750, lr = 1e-05
I0614 15:45:22.542562  5755 solver.cpp:270] Iteration 5800 (3.94922 iter/s, 12.6607s/50 iter), loss = 0.00215707, remaining 0 hours and 26 minutes
I0614 15:45:22.542888  5755 solver.cpp:291]     Train net output #0: loss = 0.00215711 (* 1 = 0.00215711 loss)
I0614 15:45:22.542897  5755 sgd_solver.cpp:106] Iteration 5800, lr = 1e-05
I0614 15:45:35.185770  5755 solver.cpp:270] Iteration 5850 (3.95492 iter/s, 12.6425s/50 iter), loss = 0.00653611, remaining 0 hours and 25 minutes
I0614 15:45:35.185801  5755 solver.cpp:291]     Train net output #0: loss = 0.00653616 (* 1 = 0.00653616 loss)
I0614 15:45:35.185809  5755 sgd_solver.cpp:106] Iteration 5850, lr = 1e-05
I0614 15:45:47.813484  5755 solver.cpp:270] Iteration 5900 (3.95968 iter/s, 12.6273s/50 iter), loss = 0.00581251, remaining 0 hours and 25 minutes
I0614 15:45:47.813519  5755 solver.cpp:291]     Train net output #0: loss = 0.00581256 (* 1 = 0.00581256 loss)
I0614 15:45:47.813527  5755 sgd_solver.cpp:106] Iteration 5900, lr = 1e-05
I0614 15:46:00.476573  5755 solver.cpp:270] Iteration 5950 (3.94862 iter/s, 12.6626s/50 iter), loss = 0.00685345, remaining 0 hours and 25 minutes
I0614 15:46:00.476824  5755 solver.cpp:291]     Train net output #0: loss = 0.0068535 (* 1 = 0.0068535 loss)
I0614 15:46:00.476833  5755 sgd_solver.cpp:106] Iteration 5950, lr = 1e-05
I0614 15:46:12.887571  5755 solver.cpp:935] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.3/snapshots/_iter_6000.caffemodel
I0614 15:46:18.753559  5755 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.3/snapshots/_iter_6000.solverstate
I0614 15:46:22.385614  5755 solver.cpp:424] Iteration 6000, Testing net (#0)
I0614 15:46:23.809255  5755 solver.cpp:523]     Test net output #0: accuracy = 0.95525
I0614 15:46:23.809286  5755 solver.cpp:523]     Test net output #1: loss = 0.146242 (* 1 = 0.146242 loss)
I0614 15:46:23.809291  5755 solver.cpp:523]     Test net output #2: top-1 = 0.95525
I0614 15:46:24.053462  5755 solver.cpp:270] Iteration 6000 (2.12081 iter/s, 23.5759s/50 iter), loss = 0.00935213, remaining 0 hours and 47 minutes
I0614 15:46:24.053490  5755 solver.cpp:291]     Train net output #0: loss = 0.00935218 (* 1 = 0.00935218 loss)
I0614 15:46:24.053498  5755 sgd_solver.cpp:106] Iteration 6000, lr = 1e-05
I0614 15:46:36.629571  5755 solver.cpp:270] Iteration 6050 (3.97593 iter/s, 12.5757s/50 iter), loss = 0.0141611, remaining 0 hours and 24 minutes
I0614 15:46:36.629806  5755 solver.cpp:291]     Train net output #0: loss = 0.0141612 (* 1 = 0.0141612 loss)
I0614 15:46:36.629813  5755 sgd_solver.cpp:106] Iteration 6050, lr = 1e-05
I0614 15:46:49.196893  5755 solver.cpp:270] Iteration 6100 (3.97878 iter/s, 12.5667s/50 iter), loss = 0.00399876, remaining 0 hours and 24 minutes
I0614 15:46:49.196926  5755 solver.cpp:291]     Train net output #0: loss = 0.00399881 (* 1 = 0.00399881 loss)
I0614 15:46:49.196934  5755 sgd_solver.cpp:106] Iteration 6100, lr = 1e-05
I0614 15:47:01.845923  5755 solver.cpp:270] Iteration 6150 (3.95301 iter/s, 12.6486s/50 iter), loss = 0.0210236, remaining 0 hours and 24 minutes
I0614 15:47:01.845954  5755 solver.cpp:291]     Train net output #0: loss = 0.0210236 (* 1 = 0.0210236 loss)
I0614 15:47:01.845963  5755 sgd_solver.cpp:106] Iteration 6150, lr = 1e-05
I0614 15:47:14.500653  5755 solver.cpp:270] Iteration 6200 (3.95123 iter/s, 12.6543s/50 iter), loss = 0.00430123, remaining 0 hours and 24 minutes
I0614 15:47:14.500908  5755 solver.cpp:291]     Train net output #0: loss = 0.00430127 (* 1 = 0.00430127 loss)
I0614 15:47:14.500916  5755 sgd_solver.cpp:106] Iteration 6200, lr = 1e-05
I0614 15:47:27.156061  5755 solver.cpp:270] Iteration 6250 (3.95109 iter/s, 12.6547s/50 iter), loss = 0.00438467, remaining 0 hours and 24 minutes
I0614 15:47:27.156092  5755 solver.cpp:291]     Train net output #0: loss = 0.00438472 (* 1 = 0.00438472 loss)
I0614 15:47:27.156100  5755 sgd_solver.cpp:106] Iteration 6250, lr = 1e-05
I0614 15:47:39.822798  5755 solver.cpp:270] Iteration 6300 (3.94748 iter/s, 12.6663s/50 iter), loss = 0.00584938, remaining 0 hours and 24 minutes
I0614 15:47:39.822829  5755 solver.cpp:291]     Train net output #0: loss = 0.00584942 (* 1 = 0.00584942 loss)
I0614 15:47:39.822836  5755 sgd_solver.cpp:106] Iteration 6300, lr = 1e-05
I0614 15:47:52.467972  5755 solver.cpp:270] Iteration 6350 (3.95421 iter/s, 12.6447s/50 iter), loss = 0.00665038, remaining 0 hours and 23 minutes
I0614 15:47:52.468313  5755 solver.cpp:291]     Train net output #0: loss = 0.00665042 (* 1 = 0.00665042 loss)
I0614 15:47:52.468338  5755 sgd_solver.cpp:106] Iteration 6350, lr = 1e-05
I0614 15:48:05.118889  5755 solver.cpp:270] Iteration 6400 (3.95252 iter/s, 12.6502s/50 iter), loss = 0.000678296, remaining 0 hours and 23 minutes
I0614 15:48:05.118921  5755 solver.cpp:291]     Train net output #0: loss = 0.000678337 (* 1 = 0.000678337 loss)
I0614 15:48:05.118928  5755 sgd_solver.cpp:106] Iteration 6400, lr = 1e-05
I0614 15:48:17.773705  5755 solver.cpp:270] Iteration 6450 (3.9512 iter/s, 12.6544s/50 iter), loss = 0.00063292, remaining 0 hours and 23 minutes
I0614 15:48:17.773736  5755 solver.cpp:291]     Train net output #0: loss = 0.000632958 (* 1 = 0.000632958 loss)
I0614 15:48:17.773742  5755 sgd_solver.cpp:106] Iteration 6450, lr = 1e-05
I0614 15:48:30.445578  5755 solver.cpp:270] Iteration 6500 (3.94588 iter/s, 12.6714s/50 iter), loss = 0.0107789, remaining 0 hours and 23 minutes
I0614 15:48:30.445828  5755 solver.cpp:291]     Train net output #0: loss = 0.0107789 (* 1 = 0.0107789 loss)
I0614 15:48:30.445837  5755 sgd_solver.cpp:106] Iteration 6500, lr = 1e-05
I0614 15:48:43.110543  5755 solver.cpp:270] Iteration 6550 (3.9481 iter/s, 12.6643s/50 iter), loss = 0.00563122, remaining 0 hours and 22 minutes
I0614 15:48:43.110575  5755 solver.cpp:291]     Train net output #0: loss = 0.00563126 (* 1 = 0.00563126 loss)
I0614 15:48:43.110599  5755 sgd_solver.cpp:106] Iteration 6550, lr = 1e-05
I0614 15:48:55.782189  5755 solver.cpp:270] Iteration 6600 (3.94595 iter/s, 12.6712s/50 iter), loss = 0.00567094, remaining 0 hours and 22 minutes
I0614 15:48:55.782222  5755 solver.cpp:291]     Train net output #0: loss = 0.00567098 (* 1 = 0.00567098 loss)
I0614 15:48:55.782244  5755 sgd_solver.cpp:106] Iteration 6600, lr = 1e-05
I0614 15:49:08.445187  5755 solver.cpp:270] Iteration 6650 (3.94865 iter/s, 12.6626s/50 iter), loss = 0.00669216, remaining 0 hours and 22 minutes
I0614 15:49:08.445456  5755 solver.cpp:291]     Train net output #0: loss = 0.0066922 (* 1 = 0.0066922 loss)
I0614 15:49:08.445480  5755 sgd_solver.cpp:106] Iteration 6650, lr = 1e-05
I0614 15:49:21.097800  5755 solver.cpp:270] Iteration 6700 (3.95196 iter/s, 12.6519s/50 iter), loss = 0.0115217, remaining 0 hours and 22 minutes
I0614 15:49:21.097833  5755 solver.cpp:291]     Train net output #0: loss = 0.0115218 (* 1 = 0.0115218 loss)
I0614 15:49:21.097841  5755 sgd_solver.cpp:106] Iteration 6700, lr = 1e-05
I0614 15:49:33.759959  5755 solver.cpp:270] Iteration 6750 (3.94891 iter/s, 12.6617s/50 iter), loss = 0.0051737, remaining 0 hours and 22 minutes
I0614 15:49:33.759994  5755 solver.cpp:291]     Train net output #0: loss = 0.00517374 (* 1 = 0.00517374 loss)
I0614 15:49:33.760016  5755 sgd_solver.cpp:106] Iteration 6750, lr = 1e-05
I0614 15:49:46.424387  5755 solver.cpp:270] Iteration 6800 (3.9482 iter/s, 12.664s/50 iter), loss = 0.00246861, remaining 0 hours and 21 minutes
I0614 15:49:46.424635  5755 solver.cpp:291]     Train net output #0: loss = 0.00246865 (* 1 = 0.00246865 loss)
I0614 15:49:46.424659  5755 sgd_solver.cpp:106] Iteration 6800, lr = 1e-05
I0614 15:49:59.073297  5755 solver.cpp:270] Iteration 6850 (3.95312 iter/s, 12.6483s/50 iter), loss = 0.000512474, remaining 0 hours and 21 minutes
I0614 15:49:59.073328  5755 solver.cpp:291]     Train net output #0: loss = 0.00051252 (* 1 = 0.00051252 loss)
I0614 15:49:59.073336  5755 sgd_solver.cpp:106] Iteration 6850, lr = 1e-05
I0614 15:50:11.734266  5755 solver.cpp:270] Iteration 6900 (3.94928 iter/s, 12.6605s/50 iter), loss = 0.00302424, remaining 0 hours and 21 minutes
I0614 15:50:11.734297  5755 solver.cpp:291]     Train net output #0: loss = 0.00302429 (* 1 = 0.00302429 loss)
I0614 15:50:11.734305  5755 sgd_solver.cpp:106] Iteration 6900, lr = 1e-05
I0614 15:50:24.350639  5755 solver.cpp:270] Iteration 6950 (3.96324 iter/s, 12.6159s/50 iter), loss = 0.0016727, remaining 0 hours and 21 minutes
I0614 15:50:24.350911  5755 solver.cpp:291]     Train net output #0: loss = 0.00167275 (* 1 = 0.00167275 loss)
I0614 15:50:24.350919  5755 sgd_solver.cpp:106] Iteration 6950, lr = 1e-05
I0614 15:50:36.751861  5755 solver.cpp:424] Iteration 7000, Testing net (#0)
I0614 15:50:38.218379  5755 solver.cpp:523]     Test net output #0: accuracy = 0.95725
I0614 15:50:38.218410  5755 solver.cpp:523]     Test net output #1: loss = 0.163355 (* 1 = 0.163355 loss)
I0614 15:50:38.218415  5755 solver.cpp:523]     Test net output #2: top-1 = 0.95725
I0614 15:50:38.470623  5755 solver.cpp:270] Iteration 7000 (3.54126 iter/s, 14.1193s/50 iter), loss = 0.00851269, remaining 0 hours and 23 minutes
I0614 15:50:38.470652  5755 solver.cpp:291]     Train net output #0: loss = 0.00851275 (* 1 = 0.00851275 loss)
I0614 15:50:38.470675  5755 sgd_solver.cpp:106] Iteration 7000, lr = 1e-05
I0614 15:50:51.106424  5755 solver.cpp:270] Iteration 7050 (3.95715 iter/s, 12.6354s/50 iter), loss = 0.00791411, remaining 0 hours and 20 minutes
I0614 15:50:51.106456  5755 solver.cpp:291]     Train net output #0: loss = 0.00791416 (* 1 = 0.00791416 loss)
I0614 15:50:51.106463  5755 sgd_solver.cpp:106] Iteration 7050, lr = 1e-05
I0614 15:51:03.776499  5755 solver.cpp:270] Iteration 7100 (3.94644 iter/s, 12.6696s/50 iter), loss = 0.00110245, remaining 0 hours and 20 minutes
I0614 15:51:03.776715  5755 solver.cpp:291]     Train net output #0: loss = 0.0011025 (* 1 = 0.0011025 loss)
I0614 15:51:03.776738  5755 sgd_solver.cpp:106] Iteration 7100, lr = 1e-05
I0614 15:51:16.406563  5755 solver.cpp:270] Iteration 7150 (3.959 iter/s, 12.6294s/50 iter), loss = 0.012773, remaining 0 hours and 20 minutes
I0614 15:51:16.406606  5755 solver.cpp:291]     Train net output #0: loss = 0.0127731 (* 1 = 0.0127731 loss)
I0614 15:51:16.406613  5755 sgd_solver.cpp:106] Iteration 7150, lr = 1e-05
I0614 15:51:29.418562  5755 solver.cpp:270] Iteration 7200 (3.84274 iter/s, 13.0115s/50 iter), loss = 0.015935, remaining 0 hours and 20 minutes
I0614 15:51:29.418596  5755 solver.cpp:291]     Train net output #0: loss = 0.0159351 (* 1 = 0.0159351 loss)
I0614 15:51:29.418619  5755 sgd_solver.cpp:106] Iteration 7200, lr = 1e-05
I0614 15:51:42.193836  5755 solver.cpp:270] Iteration 7250 (3.91395 iter/s, 12.7748s/50 iter), loss = 0.0111919, remaining 0 hours and 20 minutes
I0614 15:51:42.194038  5755 solver.cpp:291]     Train net output #0: loss = 0.0111919 (* 1 = 0.0111919 loss)
I0614 15:51:42.194061  5755 sgd_solver.cpp:106] Iteration 7250, lr = 1e-05
I0614 15:51:54.821311  5755 solver.cpp:270] Iteration 7300 (3.95981 iter/s, 12.6269s/50 iter), loss = 0.00628191, remaining 0 hours and 19 minutes
I0614 15:51:54.821341  5755 solver.cpp:291]     Train net output #0: loss = 0.00628197 (* 1 = 0.00628197 loss)
I0614 15:51:54.821348  5755 sgd_solver.cpp:106] Iteration 7300, lr = 1e-05
I0614 15:52:07.475939  5755 solver.cpp:270] Iteration 7350 (3.95126 iter/s, 12.6542s/50 iter), loss = 0.00636048, remaining 0 hours and 19 minutes
I0614 15:52:07.475972  5755 solver.cpp:291]     Train net output #0: loss = 0.00636053 (* 1 = 0.00636053 loss)
I0614 15:52:07.475996  5755 sgd_solver.cpp:106] Iteration 7350, lr = 1e-05
I0614 15:52:20.103689  5755 solver.cpp:270] Iteration 7400 (3.95967 iter/s, 12.6273s/50 iter), loss = 0.0131945, remaining 0 hours and 19 minutes
I0614 15:52:20.103943  5755 solver.cpp:291]     Train net output #0: loss = 0.0131945 (* 1 = 0.0131945 loss)
I0614 15:52:20.103951  5755 sgd_solver.cpp:106] Iteration 7400, lr = 1e-05
I0614 15:52:32.741044  5755 solver.cpp:270] Iteration 7450 (3.95673 iter/s, 12.6367s/50 iter), loss = 0.0184283, remaining 0 hours and 18 minutes
I0614 15:52:32.741075  5755 solver.cpp:291]     Train net output #0: loss = 0.0184283 (* 1 = 0.0184283 loss)
I0614 15:52:32.741082  5755 sgd_solver.cpp:106] Iteration 7450, lr = 1e-05
I0614 15:52:45.380836  5755 solver.cpp:270] Iteration 7500 (3.9559 iter/s, 12.6394s/50 iter), loss = 0.00393638, remaining 0 hours and 18 minutes
I0614 15:52:45.380868  5755 solver.cpp:291]     Train net output #0: loss = 0.00393643 (* 1 = 0.00393643 loss)
I0614 15:52:45.380893  5755 sgd_solver.cpp:106] Iteration 7500, lr = 1e-06
I0614 15:52:58.007488  5755 solver.cpp:270] Iteration 7550 (3.96002 iter/s, 12.6262s/50 iter), loss = 0.00333427, remaining 0 hours and 18 minutes
I0614 15:52:58.007769  5755 solver.cpp:291]     Train net output #0: loss = 0.00333432 (* 1 = 0.00333432 loss)
I0614 15:52:58.007779  5755 sgd_solver.cpp:106] Iteration 7550, lr = 1e-06
I0614 15:53:10.626871  5755 solver.cpp:270] Iteration 7600 (3.96237 iter/s, 12.6187s/50 iter), loss = 0.00170828, remaining 0 hours and 18 minutes
I0614 15:53:10.626904  5755 solver.cpp:291]     Train net output #0: loss = 0.00170833 (* 1 = 0.00170833 loss)
I0614 15:53:10.626911  5755 sgd_solver.cpp:106] Iteration 7600, lr = 1e-06
I0614 15:53:23.273888  5755 solver.cpp:270] Iteration 7650 (3.95364 iter/s, 12.6466s/50 iter), loss = 0.00779897, remaining 0 hours and 18 minutes
I0614 15:53:23.273921  5755 solver.cpp:291]     Train net output #0: loss = 0.00779903 (* 1 = 0.00779903 loss)
I0614 15:53:23.273928  5755 sgd_solver.cpp:106] Iteration 7650, lr = 1e-06
I0614 15:53:35.922749  5755 solver.cpp:270] Iteration 7700 (3.95306 iter/s, 12.6484s/50 iter), loss = 0.0018002, remaining 0 hours and 17 minutes
I0614 15:53:35.922998  5755 solver.cpp:291]     Train net output #0: loss = 0.00180025 (* 1 = 0.00180025 loss)
I0614 15:53:35.923023  5755 sgd_solver.cpp:106] Iteration 7700, lr = 1e-06
I0614 15:53:48.567755  5755 solver.cpp:270] Iteration 7750 (3.95434 iter/s, 12.6443s/50 iter), loss = 0.00629731, remaining 0 hours and 17 minutes
I0614 15:53:48.567786  5755 solver.cpp:291]     Train net output #0: loss = 0.00629737 (* 1 = 0.00629737 loss)
I0614 15:53:48.567795  5755 sgd_solver.cpp:106] Iteration 7750, lr = 1e-06
I0614 15:54:01.203771  5755 solver.cpp:270] Iteration 7800 (3.95708 iter/s, 12.6356s/50 iter), loss = 0.0154414, remaining 0 hours and 17 minutes
I0614 15:54:01.203804  5755 solver.cpp:291]     Train net output #0: loss = 0.0154415 (* 1 = 0.0154415 loss)
I0614 15:54:01.203811  5755 sgd_solver.cpp:106] Iteration 7800, lr = 1e-06
I0614 15:54:13.830427  5755 solver.cpp:270] Iteration 7850 (3.96001 iter/s, 12.6262s/50 iter), loss = 0.0171878, remaining 0 hours and 17 minutes
I0614 15:54:13.830648  5755 solver.cpp:291]     Train net output #0: loss = 0.0171878 (* 1 = 0.0171878 loss)
I0614 15:54:13.830657  5755 sgd_solver.cpp:106] Iteration 7850, lr = 1e-06
I0614 15:54:26.473721  5755 solver.cpp:270] Iteration 7900 (3.95486 iter/s, 12.6427s/50 iter), loss = 0.00126868, remaining 0 hours and 17 minutes
I0614 15:54:26.473752  5755 solver.cpp:291]     Train net output #0: loss = 0.00126874 (* 1 = 0.00126874 loss)
I0614 15:54:26.473775  5755 sgd_solver.cpp:106] Iteration 7900, lr = 1e-06
I0614 15:54:39.102726  5755 solver.cpp:270] Iteration 7950 (3.95928 iter/s, 12.6286s/50 iter), loss = 0.00410245, remaining 0 hours and 16 minutes
I0614 15:54:39.102757  5755 solver.cpp:291]     Train net output #0: loss = 0.0041025 (* 1 = 0.0041025 loss)
I0614 15:54:39.102766  5755 sgd_solver.cpp:106] Iteration 7950, lr = 1e-06
I0614 15:54:51.512521  5755 solver.cpp:424] Iteration 8000, Testing net (#0)
I0614 15:54:53.012908  5755 solver.cpp:523]     Test net output #0: accuracy = 0.95625
I0614 15:54:53.012938  5755 solver.cpp:523]     Test net output #1: loss = 0.190585 (* 1 = 0.190585 loss)
I0614 15:54:53.012943  5755 solver.cpp:523]     Test net output #2: top-1 = 0.95625
I0614 15:54:53.259366  5755 solver.cpp:270] Iteration 8000 (3.53203 iter/s, 14.1562s/50 iter), loss = 0.00177791, remaining 0 hours and 18 minutes
I0614 15:54:53.259397  5755 solver.cpp:291]     Train net output #0: loss = 0.00177797 (* 1 = 0.00177797 loss)
I0614 15:54:53.259404  5755 sgd_solver.cpp:106] Iteration 8000, lr = 1e-06
I0614 15:55:05.902395  5755 solver.cpp:270] Iteration 8050 (3.95489 iter/s, 12.6426s/50 iter), loss = 0.0243611, remaining 0 hours and 16 minutes
I0614 15:55:05.902426  5755 solver.cpp:291]     Train net output #0: loss = 0.0243612 (* 1 = 0.0243612 loss)
I0614 15:55:05.902433  5755 sgd_solver.cpp:106] Iteration 8050, lr = 1e-06
I0614 15:55:18.558845  5755 solver.cpp:270] Iteration 8100 (3.95069 iter/s, 12.656s/50 iter), loss = 0.014331, remaining 0 hours and 16 minutes
I0614 15:55:18.558876  5755 solver.cpp:291]     Train net output #0: loss = 0.014331 (* 1 = 0.014331 loss)
I0614 15:55:18.558884  5755 sgd_solver.cpp:106] Iteration 8100, lr = 1e-06
I0614 15:55:31.177618  5755 solver.cpp:270] Iteration 8150 (3.96249 iter/s, 12.6183s/50 iter), loss = 0.0165269, remaining 0 hours and 16 minutes
I0614 15:55:31.177956  5755 solver.cpp:291]     Train net output #0: loss = 0.016527 (* 1 = 0.016527 loss)
I0614 15:55:31.177966  5755 sgd_solver.cpp:106] Iteration 8150, lr = 1e-06
I0614 15:55:43.830291  5755 solver.cpp:270] Iteration 8200 (3.95197 iter/s, 12.6519s/50 iter), loss = 0.00431927, remaining 0 hours and 15 minutes
I0614 15:55:43.830323  5755 solver.cpp:291]     Train net output #0: loss = 0.00431932 (* 1 = 0.00431932 loss)
I0614 15:55:43.830332  5755 sgd_solver.cpp:106] Iteration 8200, lr = 1e-06
I0614 15:55:56.478400  5755 solver.cpp:270] Iteration 8250 (3.9533 iter/s, 12.6477s/50 iter), loss = 0.00600283, remaining 0 hours and 15 minutes
I0614 15:55:56.478433  5755 solver.cpp:291]     Train net output #0: loss = 0.00600289 (* 1 = 0.00600289 loss)
I0614 15:55:56.478441  5755 sgd_solver.cpp:106] Iteration 8250, lr = 1e-06
I0614 15:56:09.101358  5755 solver.cpp:270] Iteration 8300 (3.96117 iter/s, 12.6225s/50 iter), loss = 0.00279445, remaining 0 hours and 15 minutes
I0614 15:56:09.101617  5755 solver.cpp:291]     Train net output #0: loss = 0.00279451 (* 1 = 0.00279451 loss)
I0614 15:56:09.101626  5755 sgd_solver.cpp:106] Iteration 8300, lr = 1e-06
I0614 15:56:21.719641  5755 solver.cpp:270] Iteration 8350 (3.96271 iter/s, 12.6176s/50 iter), loss = 0.0022421, remaining 0 hours and 15 minutes
I0614 15:56:21.719672  5755 solver.cpp:291]     Train net output #0: loss = 0.00224216 (* 1 = 0.00224216 loss)
I0614 15:56:21.719696  5755 sgd_solver.cpp:106] Iteration 8350, lr = 1e-06
I0614 15:56:34.352160  5755 solver.cpp:270] Iteration 8400 (3.95818 iter/s, 12.6321s/50 iter), loss = 0.00643915, remaining 0 hours and 15 minutes
I0614 15:56:34.352191  5755 solver.cpp:291]     Train net output #0: loss = 0.00643921 (* 1 = 0.00643921 loss)
I0614 15:56:34.352216  5755 sgd_solver.cpp:106] Iteration 8400, lr = 1e-06
I0614 15:56:46.990480  5755 solver.cpp:270] Iteration 8450 (3.95636 iter/s, 12.6379s/50 iter), loss = 0.00633288, remaining 0 hours and 14 minutes
I0614 15:56:46.990739  5755 solver.cpp:291]     Train net output #0: loss = 0.00633294 (* 1 = 0.00633294 loss)
I0614 15:56:46.990748  5755 sgd_solver.cpp:106] Iteration 8450, lr = 1e-06
I0614 15:56:59.626298  5755 solver.cpp:270] Iteration 8500 (3.95721 iter/s, 12.6352s/50 iter), loss = 0.0186502, remaining 0 hours and 14 minutes
I0614 15:56:59.626329  5755 solver.cpp:291]     Train net output #0: loss = 0.0186503 (* 1 = 0.0186503 loss)
I0614 15:56:59.626338  5755 sgd_solver.cpp:106] Iteration 8500, lr = 1e-06
I0614 15:57:12.255201  5755 solver.cpp:270] Iteration 8550 (3.95931 iter/s, 12.6285s/50 iter), loss = 0.0176977, remaining 0 hours and 14 minutes
I0614 15:57:12.255234  5755 solver.cpp:291]     Train net output #0: loss = 0.0176978 (* 1 = 0.0176978 loss)
I0614 15:57:12.255241  5755 sgd_solver.cpp:106] Iteration 8550, lr = 1e-06
I0614 15:57:24.879209  5755 solver.cpp:270] Iteration 8600 (3.96084 iter/s, 12.6236s/50 iter), loss = 0.00913024, remaining 0 hours and 14 minutes
I0614 15:57:24.879465  5755 solver.cpp:291]     Train net output #0: loss = 0.00913029 (* 1 = 0.00913029 loss)
I0614 15:57:24.879489  5755 sgd_solver.cpp:106] Iteration 8600, lr = 1e-06
I0614 15:57:37.524333  5755 solver.cpp:270] Iteration 8650 (3.9543 iter/s, 12.6445s/50 iter), loss = 0.000303139, remaining 0 hours and 13 minutes
I0614 15:57:37.524364  5755 solver.cpp:291]     Train net output #0: loss = 0.000303196 (* 1 = 0.000303196 loss)
I0614 15:57:37.524389  5755 sgd_solver.cpp:106] Iteration 8650, lr = 1e-06
I0614 15:57:50.169183  5755 solver.cpp:270] Iteration 8700 (3.95432 iter/s, 12.6444s/50 iter), loss = 0.0109332, remaining 0 hours and 13 minutes
I0614 15:57:50.169215  5755 solver.cpp:291]     Train net output #0: loss = 0.0109332 (* 1 = 0.0109332 loss)
I0614 15:57:50.169224  5755 sgd_solver.cpp:106] Iteration 8700, lr = 1e-06
I0614 15:58:02.777493  5755 solver.cpp:270] Iteration 8750 (3.96578 iter/s, 12.6079s/50 iter), loss = 0.0341861, remaining 0 hours and 13 minutes
I0614 15:58:02.777827  5755 solver.cpp:291]     Train net output #0: loss = 0.0341862 (* 1 = 0.0341862 loss)
I0614 15:58:02.777853  5755 sgd_solver.cpp:106] Iteration 8750, lr = 1e-06
I0614 15:58:15.398514  5755 solver.cpp:270] Iteration 8800 (3.96188 iter/s, 12.6203s/50 iter), loss = 0.00944293, remaining 0 hours and 13 minutes
I0614 15:58:15.398545  5755 solver.cpp:291]     Train net output #0: loss = 0.00944299 (* 1 = 0.00944299 loss)
I0614 15:58:15.398553  5755 sgd_solver.cpp:106] Iteration 8800, lr = 1e-06
I0614 15:58:28.032828  5755 solver.cpp:270] Iteration 8850 (3.95761 iter/s, 12.6339s/50 iter), loss = 0.0079894, remaining 0 hours and 13 minutes
I0614 15:58:28.032860  5755 solver.cpp:291]     Train net output #0: loss = 0.00798945 (* 1 = 0.00798945 loss)
I0614 15:58:28.032886  5755 sgd_solver.cpp:106] Iteration 8850, lr = 1e-06
I0614 15:58:40.675308  5755 solver.cpp:270] Iteration 8900 (3.95506 iter/s, 12.642s/50 iter), loss = 0.00129441, remaining 0 hours and 12 minutes
I0614 15:58:40.675559  5755 solver.cpp:291]     Train net output #0: loss = 0.00129446 (* 1 = 0.00129446 loss)
I0614 15:58:40.675567  5755 sgd_solver.cpp:106] Iteration 8900, lr = 1e-06
I0614 15:58:53.295806  5755 solver.cpp:270] Iteration 8950 (3.96201 iter/s, 12.6198s/50 iter), loss = 0.00159184, remaining 0 hours and 12 minutes
I0614 15:58:53.295837  5755 solver.cpp:291]     Train net output #0: loss = 0.00159189 (* 1 = 0.00159189 loss)
I0614 15:58:53.295845  5755 sgd_solver.cpp:106] Iteration 8950, lr = 1e-06
I0614 15:59:05.675518  5755 solver.cpp:424] Iteration 9000, Testing net (#0)
I0614 15:59:07.170281  5755 solver.cpp:523]     Test net output #0: accuracy = 0.956
I0614 15:59:07.170310  5755 solver.cpp:523]     Test net output #1: loss = 0.211107 (* 1 = 0.211107 loss)
I0614 15:59:07.170313  5755 solver.cpp:523]     Test net output #2: top-1 = 0.956
I0614 15:59:07.417210  5755 solver.cpp:270] Iteration 9000 (3.54085 iter/s, 14.1209s/50 iter), loss = 0.0230507, remaining 0 hours and 14 minutes
I0614 15:59:07.417241  5755 solver.cpp:291]     Train net output #0: loss = 0.0230507 (* 1 = 0.0230507 loss)
I0614 15:59:07.417249  5755 sgd_solver.cpp:106] Iteration 9000, lr = 1e-06
I0614 15:59:20.071854  5755 solver.cpp:270] Iteration 9050 (3.95126 iter/s, 12.6542s/50 iter), loss = 0.00686444, remaining 0 hours and 12 minutes
I0614 15:59:20.072110  5755 solver.cpp:291]     Train net output #0: loss = 0.00686449 (* 1 = 0.00686449 loss)
I0614 15:59:20.072118  5755 sgd_solver.cpp:106] Iteration 9050, lr = 1e-06
I0614 15:59:32.707954  5755 solver.cpp:270] Iteration 9100 (3.95712 iter/s, 12.6354s/50 iter), loss = 0.0148782, remaining 0 hours and 12 minutes
I0614 15:59:32.707986  5755 solver.cpp:291]     Train net output #0: loss = 0.0148783 (* 1 = 0.0148783 loss)
I0614 15:59:32.708010  5755 sgd_solver.cpp:106] Iteration 9100, lr = 1e-06
I0614 15:59:45.318073  5755 solver.cpp:270] Iteration 9150 (3.96521 iter/s, 12.6097s/50 iter), loss = 0.00245806, remaining 0 hours and 11 minutes
I0614 15:59:45.318105  5755 solver.cpp:291]     Train net output #0: loss = 0.00245811 (* 1 = 0.00245811 loss)
I0614 15:59:45.318114  5755 sgd_solver.cpp:106] Iteration 9150, lr = 1e-06
I0614 15:59:57.972759  5755 solver.cpp:270] Iteration 9200 (3.95124 iter/s, 12.6542s/50 iter), loss = 0.0032075, remaining 0 hours and 11 minutes
I0614 15:59:57.973013  5755 solver.cpp:291]     Train net output #0: loss = 0.00320755 (* 1 = 0.00320755 loss)
I0614 15:59:57.973039  5755 sgd_solver.cpp:106] Iteration 9200, lr = 1e-06
I0614 16:00:10.623718  5755 solver.cpp:270] Iteration 9250 (3.95248 iter/s, 12.6503s/50 iter), loss = 0.00572208, remaining 0 hours and 11 minutes
I0614 16:00:10.623750  5755 solver.cpp:291]     Train net output #0: loss = 0.00572213 (* 1 = 0.00572213 loss)
I0614 16:00:10.623759  5755 sgd_solver.cpp:106] Iteration 9250, lr = 1e-06
I0614 16:00:23.245941  5755 solver.cpp:270] Iteration 9300 (3.9614 iter/s, 12.6218s/50 iter), loss = 0.0498891, remaining 0 hours and 11 minutes
I0614 16:00:23.245975  5755 solver.cpp:291]     Train net output #0: loss = 0.0498891 (* 1 = 0.0498891 loss)
I0614 16:00:23.245983  5755 sgd_solver.cpp:106] Iteration 9300, lr = 1e-06
I0614 16:00:35.884395  5755 solver.cpp:270] Iteration 9350 (3.95632 iter/s, 12.638s/50 iter), loss = 0.0062465, remaining 0 hours and 11 minutes
I0614 16:00:35.884721  5755 solver.cpp:291]     Train net output #0: loss = 0.00624655 (* 1 = 0.00624655 loss)
I0614 16:00:35.884745  5755 sgd_solver.cpp:106] Iteration 9350, lr = 1e-06
I0614 16:00:48.536908  5755 solver.cpp:270] Iteration 9400 (3.95201 iter/s, 12.6518s/50 iter), loss = 0.0124988, remaining 0 hours and 10 minutes
I0614 16:00:48.536940  5755 solver.cpp:291]     Train net output #0: loss = 0.0124988 (* 1 = 0.0124988 loss)
I0614 16:00:48.536948  5755 sgd_solver.cpp:106] Iteration 9400, lr = 1e-06
I0614 16:01:01.169411  5755 solver.cpp:270] Iteration 9450 (3.95818 iter/s, 12.6321s/50 iter), loss = 0.00793789, remaining 0 hours and 10 minutes
I0614 16:01:01.169445  5755 solver.cpp:291]     Train net output #0: loss = 0.00793793 (* 1 = 0.00793793 loss)
I0614 16:01:01.169452  5755 sgd_solver.cpp:106] Iteration 9450, lr = 1e-06
I0614 16:01:13.821586  5755 solver.cpp:270] Iteration 9500 (3.95203 iter/s, 12.6517s/50 iter), loss = 0.0196032, remaining 0 hours and 10 minutes
I0614 16:01:13.821846  5755 solver.cpp:291]     Train net output #0: loss = 0.0196033 (* 1 = 0.0196033 loss)
I0614 16:01:13.821869  5755 sgd_solver.cpp:106] Iteration 9500, lr = 1e-06
I0614 16:01:26.454563  5755 solver.cpp:270] Iteration 9550 (3.9581 iter/s, 12.6323s/50 iter), loss = 0.00179001, remaining 0 hours and 10 minutes
I0614 16:01:26.454594  5755 solver.cpp:291]     Train net output #0: loss = 0.00179007 (* 1 = 0.00179007 loss)
I0614 16:01:26.454618  5755 sgd_solver.cpp:106] Iteration 9550, lr = 1e-06
I0614 16:01:39.110671  5755 solver.cpp:270] Iteration 9600 (3.9508 iter/s, 12.6557s/50 iter), loss = 0.000904924, remaining 0 hours and 10 minutes
I0614 16:01:39.110705  5755 solver.cpp:291]     Train net output #0: loss = 0.000904973 (* 1 = 0.000904973 loss)
I0614 16:01:39.110715  5755 sgd_solver.cpp:106] Iteration 9600, lr = 1e-06
I0614 16:01:51.743537  5755 solver.cpp:270] Iteration 9650 (3.95807 iter/s, 12.6324s/50 iter), loss = 0.022338, remaining 0 hours and 9 minutes
I0614 16:01:51.743777  5755 solver.cpp:291]     Train net output #0: loss = 0.022338 (* 1 = 0.022338 loss)
I0614 16:01:51.743784  5755 sgd_solver.cpp:106] Iteration 9650, lr = 1e-06
I0614 16:02:04.363204  5755 solver.cpp:270] Iteration 9700 (3.96227 iter/s, 12.619s/50 iter), loss = 0.00133508, remaining 0 hours and 9 minutes
I0614 16:02:04.363234  5755 solver.cpp:291]     Train net output #0: loss = 0.00133513 (* 1 = 0.00133513 loss)
I0614 16:02:04.363243  5755 sgd_solver.cpp:106] Iteration 9700, lr = 1e-06
I0614 16:02:17.001981  5755 solver.cpp:270] Iteration 9750 (3.95622 iter/s, 12.6383s/50 iter), loss = 0.00352992, remaining 0 hours and 9 minutes
I0614 16:02:17.002013  5755 solver.cpp:291]     Train net output #0: loss = 0.00352997 (* 1 = 0.00352997 loss)
I0614 16:02:17.002022  5755 sgd_solver.cpp:106] Iteration 9750, lr = 1e-06
I0614 16:02:29.652978  5755 solver.cpp:270] Iteration 9800 (3.95239 iter/s, 12.6506s/50 iter), loss = 0.00421393, remaining 0 hours and 9 minutes
I0614 16:02:29.653239  5755 solver.cpp:291]     Train net output #0: loss = 0.00421398 (* 1 = 0.00421398 loss)
I0614 16:02:29.653249  5755 sgd_solver.cpp:106] Iteration 9800, lr = 1e-06
I0614 16:02:42.262899  5755 solver.cpp:270] Iteration 9850 (3.96534 iter/s, 12.6093s/50 iter), loss = 0.0092278, remaining 0 hours and 8 minutes
I0614 16:02:42.262931  5755 solver.cpp:291]     Train net output #0: loss = 0.00922784 (* 1 = 0.00922784 loss)
I0614 16:02:42.262956  5755 sgd_solver.cpp:106] Iteration 9850, lr = 1e-06
I0614 16:02:54.917824  5755 solver.cpp:270] Iteration 9900 (3.95117 iter/s, 12.6545s/50 iter), loss = 0.00134386, remaining 0 hours and 8 minutes
I0614 16:02:54.917856  5755 solver.cpp:291]     Train net output #0: loss = 0.00134391 (* 1 = 0.00134391 loss)
I0614 16:02:54.917865  5755 sgd_solver.cpp:106] Iteration 9900, lr = 1e-06
I0614 16:03:07.557713  5755 solver.cpp:270] Iteration 9950 (3.95587 iter/s, 12.6394s/50 iter), loss = 0.00150054, remaining 0 hours and 8 minutes
I0614 16:03:07.558034  5755 solver.cpp:291]     Train net output #0: loss = 0.00150059 (* 1 = 0.00150059 loss)
I0614 16:03:07.558058  5755 sgd_solver.cpp:106] Iteration 9950, lr = 1e-06
I0614 16:03:19.941828  5755 solver.cpp:424] Iteration 10000, Testing net (#0)
I0614 16:03:21.448169  5755 solver.cpp:523]     Test net output #0: accuracy = 0.95575
I0614 16:03:21.448200  5755 solver.cpp:523]     Test net output #1: loss = 0.220271 (* 1 = 0.220271 loss)
I0614 16:03:21.448204  5755 solver.cpp:523]     Test net output #2: top-1 = 0.95575
I0614 16:03:21.694671  5755 solver.cpp:270] Iteration 10000 (3.53702 iter/s, 14.1362s/50 iter), loss = 0.00466258, remaining 0 hours and 9 minutes
I0614 16:03:21.694703  5755 solver.cpp:291]     Train net output #0: loss = 0.00466262 (* 1 = 0.00466262 loss)
I0614 16:03:21.694711  5755 sgd_solver.cpp:106] Iteration 10000, lr = 1e-07
I0614 16:03:34.364531  5755 solver.cpp:270] Iteration 10050 (3.94651 iter/s, 12.6694s/50 iter), loss = 0.00468126, remaining 0 hours and 8 minutes
I0614 16:03:34.364560  5755 solver.cpp:291]     Train net output #0: loss = 0.00468131 (* 1 = 0.00468131 loss)
I0614 16:03:34.364568  5755 sgd_solver.cpp:106] Iteration 10050, lr = 1e-07
I0614 16:03:47.016875  5755 solver.cpp:270] Iteration 10100 (3.95197 iter/s, 12.6519s/50 iter), loss = 0.00152338, remaining 0 hours and 7 minutes
I0614 16:03:47.017151  5755 solver.cpp:291]     Train net output #0: loss = 0.00152343 (* 1 = 0.00152343 loss)
I0614 16:03:47.017161  5755 sgd_solver.cpp:106] Iteration 10100, lr = 1e-07
I0614 16:03:59.653795  5755 solver.cpp:270] Iteration 10150 (3.95687 iter/s, 12.6362s/50 iter), loss = 0.00141045, remaining 0 hours and 7 minutes
I0614 16:03:59.653828  5755 solver.cpp:291]     Train net output #0: loss = 0.00141049 (* 1 = 0.00141049 loss)
I0614 16:03:59.653837  5755 sgd_solver.cpp:106] Iteration 10150, lr = 1e-07
I0614 16:04:12.269778  5755 solver.cpp:270] Iteration 10200 (3.96337 iter/s, 12.6155s/50 iter), loss = 0.000868538, remaining 0 hours and 7 minutes
I0614 16:04:12.269809  5755 solver.cpp:291]     Train net output #0: loss = 0.000868586 (* 1 = 0.000868586 loss)
I0614 16:04:12.269817  5755 sgd_solver.cpp:106] Iteration 10200, lr = 1e-07
I0614 16:04:24.899699  5755 solver.cpp:270] Iteration 10250 (3.95899 iter/s, 12.6295s/50 iter), loss = 0.00410417, remaining 0 hours and 7 minutes
I0614 16:04:24.899961  5755 solver.cpp:291]     Train net output #0: loss = 0.00410421 (* 1 = 0.00410421 loss)
I0614 16:04:24.899971  5755 sgd_solver.cpp:106] Iteration 10250, lr = 1e-07
I0614 16:04:37.552515  5755 solver.cpp:270] Iteration 10300 (3.9519 iter/s, 12.6521s/50 iter), loss = 0.0141409, remaining 0 hours and 7 minutes
I0614 16:04:37.552546  5755 solver.cpp:291]     Train net output #0: loss = 0.014141 (* 1 = 0.014141 loss)
I0614 16:04:37.552553  5755 sgd_solver.cpp:106] Iteration 10300, lr = 1e-07
I0614 16:04:50.195472  5755 solver.cpp:270] Iteration 10350 (3.95491 iter/s, 12.6425s/50 iter), loss = 0.00128475, remaining 0 hours and 6 minutes
I0614 16:04:50.195504  5755 solver.cpp:291]     Train net output #0: loss = 0.00128479 (* 1 = 0.00128479 loss)
I0614 16:04:50.195513  5755 sgd_solver.cpp:106] Iteration 10350, lr = 1e-07
I0614 16:05:02.841045  5755 solver.cpp:270] Iteration 10400 (3.95409 iter/s, 12.6451s/50 iter), loss = 0.00356168, remaining 0 hours and 6 minutes
I0614 16:05:02.841387  5755 solver.cpp:291]     Train net output #0: loss = 0.00356172 (* 1 = 0.00356172 loss)
I0614 16:05:02.841413  5755 sgd_solver.cpp:106] Iteration 10400, lr = 1e-07
I0614 16:05:15.490689  5755 solver.cpp:270] Iteration 10450 (3.95291 iter/s, 12.6489s/50 iter), loss = 0.0144436, remaining 0 hours and 6 minutes
I0614 16:05:15.490720  5755 solver.cpp:291]     Train net output #0: loss = 0.0144437 (* 1 = 0.0144437 loss)
I0614 16:05:15.490744  5755 sgd_solver.cpp:106] Iteration 10450, lr = 1e-07
I0614 16:05:28.115936  5755 solver.cpp:270] Iteration 10500 (3.96046 iter/s, 12.6248s/50 iter), loss = 0.00436576, remaining 0 hours and 6 minutes
I0614 16:05:28.115965  5755 solver.cpp:291]     Train net output #0: loss = 0.00436579 (* 1 = 0.00436579 loss)
I0614 16:05:28.115973  5755 sgd_solver.cpp:106] Iteration 10500, lr = 1e-07
I0614 16:05:40.762181  5755 solver.cpp:270] Iteration 10550 (3.95388 iter/s, 12.6458s/50 iter), loss = 0.0235372, remaining 0 hours and 6 minutes
I0614 16:05:40.762442  5755 solver.cpp:291]     Train net output #0: loss = 0.0235373 (* 1 = 0.0235373 loss)
I0614 16:05:40.762452  5755 sgd_solver.cpp:106] Iteration 10550, lr = 1e-07
I0614 16:05:53.393769  5755 solver.cpp:270] Iteration 10600 (3.95854 iter/s, 12.6309s/50 iter), loss = 0.000782282, remaining 0 hours and 5 minutes
I0614 16:05:53.393800  5755 solver.cpp:291]     Train net output #0: loss = 0.000782325 (* 1 = 0.000782325 loss)
I0614 16:05:53.393807  5755 sgd_solver.cpp:106] Iteration 10600, lr = 1e-07
I0614 16:06:06.029570  5755 solver.cpp:270] Iteration 10650 (3.95715 iter/s, 12.6354s/50 iter), loss = 0.00350818, remaining 0 hours and 5 minutes
I0614 16:06:06.029605  5755 solver.cpp:291]     Train net output #0: loss = 0.00350823 (* 1 = 0.00350823 loss)
I0614 16:06:06.029629  5755 sgd_solver.cpp:106] Iteration 10650, lr = 1e-07
I0614 16:06:18.673143  5755 solver.cpp:270] Iteration 10700 (3.95472 iter/s, 12.6431s/50 iter), loss = 0.00142478, remaining 0 hours and 5 minutes
I0614 16:06:18.673418  5755 solver.cpp:291]     Train net output #0: loss = 0.00142483 (* 1 = 0.00142483 loss)
I0614 16:06:18.673429  5755 sgd_solver.cpp:106] Iteration 10700, lr = 1e-07
I0614 16:06:31.333336  5755 solver.cpp:270] Iteration 10750 (3.9496 iter/s, 12.6595s/50 iter), loss = 0.0134054, remaining 0 hours and 5 minutes
I0614 16:06:31.333369  5755 solver.cpp:291]     Train net output #0: loss = 0.0134054 (* 1 = 0.0134054 loss)
I0614 16:06:31.333379  5755 sgd_solver.cpp:106] Iteration 10750, lr = 1e-07
I0614 16:06:43.983270  5755 solver.cpp:270] Iteration 10800 (3.95273 iter/s, 12.6495s/50 iter), loss = 0.010154, remaining 0 hours and 5 minutes
I0614 16:06:43.983302  5755 solver.cpp:291]     Train net output #0: loss = 0.0101541 (* 1 = 0.0101541 loss)
I0614 16:06:43.983311  5755 sgd_solver.cpp:106] Iteration 10800, lr = 1e-07
I0614 16:06:56.619376  5755 solver.cpp:270] Iteration 10850 (3.95705 iter/s, 12.6357s/50 iter), loss = 0.00724876, remaining 0 hours and 4 minutes
I0614 16:06:56.619570  5755 solver.cpp:291]     Train net output #0: loss = 0.0072488 (* 1 = 0.0072488 loss)
I0614 16:06:56.619578  5755 sgd_solver.cpp:106] Iteration 10850, lr = 1e-07
I0614 16:07:09.281594  5755 solver.cpp:270] Iteration 10900 (3.94894 iter/s, 12.6616s/50 iter), loss = 0.0131933, remaining 0 hours and 4 minutes
I0614 16:07:09.281626  5755 solver.cpp:291]     Train net output #0: loss = 0.0131934 (* 1 = 0.0131934 loss)
I0614 16:07:09.281651  5755 sgd_solver.cpp:106] Iteration 10900, lr = 1e-07
I0614 16:07:21.925997  5755 solver.cpp:270] Iteration 10950 (3.95446 iter/s, 12.644s/50 iter), loss = 0.00804614, remaining 0 hours and 4 minutes
I0614 16:07:21.926039  5755 solver.cpp:291]     Train net output #0: loss = 0.00804617 (* 1 = 0.00804617 loss)
I0614 16:07:21.926065  5755 sgd_solver.cpp:106] Iteration 10950, lr = 1e-07
I0614 16:07:34.309852  5755 solver.cpp:424] Iteration 11000, Testing net (#0)
I0614 16:07:35.816557  5755 solver.cpp:523]     Test net output #0: accuracy = 0.95625
I0614 16:07:35.816587  5755 solver.cpp:523]     Test net output #1: loss = 0.224814 (* 1 = 0.224814 loss)
I0614 16:07:35.816592  5755 solver.cpp:523]     Test net output #2: top-1 = 0.95625
I0614 16:07:36.062628  5755 solver.cpp:270] Iteration 11000 (3.53703 iter/s, 14.1361s/50 iter), loss = 0.00314218, remaining 0 hours and 4 minutes
I0614 16:07:36.062659  5755 solver.cpp:291]     Train net output #0: loss = 0.00314222 (* 1 = 0.00314222 loss)
I0614 16:07:36.062669  5755 sgd_solver.cpp:106] Iteration 11000, lr = 1e-07
I0614 16:07:48.717810  5755 solver.cpp:270] Iteration 11050 (3.95109 iter/s, 12.6547s/50 iter), loss = 0.00116154, remaining 0 hours and 3 minutes
I0614 16:07:48.717844  5755 solver.cpp:291]     Train net output #0: loss = 0.00116158 (* 1 = 0.00116158 loss)
I0614 16:07:48.717869  5755 sgd_solver.cpp:106] Iteration 11050, lr = 1e-07
I0614 16:08:01.340436  5755 solver.cpp:270] Iteration 11100 (3.96128 iter/s, 12.6222s/50 iter), loss = 0.00341886, remaining 0 hours and 3 minutes
I0614 16:08:01.340469  5755 solver.cpp:291]     Train net output #0: loss = 0.0034189 (* 1 = 0.0034189 loss)
I0614 16:08:01.340479  5755 sgd_solver.cpp:106] Iteration 11100, lr = 1e-07
I0614 16:08:13.982681  5755 solver.cpp:270] Iteration 11150 (3.95513 iter/s, 12.6418s/50 iter), loss = 0.00121294, remaining 0 hours and 3 minutes
I0614 16:08:13.983031  5755 solver.cpp:291]     Train net output #0: loss = 0.00121298 (* 1 = 0.00121298 loss)
I0614 16:08:13.983039  5755 sgd_solver.cpp:106] Iteration 11150, lr = 1e-07
I0614 16:08:26.624018  5755 solver.cpp:270] Iteration 11200 (3.95551 iter/s, 12.6406s/50 iter), loss = 0.00185542, remaining 0 hours and 3 minutes
I0614 16:08:26.624051  5755 solver.cpp:291]     Train net output #0: loss = 0.00185547 (* 1 = 0.00185547 loss)
I0614 16:08:26.624059  5755 sgd_solver.cpp:106] Iteration 11200, lr = 1e-07
I0614 16:08:39.237751  5755 solver.cpp:270] Iteration 11250 (3.96407 iter/s, 12.6133s/50 iter), loss = 0.00324854, remaining 0 hours and 3 minutes
I0614 16:08:39.237782  5755 solver.cpp:291]     Train net output #0: loss = 0.00324858 (* 1 = 0.00324858 loss)
I0614 16:08:39.237790  5755 sgd_solver.cpp:106] Iteration 11250, lr = 1e-07
I0614 16:08:51.870476  5755 solver.cpp:270] Iteration 11300 (3.95811 iter/s, 12.6323s/50 iter), loss = 0.00403602, remaining 0 hours and 2 minutes
I0614 16:08:51.870731  5755 solver.cpp:291]     Train net output #0: loss = 0.00403607 (* 1 = 0.00403607 loss)
I0614 16:08:51.870740  5755 sgd_solver.cpp:106] Iteration 11300, lr = 1e-07
I0614 16:09:04.517000  5755 solver.cpp:270] Iteration 11350 (3.95386 iter/s, 12.6459s/50 iter), loss = 0.00222328, remaining 0 hours and 2 minutes
I0614 16:09:04.517033  5755 solver.cpp:291]     Train net output #0: loss = 0.00222332 (* 1 = 0.00222332 loss)
I0614 16:09:04.517043  5755 sgd_solver.cpp:106] Iteration 11350, lr = 1e-07
I0614 16:09:17.163897  5755 solver.cpp:270] Iteration 11400 (3.95368 iter/s, 12.6465s/50 iter), loss = 0.000968852, remaining 0 hours and 2 minutes
I0614 16:09:17.163928  5755 solver.cpp:291]     Train net output #0: loss = 0.000968897 (* 1 = 0.000968897 loss)
I0614 16:09:17.163951  5755 sgd_solver.cpp:106] Iteration 11400, lr = 1e-07
I0614 16:09:29.789824  5755 solver.cpp:270] Iteration 11450 (3.96024 iter/s, 12.6255s/50 iter), loss = 0.00158477, remaining 0 hours and 2 minutes
I0614 16:09:29.789947  5755 solver.cpp:291]     Train net output #0: loss = 0.00158482 (* 1 = 0.00158482 loss)
I0614 16:09:29.789974  5755 sgd_solver.cpp:106] Iteration 11450, lr = 1e-07
I0614 16:09:42.401322  5755 solver.cpp:270] Iteration 11500 (3.9648 iter/s, 12.611s/50 iter), loss = 0.0253577, remaining 0 hours and 2 minutes
I0614 16:09:42.401353  5755 solver.cpp:291]     Train net output #0: loss = 0.0253578 (* 1 = 0.0253578 loss)
I0614 16:09:42.401361  5755 sgd_solver.cpp:106] Iteration 11500, lr = 1e-07
I0614 16:09:55.035420  5755 solver.cpp:270] Iteration 11550 (3.95768 iter/s, 12.6337s/50 iter), loss = 0.00919219, remaining 0 hours and 1 minutes
I0614 16:09:55.035450  5755 solver.cpp:291]     Train net output #0: loss = 0.00919224 (* 1 = 0.00919224 loss)
I0614 16:09:55.035475  5755 sgd_solver.cpp:106] Iteration 11550, lr = 1e-07
I0614 16:10:07.680609  5755 solver.cpp:270] Iteration 11600 (3.95421 iter/s, 12.6447s/50 iter), loss = 0.00136592, remaining 0 hours and 1 minutes
I0614 16:10:07.680927  5755 solver.cpp:291]     Train net output #0: loss = 0.00136597 (* 1 = 0.00136597 loss)
I0614 16:10:07.680953  5755 sgd_solver.cpp:106] Iteration 11600, lr = 1e-07
I0614 16:10:20.315543  5755 solver.cpp:270] Iteration 11650 (3.95751 iter/s, 12.6342s/50 iter), loss = 0.0139931, remaining 0 hours and 1 minutes
I0614 16:10:20.315577  5755 solver.cpp:291]     Train net output #0: loss = 0.0139932 (* 1 = 0.0139932 loss)
I0614 16:10:20.315585  5755 sgd_solver.cpp:106] Iteration 11650, lr = 1e-07
I0614 16:10:32.934366  5755 solver.cpp:270] Iteration 11700 (3.96247 iter/s, 12.6184s/50 iter), loss = 0.00625343, remaining 0 hours and 1 minutes
I0614 16:10:32.934398  5755 solver.cpp:291]     Train net output #0: loss = 0.00625347 (* 1 = 0.00625347 loss)
I0614 16:10:32.934407  5755 sgd_solver.cpp:106] Iteration 11700, lr = 1e-07
I0614 16:10:45.576371  5755 solver.cpp:270] Iteration 11750 (3.95521 iter/s, 12.6416s/50 iter), loss = 0.000882046, remaining 0 hours and 1 minutes
I0614 16:10:45.576572  5755 solver.cpp:291]     Train net output #0: loss = 0.000882085 (* 1 = 0.000882085 loss)
I0614 16:10:45.576581  5755 sgd_solver.cpp:106] Iteration 11750, lr = 1e-07
I0614 16:10:58.214756  5755 solver.cpp:270] Iteration 11800 (3.95639 iter/s, 12.6378s/50 iter), loss = 0.0288197, remaining 0 hours and 0 minutes
I0614 16:10:58.214789  5755 solver.cpp:291]     Train net output #0: loss = 0.0288198 (* 1 = 0.0288198 loss)
I0614 16:10:58.214813  5755 sgd_solver.cpp:106] Iteration 11800, lr = 1e-07
I0614 16:11:10.836546  5755 solver.cpp:270] Iteration 11850 (3.96154 iter/s, 12.6214s/50 iter), loss = 0.00213918, remaining 0 hours and 0 minutes
I0614 16:11:10.836577  5755 solver.cpp:291]     Train net output #0: loss = 0.00213922 (* 1 = 0.00213922 loss)
I0614 16:11:10.836585  5755 sgd_solver.cpp:106] Iteration 11850, lr = 1e-07
I0614 16:11:23.478994  5755 solver.cpp:270] Iteration 11900 (3.95507 iter/s, 12.642s/50 iter), loss = 0.0124917, remaining 0 hours and 0 minutes
I0614 16:11:23.479249  5755 solver.cpp:291]     Train net output #0: loss = 0.0124917 (* 1 = 0.0124917 loss)
I0614 16:11:23.479257  5755 sgd_solver.cpp:106] Iteration 11900, lr = 1e-07
I0614 16:11:36.200470  5755 solver.cpp:270] Iteration 11950 (3.93057 iter/s, 12.7208s/50 iter), loss = 0.00905239, remaining 0 hours and 0 minutes
I0614 16:11:36.200503  5755 solver.cpp:291]     Train net output #0: loss = 0.00905243 (* 1 = 0.00905243 loss)
I0614 16:11:36.200511  5755 sgd_solver.cpp:106] Iteration 11950, lr = 1e-07
I0614 16:11:48.697065  5755 solver.cpp:935] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.3/snapshots/_iter_12000.caffemodel
I0614 16:11:54.841199  5755 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.3/snapshots/_iter_12000.solverstate
I0614 16:11:58.668203  5755 solver.cpp:384] Iteration 12000, loss = 0.00410078
I0614 16:11:58.668231  5755 solver.cpp:424] Iteration 12000, Testing net (#0)
I0614 16:12:00.075039  5755 solver.cpp:523]     Test net output #0: accuracy = 0.9565
I0614 16:12:00.075068  5755 solver.cpp:523]     Test net output #1: loss = 0.227058 (* 1 = 0.227058 loss)
I0614 16:12:00.075073  5755 solver.cpp:523]     Test net output #2: top-1 = 0.9565
I0614 16:12:00.075078  5755 solver.cpp:392] Optimization Done (3.92952 iter/s).
I0614 16:12:00.075081  5755 caffe_interface.cpp:576] Optimization Done.
(c) Copyright 2016â2019 Xilinx, Inc. All rights reserved.

I0614 16:12:00.872561  5852 pruning_runner.cpp:234] Analysis info found.
I0614 16:12:02.556005  5852 pruning_runner.cpp:265] Start pruning, please wait...
I0614 16:12:11.848764  5852 pruning_runner.cpp:312] Compression complete 0%
I0614 16:12:20.792750  5852 pruning_runner.cpp:312] Compression complete 0%
I0614 16:12:29.506999  5852 pruning_runner.cpp:312] Compression complete 0%
I0614 16:12:38.232441  5852 pruning_runner.cpp:312] Compression complete 0%
I0614 16:12:47.202939  5852 pruning_runner.cpp:312] Compression complete 0%
I0614 16:12:57.894917  5852 pruning_runner.cpp:312] Compression complete 0%
I0614 16:13:06.840488  5852 pruning_runner.cpp:312] Compression complete 0%
I0614 16:13:15.952977  5852 pruning_runner.cpp:312] Compression complete 0%
I0614 16:13:24.982725  5852 pruning_runner.cpp:312] Compression complete 0%
I0614 16:13:33.973438  5852 pruning_runner.cpp:312] Compression complete 0%
I0614 16:13:45.314147  5852 pruning_runner.cpp:365] pruning done, output model: pruning/alexnetBNnoLRN/regular_rate_0.4/sparse.caffemodel
I0614 16:13:45.314177  5852 pruning_runner.cpp:379] summary of REGULAR compression with rate 0.4:
+-------------------------------------------------------------------+
| Item           | Baseline       | Compressed     | Delta          |
+-------------------------------------------------------------------+
| Accuracy       | 0.953499794    | 0.956499696    | 0.00299990177  |
+-------------------------------------------------------------------+
| Weights        | 3.74857903 M   | 1.15144897 M   | -69.2830582%   |
+-------------------------------------------------------------------+
| Operations     | 2.05460167 G   | 1.17685986 G   | -42.7207718%   |
+-------------------------------------------------------------------+
To fine-tune the pruned model, please run:
vai_p_caffe finetune -config /workspace/TUTORIALS/VAI2.0bash-Caffe-ML-CATSvsDOGS/files/pruning/alexnetBNnoLRN/config4.prototxt
(c) Copyright 2016â2019 Xilinx, Inc. All rights reserved.

W0614 16:13:45.925612  6907 utils.cpp:207] BVLC BatchNormLayer without ScaleLayer detected: 3, it will be converted to NVCaffe Format.
W0614 16:13:45.973006  6907 utils.cpp:207] BVLC BatchNormLayer without ScaleLayer detected: 7, it will be converted to NVCaffe Format.
W0614 16:13:45.973101  6907 utils.cpp:207] BVLC BatchNormLayer without ScaleLayer detected: 21, it will be converted to NVCaffe Format.
I0614 16:13:45.983855  6907 vai_p_caffe.cpp:287] pruning/alexnetBNnoLRN/regular_rate_0.4/net_finetune.prototxt
I0614 16:13:46.220783  6907 gpu_memory.cpp:53] GPUMemory::Manager initialized with Caching (CUB) GPU Allocator
I0614 16:13:46.220806  6907 gpu_memory.cpp:55] Total memory: 25635127296, Free: 24769593344, dev_info[0]: total=25635127296 free=24769593344
I0614 16:13:46.220958  6907 caffe_interface.cpp:539] Using GPUs 0
I0614 16:13:46.221081  6907 caffe_interface.cpp:544] GPU 0: Quadro P6000
I0614 16:13:46.879063  6907 solver.cpp:51] Initializing solver from parameters: 
test_iter: 80
test_interval: 1000
base_lr: 0.001
display: 50
max_iter: 12000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 2500
snapshot: 6000
snapshot_prefix: "pruning/alexnetBNnoLRN/regular_rate_0.4/snapshots/"
solver_mode: GPU
device_id: 0
random_seed: 1201
net: "pruning/alexnetBNnoLRN/regular_rate_0.4/net_finetune.prototxt"
type: "Adam"
I0614 16:13:46.880132  6907 solver.cpp:99] Creating training net from net file: pruning/alexnetBNnoLRN/regular_rate_0.4/net_finetune.prototxt
I0614 16:13:46.880806  6907 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0614 16:13:46.880821  6907 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0614 16:13:46.880826  6907 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy-top1
I0614 16:13:46.880833  6907 net.cpp:52] Initializing net from parameters: 
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_value: 106
    mean_value: 116
    mean_value: 124
  }
  data_param {
    source: "input/lmdb/train_lmdb"
    batch_size: 256
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 0
    kernel_size: 8
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "bn1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn2"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "bn2"
  top: "relu2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "relu6"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "drop6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn7"
  type: "BatchNorm"
  bottom: "fc7"
  top: "bn7"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "bn7"
  top: "relu7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "relu7"
  top: "drop7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "drop7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0614 16:13:46.881321  6907 layer_factory.hpp:77] Creating layer data
I0614 16:13:46.881485  6907 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0614 16:13:46.884405  6907 net.cpp:94] Creating Layer data
I0614 16:13:46.884443  6907 net.cpp:409] data -> data
I0614 16:13:46.884471  6907 net.cpp:409] data -> label
I0614 16:13:46.885468  6944 db_lmdb.cpp:35] Opened lmdb input/lmdb/train_lmdb
I0614 16:13:46.885496  6944 db_lmdb.cpp:38] Items count: 20000
I0614 16:13:46.885535  6944 data_reader.cpp:124] TRAIN: reading data using 1 channel(s)
I0614 16:13:46.885967  6907 data_layer.cpp:78] ReshapePrefetch 256, 3, 227, 227
I0614 16:13:46.886132  6907 data_layer.cpp:83] output data size: 256,3,227,227
I0614 16:13:47.429184  6907 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0614 16:13:47.429410  6907 net.cpp:144] Setting up data
I0614 16:13:47.429416  6907 net.cpp:151] Top shape: 256 3 227 227 (39574272)
I0614 16:13:47.429425  6907 net.cpp:151] Top shape: 256 (256)
I0614 16:13:47.429430  6907 net.cpp:159] Memory required for data: 158298112
I0614 16:13:47.429435  6907 layer_factory.hpp:77] Creating layer conv1
I0614 16:13:47.429445  6907 net.cpp:94] Creating Layer conv1
I0614 16:13:47.429448  6907 net.cpp:435] conv1 <- data
I0614 16:13:47.429453  6907 net.cpp:409] conv1 -> conv1
I0614 16:13:47.429958  6907 net.cpp:144] Setting up conv1
I0614 16:13:47.429967  6907 net.cpp:151] Top shape: 256 96 55 55 (74342400)
I0614 16:13:47.429973  6907 net.cpp:159] Memory required for data: 455667712
I0614 16:13:47.429983  6907 layer_factory.hpp:77] Creating layer bn1
I0614 16:13:47.429991  6907 net.cpp:94] Creating Layer bn1
I0614 16:13:47.429996  6907 net.cpp:435] bn1 <- conv1
I0614 16:13:47.430001  6907 net.cpp:409] bn1 -> bn1
I0614 16:13:47.430307  6907 net.cpp:144] Setting up bn1
I0614 16:13:47.430315  6907 net.cpp:151] Top shape: 256 96 55 55 (74342400)
I0614 16:13:47.430320  6907 net.cpp:159] Memory required for data: 753037312
I0614 16:13:47.430330  6907 layer_factory.hpp:77] Creating layer relu1
I0614 16:13:47.430335  6907 net.cpp:94] Creating Layer relu1
I0614 16:13:47.430339  6907 net.cpp:435] relu1 <- bn1
I0614 16:13:47.430344  6907 net.cpp:409] relu1 -> relu1
I0614 16:13:47.430359  6907 net.cpp:144] Setting up relu1
I0614 16:13:47.430363  6907 net.cpp:151] Top shape: 256 96 55 55 (74342400)
I0614 16:13:47.430368  6907 net.cpp:159] Memory required for data: 1050406912
I0614 16:13:47.430371  6907 layer_factory.hpp:77] Creating layer pool1
I0614 16:13:47.430377  6907 net.cpp:94] Creating Layer pool1
I0614 16:13:47.430382  6907 net.cpp:435] pool1 <- relu1
I0614 16:13:47.430385  6907 net.cpp:409] pool1 -> pool1
I0614 16:13:47.430413  6907 net.cpp:144] Setting up pool1
I0614 16:13:47.430418  6907 net.cpp:151] Top shape: 256 96 27 27 (17915904)
I0614 16:13:47.430423  6907 net.cpp:159] Memory required for data: 1122070528
I0614 16:13:47.430425  6907 layer_factory.hpp:77] Creating layer conv2
I0614 16:13:47.430433  6907 net.cpp:94] Creating Layer conv2
I0614 16:13:47.430435  6907 net.cpp:435] conv2 <- pool1
I0614 16:13:47.430440  6907 net.cpp:409] conv2 -> conv2
I0614 16:13:47.446961  6907 net.cpp:144] Setting up conv2
I0614 16:13:47.446977  6907 net.cpp:151] Top shape: 256 256 27 27 (47775744)
I0614 16:13:47.446985  6907 net.cpp:159] Memory required for data: 1313173504
I0614 16:13:47.446995  6907 layer_factory.hpp:77] Creating layer bn2
I0614 16:13:47.447005  6907 net.cpp:94] Creating Layer bn2
I0614 16:13:47.447008  6907 net.cpp:435] bn2 <- conv2
I0614 16:13:47.447016  6907 net.cpp:409] bn2 -> bn2
I0614 16:13:47.447297  6907 net.cpp:144] Setting up bn2
I0614 16:13:47.447304  6907 net.cpp:151] Top shape: 256 256 27 27 (47775744)
I0614 16:13:47.447310  6907 net.cpp:159] Memory required for data: 1504276480
I0614 16:13:47.447319  6907 layer_factory.hpp:77] Creating layer relu2
I0614 16:13:47.447324  6907 net.cpp:94] Creating Layer relu2
I0614 16:13:47.447328  6907 net.cpp:435] relu2 <- bn2
I0614 16:13:47.447333  6907 net.cpp:409] relu2 -> relu2
I0614 16:13:47.447346  6907 net.cpp:144] Setting up relu2
I0614 16:13:47.447350  6907 net.cpp:151] Top shape: 256 256 27 27 (47775744)
I0614 16:13:47.447356  6907 net.cpp:159] Memory required for data: 1695379456
I0614 16:13:47.447361  6907 layer_factory.hpp:77] Creating layer pool2
I0614 16:13:47.447369  6907 net.cpp:94] Creating Layer pool2
I0614 16:13:47.447374  6907 net.cpp:435] pool2 <- relu2
I0614 16:13:47.447382  6907 net.cpp:409] pool2 -> pool2
I0614 16:13:47.447407  6907 net.cpp:144] Setting up pool2
I0614 16:13:47.447412  6907 net.cpp:151] Top shape: 256 256 13 13 (11075584)
I0614 16:13:47.447417  6907 net.cpp:159] Memory required for data: 1739681792
I0614 16:13:47.447422  6907 layer_factory.hpp:77] Creating layer conv3
I0614 16:13:47.447845  6907 net.cpp:94] Creating Layer conv3
I0614 16:13:47.447854  6907 net.cpp:435] conv3 <- pool2
I0614 16:13:47.447863  6907 net.cpp:409] conv3 -> conv3
I0614 16:13:47.464040  6907 net.cpp:144] Setting up conv3
I0614 16:13:47.464102  6907 net.cpp:151] Top shape: 256 384 13 13 (16613376)
I0614 16:13:47.464116  6907 net.cpp:159] Memory required for data: 1806135296
I0614 16:13:47.464129  6907 layer_factory.hpp:77] Creating layer relu3
I0614 16:13:47.464139  6907 net.cpp:94] Creating Layer relu3
I0614 16:13:47.464145  6907 net.cpp:435] relu3 <- conv3
I0614 16:13:47.464154  6907 net.cpp:409] relu3 -> relu3
I0614 16:13:47.464185  6907 net.cpp:144] Setting up relu3
I0614 16:13:47.464190  6907 net.cpp:151] Top shape: 256 384 13 13 (16613376)
I0614 16:13:47.464197  6907 net.cpp:159] Memory required for data: 1872588800
I0614 16:13:47.464202  6907 layer_factory.hpp:77] Creating layer conv4
I0614 16:13:47.464212  6907 net.cpp:94] Creating Layer conv4
I0614 16:13:47.464217  6907 net.cpp:435] conv4 <- relu3
I0614 16:13:47.464224  6907 net.cpp:409] conv4 -> conv4
I0614 16:13:47.485256  6907 net.cpp:144] Setting up conv4
I0614 16:13:47.485276  6907 net.cpp:151] Top shape: 256 384 13 13 (16613376)
I0614 16:13:47.485285  6907 net.cpp:159] Memory required for data: 1939042304
I0614 16:13:47.485301  6907 layer_factory.hpp:77] Creating layer relu4
I0614 16:13:47.485308  6907 net.cpp:94] Creating Layer relu4
I0614 16:13:47.485313  6907 net.cpp:435] relu4 <- conv4
I0614 16:13:47.485319  6907 net.cpp:409] relu4 -> relu4
I0614 16:13:47.485337  6907 net.cpp:144] Setting up relu4
I0614 16:13:47.485340  6907 net.cpp:151] Top shape: 256 384 13 13 (16613376)
I0614 16:13:47.485344  6907 net.cpp:159] Memory required for data: 2005495808
I0614 16:13:47.485348  6907 layer_factory.hpp:77] Creating layer conv5
I0614 16:13:47.485356  6907 net.cpp:94] Creating Layer conv5
I0614 16:13:47.485360  6907 net.cpp:435] conv5 <- relu4
I0614 16:13:47.485365  6907 net.cpp:409] conv5 -> conv5
I0614 16:13:47.500800  6907 net.cpp:144] Setting up conv5
I0614 16:13:47.500864  6907 net.cpp:151] Top shape: 256 256 13 13 (11075584)
I0614 16:13:47.500876  6907 net.cpp:159] Memory required for data: 2049798144
I0614 16:13:47.500888  6907 layer_factory.hpp:77] Creating layer relu5
I0614 16:13:47.500898  6907 net.cpp:94] Creating Layer relu5
I0614 16:13:47.500905  6907 net.cpp:435] relu5 <- conv5
I0614 16:13:47.500913  6907 net.cpp:409] relu5 -> relu5
I0614 16:13:47.500945  6907 net.cpp:144] Setting up relu5
I0614 16:13:47.500950  6907 net.cpp:151] Top shape: 256 256 13 13 (11075584)
I0614 16:13:47.500957  6907 net.cpp:159] Memory required for data: 2094100480
I0614 16:13:47.500962  6907 layer_factory.hpp:77] Creating layer pool5
I0614 16:13:47.500969  6907 net.cpp:94] Creating Layer pool5
I0614 16:13:47.500975  6907 net.cpp:435] pool5 <- relu5
I0614 16:13:47.500981  6907 net.cpp:409] pool5 -> pool5
I0614 16:13:47.501009  6907 net.cpp:144] Setting up pool5
I0614 16:13:47.501014  6907 net.cpp:151] Top shape: 256 256 6 6 (2359296)
I0614 16:13:47.501021  6907 net.cpp:159] Memory required for data: 2103537664
I0614 16:13:47.501026  6907 layer_factory.hpp:77] Creating layer fc6
I0614 16:13:47.501036  6907 net.cpp:94] Creating Layer fc6
I0614 16:13:47.501041  6907 net.cpp:435] fc6 <- pool5
I0614 16:13:47.501049  6907 net.cpp:409] fc6 -> fc6
I0614 16:13:47.928432  6907 net.cpp:144] Setting up fc6
I0614 16:13:47.928457  6907 net.cpp:151] Top shape: 256 4096 (1048576)
I0614 16:13:47.928465  6907 net.cpp:159] Memory required for data: 2107731968
I0614 16:13:47.928475  6907 layer_factory.hpp:77] Creating layer relu6
I0614 16:13:47.928481  6907 net.cpp:94] Creating Layer relu6
I0614 16:13:47.928485  6907 net.cpp:435] relu6 <- fc6
I0614 16:13:47.928491  6907 net.cpp:409] relu6 -> relu6
I0614 16:13:47.928505  6907 net.cpp:144] Setting up relu6
I0614 16:13:47.928508  6907 net.cpp:151] Top shape: 256 4096 (1048576)
I0614 16:13:47.928512  6907 net.cpp:159] Memory required for data: 2111926272
I0614 16:13:47.928515  6907 layer_factory.hpp:77] Creating layer drop6
I0614 16:13:47.928520  6907 net.cpp:94] Creating Layer drop6
I0614 16:13:47.928988  6907 net.cpp:435] drop6 <- relu6
I0614 16:13:47.928997  6907 net.cpp:409] drop6 -> drop6
I0614 16:13:47.929023  6907 net.cpp:144] Setting up drop6
I0614 16:13:47.929025  6907 net.cpp:151] Top shape: 256 4096 (1048576)
I0614 16:13:47.929031  6907 net.cpp:159] Memory required for data: 2116120576
I0614 16:13:47.929034  6907 layer_factory.hpp:77] Creating layer fc7
I0614 16:13:47.929042  6907 net.cpp:94] Creating Layer fc7
I0614 16:13:47.929045  6907 net.cpp:435] fc7 <- drop6
I0614 16:13:47.929051  6907 net.cpp:409] fc7 -> fc7
I0614 16:13:48.089418  6907 net.cpp:144] Setting up fc7
I0614 16:13:48.089444  6907 net.cpp:151] Top shape: 256 4096 (1048576)
I0614 16:13:48.089453  6907 net.cpp:159] Memory required for data: 2120314880
I0614 16:13:48.089462  6907 layer_factory.hpp:77] Creating layer bn7
I0614 16:13:48.089470  6907 net.cpp:94] Creating Layer bn7
I0614 16:13:48.089474  6907 net.cpp:435] bn7 <- fc7
I0614 16:13:48.089480  6907 net.cpp:409] bn7 -> bn7
I0614 16:13:48.089751  6907 net.cpp:144] Setting up bn7
I0614 16:13:48.089756  6907 net.cpp:151] Top shape: 256 4096 (1048576)
I0614 16:13:48.089761  6907 net.cpp:159] Memory required for data: 2124509184
I0614 16:13:48.089767  6907 layer_factory.hpp:77] Creating layer relu7
I0614 16:13:48.089773  6907 net.cpp:94] Creating Layer relu7
I0614 16:13:48.089776  6907 net.cpp:435] relu7 <- bn7
I0614 16:13:48.089781  6907 net.cpp:409] relu7 -> relu7
I0614 16:13:48.089793  6907 net.cpp:144] Setting up relu7
I0614 16:13:48.089797  6907 net.cpp:151] Top shape: 256 4096 (1048576)
I0614 16:13:48.089802  6907 net.cpp:159] Memory required for data: 2128703488
I0614 16:13:48.089804  6907 layer_factory.hpp:77] Creating layer drop7
I0614 16:13:48.089809  6907 net.cpp:94] Creating Layer drop7
I0614 16:13:48.089813  6907 net.cpp:435] drop7 <- relu7
I0614 16:13:48.089818  6907 net.cpp:409] drop7 -> drop7
I0614 16:13:48.089833  6907 net.cpp:144] Setting up drop7
I0614 16:13:48.089835  6907 net.cpp:151] Top shape: 256 4096 (1048576)
I0614 16:13:48.089839  6907 net.cpp:159] Memory required for data: 2132897792
I0614 16:13:48.089843  6907 layer_factory.hpp:77] Creating layer fc8
I0614 16:13:48.089849  6907 net.cpp:94] Creating Layer fc8
I0614 16:13:48.089854  6907 net.cpp:435] fc8 <- drop7
I0614 16:13:48.089857  6907 net.cpp:409] fc8 -> fc8
I0614 16:13:48.089995  6907 net.cpp:144] Setting up fc8
I0614 16:13:48.089998  6907 net.cpp:151] Top shape: 256 2 (512)
I0614 16:13:48.090003  6907 net.cpp:159] Memory required for data: 2132899840
I0614 16:13:48.090008  6907 layer_factory.hpp:77] Creating layer loss
I0614 16:13:48.090014  6907 net.cpp:94] Creating Layer loss
I0614 16:13:48.090018  6907 net.cpp:435] loss <- fc8
I0614 16:13:48.090021  6907 net.cpp:435] loss <- label
I0614 16:13:48.090026  6907 net.cpp:409] loss -> loss
I0614 16:13:48.090034  6907 layer_factory.hpp:77] Creating layer loss
I0614 16:13:48.090075  6907 net.cpp:144] Setting up loss
I0614 16:13:48.090077  6907 net.cpp:151] Top shape: (1)
I0614 16:13:48.090081  6907 net.cpp:154]     with loss weight 1
I0614 16:13:48.090093  6907 net.cpp:159] Memory required for data: 2132899844
I0614 16:13:48.090097  6907 net.cpp:220] loss needs backward computation.
I0614 16:13:48.090101  6907 net.cpp:220] fc8 needs backward computation.
I0614 16:13:48.090104  6907 net.cpp:220] drop7 needs backward computation.
I0614 16:13:48.090108  6907 net.cpp:220] relu7 needs backward computation.
I0614 16:13:48.090112  6907 net.cpp:220] bn7 needs backward computation.
I0614 16:13:48.090116  6907 net.cpp:220] fc7 needs backward computation.
I0614 16:13:48.090119  6907 net.cpp:220] drop6 needs backward computation.
I0614 16:13:48.090124  6907 net.cpp:220] relu6 needs backward computation.
I0614 16:13:48.090128  6907 net.cpp:220] fc6 needs backward computation.
I0614 16:13:48.090131  6907 net.cpp:220] pool5 needs backward computation.
I0614 16:13:48.090135  6907 net.cpp:220] relu5 needs backward computation.
I0614 16:13:48.090139  6907 net.cpp:220] conv5 needs backward computation.
I0614 16:13:48.090143  6907 net.cpp:220] relu4 needs backward computation.
I0614 16:13:48.090505  6907 net.cpp:220] conv4 needs backward computation.
I0614 16:13:48.090510  6907 net.cpp:220] relu3 needs backward computation.
I0614 16:13:48.090514  6907 net.cpp:220] conv3 needs backward computation.
I0614 16:13:48.090518  6907 net.cpp:220] pool2 needs backward computation.
I0614 16:13:48.090523  6907 net.cpp:220] relu2 needs backward computation.
I0614 16:13:48.090526  6907 net.cpp:220] bn2 needs backward computation.
I0614 16:13:48.090530  6907 net.cpp:220] conv2 needs backward computation.
I0614 16:13:48.090534  6907 net.cpp:220] pool1 needs backward computation.
I0614 16:13:48.090538  6907 net.cpp:220] relu1 needs backward computation.
I0614 16:13:48.090543  6907 net.cpp:220] bn1 needs backward computation.
I0614 16:13:48.090546  6907 net.cpp:220] conv1 needs backward computation.
I0614 16:13:48.090550  6907 net.cpp:222] data does not need backward computation.
I0614 16:13:48.090554  6907 net.cpp:264] This network produces output loss
I0614 16:13:48.090575  6907 net.cpp:284] Network initialization done.
I0614 16:13:48.091579  6907 solver.cpp:189] Creating test net (#0) specified by net file: pruning/alexnetBNnoLRN/regular_rate_0.4/net_finetune.prototxt
I0614 16:13:48.091615  6907 net.cpp:323] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0614 16:13:48.091629  6907 net.cpp:52] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_value: 106
    mean_value: 116
    mean_value: 124
  }
  data_param {
    source: "input/lmdb/valid_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 0
    kernel_size: 8
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "bn1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn2"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "bn2"
  top: "relu2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "relu6"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "drop6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn7"
  type: "BatchNorm"
  bottom: "fc7"
  top: "bn7"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "bn7"
  top: "relu7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "relu7"
  top: "drop7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "drop7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy-top1"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "top-1"
  include {
    phase: TEST
  }
}
I0614 16:13:48.092134  6907 layer_factory.hpp:77] Creating layer data
I0614 16:13:48.092180  6907 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0614 16:13:48.095506  6907 net.cpp:94] Creating Layer data
I0614 16:13:48.095546  6907 net.cpp:409] data -> data
I0614 16:13:48.095575  6907 net.cpp:409] data -> label
I0614 16:13:48.096755  6974 db_lmdb.cpp:35] Opened lmdb input/lmdb/valid_lmdb
I0614 16:13:48.096787  6974 db_lmdb.cpp:38] Items count: 4000
I0614 16:13:48.096825  6974 data_reader.cpp:124] TEST: reading data using 1 channel(s)
I0614 16:13:48.097237  6907 data_layer.cpp:78] ReshapePrefetch 50, 3, 227, 227
I0614 16:13:48.097453  6907 data_layer.cpp:83] output data size: 50,3,227,227
I0614 16:13:48.221544  6907 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0614 16:13:48.221966  6907 net.cpp:144] Setting up data
I0614 16:13:48.221973  6907 net.cpp:151] Top shape: 50 3 227 227 (7729350)
I0614 16:13:48.221982  6907 net.cpp:151] Top shape: 50 (50)
I0614 16:13:48.221985  6907 net.cpp:159] Memory required for data: 30917600
I0614 16:13:48.221990  6907 layer_factory.hpp:77] Creating layer label_data_1_split
I0614 16:13:48.221998  6907 net.cpp:94] Creating Layer label_data_1_split
I0614 16:13:48.222002  6907 net.cpp:435] label_data_1_split <- label
I0614 16:13:48.222007  6907 net.cpp:409] label_data_1_split -> label_data_1_split_0
I0614 16:13:48.222015  6907 net.cpp:409] label_data_1_split -> label_data_1_split_1
I0614 16:13:48.222019  6907 net.cpp:409] label_data_1_split -> label_data_1_split_2
I0614 16:13:48.222059  6907 net.cpp:144] Setting up label_data_1_split
I0614 16:13:48.222064  6907 net.cpp:151] Top shape: 50 (50)
I0614 16:13:48.222082  6907 net.cpp:151] Top shape: 50 (50)
I0614 16:13:48.222086  6907 net.cpp:151] Top shape: 50 (50)
I0614 16:13:48.222090  6907 net.cpp:159] Memory required for data: 30918200
I0614 16:13:48.222093  6907 layer_factory.hpp:77] Creating layer conv1
I0614 16:13:48.222106  6907 net.cpp:94] Creating Layer conv1
I0614 16:13:48.222110  6907 net.cpp:435] conv1 <- data
I0614 16:13:48.222117  6907 net.cpp:409] conv1 -> conv1
I0614 16:13:48.222468  6907 net.cpp:144] Setting up conv1
I0614 16:13:48.222476  6907 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0614 16:13:48.222482  6907 net.cpp:159] Memory required for data: 88998200
I0614 16:13:48.222491  6907 layer_factory.hpp:77] Creating layer bn1
I0614 16:13:48.222498  6907 net.cpp:94] Creating Layer bn1
I0614 16:13:48.222502  6907 net.cpp:435] bn1 <- conv1
I0614 16:13:48.222507  6907 net.cpp:409] bn1 -> bn1
I0614 16:13:48.222824  6907 net.cpp:144] Setting up bn1
I0614 16:13:48.222831  6907 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0614 16:13:48.222836  6907 net.cpp:159] Memory required for data: 147078200
I0614 16:13:48.222846  6907 layer_factory.hpp:77] Creating layer relu1
I0614 16:13:48.222851  6907 net.cpp:94] Creating Layer relu1
I0614 16:13:48.222855  6907 net.cpp:435] relu1 <- bn1
I0614 16:13:48.222860  6907 net.cpp:409] relu1 -> relu1
I0614 16:13:48.222872  6907 net.cpp:144] Setting up relu1
I0614 16:13:48.222875  6907 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0614 16:13:48.222879  6907 net.cpp:159] Memory required for data: 205158200
I0614 16:13:48.222883  6907 layer_factory.hpp:77] Creating layer pool1
I0614 16:13:48.222888  6907 net.cpp:94] Creating Layer pool1
I0614 16:13:48.222892  6907 net.cpp:435] pool1 <- relu1
I0614 16:13:48.222898  6907 net.cpp:409] pool1 -> pool1
I0614 16:13:48.222913  6907 net.cpp:144] Setting up pool1
I0614 16:13:48.222916  6907 net.cpp:151] Top shape: 50 96 27 27 (3499200)
I0614 16:13:48.222921  6907 net.cpp:159] Memory required for data: 219155000
I0614 16:13:48.222924  6907 layer_factory.hpp:77] Creating layer conv2
I0614 16:13:48.222931  6907 net.cpp:94] Creating Layer conv2
I0614 16:13:48.222934  6907 net.cpp:435] conv2 <- pool1
I0614 16:13:48.222939  6907 net.cpp:409] conv2 -> conv2
I0614 16:13:48.229985  6907 net.cpp:144] Setting up conv2
I0614 16:13:48.230002  6907 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0614 16:13:48.230010  6907 net.cpp:159] Memory required for data: 256479800
I0614 16:13:48.230019  6907 layer_factory.hpp:77] Creating layer bn2
I0614 16:13:48.230028  6907 net.cpp:94] Creating Layer bn2
I0614 16:13:48.230032  6907 net.cpp:435] bn2 <- conv2
I0614 16:13:48.230038  6907 net.cpp:409] bn2 -> bn2
I0614 16:13:48.230307  6907 net.cpp:144] Setting up bn2
I0614 16:13:48.230312  6907 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0614 16:13:48.230317  6907 net.cpp:159] Memory required for data: 293804600
I0614 16:13:48.230325  6907 layer_factory.hpp:77] Creating layer relu2
I0614 16:13:48.230331  6907 net.cpp:94] Creating Layer relu2
I0614 16:13:48.230334  6907 net.cpp:435] relu2 <- bn2
I0614 16:13:48.230340  6907 net.cpp:409] relu2 -> relu2
I0614 16:13:48.230351  6907 net.cpp:144] Setting up relu2
I0614 16:13:48.230757  6907 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0614 16:13:48.230763  6907 net.cpp:159] Memory required for data: 331129400
I0614 16:13:48.230767  6907 layer_factory.hpp:77] Creating layer pool2
I0614 16:13:48.230772  6907 net.cpp:94] Creating Layer pool2
I0614 16:13:48.230777  6907 net.cpp:435] pool2 <- relu2
I0614 16:13:48.230782  6907 net.cpp:409] pool2 -> pool2
I0614 16:13:48.230800  6907 net.cpp:144] Setting up pool2
I0614 16:13:48.230805  6907 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0614 16:13:48.230813  6907 net.cpp:159] Memory required for data: 339782200
I0614 16:13:48.230816  6907 layer_factory.hpp:77] Creating layer conv3
I0614 16:13:48.230826  6907 net.cpp:94] Creating Layer conv3
I0614 16:13:48.230830  6907 net.cpp:435] conv3 <- pool2
I0614 16:13:48.230837  6907 net.cpp:409] conv3 -> conv3
I0614 16:13:48.244479  6907 net.cpp:144] Setting up conv3
I0614 16:13:48.244506  6907 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0614 16:13:48.244520  6907 net.cpp:159] Memory required for data: 352761400
I0614 16:13:48.244531  6907 layer_factory.hpp:77] Creating layer relu3
I0614 16:13:48.244541  6907 net.cpp:94] Creating Layer relu3
I0614 16:13:48.244547  6907 net.cpp:435] relu3 <- conv3
I0614 16:13:48.244555  6907 net.cpp:409] relu3 -> relu3
I0614 16:13:48.244582  6907 net.cpp:144] Setting up relu3
I0614 16:13:48.244587  6907 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0614 16:13:48.244594  6907 net.cpp:159] Memory required for data: 365740600
I0614 16:13:48.244599  6907 layer_factory.hpp:77] Creating layer conv4
I0614 16:13:48.244609  6907 net.cpp:94] Creating Layer conv4
I0614 16:13:48.244614  6907 net.cpp:435] conv4 <- relu3
I0614 16:13:48.244621  6907 net.cpp:409] conv4 -> conv4
I0614 16:13:48.262352  6907 net.cpp:144] Setting up conv4
I0614 16:13:48.262373  6907 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0614 16:13:48.262382  6907 net.cpp:159] Memory required for data: 378719800
I0614 16:13:48.262394  6907 layer_factory.hpp:77] Creating layer relu4
I0614 16:13:48.262401  6907 net.cpp:94] Creating Layer relu4
I0614 16:13:48.262405  6907 net.cpp:435] relu4 <- conv4
I0614 16:13:48.262413  6907 net.cpp:409] relu4 -> relu4
I0614 16:13:48.262432  6907 net.cpp:144] Setting up relu4
I0614 16:13:48.262436  6907 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0614 16:13:48.262440  6907 net.cpp:159] Memory required for data: 391699000
I0614 16:13:48.262444  6907 layer_factory.hpp:77] Creating layer conv5
I0614 16:13:48.262451  6907 net.cpp:94] Creating Layer conv5
I0614 16:13:48.262455  6907 net.cpp:435] conv5 <- relu4
I0614 16:13:48.262459  6907 net.cpp:409] conv5 -> conv5
I0614 16:13:48.277067  6907 net.cpp:144] Setting up conv5
I0614 16:13:48.277086  6907 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0614 16:13:48.277110  6907 net.cpp:159] Memory required for data: 400351800
I0614 16:13:48.277124  6907 layer_factory.hpp:77] Creating layer relu5
I0614 16:13:48.277135  6907 net.cpp:94] Creating Layer relu5
I0614 16:13:48.277143  6907 net.cpp:435] relu5 <- conv5
I0614 16:13:48.277153  6907 net.cpp:409] relu5 -> relu5
I0614 16:13:48.277184  6907 net.cpp:144] Setting up relu5
I0614 16:13:48.277204  6907 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0614 16:13:48.277211  6907 net.cpp:159] Memory required for data: 409004600
I0614 16:13:48.277216  6907 layer_factory.hpp:77] Creating layer pool5
I0614 16:13:48.277225  6907 net.cpp:94] Creating Layer pool5
I0614 16:13:48.277230  6907 net.cpp:435] pool5 <- relu5
I0614 16:13:48.277237  6907 net.cpp:409] pool5 -> pool5
I0614 16:13:48.277262  6907 net.cpp:144] Setting up pool5
I0614 16:13:48.277267  6907 net.cpp:151] Top shape: 50 256 6 6 (460800)
I0614 16:13:48.277273  6907 net.cpp:159] Memory required for data: 410847800
I0614 16:13:48.277278  6907 layer_factory.hpp:77] Creating layer fc6
I0614 16:13:48.277287  6907 net.cpp:94] Creating Layer fc6
I0614 16:13:48.277292  6907 net.cpp:435] fc6 <- pool5
I0614 16:13:48.277299  6907 net.cpp:409] fc6 -> fc6
I0614 16:13:48.637419  6907 net.cpp:144] Setting up fc6
I0614 16:13:48.637442  6907 net.cpp:151] Top shape: 50 4096 (204800)
I0614 16:13:48.637879  6907 net.cpp:159] Memory required for data: 411667000
I0614 16:13:48.637895  6907 layer_factory.hpp:77] Creating layer relu6
I0614 16:13:48.637907  6907 net.cpp:94] Creating Layer relu6
I0614 16:13:48.637917  6907 net.cpp:435] relu6 <- fc6
I0614 16:13:48.637925  6907 net.cpp:409] relu6 -> relu6
I0614 16:13:48.637969  6907 net.cpp:144] Setting up relu6
I0614 16:13:48.637974  6907 net.cpp:151] Top shape: 50 4096 (204800)
I0614 16:13:48.637979  6907 net.cpp:159] Memory required for data: 412486200
I0614 16:13:48.637982  6907 layer_factory.hpp:77] Creating layer drop6
I0614 16:13:48.637989  6907 net.cpp:94] Creating Layer drop6
I0614 16:13:48.637992  6907 net.cpp:435] drop6 <- relu6
I0614 16:13:48.637997  6907 net.cpp:409] drop6 -> drop6
I0614 16:13:48.638016  6907 net.cpp:144] Setting up drop6
I0614 16:13:48.638021  6907 net.cpp:151] Top shape: 50 4096 (204800)
I0614 16:13:48.638026  6907 net.cpp:159] Memory required for data: 413305400
I0614 16:13:48.638029  6907 layer_factory.hpp:77] Creating layer fc7
I0614 16:13:48.638036  6907 net.cpp:94] Creating Layer fc7
I0614 16:13:48.638041  6907 net.cpp:435] fc7 <- drop6
I0614 16:13:48.638046  6907 net.cpp:409] fc7 -> fc7
I0614 16:13:48.796769  6907 net.cpp:144] Setting up fc7
I0614 16:13:48.796793  6907 net.cpp:151] Top shape: 50 4096 (204800)
I0614 16:13:48.796802  6907 net.cpp:159] Memory required for data: 414124600
I0614 16:13:48.796811  6907 layer_factory.hpp:77] Creating layer bn7
I0614 16:13:48.796820  6907 net.cpp:94] Creating Layer bn7
I0614 16:13:48.796824  6907 net.cpp:435] bn7 <- fc7
I0614 16:13:48.796830  6907 net.cpp:409] bn7 -> bn7
I0614 16:13:48.797161  6907 net.cpp:144] Setting up bn7
I0614 16:13:48.797168  6907 net.cpp:151] Top shape: 50 4096 (204800)
I0614 16:13:48.797175  6907 net.cpp:159] Memory required for data: 414943800
I0614 16:13:48.797199  6907 layer_factory.hpp:77] Creating layer relu7
I0614 16:13:48.797206  6907 net.cpp:94] Creating Layer relu7
I0614 16:13:48.797211  6907 net.cpp:435] relu7 <- bn7
I0614 16:13:48.797219  6907 net.cpp:409] relu7 -> relu7
I0614 16:13:48.797232  6907 net.cpp:144] Setting up relu7
I0614 16:13:48.797235  6907 net.cpp:151] Top shape: 50 4096 (204800)
I0614 16:13:48.797241  6907 net.cpp:159] Memory required for data: 415763000
I0614 16:13:48.797246  6907 layer_factory.hpp:77] Creating layer drop7
I0614 16:13:48.797252  6907 net.cpp:94] Creating Layer drop7
I0614 16:13:48.797256  6907 net.cpp:435] drop7 <- relu7
I0614 16:13:48.797261  6907 net.cpp:409] drop7 -> drop7
I0614 16:13:48.797277  6907 net.cpp:144] Setting up drop7
I0614 16:13:48.797281  6907 net.cpp:151] Top shape: 50 4096 (204800)
I0614 16:13:48.797286  6907 net.cpp:159] Memory required for data: 416582200
I0614 16:13:48.797289  6907 layer_factory.hpp:77] Creating layer fc8
I0614 16:13:48.797297  6907 net.cpp:94] Creating Layer fc8
I0614 16:13:48.797300  6907 net.cpp:435] fc8 <- drop7
I0614 16:13:48.797305  6907 net.cpp:409] fc8 -> fc8
I0614 16:13:48.797453  6907 net.cpp:144] Setting up fc8
I0614 16:13:48.797458  6907 net.cpp:151] Top shape: 50 2 (100)
I0614 16:13:48.797463  6907 net.cpp:159] Memory required for data: 416582600
I0614 16:13:48.797468  6907 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0614 16:13:48.797477  6907 net.cpp:94] Creating Layer fc8_fc8_0_split
I0614 16:13:48.797482  6907 net.cpp:435] fc8_fc8_0_split <- fc8
I0614 16:13:48.797488  6907 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0614 16:13:48.797497  6907 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0614 16:13:48.797502  6907 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_2
I0614 16:13:48.797524  6907 net.cpp:144] Setting up fc8_fc8_0_split
I0614 16:13:48.797528  6907 net.cpp:151] Top shape: 50 2 (100)
I0614 16:13:48.797533  6907 net.cpp:151] Top shape: 50 2 (100)
I0614 16:13:48.797538  6907 net.cpp:151] Top shape: 50 2 (100)
I0614 16:13:48.797541  6907 net.cpp:159] Memory required for data: 416583800
I0614 16:13:48.797545  6907 layer_factory.hpp:77] Creating layer accuracy
I0614 16:13:48.797560  6907 net.cpp:94] Creating Layer accuracy
I0614 16:13:48.797905  6907 net.cpp:435] accuracy <- fc8_fc8_0_split_0
I0614 16:13:48.797912  6907 net.cpp:435] accuracy <- label_data_1_split_0
I0614 16:13:48.797917  6907 net.cpp:409] accuracy -> accuracy
I0614 16:13:48.797924  6907 net.cpp:144] Setting up accuracy
I0614 16:13:48.797928  6907 net.cpp:151] Top shape: (1)
I0614 16:13:48.797932  6907 net.cpp:159] Memory required for data: 416583804
I0614 16:13:48.797936  6907 layer_factory.hpp:77] Creating layer loss
I0614 16:13:48.797941  6907 net.cpp:94] Creating Layer loss
I0614 16:13:48.797945  6907 net.cpp:435] loss <- fc8_fc8_0_split_1
I0614 16:13:48.797950  6907 net.cpp:435] loss <- label_data_1_split_1
I0614 16:13:48.797953  6907 net.cpp:409] loss -> loss
I0614 16:13:48.797962  6907 layer_factory.hpp:77] Creating layer loss
I0614 16:13:48.798010  6907 net.cpp:144] Setting up loss
I0614 16:13:48.798014  6907 net.cpp:151] Top shape: (1)
I0614 16:13:48.798018  6907 net.cpp:154]     with loss weight 1
I0614 16:13:48.798030  6907 net.cpp:159] Memory required for data: 416583808
I0614 16:13:48.798034  6907 layer_factory.hpp:77] Creating layer accuracy-top1
I0614 16:13:48.798041  6907 net.cpp:94] Creating Layer accuracy-top1
I0614 16:13:48.798045  6907 net.cpp:435] accuracy-top1 <- fc8_fc8_0_split_2
I0614 16:13:48.798049  6907 net.cpp:435] accuracy-top1 <- label_data_1_split_2
I0614 16:13:48.798054  6907 net.cpp:409] accuracy-top1 -> top-1
I0614 16:13:48.798060  6907 net.cpp:144] Setting up accuracy-top1
I0614 16:13:48.798064  6907 net.cpp:151] Top shape: (1)
I0614 16:13:48.798069  6907 net.cpp:159] Memory required for data: 416583812
I0614 16:13:48.798071  6907 net.cpp:222] accuracy-top1 does not need backward computation.
I0614 16:13:48.798075  6907 net.cpp:220] loss needs backward computation.
I0614 16:13:48.798080  6907 net.cpp:222] accuracy does not need backward computation.
I0614 16:13:48.798084  6907 net.cpp:220] fc8_fc8_0_split needs backward computation.
I0614 16:13:48.798089  6907 net.cpp:220] fc8 needs backward computation.
I0614 16:13:48.798092  6907 net.cpp:220] drop7 needs backward computation.
I0614 16:13:48.798095  6907 net.cpp:220] relu7 needs backward computation.
I0614 16:13:48.798099  6907 net.cpp:220] bn7 needs backward computation.
I0614 16:13:48.798103  6907 net.cpp:220] fc7 needs backward computation.
I0614 16:13:48.798107  6907 net.cpp:220] drop6 needs backward computation.
I0614 16:13:48.798111  6907 net.cpp:220] relu6 needs backward computation.
I0614 16:13:48.798115  6907 net.cpp:220] fc6 needs backward computation.
I0614 16:13:48.798120  6907 net.cpp:220] pool5 needs backward computation.
I0614 16:13:48.798123  6907 net.cpp:220] relu5 needs backward computation.
I0614 16:13:48.798127  6907 net.cpp:220] conv5 needs backward computation.
I0614 16:13:48.798131  6907 net.cpp:220] relu4 needs backward computation.
I0614 16:13:48.798135  6907 net.cpp:220] conv4 needs backward computation.
I0614 16:13:48.798139  6907 net.cpp:220] relu3 needs backward computation.
I0614 16:13:48.798146  6907 net.cpp:220] conv3 needs backward computation.
I0614 16:13:48.798151  6907 net.cpp:220] pool2 needs backward computation.
I0614 16:13:48.798156  6907 net.cpp:220] relu2 needs backward computation.
I0614 16:13:48.798161  6907 net.cpp:220] bn2 needs backward computation.
I0614 16:13:48.798166  6907 net.cpp:220] conv2 needs backward computation.
I0614 16:13:48.798171  6907 net.cpp:220] pool1 needs backward computation.
I0614 16:13:48.798177  6907 net.cpp:220] relu1 needs backward computation.
I0614 16:13:48.798182  6907 net.cpp:220] bn1 needs backward computation.
I0614 16:13:48.798187  6907 net.cpp:220] conv1 needs backward computation.
I0614 16:13:48.798192  6907 net.cpp:222] label_data_1_split does not need backward computation.
I0614 16:13:48.798197  6907 net.cpp:222] data does not need backward computation.
I0614 16:13:48.798202  6907 net.cpp:264] This network produces output accuracy
I0614 16:13:48.798206  6907 net.cpp:264] This network produces output loss
I0614 16:13:48.798210  6907 net.cpp:264] This network produces output top-1
I0614 16:13:48.798722  6907 net.cpp:284] Network initialization done.
I0614 16:13:48.798904  6907 solver.cpp:63] Solver scaffolding done.
I0614 16:13:48.800704  6907 caffe_interface.cpp:139] Finetuning from pruning/alexnetBNnoLRN/regular_rate_0.4/sparse.caffemodel
I0614 16:13:51.255972  6907 caffe_interface.cpp:573] Starting Optimization
I0614 16:13:51.255997  6907 solver.cpp:341] Solving 
I0614 16:13:51.256000  6907 solver.cpp:342] Learning Rate Policy: step
I0614 16:13:51.257239  6907 solver.cpp:424] Iteration 0, Testing net (#0)
I0614 16:13:52.725818  6907 solver.cpp:523]     Test net output #0: accuracy = 0.9565
I0614 16:13:52.725852  6907 solver.cpp:523]     Test net output #1: loss = 0.227058 (* 1 = 0.227058 loss)
I0614 16:13:52.725857  6907 solver.cpp:523]     Test net output #2: top-1 = 0.9565
I0614 16:13:52.975816  6907 solver.cpp:270] Iteration 0 (0 iter/s, 1.7197s/50 iter), loss = 0.0112823, remaining 333333 hours and 20 minutes
I0614 16:13:52.975847  6907 solver.cpp:291]     Train net output #0: loss = 0.0112823 (* 1 = 0.0112823 loss)
I0614 16:13:52.975854  6907 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0614 16:14:05.354569  6907 solver.cpp:270] Iteration 50 (4.03934 iter/s, 12.3783s/50 iter), loss = 0.0853966, remaining 0 hours and 49 minutes
I0614 16:14:05.354601  6907 solver.cpp:291]     Train net output #0: loss = 0.0853966 (* 1 = 0.0853966 loss)
I0614 16:14:05.354625  6907 sgd_solver.cpp:106] Iteration 50, lr = 0.001
I0614 16:14:17.836048  6907 solver.cpp:270] Iteration 100 (4.00609 iter/s, 12.481s/50 iter), loss = 0.0703206, remaining 0 hours and 49 minutes
I0614 16:14:17.836282  6907 solver.cpp:291]     Train net output #0: loss = 0.0703206 (* 1 = 0.0703206 loss)
I0614 16:14:17.836290  6907 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I0614 16:14:30.378865  6907 solver.cpp:270] Iteration 150 (3.98655 iter/s, 12.5422s/50 iter), loss = 0.0894193, remaining 0 hours and 49 minutes
I0614 16:14:30.378896  6907 solver.cpp:291]     Train net output #0: loss = 0.0894193 (* 1 = 0.0894193 loss)
I0614 16:14:30.378903  6907 sgd_solver.cpp:106] Iteration 150, lr = 0.001
I0614 16:14:43.147704  6907 solver.cpp:270] Iteration 200 (3.91591 iter/s, 12.7684s/50 iter), loss = 0.0551543, remaining 0 hours and 50 minutes
I0614 16:14:43.147737  6907 solver.cpp:291]     Train net output #0: loss = 0.0551544 (* 1 = 0.0551544 loss)
I0614 16:14:43.147760  6907 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I0614 16:14:56.869752  6907 solver.cpp:270] Iteration 250 (3.6439 iter/s, 13.7216s/50 iter), loss = 0.068099, remaining 0 hours and 53 minutes
I0614 16:14:56.870003  6907 solver.cpp:291]     Train net output #0: loss = 0.068099 (* 1 = 0.068099 loss)
I0614 16:14:56.870011  6907 sgd_solver.cpp:106] Iteration 250, lr = 0.001
I0614 16:15:09.923023  6907 solver.cpp:270] Iteration 300 (3.83066 iter/s, 13.0526s/50 iter), loss = 0.0639911, remaining 0 hours and 50 minutes
I0614 16:15:09.923058  6907 solver.cpp:291]     Train net output #0: loss = 0.0639911 (* 1 = 0.0639911 loss)
I0614 16:15:09.923082  6907 sgd_solver.cpp:106] Iteration 300, lr = 0.001
I0614 16:15:23.220124  6907 solver.cpp:270] Iteration 350 (3.76035 iter/s, 13.2966s/50 iter), loss = 0.0790436, remaining 0 hours and 51 minutes
I0614 16:15:23.220156  6907 solver.cpp:291]     Train net output #0: loss = 0.0790436 (* 1 = 0.0790436 loss)
I0614 16:15:23.220165  6907 sgd_solver.cpp:106] Iteration 350, lr = 0.001
I0614 16:15:36.575351  6907 solver.cpp:270] Iteration 400 (3.74398 iter/s, 13.3548s/50 iter), loss = 0.0841301, remaining 0 hours and 51 minutes
I0614 16:15:36.575605  6907 solver.cpp:291]     Train net output #0: loss = 0.0841302 (* 1 = 0.0841302 loss)
I0614 16:15:36.575613  6907 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I0614 16:15:49.784377  6907 solver.cpp:270] Iteration 450 (3.78549 iter/s, 13.2083s/50 iter), loss = 0.075126, remaining 0 hours and 50 minutes
I0614 16:15:49.784412  6907 solver.cpp:291]     Train net output #0: loss = 0.075126 (* 1 = 0.075126 loss)
I0614 16:15:49.784421  6907 sgd_solver.cpp:106] Iteration 450, lr = 0.001
I0614 16:16:03.384693  6907 solver.cpp:270] Iteration 500 (3.67651 iter/s, 13.5998s/50 iter), loss = 0.0748367, remaining 0 hours and 51 minutes
I0614 16:16:03.384727  6907 solver.cpp:291]     Train net output #0: loss = 0.0748367 (* 1 = 0.0748367 loss)
I0614 16:16:03.384784  6907 sgd_solver.cpp:106] Iteration 500, lr = 0.001
I0614 16:16:17.306442  6907 solver.cpp:270] Iteration 550 (3.59164 iter/s, 13.9212s/50 iter), loss = 0.0891181, remaining 0 hours and 52 minutes
I0614 16:16:17.306813  6907 solver.cpp:291]     Train net output #0: loss = 0.0891181 (* 1 = 0.0891181 loss)
I0614 16:16:17.306823  6907 sgd_solver.cpp:106] Iteration 550, lr = 0.001
I0614 16:16:31.184854  6907 solver.cpp:270] Iteration 600 (3.60293 iter/s, 13.8776s/50 iter), loss = 0.0989666, remaining 0 hours and 52 minutes
I0614 16:16:31.184887  6907 solver.cpp:291]     Train net output #0: loss = 0.0989666 (* 1 = 0.0989666 loss)
I0614 16:16:31.184911  6907 sgd_solver.cpp:106] Iteration 600, lr = 0.001
I0614 16:16:45.027030  6907 solver.cpp:270] Iteration 650 (3.61227 iter/s, 13.8417s/50 iter), loss = 0.0802651, remaining 0 hours and 52 minutes
I0614 16:16:45.027065  6907 solver.cpp:291]     Train net output #0: loss = 0.0802651 (* 1 = 0.0802651 loss)
I0614 16:16:45.027470  6907 sgd_solver.cpp:106] Iteration 650, lr = 0.001
I0614 16:16:58.802042  6907 solver.cpp:270] Iteration 700 (3.62999 iter/s, 13.7741s/50 iter), loss = 0.120071, remaining 0 hours and 51 minutes
I0614 16:16:58.802392  6907 solver.cpp:291]     Train net output #0: loss = 0.120071 (* 1 = 0.120071 loss)
I0614 16:16:58.802400  6907 sgd_solver.cpp:106] Iteration 700, lr = 0.001
I0614 16:17:12.145540  6907 solver.cpp:270] Iteration 750 (3.74736 iter/s, 13.3427s/50 iter), loss = 0.0885397, remaining 0 hours and 49 minutes
I0614 16:17:12.145574  6907 solver.cpp:291]     Train net output #0: loss = 0.0885398 (* 1 = 0.0885398 loss)
I0614 16:17:12.145582  6907 sgd_solver.cpp:106] Iteration 750, lr = 0.001
I0614 16:17:25.061578  6907 solver.cpp:270] Iteration 800 (3.87129 iter/s, 12.9156s/50 iter), loss = 0.0708416, remaining 0 hours and 48 minutes
I0614 16:17:25.061612  6907 solver.cpp:291]     Train net output #0: loss = 0.0708416 (* 1 = 0.0708416 loss)
I0614 16:17:25.061636  6907 sgd_solver.cpp:106] Iteration 800, lr = 0.001
I0614 16:17:37.694006  6907 solver.cpp:270] Iteration 850 (3.95821 iter/s, 12.632s/50 iter), loss = 0.0671485, remaining 0 hours and 46 minutes
I0614 16:17:37.694316  6907 solver.cpp:291]     Train net output #0: loss = 0.0671485 (* 1 = 0.0671485 loss)
I0614 16:17:37.694324  6907 sgd_solver.cpp:106] Iteration 850, lr = 0.001
I0614 16:17:50.357347  6907 solver.cpp:270] Iteration 900 (3.94863 iter/s, 12.6626s/50 iter), loss = 0.123348, remaining 0 hours and 46 minutes
I0614 16:17:50.357381  6907 solver.cpp:291]     Train net output #0: loss = 0.123348 (* 1 = 0.123348 loss)
I0614 16:17:50.357404  6907 sgd_solver.cpp:106] Iteration 900, lr = 0.001
I0614 16:18:03.001631  6907 solver.cpp:270] Iteration 950 (3.95449 iter/s, 12.6438s/50 iter), loss = 0.0862111, remaining 0 hours and 46 minutes
I0614 16:18:03.001662  6907 solver.cpp:291]     Train net output #0: loss = 0.0862111 (* 1 = 0.0862111 loss)
I0614 16:18:03.001672  6907 sgd_solver.cpp:106] Iteration 950, lr = 0.001
I0614 16:18:15.395871  6907 solver.cpp:424] Iteration 1000, Testing net (#0)
I0614 16:18:16.903278  6907 solver.cpp:523]     Test net output #0: accuracy = 0.93475
I0614 16:18:16.903306  6907 solver.cpp:523]     Test net output #1: loss = 0.229651 (* 1 = 0.229651 loss)
I0614 16:18:16.903311  6907 solver.cpp:523]     Test net output #2: top-1 = 0.93475
I0614 16:18:17.153796  6907 solver.cpp:270] Iteration 1000 (3.53315 iter/s, 14.1517s/50 iter), loss = 0.0842533, remaining 0 hours and 51 minutes
I0614 16:18:17.153827  6907 solver.cpp:291]     Train net output #0: loss = 0.0842533 (* 1 = 0.0842533 loss)
I0614 16:18:17.153834  6907 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I0614 16:18:29.801553  6907 solver.cpp:270] Iteration 1050 (3.95341 iter/s, 12.6473s/50 iter), loss = 0.0639951, remaining 0 hours and 46 minutes
I0614 16:18:29.801586  6907 solver.cpp:291]     Train net output #0: loss = 0.0639951 (* 1 = 0.0639951 loss)
I0614 16:18:29.801594  6907 sgd_solver.cpp:106] Iteration 1050, lr = 0.001
I0614 16:18:42.463228  6907 solver.cpp:270] Iteration 1100 (3.94906 iter/s, 12.6612s/50 iter), loss = 0.109252, remaining 0 hours and 45 minutes
I0614 16:18:42.463259  6907 solver.cpp:291]     Train net output #0: loss = 0.109252 (* 1 = 0.109252 loss)
I0614 16:18:42.463268  6907 sgd_solver.cpp:106] Iteration 1100, lr = 0.001
I0614 16:18:55.102818  6907 solver.cpp:270] Iteration 1150 (3.95596 iter/s, 12.6391s/50 iter), loss = 0.0945171, remaining 0 hours and 45 minutes
I0614 16:18:55.103113  6907 solver.cpp:291]     Train net output #0: loss = 0.0945172 (* 1 = 0.0945172 loss)
I0614 16:18:55.103121  6907 sgd_solver.cpp:106] Iteration 1150, lr = 0.001
I0614 16:19:07.761473  6907 solver.cpp:270] Iteration 1200 (3.95009 iter/s, 12.658s/50 iter), loss = 0.101033, remaining 0 hours and 45 minutes
I0614 16:19:07.761504  6907 solver.cpp:291]     Train net output #0: loss = 0.101033 (* 1 = 0.101033 loss)
I0614 16:19:07.761512  6907 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I0614 16:19:20.425709  6907 solver.cpp:270] Iteration 1250 (3.94826 iter/s, 12.6638s/50 iter), loss = 0.158409, remaining 0 hours and 45 minutes
I0614 16:19:20.425741  6907 solver.cpp:291]     Train net output #0: loss = 0.158409 (* 1 = 0.158409 loss)
I0614 16:19:20.425750  6907 sgd_solver.cpp:106] Iteration 1250, lr = 0.001
I0614 16:19:33.079020  6907 solver.cpp:270] Iteration 1300 (3.95167 iter/s, 12.6529s/50 iter), loss = 0.0760226, remaining 0 hours and 45 minutes
I0614 16:19:33.079264  6907 solver.cpp:291]     Train net output #0: loss = 0.0760227 (* 1 = 0.0760227 loss)
I0614 16:19:33.079288  6907 sgd_solver.cpp:106] Iteration 1300, lr = 0.001
I0614 16:19:45.712214  6907 solver.cpp:270] Iteration 1350 (3.95803 iter/s, 12.6325s/50 iter), loss = 0.0798431, remaining 0 hours and 44 minutes
I0614 16:19:45.712249  6907 solver.cpp:291]     Train net output #0: loss = 0.0798431 (* 1 = 0.0798431 loss)
I0614 16:19:45.712256  6907 sgd_solver.cpp:106] Iteration 1350, lr = 0.001
I0614 16:19:58.357921  6907 solver.cpp:270] Iteration 1400 (3.95405 iter/s, 12.6453s/50 iter), loss = 0.0831723, remaining 0 hours and 44 minutes
I0614 16:19:58.357954  6907 solver.cpp:291]     Train net output #0: loss = 0.0831723 (* 1 = 0.0831723 loss)
I0614 16:19:58.357962  6907 sgd_solver.cpp:106] Iteration 1400, lr = 0.001
I0614 16:20:11.009663  6907 solver.cpp:270] Iteration 1450 (3.95216 iter/s, 12.6513s/50 iter), loss = 0.0538142, remaining 0 hours and 44 minutes
I0614 16:20:11.009912  6907 solver.cpp:291]     Train net output #0: loss = 0.0538143 (* 1 = 0.0538143 loss)
I0614 16:20:11.009936  6907 sgd_solver.cpp:106] Iteration 1450, lr = 0.001
I0614 16:20:24.206333  6907 solver.cpp:270] Iteration 1500 (3.78903 iter/s, 13.196s/50 iter), loss = 0.118359, remaining 0 hours and 46 minutes
I0614 16:20:24.206367  6907 solver.cpp:291]     Train net output #0: loss = 0.118359 (* 1 = 0.118359 loss)
I0614 16:20:24.206375  6907 sgd_solver.cpp:106] Iteration 1500, lr = 0.001
I0614 16:20:37.065837  6907 solver.cpp:270] Iteration 1550 (3.88831 iter/s, 12.8591s/50 iter), loss = 0.103787, remaining 0 hours and 44 minutes
I0614 16:20:37.065871  6907 solver.cpp:291]     Train net output #0: loss = 0.103787 (* 1 = 0.103787 loss)
I0614 16:20:37.065877  6907 sgd_solver.cpp:106] Iteration 1550, lr = 0.001
I0614 16:20:49.807685  6907 solver.cpp:270] Iteration 1600 (3.92421 iter/s, 12.7414s/50 iter), loss = 0.0737631, remaining 0 hours and 44 minutes
I0614 16:20:49.807989  6907 solver.cpp:291]     Train net output #0: loss = 0.0737631 (* 1 = 0.0737631 loss)
I0614 16:20:49.807997  6907 sgd_solver.cpp:106] Iteration 1600, lr = 0.001
I0614 16:21:02.522982  6907 solver.cpp:270] Iteration 1650 (3.93249 iter/s, 12.7146s/50 iter), loss = 0.0714741, remaining 0 hours and 43 minutes
I0614 16:21:02.523013  6907 solver.cpp:291]     Train net output #0: loss = 0.0714741 (* 1 = 0.0714741 loss)
I0614 16:21:02.523022  6907 sgd_solver.cpp:106] Iteration 1650, lr = 0.001
I0614 16:21:15.332669  6907 solver.cpp:270] Iteration 1700 (3.90343 iter/s, 12.8092s/50 iter), loss = 0.135636, remaining 0 hours and 43 minutes
I0614 16:21:15.332701  6907 solver.cpp:291]     Train net output #0: loss = 0.135636 (* 1 = 0.135636 loss)
I0614 16:21:15.332708  6907 sgd_solver.cpp:106] Iteration 1700, lr = 0.001
I0614 16:21:27.957351  6907 solver.cpp:270] Iteration 1750 (3.96063 iter/s, 12.6242s/50 iter), loss = 0.15889, remaining 0 hours and 42 minutes
I0614 16:21:27.957662  6907 solver.cpp:291]     Train net output #0: loss = 0.15889 (* 1 = 0.15889 loss)
I0614 16:21:27.957670  6907 sgd_solver.cpp:106] Iteration 1750, lr = 0.001
I0614 16:21:40.609191  6907 solver.cpp:270] Iteration 1800 (3.95222 iter/s, 12.6511s/50 iter), loss = 0.0903547, remaining 0 hours and 43 minutes
I0614 16:21:40.609223  6907 solver.cpp:291]     Train net output #0: loss = 0.0903547 (* 1 = 0.0903547 loss)
I0614 16:21:40.609231  6907 sgd_solver.cpp:106] Iteration 1800, lr = 0.001
I0614 16:21:53.247117  6907 solver.cpp:270] Iteration 1850 (3.95648 iter/s, 12.6375s/50 iter), loss = 0.0606748, remaining 0 hours and 42 minutes
I0614 16:21:53.247150  6907 solver.cpp:291]     Train net output #0: loss = 0.0606748 (* 1 = 0.0606748 loss)
I0614 16:21:53.247157  6907 sgd_solver.cpp:106] Iteration 1850, lr = 0.001
I0614 16:22:05.870311  6907 solver.cpp:270] Iteration 1900 (3.9611 iter/s, 12.6228s/50 iter), loss = 0.173802, remaining 0 hours and 42 minutes
I0614 16:22:05.870517  6907 solver.cpp:291]     Train net output #0: loss = 0.173802 (* 1 = 0.173802 loss)
I0614 16:22:05.870525  6907 sgd_solver.cpp:106] Iteration 1900, lr = 0.001
I0614 16:22:18.477926  6907 solver.cpp:270] Iteration 1950 (3.96605 iter/s, 12.607s/50 iter), loss = 0.0747978, remaining 0 hours and 42 minutes
I0614 16:22:18.477959  6907 solver.cpp:291]     Train net output #0: loss = 0.0747978 (* 1 = 0.0747978 loss)
I0614 16:22:18.477982  6907 sgd_solver.cpp:106] Iteration 1950, lr = 0.001
I0614 16:22:30.844718  6907 solver.cpp:424] Iteration 2000, Testing net (#0)
I0614 16:22:32.327689  6907 solver.cpp:523]     Test net output #0: accuracy = 0.904
I0614 16:22:32.327718  6907 solver.cpp:523]     Test net output #1: loss = 0.298132 (* 1 = 0.298132 loss)
I0614 16:22:32.327723  6907 solver.cpp:523]     Test net output #2: top-1 = 0.904
I0614 16:22:32.574025  6907 solver.cpp:270] Iteration 2000 (3.5472 iter/s, 14.0956s/50 iter), loss = 0.0831305, remaining 0 hours and 46 minutes
I0614 16:22:32.574059  6907 solver.cpp:291]     Train net output #0: loss = 0.0831306 (* 1 = 0.0831306 loss)
I0614 16:22:32.574066  6907 sgd_solver.cpp:106] Iteration 2000, lr = 0.001
I0614 16:22:45.207600  6907 solver.cpp:270] Iteration 2050 (3.95785 iter/s, 12.6331s/50 iter), loss = 0.111196, remaining 0 hours and 41 minutes
I0614 16:22:45.207849  6907 solver.cpp:291]     Train net output #0: loss = 0.111196 (* 1 = 0.111196 loss)
I0614 16:22:45.207857  6907 sgd_solver.cpp:106] Iteration 2050, lr = 0.001
I0614 16:22:57.833218  6907 solver.cpp:270] Iteration 2100 (3.96041 iter/s, 12.625s/50 iter), loss = 0.0446797, remaining 0 hours and 41 minutes
I0614 16:22:57.833249  6907 solver.cpp:291]     Train net output #0: loss = 0.0446797 (* 1 = 0.0446797 loss)
I0614 16:22:57.833257  6907 sgd_solver.cpp:106] Iteration 2100, lr = 0.001
I0614 16:23:10.482786  6907 solver.cpp:270] Iteration 2150 (3.95284 iter/s, 12.6491s/50 iter), loss = 0.100948, remaining 0 hours and 41 minutes
I0614 16:23:10.482818  6907 solver.cpp:291]     Train net output #0: loss = 0.100948 (* 1 = 0.100948 loss)
I0614 16:23:10.482826  6907 sgd_solver.cpp:106] Iteration 2150, lr = 0.001
I0614 16:23:23.116904  6907 solver.cpp:270] Iteration 2200 (3.95768 iter/s, 12.6337s/50 iter), loss = 0.109734, remaining 0 hours and 41 minutes
I0614 16:23:23.117151  6907 solver.cpp:291]     Train net output #0: loss = 0.109734 (* 1 = 0.109734 loss)
I0614 16:23:23.117159  6907 sgd_solver.cpp:106] Iteration 2200, lr = 0.001
I0614 16:23:35.756662  6907 solver.cpp:270] Iteration 2250 (3.95598 iter/s, 12.6391s/50 iter), loss = 0.0619351, remaining 0 hours and 40 minutes
I0614 16:23:35.756695  6907 solver.cpp:291]     Train net output #0: loss = 0.0619351 (* 1 = 0.0619351 loss)
I0614 16:23:35.756718  6907 sgd_solver.cpp:106] Iteration 2250, lr = 0.001
I0614 16:23:48.378441  6907 solver.cpp:270] Iteration 2300 (3.96154 iter/s, 12.6213s/50 iter), loss = 0.0707028, remaining 0 hours and 40 minutes
I0614 16:23:48.378473  6907 solver.cpp:291]     Train net output #0: loss = 0.0707029 (* 1 = 0.0707029 loss)
I0614 16:23:48.378481  6907 sgd_solver.cpp:106] Iteration 2300, lr = 0.001
I0614 16:24:01.012567  6907 solver.cpp:270] Iteration 2350 (3.95767 iter/s, 12.6337s/50 iter), loss = 0.0867766, remaining 0 hours and 40 minutes
I0614 16:24:01.012912  6907 solver.cpp:291]     Train net output #0: loss = 0.0867766 (* 1 = 0.0867766 loss)
I0614 16:24:01.012920  6907 sgd_solver.cpp:106] Iteration 2350, lr = 0.001
I0614 16:24:13.642051  6907 solver.cpp:270] Iteration 2400 (3.95923 iter/s, 12.6287s/50 iter), loss = 0.0541476, remaining 0 hours and 40 minutes
I0614 16:24:13.642083  6907 solver.cpp:291]     Train net output #0: loss = 0.0541477 (* 1 = 0.0541477 loss)
I0614 16:24:13.642107  6907 sgd_solver.cpp:106] Iteration 2400, lr = 0.001
I0614 16:24:26.269367  6907 solver.cpp:270] Iteration 2450 (3.95981 iter/s, 12.6269s/50 iter), loss = 0.0882141, remaining 0 hours and 40 minutes
I0614 16:24:26.269400  6907 solver.cpp:291]     Train net output #0: loss = 0.0882141 (* 1 = 0.0882141 loss)
I0614 16:24:26.269424  6907 sgd_solver.cpp:106] Iteration 2450, lr = 0.001
I0614 16:24:38.997421  6907 solver.cpp:270] Iteration 2500 (3.92847 iter/s, 12.7276s/50 iter), loss = 0.108065, remaining 0 hours and 40 minutes
I0614 16:24:38.997671  6907 solver.cpp:291]     Train net output #0: loss = 0.108065 (* 1 = 0.108065 loss)
I0614 16:24:38.997679  6907 sgd_solver.cpp:106] Iteration 2500, lr = 0.0001
I0614 16:24:51.726328  6907 solver.cpp:270] Iteration 2550 (3.92827 iter/s, 12.7282s/50 iter), loss = 0.0653221, remaining 0 hours and 39 minutes
I0614 16:24:51.726362  6907 solver.cpp:291]     Train net output #0: loss = 0.0653222 (* 1 = 0.0653222 loss)
I0614 16:24:51.726370  6907 sgd_solver.cpp:106] Iteration 2550, lr = 0.0001
I0614 16:25:04.406363  6907 solver.cpp:270] Iteration 2600 (3.94334 iter/s, 12.6796s/50 iter), loss = 0.0579001, remaining 0 hours and 39 minutes
I0614 16:25:04.406396  6907 solver.cpp:291]     Train net output #0: loss = 0.0579001 (* 1 = 0.0579001 loss)
I0614 16:25:04.406404  6907 sgd_solver.cpp:106] Iteration 2600, lr = 0.0001
I0614 16:25:17.052474  6907 solver.cpp:270] Iteration 2650 (3.95392 iter/s, 12.6457s/50 iter), loss = 0.0318641, remaining 0 hours and 39 minutes
I0614 16:25:17.052675  6907 solver.cpp:291]     Train net output #0: loss = 0.0318641 (* 1 = 0.0318641 loss)
I0614 16:25:17.052700  6907 sgd_solver.cpp:106] Iteration 2650, lr = 0.0001
I0614 16:25:29.689148  6907 solver.cpp:270] Iteration 2700 (3.95693 iter/s, 12.6361s/50 iter), loss = 0.019934, remaining 0 hours and 39 minutes
I0614 16:25:29.689179  6907 solver.cpp:291]     Train net output #0: loss = 0.019934 (* 1 = 0.019934 loss)
I0614 16:25:29.689188  6907 sgd_solver.cpp:106] Iteration 2700, lr = 0.0001
I0614 16:25:42.311748  6907 solver.cpp:270] Iteration 2750 (3.96129 iter/s, 12.6222s/50 iter), loss = 0.050618, remaining 0 hours and 38 minutes
I0614 16:25:42.311782  6907 solver.cpp:291]     Train net output #0: loss = 0.050618 (* 1 = 0.050618 loss)
I0614 16:25:42.311805  6907 sgd_solver.cpp:106] Iteration 2750, lr = 0.0001
I0614 16:25:54.927860  6907 solver.cpp:270] Iteration 2800 (3.96333 iter/s, 12.6157s/50 iter), loss = 0.037556, remaining 0 hours and 38 minutes
I0614 16:25:54.928095  6907 solver.cpp:291]     Train net output #0: loss = 0.037556 (* 1 = 0.037556 loss)
I0614 16:25:54.928120  6907 sgd_solver.cpp:106] Iteration 2800, lr = 0.0001
I0614 16:26:07.565109  6907 solver.cpp:270] Iteration 2850 (3.95676 iter/s, 12.6366s/50 iter), loss = 0.0345901, remaining 0 hours and 38 minutes
I0614 16:26:07.565140  6907 solver.cpp:291]     Train net output #0: loss = 0.0345902 (* 1 = 0.0345902 loss)
I0614 16:26:07.565147  6907 sgd_solver.cpp:106] Iteration 2850, lr = 0.0001
I0614 16:26:20.208638  6907 solver.cpp:270] Iteration 2900 (3.95473 iter/s, 12.6431s/50 iter), loss = 0.0305058, remaining 0 hours and 38 minutes
I0614 16:26:20.208669  6907 solver.cpp:291]     Train net output #0: loss = 0.0305058 (* 1 = 0.0305058 loss)
I0614 16:26:20.208676  6907 sgd_solver.cpp:106] Iteration 2900, lr = 0.0001
I0614 16:26:32.828466  6907 solver.cpp:270] Iteration 2950 (3.96216 iter/s, 12.6194s/50 iter), loss = 0.030048, remaining 0 hours and 37 minutes
I0614 16:26:32.828737  6907 solver.cpp:291]     Train net output #0: loss = 0.030048 (* 1 = 0.030048 loss)
I0614 16:26:32.828744  6907 sgd_solver.cpp:106] Iteration 2950, lr = 0.0001
I0614 16:26:45.198784  6907 solver.cpp:424] Iteration 3000, Testing net (#0)
I0614 16:26:46.704111  6907 solver.cpp:523]     Test net output #0: accuracy = 0.951
I0614 16:26:46.704141  6907 solver.cpp:523]     Test net output #1: loss = 0.121318 (* 1 = 0.121318 loss)
I0614 16:26:46.704145  6907 solver.cpp:523]     Test net output #2: top-1 = 0.951
I0614 16:26:46.949875  6907 solver.cpp:270] Iteration 3000 (3.5409 iter/s, 14.1207s/50 iter), loss = 0.0234263, remaining 0 hours and 42 minutes
I0614 16:26:46.949905  6907 solver.cpp:291]     Train net output #0: loss = 0.0234263 (* 1 = 0.0234263 loss)
I0614 16:26:46.949928  6907 sgd_solver.cpp:106] Iteration 3000, lr = 0.0001
I0614 16:26:59.594393  6907 solver.cpp:270] Iteration 3050 (3.95442 iter/s, 12.6441s/50 iter), loss = 0.0459853, remaining 0 hours and 37 minutes
I0614 16:26:59.594424  6907 solver.cpp:291]     Train net output #0: loss = 0.0459853 (* 1 = 0.0459853 loss)
I0614 16:26:59.594432  6907 sgd_solver.cpp:106] Iteration 3050, lr = 0.0001
I0614 16:27:12.227053  6907 solver.cpp:270] Iteration 3100 (3.95813 iter/s, 12.6322s/50 iter), loss = 0.00800545, remaining 0 hours and 37 minutes
I0614 16:27:12.227309  6907 solver.cpp:291]     Train net output #0: loss = 0.00800546 (* 1 = 0.00800546 loss)
I0614 16:27:12.227334  6907 sgd_solver.cpp:106] Iteration 3100, lr = 0.0001
I0614 16:27:24.907279  6907 solver.cpp:270] Iteration 3150 (3.94335 iter/s, 12.6796s/50 iter), loss = 0.0786018, remaining 0 hours and 37 minutes
I0614 16:27:24.907310  6907 solver.cpp:291]     Train net output #0: loss = 0.0786018 (* 1 = 0.0786018 loss)
I0614 16:27:24.907317  6907 sgd_solver.cpp:106] Iteration 3150, lr = 0.0001
I0614 16:27:37.633415  6907 solver.cpp:270] Iteration 3200 (3.92906 iter/s, 12.7257s/50 iter), loss = 0.0121347, remaining 0 hours and 37 minutes
I0614 16:27:37.633450  6907 solver.cpp:291]     Train net output #0: loss = 0.0121347 (* 1 = 0.0121347 loss)
I0614 16:27:37.633457  6907 sgd_solver.cpp:106] Iteration 3200, lr = 0.0001
I0614 16:27:50.346504  6907 solver.cpp:270] Iteration 3250 (3.93309 iter/s, 12.7126s/50 iter), loss = 0.0349862, remaining 0 hours and 36 minutes
I0614 16:27:50.346762  6907 solver.cpp:291]     Train net output #0: loss = 0.0349862 (* 1 = 0.0349862 loss)
I0614 16:27:50.346769  6907 sgd_solver.cpp:106] Iteration 3250, lr = 0.0001
I0614 16:28:02.981228  6907 solver.cpp:270] Iteration 3300 (3.95756 iter/s, 12.6341s/50 iter), loss = 0.0300874, remaining 0 hours and 36 minutes
I0614 16:28:02.981262  6907 solver.cpp:291]     Train net output #0: loss = 0.0300874 (* 1 = 0.0300874 loss)
I0614 16:28:02.981269  6907 sgd_solver.cpp:106] Iteration 3300, lr = 0.0001
I0614 16:28:15.601135  6907 solver.cpp:270] Iteration 3350 (3.96213 iter/s, 12.6195s/50 iter), loss = 0.0213569, remaining 0 hours and 36 minutes
I0614 16:28:15.601168  6907 solver.cpp:291]     Train net output #0: loss = 0.0213569 (* 1 = 0.0213569 loss)
I0614 16:28:15.601176  6907 sgd_solver.cpp:106] Iteration 3350, lr = 0.0001
I0614 16:28:28.223222  6907 solver.cpp:270] Iteration 3400 (3.96145 iter/s, 12.6216s/50 iter), loss = 0.0487546, remaining 0 hours and 36 minutes
I0614 16:28:28.223554  6907 solver.cpp:291]     Train net output #0: loss = 0.0487546 (* 1 = 0.0487546 loss)
I0614 16:28:28.223578  6907 sgd_solver.cpp:106] Iteration 3400, lr = 0.0001
I0614 16:28:40.834550  6907 solver.cpp:270] Iteration 3450 (3.96492 iter/s, 12.6106s/50 iter), loss = 0.0186381, remaining 0 hours and 35 minutes
I0614 16:28:40.834594  6907 solver.cpp:291]     Train net output #0: loss = 0.0186381 (* 1 = 0.0186381 loss)
I0614 16:28:40.834617  6907 sgd_solver.cpp:106] Iteration 3450, lr = 0.0001
I0614 16:28:53.474645  6907 solver.cpp:270] Iteration 3500 (3.95581 iter/s, 12.6396s/50 iter), loss = 0.0154544, remaining 0 hours and 35 minutes
I0614 16:28:53.474678  6907 solver.cpp:291]     Train net output #0: loss = 0.0154544 (* 1 = 0.0154544 loss)
I0614 16:28:53.474686  6907 sgd_solver.cpp:106] Iteration 3500, lr = 0.0001
I0614 16:29:06.118408  6907 solver.cpp:270] Iteration 3550 (3.95466 iter/s, 12.6433s/50 iter), loss = 0.0468983, remaining 0 hours and 35 minutes
I0614 16:29:06.118669  6907 solver.cpp:291]     Train net output #0: loss = 0.0468983 (* 1 = 0.0468983 loss)
I0614 16:29:06.118677  6907 sgd_solver.cpp:106] Iteration 3550, lr = 0.0001
I0614 16:29:18.734031  6907 solver.cpp:270] Iteration 3600 (3.96355 iter/s, 12.615s/50 iter), loss = 0.0304954, remaining 0 hours and 35 minutes
I0614 16:29:18.734063  6907 solver.cpp:291]     Train net output #0: loss = 0.0304954 (* 1 = 0.0304954 loss)
I0614 16:29:18.734071  6907 sgd_solver.cpp:106] Iteration 3600, lr = 0.0001
I0614 16:29:31.356914  6907 solver.cpp:270] Iteration 3650 (3.9612 iter/s, 12.6224s/50 iter), loss = 0.0166134, remaining 0 hours and 35 minutes
I0614 16:29:31.356945  6907 solver.cpp:291]     Train net output #0: loss = 0.0166134 (* 1 = 0.0166134 loss)
I0614 16:29:31.356952  6907 sgd_solver.cpp:106] Iteration 3650, lr = 0.0001
I0614 16:29:43.967049  6907 solver.cpp:270] Iteration 3700 (3.9652 iter/s, 12.6097s/50 iter), loss = 0.00812219, remaining 0 hours and 34 minutes
I0614 16:29:43.967303  6907 solver.cpp:291]     Train net output #0: loss = 0.00812217 (* 1 = 0.00812217 loss)
I0614 16:29:43.967311  6907 sgd_solver.cpp:106] Iteration 3700, lr = 0.0001
I0614 16:29:56.602078  6907 solver.cpp:270] Iteration 3750 (3.95746 iter/s, 12.6344s/50 iter), loss = 0.0326242, remaining 0 hours and 34 minutes
I0614 16:29:56.602111  6907 solver.cpp:291]     Train net output #0: loss = 0.0326242 (* 1 = 0.0326242 loss)
I0614 16:29:56.602134  6907 sgd_solver.cpp:106] Iteration 3750, lr = 0.0001
I0614 16:30:09.232553  6907 solver.cpp:270] Iteration 3800 (3.95882 iter/s, 12.63s/50 iter), loss = 0.0215122, remaining 0 hours and 34 minutes
I0614 16:30:09.232584  6907 solver.cpp:291]     Train net output #0: loss = 0.0215122 (* 1 = 0.0215122 loss)
I0614 16:30:09.232592  6907 sgd_solver.cpp:106] Iteration 3800, lr = 0.0001
I0614 16:30:21.862078  6907 solver.cpp:270] Iteration 3850 (3.95911 iter/s, 12.6291s/50 iter), loss = 0.00991967, remaining 0 hours and 34 minutes
I0614 16:30:21.862330  6907 solver.cpp:291]     Train net output #0: loss = 0.00991966 (* 1 = 0.00991966 loss)
I0614 16:30:21.862339  6907 sgd_solver.cpp:106] Iteration 3850, lr = 0.0001
I0614 16:30:34.479704  6907 solver.cpp:270] Iteration 3900 (3.96292 iter/s, 12.617s/50 iter), loss = 0.00310983, remaining 0 hours and 34 minutes
I0614 16:30:34.479738  6907 solver.cpp:291]     Train net output #0: loss = 0.00310981 (* 1 = 0.00310981 loss)
I0614 16:30:34.479745  6907 sgd_solver.cpp:106] Iteration 3900, lr = 0.0001
I0614 16:30:47.111060  6907 solver.cpp:270] Iteration 3950 (3.95854 iter/s, 12.6309s/50 iter), loss = 0.00693549, remaining 0 hours and 33 minutes
I0614 16:30:47.111093  6907 solver.cpp:291]     Train net output #0: loss = 0.00693548 (* 1 = 0.00693548 loss)
I0614 16:30:47.111100  6907 sgd_solver.cpp:106] Iteration 3950, lr = 0.0001
I0614 16:30:59.466156  6907 solver.cpp:424] Iteration 4000, Testing net (#0)
I0614 16:31:00.967463  6907 solver.cpp:523]     Test net output #0: accuracy = 0.95175
I0614 16:31:00.967494  6907 solver.cpp:523]     Test net output #1: loss = 0.121745 (* 1 = 0.121745 loss)
I0614 16:31:00.967497  6907 solver.cpp:523]     Test net output #2: top-1 = 0.95175
I0614 16:31:01.214299  6907 solver.cpp:270] Iteration 4000 (3.54541 iter/s, 14.1028s/50 iter), loss = 0.0131962, remaining 0 hours and 37 minutes
I0614 16:31:01.214329  6907 solver.cpp:291]     Train net output #0: loss = 0.0131962 (* 1 = 0.0131962 loss)
I0614 16:31:01.214336  6907 sgd_solver.cpp:106] Iteration 4000, lr = 0.0001
I0614 16:31:13.843803  6907 solver.cpp:270] Iteration 4050 (3.95912 iter/s, 12.6291s/50 iter), loss = 0.0287942, remaining 0 hours and 33 minutes
I0614 16:31:13.843837  6907 solver.cpp:291]     Train net output #0: loss = 0.0287942 (* 1 = 0.0287942 loss)
I0614 16:31:13.843859  6907 sgd_solver.cpp:106] Iteration 4050, lr = 0.0001
I0614 16:31:26.461896  6907 solver.cpp:270] Iteration 4100 (3.9627 iter/s, 12.6177s/50 iter), loss = 0.014762, remaining 0 hours and 33 minutes
I0614 16:31:26.461928  6907 solver.cpp:291]     Train net output #0: loss = 0.014762 (* 1 = 0.014762 loss)
I0614 16:31:26.461936  6907 sgd_solver.cpp:106] Iteration 4100, lr = 0.0001
I0614 16:31:39.076565  6907 solver.cpp:270] Iteration 4150 (3.96378 iter/s, 12.6142s/50 iter), loss = 0.0537117, remaining 0 hours and 32 minutes
I0614 16:31:39.076908  6907 solver.cpp:291]     Train net output #0: loss = 0.0537117 (* 1 = 0.0537117 loss)
I0614 16:31:39.076920  6907 sgd_solver.cpp:106] Iteration 4150, lr = 0.0001
I0614 16:31:51.694262  6907 solver.cpp:270] Iteration 4200 (3.96292 iter/s, 12.6169s/50 iter), loss = 0.0103094, remaining 0 hours and 32 minutes
I0614 16:31:51.694296  6907 solver.cpp:291]     Train net output #0: loss = 0.0103094 (* 1 = 0.0103094 loss)
I0614 16:31:51.694304  6907 sgd_solver.cpp:106] Iteration 4200, lr = 0.0001
I0614 16:32:04.307672  6907 solver.cpp:270] Iteration 4250 (3.96417 iter/s, 12.613s/50 iter), loss = 0.00855509, remaining 0 hours and 32 minutes
I0614 16:32:04.307701  6907 solver.cpp:291]     Train net output #0: loss = 0.00855508 (* 1 = 0.00855508 loss)
I0614 16:32:04.307709  6907 sgd_solver.cpp:106] Iteration 4250, lr = 0.0001
I0614 16:32:16.919091  6907 solver.cpp:270] Iteration 4300 (3.9648 iter/s, 12.611s/50 iter), loss = 0.0247511, remaining 0 hours and 32 minutes
I0614 16:32:16.919345  6907 solver.cpp:291]     Train net output #0: loss = 0.0247511 (* 1 = 0.0247511 loss)
I0614 16:32:16.919353  6907 sgd_solver.cpp:106] Iteration 4300, lr = 0.0001
I0614 16:32:29.543624  6907 solver.cpp:270] Iteration 4350 (3.96075 iter/s, 12.6239s/50 iter), loss = 0.0106313, remaining 0 hours and 32 minutes
I0614 16:32:29.543655  6907 solver.cpp:291]     Train net output #0: loss = 0.0106313 (* 1 = 0.0106313 loss)
I0614 16:32:29.543679  6907 sgd_solver.cpp:106] Iteration 4350, lr = 0.0001
I0614 16:32:42.190294  6907 solver.cpp:270] Iteration 4400 (3.95375 iter/s, 12.6462s/50 iter), loss = 0.0218497, remaining 0 hours and 31 minutes
I0614 16:32:42.190325  6907 solver.cpp:291]     Train net output #0: loss = 0.0218496 (* 1 = 0.0218496 loss)
I0614 16:32:42.190332  6907 sgd_solver.cpp:106] Iteration 4400, lr = 0.0001
I0614 16:32:54.809995  6907 solver.cpp:270] Iteration 4450 (3.9622 iter/s, 12.6193s/50 iter), loss = 0.00693401, remaining 0 hours and 31 minutes
I0614 16:32:54.810256  6907 solver.cpp:291]     Train net output #0: loss = 0.00693399 (* 1 = 0.00693399 loss)
I0614 16:32:54.810266  6907 sgd_solver.cpp:106] Iteration 4450, lr = 0.0001
I0614 16:33:07.437281  6907 solver.cpp:270] Iteration 4500 (3.95989 iter/s, 12.6266s/50 iter), loss = 0.0242799, remaining 0 hours and 31 minutes
I0614 16:33:07.437315  6907 solver.cpp:291]     Train net output #0: loss = 0.0242799 (* 1 = 0.0242799 loss)
I0614 16:33:07.437322  6907 sgd_solver.cpp:106] Iteration 4500, lr = 0.0001
I0614 16:33:20.068575  6907 solver.cpp:270] Iteration 4550 (3.95856 iter/s, 12.6309s/50 iter), loss = 0.0146958, remaining 0 hours and 31 minutes
I0614 16:33:20.068608  6907 solver.cpp:291]     Train net output #0: loss = 0.0146958 (* 1 = 0.0146958 loss)
I0614 16:33:20.068616  6907 sgd_solver.cpp:106] Iteration 4550, lr = 0.0001
I0614 16:33:32.694569  6907 solver.cpp:270] Iteration 4600 (3.96022 iter/s, 12.6256s/50 iter), loss = 0.0116946, remaining 0 hours and 31 minutes
I0614 16:33:32.694896  6907 solver.cpp:291]     Train net output #0: loss = 0.0116946 (* 1 = 0.0116946 loss)
I0614 16:33:32.694921  6907 sgd_solver.cpp:106] Iteration 4600, lr = 0.0001
I0614 16:33:45.338346  6907 solver.cpp:270] Iteration 4650 (3.95474 iter/s, 12.643s/50 iter), loss = 0.0295012, remaining 0 hours and 30 minutes
I0614 16:33:45.338390  6907 solver.cpp:291]     Train net output #0: loss = 0.0295012 (* 1 = 0.0295012 loss)
I0614 16:33:45.338398  6907 sgd_solver.cpp:106] Iteration 4650, lr = 0.0001
I0614 16:33:57.987608  6907 solver.cpp:270] Iteration 4700 (3.95294 iter/s, 12.6488s/50 iter), loss = 0.028231, remaining 0 hours and 30 minutes
I0614 16:33:57.987639  6907 solver.cpp:291]     Train net output #0: loss = 0.0282309 (* 1 = 0.0282309 loss)
I0614 16:33:57.987648  6907 sgd_solver.cpp:106] Iteration 4700, lr = 0.0001
I0614 16:34:10.601797  6907 solver.cpp:270] Iteration 4750 (3.96393 iter/s, 12.6138s/50 iter), loss = 0.0157301, remaining 0 hours and 30 minutes
I0614 16:34:10.602032  6907 solver.cpp:291]     Train net output #0: loss = 0.0157301 (* 1 = 0.0157301 loss)
I0614 16:34:10.602057  6907 sgd_solver.cpp:106] Iteration 4750, lr = 0.0001
I0614 16:34:23.235116  6907 solver.cpp:270] Iteration 4800 (3.95799 iter/s, 12.6327s/50 iter), loss = 0.0167067, remaining 0 hours and 30 minutes
I0614 16:34:23.235147  6907 solver.cpp:291]     Train net output #0: loss = 0.0167067 (* 1 = 0.0167067 loss)
I0614 16:34:23.235154  6907 sgd_solver.cpp:106] Iteration 4800, lr = 0.0001
I0614 16:34:35.863296  6907 solver.cpp:270] Iteration 4850 (3.95954 iter/s, 12.6277s/50 iter), loss = 0.0261583, remaining 0 hours and 30 minutes
I0614 16:34:35.863327  6907 solver.cpp:291]     Train net output #0: loss = 0.0261583 (* 1 = 0.0261583 loss)
I0614 16:34:35.863333  6907 sgd_solver.cpp:106] Iteration 4850, lr = 0.0001
I0614 16:34:48.493011  6907 solver.cpp:270] Iteration 4900 (3.95905 iter/s, 12.6293s/50 iter), loss = 0.0077785, remaining 0 hours and 29 minutes
I0614 16:34:48.493252  6907 solver.cpp:291]     Train net output #0: loss = 0.00777847 (* 1 = 0.00777847 loss)
I0614 16:34:48.493260  6907 sgd_solver.cpp:106] Iteration 4900, lr = 0.0001
I0614 16:35:01.115547  6907 solver.cpp:270] Iteration 4950 (3.96137 iter/s, 12.6219s/50 iter), loss = 0.0178902, remaining 0 hours and 29 minutes
I0614 16:35:01.115595  6907 solver.cpp:291]     Train net output #0: loss = 0.0178902 (* 1 = 0.0178902 loss)
I0614 16:35:01.115603  6907 sgd_solver.cpp:106] Iteration 4950, lr = 0.0001
I0614 16:35:13.481309  6907 solver.cpp:424] Iteration 5000, Testing net (#0)
I0614 16:35:14.984649  6907 solver.cpp:523]     Test net output #0: accuracy = 0.9595
I0614 16:35:14.984679  6907 solver.cpp:523]     Test net output #1: loss = 0.137374 (* 1 = 0.137374 loss)
I0614 16:35:14.984684  6907 solver.cpp:523]     Test net output #2: top-1 = 0.9595
I0614 16:35:15.231091  6907 solver.cpp:270] Iteration 5000 (3.54232 iter/s, 14.115s/50 iter), loss = 0.0273124, remaining 0 hours and 32 minutes
I0614 16:35:15.231122  6907 solver.cpp:291]     Train net output #0: loss = 0.0273124 (* 1 = 0.0273124 loss)
I0614 16:35:15.231129  6907 sgd_solver.cpp:106] Iteration 5000, lr = 1e-05
I0614 16:35:27.867404  6907 solver.cpp:270] Iteration 5050 (3.95699 iter/s, 12.6359s/50 iter), loss = 0.0301334, remaining 0 hours and 29 minutes
I0614 16:35:27.867583  6907 solver.cpp:291]     Train net output #0: loss = 0.0301334 (* 1 = 0.0301334 loss)
I0614 16:35:27.867591  6907 sgd_solver.cpp:106] Iteration 5050, lr = 1e-05
I0614 16:35:40.494339  6907 solver.cpp:270] Iteration 5100 (3.95997 iter/s, 12.6263s/50 iter), loss = 0.0144271, remaining 0 hours and 29 minutes
I0614 16:35:40.494371  6907 solver.cpp:291]     Train net output #0: loss = 0.014427 (* 1 = 0.014427 loss)
I0614 16:35:40.494379  6907 sgd_solver.cpp:106] Iteration 5100, lr = 1e-05
I0614 16:35:53.134294  6907 solver.cpp:270] Iteration 5150 (3.95585 iter/s, 12.6395s/50 iter), loss = 0.0135409, remaining 0 hours and 28 minutes
I0614 16:35:53.134330  6907 solver.cpp:291]     Train net output #0: loss = 0.0135409 (* 1 = 0.0135409 loss)
I0614 16:35:53.134336  6907 sgd_solver.cpp:106] Iteration 5150, lr = 1e-05
I0614 16:36:05.755919  6907 solver.cpp:270] Iteration 5200 (3.96159 iter/s, 12.6212s/50 iter), loss = 0.0167882, remaining 0 hours and 28 minutes
I0614 16:36:05.756135  6907 solver.cpp:291]     Train net output #0: loss = 0.0167881 (* 1 = 0.0167881 loss)
I0614 16:36:05.756160  6907 sgd_solver.cpp:106] Iteration 5200, lr = 1e-05
I0614 16:36:18.363294  6907 solver.cpp:270] Iteration 5250 (3.96613 iter/s, 12.6068s/50 iter), loss = 0.0179872, remaining 0 hours and 28 minutes
I0614 16:36:18.363327  6907 solver.cpp:291]     Train net output #0: loss = 0.0179872 (* 1 = 0.0179872 loss)
I0614 16:36:18.363337  6907 sgd_solver.cpp:106] Iteration 5250, lr = 1e-05
I0614 16:36:30.980715  6907 solver.cpp:270] Iteration 5300 (3.96291 iter/s, 12.617s/50 iter), loss = 0.00810558, remaining 0 hours and 28 minutes
I0614 16:36:30.980746  6907 solver.cpp:291]     Train net output #0: loss = 0.00810556 (* 1 = 0.00810556 loss)
I0614 16:36:30.980753  6907 sgd_solver.cpp:106] Iteration 5300, lr = 1e-05
I0614 16:36:43.604403  6907 solver.cpp:270] Iteration 5350 (3.96095 iter/s, 12.6232s/50 iter), loss = 0.0101275, remaining 0 hours and 27 minutes
I0614 16:36:43.604660  6907 solver.cpp:291]     Train net output #0: loss = 0.0101275 (* 1 = 0.0101275 loss)
I0614 16:36:43.604684  6907 sgd_solver.cpp:106] Iteration 5350, lr = 1e-05
I0614 16:36:56.258584  6907 solver.cpp:270] Iteration 5400 (3.95148 iter/s, 12.6535s/50 iter), loss = 0.0122188, remaining 0 hours and 27 minutes
I0614 16:36:56.258616  6907 solver.cpp:291]     Train net output #0: loss = 0.0122188 (* 1 = 0.0122188 loss)
I0614 16:36:56.258625  6907 sgd_solver.cpp:106] Iteration 5400, lr = 1e-05
I0614 16:37:08.871944  6907 solver.cpp:270] Iteration 5450 (3.96419 iter/s, 12.6129s/50 iter), loss = 0.015096, remaining 0 hours and 27 minutes
I0614 16:37:08.871977  6907 solver.cpp:291]     Train net output #0: loss = 0.015096 (* 1 = 0.015096 loss)
I0614 16:37:08.871985  6907 sgd_solver.cpp:106] Iteration 5450, lr = 1e-05
I0614 16:37:21.516181  6907 solver.cpp:270] Iteration 5500 (3.95451 iter/s, 12.6438s/50 iter), loss = 0.015906, remaining 0 hours and 27 minutes
I0614 16:37:21.516436  6907 solver.cpp:291]     Train net output #0: loss = 0.015906 (* 1 = 0.015906 loss)
I0614 16:37:21.516460  6907 sgd_solver.cpp:106] Iteration 5500, lr = 1e-05
I0614 16:37:34.141134  6907 solver.cpp:270] Iteration 5550 (3.96062 iter/s, 12.6243s/50 iter), loss = 0.0323867, remaining 0 hours and 27 minutes
I0614 16:37:34.141162  6907 solver.cpp:291]     Train net output #0: loss = 0.0323867 (* 1 = 0.0323867 loss)
I0614 16:37:34.141170  6907 sgd_solver.cpp:106] Iteration 5550, lr = 1e-05
I0614 16:37:46.769145  6907 solver.cpp:270] Iteration 5600 (3.95959 iter/s, 12.6276s/50 iter), loss = 0.0102239, remaining 0 hours and 26 minutes
I0614 16:37:46.769179  6907 solver.cpp:291]     Train net output #0: loss = 0.0102238 (* 1 = 0.0102238 loss)
I0614 16:37:46.769187  6907 sgd_solver.cpp:106] Iteration 5600, lr = 1e-05
I0614 16:37:59.391048  6907 solver.cpp:270] Iteration 5650 (3.96151 iter/s, 12.6215s/50 iter), loss = 0.00647336, remaining 0 hours and 26 minutes
I0614 16:37:59.391306  6907 solver.cpp:291]     Train net output #0: loss = 0.00647333 (* 1 = 0.00647333 loss)
I0614 16:37:59.391314  6907 sgd_solver.cpp:106] Iteration 5650, lr = 1e-05
I0614 16:38:11.994459  6907 solver.cpp:270] Iteration 5700 (3.96739 iter/s, 12.6027s/50 iter), loss = 0.00567982, remaining 0 hours and 26 minutes
I0614 16:38:11.994493  6907 solver.cpp:291]     Train net output #0: loss = 0.00567979 (* 1 = 0.00567979 loss)
I0614 16:38:11.994499  6907 sgd_solver.cpp:106] Iteration 5700, lr = 1e-05
I0614 16:38:24.603741  6907 solver.cpp:270] Iteration 5750 (3.96547 iter/s, 12.6088s/50 iter), loss = 0.0242794, remaining 0 hours and 26 minutes
I0614 16:38:24.603771  6907 solver.cpp:291]     Train net output #0: loss = 0.0242794 (* 1 = 0.0242794 loss)
I0614 16:38:24.603780  6907 sgd_solver.cpp:106] Iteration 5750, lr = 1e-05
I0614 16:38:37.208338  6907 solver.cpp:270] Iteration 5800 (3.96694 iter/s, 12.6042s/50 iter), loss = 0.00251727, remaining 0 hours and 25 minutes
I0614 16:38:37.208683  6907 solver.cpp:291]     Train net output #0: loss = 0.00251724 (* 1 = 0.00251724 loss)
I0614 16:38:37.208693  6907 sgd_solver.cpp:106] Iteration 5800, lr = 1e-05
I0614 16:38:49.828388  6907 solver.cpp:270] Iteration 5850 (3.96219 iter/s, 12.6193s/50 iter), loss = 0.00969339, remaining 0 hours and 25 minutes
I0614 16:38:49.828420  6907 solver.cpp:291]     Train net output #0: loss = 0.00969336 (* 1 = 0.00969336 loss)
I0614 16:38:49.828428  6907 sgd_solver.cpp:106] Iteration 5850, lr = 1e-05
I0614 16:39:02.448110  6907 solver.cpp:270] Iteration 5900 (3.96219 iter/s, 12.6193s/50 iter), loss = 0.0159069, remaining 0 hours and 25 minutes
I0614 16:39:02.448141  6907 solver.cpp:291]     Train net output #0: loss = 0.0159068 (* 1 = 0.0159068 loss)
I0614 16:39:02.448149  6907 sgd_solver.cpp:106] Iteration 5900, lr = 1e-05
I0614 16:39:15.058037  6907 solver.cpp:270] Iteration 5950 (3.96527 iter/s, 12.6095s/50 iter), loss = 0.0147764, remaining 0 hours and 25 minutes
I0614 16:39:15.058300  6907 solver.cpp:291]     Train net output #0: loss = 0.0147763 (* 1 = 0.0147763 loss)
I0614 16:39:15.058307  6907 sgd_solver.cpp:106] Iteration 5950, lr = 1e-05
I0614 16:39:27.419987  6907 solver.cpp:935] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.4/snapshots/_iter_6000.caffemodel
I0614 16:39:33.471088  6907 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.4/snapshots/_iter_6000.solverstate
I0614 16:39:37.075374  6907 solver.cpp:424] Iteration 6000, Testing net (#0)
I0614 16:39:38.490780  6907 solver.cpp:523]     Test net output #0: accuracy = 0.958
I0614 16:39:38.490810  6907 solver.cpp:523]     Test net output #1: loss = 0.142347 (* 1 = 0.142347 loss)
I0614 16:39:38.490814  6907 solver.cpp:523]     Test net output #2: top-1 = 0.958
I0614 16:39:38.729509  6907 solver.cpp:270] Iteration 6000 (2.11234 iter/s, 23.6705s/50 iter), loss = 0.00587427, remaining 0 hours and 47 minutes
I0614 16:39:38.729542  6907 solver.cpp:291]     Train net output #0: loss = 0.00587424 (* 1 = 0.00587424 loss)
I0614 16:39:38.729549  6907 sgd_solver.cpp:106] Iteration 6000, lr = 1e-05
I0614 16:39:51.269353  6907 solver.cpp:270] Iteration 6050 (3.98743 iter/s, 12.5394s/50 iter), loss = 0.0142927, remaining 0 hours and 24 minutes
I0614 16:39:51.269616  6907 solver.cpp:291]     Train net output #0: loss = 0.0142926 (* 1 = 0.0142926 loss)
I0614 16:39:51.269624  6907 sgd_solver.cpp:106] Iteration 6050, lr = 1e-05
I0614 16:40:03.817106  6907 solver.cpp:270] Iteration 6100 (3.98499 iter/s, 12.5471s/50 iter), loss = 0.008904, remaining 0 hours and 24 minutes
I0614 16:40:03.817138  6907 solver.cpp:291]     Train net output #0: loss = 0.00890397 (* 1 = 0.00890397 loss)
I0614 16:40:03.817147  6907 sgd_solver.cpp:106] Iteration 6100, lr = 1e-05
I0614 16:40:16.377162  6907 solver.cpp:270] Iteration 6150 (3.98101 iter/s, 12.5596s/50 iter), loss = 0.0190642, remaining 0 hours and 24 minutes
I0614 16:40:16.377193  6907 solver.cpp:291]     Train net output #0: loss = 0.0190642 (* 1 = 0.0190642 loss)
I0614 16:40:16.377200  6907 sgd_solver.cpp:106] Iteration 6150, lr = 1e-05
I0614 16:40:29.001547  6907 solver.cpp:270] Iteration 6200 (3.96073 iter/s, 12.6239s/50 iter), loss = 0.00862821, remaining 0 hours and 24 minutes
I0614 16:40:29.001783  6907 solver.cpp:291]     Train net output #0: loss = 0.00862818 (* 1 = 0.00862818 loss)
I0614 16:40:29.001791  6907 sgd_solver.cpp:106] Iteration 6200, lr = 1e-05
I0614 16:40:41.612972  6907 solver.cpp:270] Iteration 6250 (3.96486 iter/s, 12.6108s/50 iter), loss = 0.0103682, remaining 0 hours and 23 minutes
I0614 16:40:41.613003  6907 solver.cpp:291]     Train net output #0: loss = 0.0103682 (* 1 = 0.0103682 loss)
I0614 16:40:41.613024  6907 sgd_solver.cpp:106] Iteration 6250, lr = 1e-05
I0614 16:40:54.248948  6907 solver.cpp:270] Iteration 6300 (3.95709 iter/s, 12.6355s/50 iter), loss = 0.00454962, remaining 0 hours and 24 minutes
I0614 16:40:54.248981  6907 solver.cpp:291]     Train net output #0: loss = 0.0045496 (* 1 = 0.0045496 loss)
I0614 16:40:54.248988  6907 sgd_solver.cpp:106] Iteration 6300, lr = 1e-05
I0614 16:41:06.885679  6907 solver.cpp:270] Iteration 6350 (3.95686 iter/s, 12.6363s/50 iter), loss = 0.00285178, remaining 0 hours and 23 minutes
I0614 16:41:06.886009  6907 solver.cpp:291]     Train net output #0: loss = 0.00285176 (* 1 = 0.00285176 loss)
I0614 16:41:06.886034  6907 sgd_solver.cpp:106] Iteration 6350, lr = 1e-05
I0614 16:41:19.519289  6907 solver.cpp:270] Iteration 6400 (3.95793 iter/s, 12.6329s/50 iter), loss = 0.00188616, remaining 0 hours and 23 minutes
I0614 16:41:19.519321  6907 solver.cpp:291]     Train net output #0: loss = 0.00188613 (* 1 = 0.00188613 loss)
I0614 16:41:19.519330  6907 sgd_solver.cpp:106] Iteration 6400, lr = 1e-05
I0614 16:41:32.138099  6907 solver.cpp:270] Iteration 6450 (3.96248 iter/s, 12.6184s/50 iter), loss = 0.000331261, remaining 0 hours and 23 minutes
I0614 16:41:32.138130  6907 solver.cpp:291]     Train net output #0: loss = 0.000331239 (* 1 = 0.000331239 loss)
I0614 16:41:32.138139  6907 sgd_solver.cpp:106] Iteration 6450, lr = 1e-05
I0614 16:41:44.758251  6907 solver.cpp:270] Iteration 6500 (3.96205 iter/s, 12.6197s/50 iter), loss = 0.0077581, remaining 0 hours and 22 minutes
I0614 16:41:44.758461  6907 solver.cpp:291]     Train net output #0: loss = 0.00775808 (* 1 = 0.00775808 loss)
I0614 16:41:44.758469  6907 sgd_solver.cpp:106] Iteration 6500, lr = 1e-05
I0614 16:41:57.365762  6907 solver.cpp:270] Iteration 6550 (3.96608 iter/s, 12.6069s/50 iter), loss = 0.0074396, remaining 0 hours and 22 minutes
I0614 16:41:57.365793  6907 solver.cpp:291]     Train net output #0: loss = 0.00743958 (* 1 = 0.00743958 loss)
I0614 16:41:57.365818  6907 sgd_solver.cpp:106] Iteration 6550, lr = 1e-05
I0614 16:42:09.981227  6907 solver.cpp:270] Iteration 6600 (3.96353 iter/s, 12.615s/50 iter), loss = 0.0302637, remaining 0 hours and 22 minutes
I0614 16:42:09.981258  6907 solver.cpp:291]     Train net output #0: loss = 0.0302637 (* 1 = 0.0302637 loss)
I0614 16:42:09.981266  6907 sgd_solver.cpp:106] Iteration 6600, lr = 1e-05
I0614 16:42:22.609149  6907 solver.cpp:270] Iteration 6650 (3.95962 iter/s, 12.6275s/50 iter), loss = 0.00881947, remaining 0 hours and 22 minutes
I0614 16:42:22.609427  6907 solver.cpp:291]     Train net output #0: loss = 0.00881945 (* 1 = 0.00881945 loss)
I0614 16:42:22.609436  6907 sgd_solver.cpp:106] Iteration 6650, lr = 1e-05
I0614 16:42:35.245062  6907 solver.cpp:270] Iteration 6700 (3.95719 iter/s, 12.6352s/50 iter), loss = 0.00548493, remaining 0 hours and 22 minutes
I0614 16:42:35.245095  6907 solver.cpp:291]     Train net output #0: loss = 0.00548491 (* 1 = 0.00548491 loss)
I0614 16:42:35.245102  6907 sgd_solver.cpp:106] Iteration 6700, lr = 1e-05
I0614 16:42:47.875422  6907 solver.cpp:270] Iteration 6750 (3.95885 iter/s, 12.6299s/50 iter), loss = 0.003069, remaining 0 hours and 21 minutes
I0614 16:42:47.875454  6907 solver.cpp:291]     Train net output #0: loss = 0.00306899 (* 1 = 0.00306899 loss)
I0614 16:42:47.875463  6907 sgd_solver.cpp:106] Iteration 6750, lr = 1e-05
I0614 16:43:00.477401  6907 solver.cpp:270] Iteration 6800 (3.96777 iter/s, 12.6015s/50 iter), loss = 0.003902, remaining 0 hours and 21 minutes
I0614 16:43:00.477602  6907 solver.cpp:291]     Train net output #0: loss = 0.00390198 (* 1 = 0.00390198 loss)
I0614 16:43:00.477610  6907 sgd_solver.cpp:106] Iteration 6800, lr = 1e-05
I0614 16:43:13.080895  6907 solver.cpp:270] Iteration 6850 (3.96734 iter/s, 12.6029s/50 iter), loss = 0.00272381, remaining 0 hours and 21 minutes
I0614 16:43:13.080929  6907 solver.cpp:291]     Train net output #0: loss = 0.00272379 (* 1 = 0.00272379 loss)
I0614 16:43:13.080938  6907 sgd_solver.cpp:106] Iteration 6850, lr = 1e-05
I0614 16:43:25.691622  6907 solver.cpp:270] Iteration 6900 (3.96502 iter/s, 12.6103s/50 iter), loss = 0.00549993, remaining 0 hours and 21 minutes
I0614 16:43:25.691653  6907 solver.cpp:291]     Train net output #0: loss = 0.00549991 (* 1 = 0.00549991 loss)
I0614 16:43:25.691661  6907 sgd_solver.cpp:106] Iteration 6900, lr = 1e-05
I0614 16:43:38.290253  6907 solver.cpp:270] Iteration 6950 (3.96882 iter/s, 12.5982s/50 iter), loss = 0.00194267, remaining 0 hours and 21 minutes
I0614 16:43:38.290587  6907 solver.cpp:291]     Train net output #0: loss = 0.00194265 (* 1 = 0.00194265 loss)
I0614 16:43:38.290596  6907 sgd_solver.cpp:106] Iteration 6950, lr = 1e-05
I0614 16:43:50.653302  6907 solver.cpp:424] Iteration 7000, Testing net (#0)
I0614 16:43:52.148391  6907 solver.cpp:523]     Test net output #0: accuracy = 0.95925
I0614 16:43:52.148420  6907 solver.cpp:523]     Test net output #1: loss = 0.158511 (* 1 = 0.158511 loss)
I0614 16:43:52.148425  6907 solver.cpp:523]     Test net output #2: top-1 = 0.95925
I0614 16:43:52.394964  6907 solver.cpp:270] Iteration 7000 (3.54511 iter/s, 14.1039s/50 iter), loss = 0.00741004, remaining 0 hours and 23 minutes
I0614 16:43:52.394994  6907 solver.cpp:291]     Train net output #0: loss = 0.00741002 (* 1 = 0.00741002 loss)
I0614 16:43:52.395018  6907 sgd_solver.cpp:106] Iteration 7000, lr = 1e-05
I0614 16:44:05.009152  6907 solver.cpp:270] Iteration 7050 (3.96393 iter/s, 12.6137s/50 iter), loss = 0.00394527, remaining 0 hours and 20 minutes
I0614 16:44:05.009183  6907 solver.cpp:291]     Train net output #0: loss = 0.00394525 (* 1 = 0.00394525 loss)
I0614 16:44:05.009191  6907 sgd_solver.cpp:106] Iteration 7050, lr = 1e-05
I0614 16:44:17.614152  6907 solver.cpp:270] Iteration 7100 (3.96682 iter/s, 12.6046s/50 iter), loss = 0.00138144, remaining 0 hours and 20 minutes
I0614 16:44:17.614415  6907 solver.cpp:291]     Train net output #0: loss = 0.00138141 (* 1 = 0.00138141 loss)
I0614 16:44:17.614424  6907 sgd_solver.cpp:106] Iteration 7100, lr = 1e-05
I0614 16:44:30.222993  6907 solver.cpp:270] Iteration 7150 (3.96568 iter/s, 12.6082s/50 iter), loss = 0.034927, remaining 0 hours and 20 minutes
I0614 16:44:30.223026  6907 solver.cpp:291]     Train net output #0: loss = 0.034927 (* 1 = 0.034927 loss)
I0614 16:44:30.223048  6907 sgd_solver.cpp:106] Iteration 7150, lr = 1e-05
I0614 16:44:42.841097  6907 solver.cpp:270] Iteration 7200 (3.9627 iter/s, 12.6177s/50 iter), loss = 0.0131681, remaining 0 hours and 20 minutes
I0614 16:44:42.841128  6907 solver.cpp:291]     Train net output #0: loss = 0.013168 (* 1 = 0.013168 loss)
I0614 16:44:42.841135  6907 sgd_solver.cpp:106] Iteration 7200, lr = 1e-05
I0614 16:44:55.457808  6907 solver.cpp:270] Iteration 7250 (3.96314 iter/s, 12.6163s/50 iter), loss = 0.0095595, remaining 0 hours and 19 minutes
I0614 16:44:55.458067  6907 solver.cpp:291]     Train net output #0: loss = 0.00955948 (* 1 = 0.00955948 loss)
I0614 16:44:55.458076  6907 sgd_solver.cpp:106] Iteration 7250, lr = 1e-05
I0614 16:45:08.067426  6907 solver.cpp:270] Iteration 7300 (3.96544 iter/s, 12.609s/50 iter), loss = 0.00175089, remaining 0 hours and 19 minutes
I0614 16:45:08.067457  6907 solver.cpp:291]     Train net output #0: loss = 0.00175087 (* 1 = 0.00175087 loss)
I0614 16:45:08.067466  6907 sgd_solver.cpp:106] Iteration 7300, lr = 1e-05
I0614 16:45:20.682400  6907 solver.cpp:270] Iteration 7350 (3.96368 iter/s, 12.6145s/50 iter), loss = 0.00263262, remaining 0 hours and 19 minutes
I0614 16:45:20.682435  6907 solver.cpp:291]     Train net output #0: loss = 0.00263259 (* 1 = 0.00263259 loss)
I0614 16:45:20.682441  6907 sgd_solver.cpp:106] Iteration 7350, lr = 1e-05
I0614 16:45:33.295151  6907 solver.cpp:270] Iteration 7400 (3.96438 iter/s, 12.6123s/50 iter), loss = 0.00522288, remaining 0 hours and 19 minutes
I0614 16:45:33.295405  6907 solver.cpp:291]     Train net output #0: loss = 0.00522286 (* 1 = 0.00522286 loss)
I0614 16:45:33.295429  6907 sgd_solver.cpp:106] Iteration 7400, lr = 1e-05
I0614 16:45:45.905382  6907 solver.cpp:270] Iteration 7450 (3.96524 iter/s, 12.6096s/50 iter), loss = 0.0247563, remaining 0 hours and 18 minutes
I0614 16:45:45.905413  6907 solver.cpp:291]     Train net output #0: loss = 0.0247563 (* 1 = 0.0247563 loss)
I0614 16:45:45.905437  6907 sgd_solver.cpp:106] Iteration 7450, lr = 1e-05
I0614 16:45:58.518329  6907 solver.cpp:270] Iteration 7500 (3.96432 iter/s, 12.6125s/50 iter), loss = 0.00431337, remaining 0 hours and 18 minutes
I0614 16:45:58.518368  6907 solver.cpp:291]     Train net output #0: loss = 0.00431334 (* 1 = 0.00431334 loss)
I0614 16:45:58.518379  6907 sgd_solver.cpp:106] Iteration 7500, lr = 1e-06
I0614 16:46:11.136993  6907 solver.cpp:270] Iteration 7550 (3.96252 iter/s, 12.6182s/50 iter), loss = 0.00351741, remaining 0 hours and 18 minutes
I0614 16:46:11.137331  6907 solver.cpp:291]     Train net output #0: loss = 0.00351737 (* 1 = 0.00351737 loss)
I0614 16:46:11.137341  6907 sgd_solver.cpp:106] Iteration 7550, lr = 1e-06
I0614 16:46:23.742844  6907 solver.cpp:270] Iteration 7600 (3.96665 iter/s, 12.6051s/50 iter), loss = 0.00268515, remaining 0 hours and 18 minutes
I0614 16:46:23.742878  6907 solver.cpp:291]     Train net output #0: loss = 0.00268512 (* 1 = 0.00268512 loss)
I0614 16:46:23.742887  6907 sgd_solver.cpp:106] Iteration 7600, lr = 1e-06
I0614 16:46:36.367522  6907 solver.cpp:270] Iteration 7650 (3.96064 iter/s, 12.6242s/50 iter), loss = 0.000978569, remaining 0 hours and 18 minutes
I0614 16:46:36.367553  6907 solver.cpp:291]     Train net output #0: loss = 0.000978539 (* 1 = 0.000978539 loss)
I0614 16:46:36.367578  6907 sgd_solver.cpp:106] Iteration 7650, lr = 1e-06
I0614 16:46:48.979975  6907 solver.cpp:270] Iteration 7700 (3.96447 iter/s, 12.612s/50 iter), loss = 0.00147276, remaining 0 hours and 17 minutes
I0614 16:46:48.980151  6907 solver.cpp:291]     Train net output #0: loss = 0.00147272 (* 1 = 0.00147272 loss)
I0614 16:46:48.980160  6907 sgd_solver.cpp:106] Iteration 7700, lr = 1e-06
I0614 16:47:01.603435  6907 solver.cpp:270] Iteration 7750 (3.96106 iter/s, 12.6229s/50 iter), loss = 0.0171201, remaining 0 hours and 17 minutes
I0614 16:47:01.603466  6907 solver.cpp:291]     Train net output #0: loss = 0.0171201 (* 1 = 0.0171201 loss)
I0614 16:47:01.603490  6907 sgd_solver.cpp:106] Iteration 7750, lr = 1e-06
I0614 16:47:14.216604  6907 solver.cpp:270] Iteration 7800 (3.96425 iter/s, 12.6127s/50 iter), loss = 0.0176394, remaining 0 hours and 17 minutes
I0614 16:47:14.216637  6907 solver.cpp:291]     Train net output #0: loss = 0.0176393 (* 1 = 0.0176393 loss)
I0614 16:47:14.216661  6907 sgd_solver.cpp:106] Iteration 7800, lr = 1e-06
I0614 16:47:26.835912  6907 solver.cpp:270] Iteration 7850 (3.96232 iter/s, 12.6189s/50 iter), loss = 0.0171899, remaining 0 hours and 17 minutes
I0614 16:47:26.836169  6907 solver.cpp:291]     Train net output #0: loss = 0.0171899 (* 1 = 0.0171899 loss)
I0614 16:47:26.836177  6907 sgd_solver.cpp:106] Iteration 7850, lr = 1e-06
I0614 16:47:39.439889  6907 solver.cpp:270] Iteration 7900 (3.96721 iter/s, 12.6033s/50 iter), loss = 0.00314567, remaining 0 hours and 17 minutes
I0614 16:47:39.439920  6907 solver.cpp:291]     Train net output #0: loss = 0.00314563 (* 1 = 0.00314563 loss)
I0614 16:47:39.439929  6907 sgd_solver.cpp:106] Iteration 7900, lr = 1e-06
I0614 16:47:52.057186  6907 solver.cpp:270] Iteration 7950 (3.96295 iter/s, 12.6169s/50 iter), loss = 0.00340594, remaining 0 hours and 16 minutes
I0614 16:47:52.057220  6907 solver.cpp:291]     Train net output #0: loss = 0.0034059 (* 1 = 0.0034059 loss)
I0614 16:47:52.057243  6907 sgd_solver.cpp:106] Iteration 7950, lr = 1e-06
I0614 16:48:04.454491  6907 solver.cpp:424] Iteration 8000, Testing net (#0)
I0614 16:48:05.936177  6907 solver.cpp:523]     Test net output #0: accuracy = 0.95825
I0614 16:48:05.936206  6907 solver.cpp:523]     Test net output #1: loss = 0.184125 (* 1 = 0.184125 loss)
I0614 16:48:05.936210  6907 solver.cpp:523]     Test net output #2: top-1 = 0.95825
I0614 16:48:06.183297  6907 solver.cpp:270] Iteration 8000 (3.53967 iter/s, 14.1256s/50 iter), loss = 0.0046634, remaining 0 hours and 18 minutes
I0614 16:48:06.183329  6907 solver.cpp:291]     Train net output #0: loss = 0.00466336 (* 1 = 0.00466336 loss)
I0614 16:48:06.183339  6907 sgd_solver.cpp:106] Iteration 8000, lr = 1e-06
I0614 16:48:18.812070  6907 solver.cpp:270] Iteration 8050 (3.95935 iter/s, 12.6283s/50 iter), loss = 0.0273297, remaining 0 hours and 16 minutes
I0614 16:48:18.812103  6907 solver.cpp:291]     Train net output #0: loss = 0.0273297 (* 1 = 0.0273297 loss)
I0614 16:48:18.812111  6907 sgd_solver.cpp:106] Iteration 8050, lr = 1e-06
I0614 16:48:31.426671  6907 solver.cpp:270] Iteration 8100 (3.9638 iter/s, 12.6142s/50 iter), loss = 0.00992673, remaining 0 hours and 16 minutes
I0614 16:48:31.426703  6907 solver.cpp:291]     Train net output #0: loss = 0.00992669 (* 1 = 0.00992669 loss)
I0614 16:48:31.426712  6907 sgd_solver.cpp:106] Iteration 8100, lr = 1e-06
I0614 16:48:44.038559  6907 solver.cpp:270] Iteration 8150 (3.96465 iter/s, 12.6114s/50 iter), loss = 0.0193673, remaining 0 hours and 16 minutes
I0614 16:48:44.038873  6907 solver.cpp:291]     Train net output #0: loss = 0.0193673 (* 1 = 0.0193673 loss)
I0614 16:48:44.038882  6907 sgd_solver.cpp:106] Iteration 8150, lr = 1e-06
I0614 16:48:56.650050  6907 solver.cpp:270] Iteration 8200 (3.96487 iter/s, 12.6108s/50 iter), loss = 0.00413424, remaining 0 hours and 15 minutes
I0614 16:48:56.650081  6907 solver.cpp:291]     Train net output #0: loss = 0.0041342 (* 1 = 0.0041342 loss)
I0614 16:48:56.650106  6907 sgd_solver.cpp:106] Iteration 8200, lr = 1e-06
I0614 16:49:09.249888  6907 solver.cpp:270] Iteration 8250 (3.96844 iter/s, 12.5994s/50 iter), loss = 0.00549953, remaining 0 hours and 15 minutes
I0614 16:49:09.249922  6907 solver.cpp:291]     Train net output #0: loss = 0.00549948 (* 1 = 0.00549948 loss)
I0614 16:49:09.249945  6907 sgd_solver.cpp:106] Iteration 8250, lr = 1e-06
I0614 16:49:21.869835  6907 solver.cpp:270] Iteration 8300 (3.96212 iter/s, 12.6195s/50 iter), loss = 0.00638597, remaining 0 hours and 15 minutes
I0614 16:49:21.870095  6907 solver.cpp:291]     Train net output #0: loss = 0.00638592 (* 1 = 0.00638592 loss)
I0614 16:49:21.870103  6907 sgd_solver.cpp:106] Iteration 8300, lr = 1e-06
I0614 16:49:34.482702  6907 solver.cpp:270] Iteration 8350 (3.96442 iter/s, 12.6122s/50 iter), loss = 0.00584698, remaining 0 hours and 15 minutes
I0614 16:49:34.482733  6907 solver.cpp:291]     Train net output #0: loss = 0.00584693 (* 1 = 0.00584693 loss)
I0614 16:49:34.482740  6907 sgd_solver.cpp:106] Iteration 8350, lr = 1e-06
I0614 16:49:47.084232  6907 solver.cpp:270] Iteration 8400 (3.96791 iter/s, 12.6011s/50 iter), loss = 0.00368696, remaining 0 hours and 15 minutes
I0614 16:49:47.084265  6907 solver.cpp:291]     Train net output #0: loss = 0.00368691 (* 1 = 0.00368691 loss)
I0614 16:49:47.084273  6907 sgd_solver.cpp:106] Iteration 8400, lr = 1e-06
I0614 16:49:59.703747  6907 solver.cpp:270] Iteration 8450 (3.96226 iter/s, 12.6191s/50 iter), loss = 0.0124375, remaining 0 hours and 14 minutes
I0614 16:49:59.703953  6907 solver.cpp:291]     Train net output #0: loss = 0.0124374 (* 1 = 0.0124374 loss)
I0614 16:49:59.703976  6907 sgd_solver.cpp:106] Iteration 8450, lr = 1e-06
I0614 16:50:12.336026  6907 solver.cpp:270] Iteration 8500 (3.95831 iter/s, 12.6317s/50 iter), loss = 0.0147943, remaining 0 hours and 14 minutes
I0614 16:50:12.336059  6907 solver.cpp:291]     Train net output #0: loss = 0.0147942 (* 1 = 0.0147942 loss)
I0614 16:50:12.336067  6907 sgd_solver.cpp:106] Iteration 8500, lr = 1e-06
I0614 16:50:24.961565  6907 solver.cpp:270] Iteration 8550 (3.96037 iter/s, 12.6251s/50 iter), loss = 0.00973185, remaining 0 hours and 14 minutes
I0614 16:50:24.961596  6907 solver.cpp:291]     Train net output #0: loss = 0.0097318 (* 1 = 0.0097318 loss)
I0614 16:50:24.961620  6907 sgd_solver.cpp:106] Iteration 8550, lr = 1e-06
I0614 16:50:37.594102  6907 solver.cpp:270] Iteration 8600 (3.95817 iter/s, 12.6321s/50 iter), loss = 0.0147099, remaining 0 hours and 14 minutes
I0614 16:50:37.594355  6907 solver.cpp:291]     Train net output #0: loss = 0.0147099 (* 1 = 0.0147099 loss)
I0614 16:50:37.594365  6907 sgd_solver.cpp:106] Iteration 8600, lr = 1e-06
I0614 16:50:50.205328  6907 solver.cpp:270] Iteration 8650 (3.96493 iter/s, 12.6106s/50 iter), loss = 0.00139743, remaining 0 hours and 13 minutes
I0614 16:50:50.205361  6907 solver.cpp:291]     Train net output #0: loss = 0.00139737 (* 1 = 0.00139737 loss)
I0614 16:50:50.205369  6907 sgd_solver.cpp:106] Iteration 8650, lr = 1e-06
I0614 16:51:02.810109  6907 solver.cpp:270] Iteration 8700 (3.96689 iter/s, 12.6043s/50 iter), loss = 0.0209195, remaining 0 hours and 13 minutes
I0614 16:51:02.810140  6907 solver.cpp:291]     Train net output #0: loss = 0.0209195 (* 1 = 0.0209195 loss)
I0614 16:51:02.810165  6907 sgd_solver.cpp:106] Iteration 8700, lr = 1e-06
I0614 16:51:15.426501  6907 solver.cpp:270] Iteration 8750 (3.96324 iter/s, 12.616s/50 iter), loss = 0.0178242, remaining 0 hours and 13 minutes
I0614 16:51:15.426767  6907 solver.cpp:291]     Train net output #0: loss = 0.0178241 (* 1 = 0.0178241 loss)
I0614 16:51:15.426776  6907 sgd_solver.cpp:106] Iteration 8750, lr = 1e-06
I0614 16:51:28.058861  6907 solver.cpp:270] Iteration 8800 (3.9583 iter/s, 12.6317s/50 iter), loss = 0.00756316, remaining 0 hours and 13 minutes
I0614 16:51:28.058897  6907 solver.cpp:291]     Train net output #0: loss = 0.00756312 (* 1 = 0.00756312 loss)
I0614 16:51:28.058904  6907 sgd_solver.cpp:106] Iteration 8800, lr = 1e-06
I0614 16:51:40.678754  6907 solver.cpp:270] Iteration 8850 (3.96214 iter/s, 12.6195s/50 iter), loss = 0.00926026, remaining 0 hours and 13 minutes
I0614 16:51:40.678788  6907 solver.cpp:291]     Train net output #0: loss = 0.00926021 (* 1 = 0.00926021 loss)
I0614 16:51:40.678797  6907 sgd_solver.cpp:106] Iteration 8850, lr = 1e-06
I0614 16:51:53.285887  6907 solver.cpp:270] Iteration 8900 (3.96615 iter/s, 12.6067s/50 iter), loss = 0.00127999, remaining 0 hours and 12 minutes
I0614 16:51:53.286123  6907 solver.cpp:291]     Train net output #0: loss = 0.00127994 (* 1 = 0.00127994 loss)
I0614 16:51:53.286131  6907 sgd_solver.cpp:106] Iteration 8900, lr = 1e-06
I0614 16:52:05.890353  6907 solver.cpp:270] Iteration 8950 (3.96705 iter/s, 12.6038s/50 iter), loss = 0.000556523, remaining 0 hours and 12 minutes
I0614 16:52:05.890386  6907 solver.cpp:291]     Train net output #0: loss = 0.000556477 (* 1 = 0.000556477 loss)
I0614 16:52:05.890394  6907 sgd_solver.cpp:106] Iteration 8950, lr = 1e-06
I0614 16:52:18.245196  6907 solver.cpp:424] Iteration 9000, Testing net (#0)
I0614 16:52:19.736618  6907 solver.cpp:523]     Test net output #0: accuracy = 0.95625
I0614 16:52:19.736646  6907 solver.cpp:523]     Test net output #1: loss = 0.200658 (* 1 = 0.200658 loss)
I0614 16:52:19.736650  6907 solver.cpp:523]     Test net output #2: top-1 = 0.95625
I0614 16:52:19.983529  6907 solver.cpp:270] Iteration 9000 (3.54794 iter/s, 14.0927s/50 iter), loss = 0.010113, remaining 0 hours and 14 minutes
I0614 16:52:19.983559  6907 solver.cpp:291]     Train net output #0: loss = 0.010113 (* 1 = 0.010113 loss)
I0614 16:52:19.983567  6907 sgd_solver.cpp:106] Iteration 9000, lr = 1e-06
I0614 16:52:32.605696  6907 solver.cpp:270] Iteration 9050 (3.96142 iter/s, 12.6217s/50 iter), loss = 0.00227346, remaining 0 hours and 12 minutes
I0614 16:52:32.605934  6907 solver.cpp:291]     Train net output #0: loss = 0.00227342 (* 1 = 0.00227342 loss)
I0614 16:52:32.605944  6907 sgd_solver.cpp:106] Iteration 9050, lr = 1e-06
I0614 16:52:45.202056  6907 solver.cpp:270] Iteration 9100 (3.9696 iter/s, 12.5957s/50 iter), loss = 0.00667356, remaining 0 hours and 12 minutes
I0614 16:52:45.202090  6907 solver.cpp:291]     Train net output #0: loss = 0.00667352 (* 1 = 0.00667352 loss)
I0614 16:52:45.202100  6907 sgd_solver.cpp:106] Iteration 9100, lr = 1e-06
I0614 16:52:57.810292  6907 solver.cpp:270] Iteration 9150 (3.9658 iter/s, 12.6078s/50 iter), loss = 0.00503568, remaining 0 hours and 11 minutes
I0614 16:52:57.810326  6907 solver.cpp:291]     Train net output #0: loss = 0.00503563 (* 1 = 0.00503563 loss)
I0614 16:52:57.810334  6907 sgd_solver.cpp:106] Iteration 9150, lr = 1e-06
I0614 16:53:10.433465  6907 solver.cpp:270] Iteration 9200 (3.96111 iter/s, 12.6227s/50 iter), loss = 0.0155121, remaining 0 hours and 11 minutes
I0614 16:53:10.433717  6907 solver.cpp:291]     Train net output #0: loss = 0.0155121 (* 1 = 0.0155121 loss)
I0614 16:53:10.433727  6907 sgd_solver.cpp:106] Iteration 9200, lr = 1e-06
I0614 16:53:23.057796  6907 solver.cpp:270] Iteration 9250 (3.96081 iter/s, 12.6237s/50 iter), loss = 0.007962, remaining 0 hours and 11 minutes
I0614 16:53:23.057829  6907 solver.cpp:291]     Train net output #0: loss = 0.00796196 (* 1 = 0.00796196 loss)
I0614 16:53:23.057853  6907 sgd_solver.cpp:106] Iteration 9250, lr = 1e-06
I0614 16:53:35.663511  6907 solver.cpp:270] Iteration 9300 (3.96659 iter/s, 12.6053s/50 iter), loss = 0.0528076, remaining 0 hours and 11 minutes
I0614 16:53:35.663542  6907 solver.cpp:291]     Train net output #0: loss = 0.0528075 (* 1 = 0.0528075 loss)
I0614 16:53:35.663549  6907 sgd_solver.cpp:106] Iteration 9300, lr = 1e-06
I0614 16:53:48.293136  6907 solver.cpp:270] Iteration 9350 (3.95908 iter/s, 12.6292s/50 iter), loss = 0.0045705, remaining 0 hours and 11 minutes
I0614 16:53:48.293488  6907 solver.cpp:291]     Train net output #0: loss = 0.00457046 (* 1 = 0.00457046 loss)
I0614 16:53:48.293498  6907 sgd_solver.cpp:106] Iteration 9350, lr = 1e-06
I0614 16:54:00.894912  6907 solver.cpp:270] Iteration 9400 (3.96793 iter/s, 12.601s/50 iter), loss = 0.00922882, remaining 0 hours and 10 minutes
I0614 16:54:00.894944  6907 solver.cpp:291]     Train net output #0: loss = 0.00922878 (* 1 = 0.00922878 loss)
I0614 16:54:00.894968  6907 sgd_solver.cpp:106] Iteration 9400, lr = 1e-06
I0614 16:54:13.515200  6907 solver.cpp:270] Iteration 9450 (3.96201 iter/s, 12.6198s/50 iter), loss = 0.00124545, remaining 0 hours and 10 minutes
I0614 16:54:13.515233  6907 solver.cpp:291]     Train net output #0: loss = 0.00124541 (* 1 = 0.00124541 loss)
I0614 16:54:13.515241  6907 sgd_solver.cpp:106] Iteration 9450, lr = 1e-06
I0614 16:54:26.125479  6907 solver.cpp:270] Iteration 9500 (3.96516 iter/s, 12.6098s/50 iter), loss = 0.0121996, remaining 0 hours and 10 minutes
I0614 16:54:26.125730  6907 solver.cpp:291]     Train net output #0: loss = 0.0121996 (* 1 = 0.0121996 loss)
I0614 16:54:26.125756  6907 sgd_solver.cpp:106] Iteration 9500, lr = 1e-06
I0614 16:54:38.742000  6907 solver.cpp:270] Iteration 9550 (3.96326 iter/s, 12.6159s/50 iter), loss = 0.00176364, remaining 0 hours and 10 minutes
I0614 16:54:38.742033  6907 solver.cpp:291]     Train net output #0: loss = 0.00176361 (* 1 = 0.00176361 loss)
I0614 16:54:38.742040  6907 sgd_solver.cpp:106] Iteration 9550, lr = 1e-06
I0614 16:54:51.362749  6907 solver.cpp:270] Iteration 9600 (3.96187 iter/s, 12.6203s/50 iter), loss = 0.00059168, remaining 0 hours and 10 minutes
I0614 16:54:51.362782  6907 solver.cpp:291]     Train net output #0: loss = 0.000591647 (* 1 = 0.000591647 loss)
I0614 16:54:51.362792  6907 sgd_solver.cpp:106] Iteration 9600, lr = 1e-06
I0614 16:55:04.001827  6907 solver.cpp:270] Iteration 9650 (3.95612 iter/s, 12.6386s/50 iter), loss = 0.00440587, remaining 0 hours and 9 minutes
I0614 16:55:04.002074  6907 solver.cpp:291]     Train net output #0: loss = 0.00440583 (* 1 = 0.00440583 loss)
I0614 16:55:04.002099  6907 sgd_solver.cpp:106] Iteration 9650, lr = 1e-06
I0614 16:55:16.633569  6907 solver.cpp:270] Iteration 9700 (3.95849 iter/s, 12.6311s/50 iter), loss = 0.00748341, remaining 0 hours and 9 minutes
I0614 16:55:16.633603  6907 solver.cpp:291]     Train net output #0: loss = 0.00748337 (* 1 = 0.00748337 loss)
I0614 16:55:16.633626  6907 sgd_solver.cpp:106] Iteration 9700, lr = 1e-06
I0614 16:55:29.257795  6907 solver.cpp:270] Iteration 9750 (3.96078 iter/s, 12.6238s/50 iter), loss = 0.00304285, remaining 0 hours and 9 minutes
I0614 16:55:29.257828  6907 solver.cpp:291]     Train net output #0: loss = 0.00304282 (* 1 = 0.00304282 loss)
I0614 16:55:29.257836  6907 sgd_solver.cpp:106] Iteration 9750, lr = 1e-06
I0614 16:55:41.863682  6907 solver.cpp:270] Iteration 9800 (3.96654 iter/s, 12.6054s/50 iter), loss = 0.00903901, remaining 0 hours and 9 minutes
I0614 16:55:41.863938  6907 solver.cpp:291]     Train net output #0: loss = 0.00903897 (* 1 = 0.00903897 loss)
I0614 16:55:41.863963  6907 sgd_solver.cpp:106] Iteration 9800, lr = 1e-06
I0614 16:55:54.471663  6907 solver.cpp:270] Iteration 9850 (3.96595 iter/s, 12.6073s/50 iter), loss = 0.0167437, remaining 0 hours and 8 minutes
I0614 16:55:54.471696  6907 solver.cpp:291]     Train net output #0: loss = 0.0167437 (* 1 = 0.0167437 loss)
I0614 16:55:54.471706  6907 sgd_solver.cpp:106] Iteration 9850, lr = 1e-06
I0614 16:56:07.101222  6907 solver.cpp:270] Iteration 9900 (3.95911 iter/s, 12.6291s/50 iter), loss = 0.003771, remaining 0 hours and 8 minutes
I0614 16:56:07.101253  6907 solver.cpp:291]     Train net output #0: loss = 0.00377096 (* 1 = 0.00377096 loss)
I0614 16:56:07.101261  6907 sgd_solver.cpp:106] Iteration 9900, lr = 1e-06
I0614 16:56:19.726547  6907 solver.cpp:270] Iteration 9950 (3.96043 iter/s, 12.6249s/50 iter), loss = 0.00345616, remaining 0 hours and 8 minutes
I0614 16:56:19.726883  6907 solver.cpp:291]     Train net output #0: loss = 0.00345613 (* 1 = 0.00345613 loss)
I0614 16:56:19.726892  6907 sgd_solver.cpp:106] Iteration 9950, lr = 1e-06
I0614 16:56:32.090502  6907 solver.cpp:424] Iteration 10000, Testing net (#0)
I0614 16:56:33.594950  6907 solver.cpp:523]     Test net output #0: accuracy = 0.95725
I0614 16:56:33.594980  6907 solver.cpp:523]     Test net output #1: loss = 0.210107 (* 1 = 0.210107 loss)
I0614 16:56:33.594985  6907 solver.cpp:523]     Test net output #2: top-1 = 0.95725
I0614 16:56:33.842149  6907 solver.cpp:270] Iteration 10000 (3.54238 iter/s, 14.1148s/50 iter), loss = 0.00484783, remaining 0 hours and 9 minutes
I0614 16:56:33.842180  6907 solver.cpp:291]     Train net output #0: loss = 0.00484779 (* 1 = 0.00484779 loss)
I0614 16:56:33.842190  6907 sgd_solver.cpp:106] Iteration 10000, lr = 1e-07
I0614 16:56:46.474886  6907 solver.cpp:270] Iteration 10050 (3.95811 iter/s, 12.6323s/50 iter), loss = 0.0126362, remaining 0 hours and 8 minutes
I0614 16:56:46.474920  6907 solver.cpp:291]     Train net output #0: loss = 0.0126362 (* 1 = 0.0126362 loss)
I0614 16:56:46.474943  6907 sgd_solver.cpp:106] Iteration 10050, lr = 1e-07
I0614 16:56:59.096146  6907 solver.cpp:270] Iteration 10100 (3.96171 iter/s, 12.6208s/50 iter), loss = 0.00584282, remaining 0 hours and 7 minutes
I0614 16:56:59.096408  6907 solver.cpp:291]     Train net output #0: loss = 0.00584279 (* 1 = 0.00584279 loss)
I0614 16:56:59.096432  6907 sgd_solver.cpp:106] Iteration 10100, lr = 1e-07
I0614 16:57:11.732631  6907 solver.cpp:270] Iteration 10150 (3.95701 iter/s, 12.6358s/50 iter), loss = 0.00442313, remaining 0 hours and 7 minutes
I0614 16:57:11.732664  6907 solver.cpp:291]     Train net output #0: loss = 0.0044231 (* 1 = 0.0044231 loss)
I0614 16:57:11.732672  6907 sgd_solver.cpp:106] Iteration 10150, lr = 1e-07
I0614 16:57:24.369958  6907 solver.cpp:270] Iteration 10200 (3.95667 iter/s, 12.6369s/50 iter), loss = 0.00123061, remaining 0 hours and 7 minutes
I0614 16:57:24.369989  6907 solver.cpp:291]     Train net output #0: loss = 0.00123058 (* 1 = 0.00123058 loss)
I0614 16:57:24.369997  6907 sgd_solver.cpp:106] Iteration 10200, lr = 1e-07
I0614 16:57:36.969951  6907 solver.cpp:270] Iteration 10250 (3.96839 iter/s, 12.5996s/50 iter), loss = 0.00180226, remaining 0 hours and 7 minutes
I0614 16:57:36.970207  6907 solver.cpp:291]     Train net output #0: loss = 0.00180223 (* 1 = 0.00180223 loss)
I0614 16:57:36.970232  6907 sgd_solver.cpp:106] Iteration 10250, lr = 1e-07
I0614 16:57:49.583796  6907 solver.cpp:270] Iteration 10300 (3.96411 iter/s, 12.6132s/50 iter), loss = 0.014485, remaining 0 hours and 7 minutes
I0614 16:57:49.583827  6907 solver.cpp:291]     Train net output #0: loss = 0.014485 (* 1 = 0.014485 loss)
I0614 16:57:49.583835  6907 sgd_solver.cpp:106] Iteration 10300, lr = 1e-07
I0614 16:58:02.199739  6907 solver.cpp:270] Iteration 10350 (3.96338 iter/s, 12.6155s/50 iter), loss = 0.000918468, remaining 0 hours and 6 minutes
I0614 16:58:02.199772  6907 solver.cpp:291]     Train net output #0: loss = 0.000918442 (* 1 = 0.000918442 loss)
I0614 16:58:02.199796  6907 sgd_solver.cpp:106] Iteration 10350, lr = 1e-07
I0614 16:58:14.823190  6907 solver.cpp:270] Iteration 10400 (3.96102 iter/s, 12.623s/50 iter), loss = 0.00570491, remaining 0 hours and 6 minutes
I0614 16:58:14.823534  6907 solver.cpp:291]     Train net output #0: loss = 0.00570488 (* 1 = 0.00570488 loss)
I0614 16:58:14.823544  6907 sgd_solver.cpp:106] Iteration 10400, lr = 1e-07
I0614 16:58:27.429895  6907 solver.cpp:270] Iteration 10450 (3.96638 iter/s, 12.606s/50 iter), loss = 0.00707452, remaining 0 hours and 6 minutes
I0614 16:58:27.429929  6907 solver.cpp:291]     Train net output #0: loss = 0.00707449 (* 1 = 0.00707449 loss)
I0614 16:58:27.429937  6907 sgd_solver.cpp:106] Iteration 10450, lr = 1e-07
I0614 16:58:40.031566  6907 solver.cpp:270] Iteration 10500 (3.96787 iter/s, 12.6012s/50 iter), loss = 0.00411951, remaining 0 hours and 6 minutes
I0614 16:58:40.031599  6907 solver.cpp:291]     Train net output #0: loss = 0.00411948 (* 1 = 0.00411948 loss)
I0614 16:58:40.031623  6907 sgd_solver.cpp:106] Iteration 10500, lr = 1e-07
I0614 16:58:52.635192  6907 solver.cpp:270] Iteration 10550 (3.96725 iter/s, 12.6032s/50 iter), loss = 0.0307622, remaining 0 hours and 6 minutes
I0614 16:58:52.635449  6907 solver.cpp:291]     Train net output #0: loss = 0.0307622 (* 1 = 0.0307622 loss)
I0614 16:58:52.635459  6907 sgd_solver.cpp:106] Iteration 10550, lr = 1e-07
I0614 16:59:05.249018  6907 solver.cpp:270] Iteration 10600 (3.96411 iter/s, 12.6132s/50 iter), loss = 0.00274446, remaining 0 hours and 5 minutes
I0614 16:59:05.249053  6907 solver.cpp:291]     Train net output #0: loss = 0.00274444 (* 1 = 0.00274444 loss)
I0614 16:59:05.249076  6907 sgd_solver.cpp:106] Iteration 10600, lr = 1e-07
I0614 16:59:17.876664  6907 solver.cpp:270] Iteration 10650 (3.9597 iter/s, 12.6272s/50 iter), loss = 0.00356144, remaining 0 hours and 5 minutes
I0614 16:59:17.876698  6907 solver.cpp:291]     Train net output #0: loss = 0.00356141 (* 1 = 0.00356141 loss)
I0614 16:59:17.876706  6907 sgd_solver.cpp:106] Iteration 10650, lr = 1e-07
I0614 16:59:30.505897  6907 solver.cpp:270] Iteration 10700 (3.95921 iter/s, 12.6288s/50 iter), loss = 0.00281661, remaining 0 hours and 5 minutes
I0614 16:59:30.506091  6907 solver.cpp:291]     Train net output #0: loss = 0.00281659 (* 1 = 0.00281659 loss)
I0614 16:59:30.506116  6907 sgd_solver.cpp:106] Iteration 10700, lr = 1e-07
I0614 16:59:43.120918  6907 solver.cpp:270] Iteration 10750 (3.96372 iter/s, 12.6144s/50 iter), loss = 0.0180942, remaining 0 hours and 5 minutes
I0614 16:59:43.120950  6907 solver.cpp:291]     Train net output #0: loss = 0.0180942 (* 1 = 0.0180942 loss)
I0614 16:59:43.120959  6907 sgd_solver.cpp:106] Iteration 10750, lr = 1e-07
I0614 16:59:55.737046  6907 solver.cpp:270] Iteration 10800 (3.96332 iter/s, 12.6157s/50 iter), loss = 0.0039396, remaining 0 hours and 5 minutes
I0614 16:59:55.737080  6907 solver.cpp:291]     Train net output #0: loss = 0.00393958 (* 1 = 0.00393958 loss)
I0614 16:59:55.737104  6907 sgd_solver.cpp:106] Iteration 10800, lr = 1e-07
I0614 17:00:08.370429  6907 solver.cpp:270] Iteration 10850 (3.95791 iter/s, 12.6329s/50 iter), loss = 0.0123592, remaining 0 hours and 4 minutes
I0614 17:00:08.370662  6907 solver.cpp:291]     Train net output #0: loss = 0.0123591 (* 1 = 0.0123591 loss)
I0614 17:00:08.370687  6907 sgd_solver.cpp:106] Iteration 10850, lr = 1e-07
I0614 17:00:20.989184  6907 solver.cpp:270] Iteration 10900 (3.96256 iter/s, 12.6181s/50 iter), loss = 0.021233, remaining 0 hours and 4 minutes
I0614 17:00:20.989217  6907 solver.cpp:291]     Train net output #0: loss = 0.021233 (* 1 = 0.021233 loss)
I0614 17:00:20.989226  6907 sgd_solver.cpp:106] Iteration 10900, lr = 1e-07
I0614 17:00:33.607409  6907 solver.cpp:270] Iteration 10950 (3.96266 iter/s, 12.6178s/50 iter), loss = 0.00298933, remaining 0 hours and 4 minutes
I0614 17:00:33.607441  6907 solver.cpp:291]     Train net output #0: loss = 0.00298931 (* 1 = 0.00298931 loss)
I0614 17:00:33.607450  6907 sgd_solver.cpp:106] Iteration 10950, lr = 1e-07
I0614 17:00:45.962736  6907 solver.cpp:424] Iteration 11000, Testing net (#0)
I0614 17:00:47.459748  6907 solver.cpp:523]     Test net output #0: accuracy = 0.9575
I0614 17:00:47.459777  6907 solver.cpp:523]     Test net output #1: loss = 0.214236 (* 1 = 0.214236 loss)
I0614 17:00:47.459781  6907 solver.cpp:523]     Test net output #2: top-1 = 0.9575
I0614 17:00:47.705971  6907 solver.cpp:270] Iteration 11000 (3.54658 iter/s, 14.0981s/50 iter), loss = 0.00160337, remaining 0 hours and 4 minutes
I0614 17:00:47.706003  6907 solver.cpp:291]     Train net output #0: loss = 0.00160335 (* 1 = 0.00160335 loss)
I0614 17:00:47.706012  6907 sgd_solver.cpp:106] Iteration 11000, lr = 1e-07
I0614 17:01:00.328068  6907 solver.cpp:270] Iteration 11050 (3.96144 iter/s, 12.6217s/50 iter), loss = 0.00135582, remaining 0 hours and 3 minutes
I0614 17:01:00.328101  6907 solver.cpp:291]     Train net output #0: loss = 0.0013558 (* 1 = 0.0013558 loss)
I0614 17:01:00.328109  6907 sgd_solver.cpp:106] Iteration 11050, lr = 1e-07
I0614 17:01:12.954424  6907 solver.cpp:270] Iteration 11100 (3.96011 iter/s, 12.6259s/50 iter), loss = 0.0009827, remaining 0 hours and 3 minutes
I0614 17:01:12.954459  6907 solver.cpp:291]     Train net output #0: loss = 0.000982686 (* 1 = 0.000982686 loss)
I0614 17:01:12.954468  6907 sgd_solver.cpp:106] Iteration 11100, lr = 1e-07
I0614 17:01:25.568682  6907 solver.cpp:270] Iteration 11150 (3.96391 iter/s, 12.6138s/50 iter), loss = 0.00116231, remaining 0 hours and 3 minutes
I0614 17:01:25.569020  6907 solver.cpp:291]     Train net output #0: loss = 0.00116229 (* 1 = 0.00116229 loss)
I0614 17:01:25.569046  6907 sgd_solver.cpp:106] Iteration 11150, lr = 1e-07
I0614 17:01:38.184381  6907 solver.cpp:270] Iteration 11200 (3.96355 iter/s, 12.615s/50 iter), loss = 0.00894807, remaining 0 hours and 3 minutes
I0614 17:01:38.184414  6907 solver.cpp:291]     Train net output #0: loss = 0.00894805 (* 1 = 0.00894805 loss)
I0614 17:01:38.184422  6907 sgd_solver.cpp:106] Iteration 11200, lr = 1e-07
I0614 17:01:50.793669  6907 solver.cpp:270] Iteration 11250 (3.96547 iter/s, 12.6088s/50 iter), loss = 0.0032044, remaining 0 hours and 3 minutes
I0614 17:01:50.793704  6907 solver.cpp:291]     Train net output #0: loss = 0.00320438 (* 1 = 0.00320438 loss)
I0614 17:01:50.793712  6907 sgd_solver.cpp:106] Iteration 11250, lr = 1e-07
I0614 17:02:03.414554  6907 solver.cpp:270] Iteration 11300 (3.96183 iter/s, 12.6204s/50 iter), loss = 0.0275023, remaining 0 hours and 2 minutes
I0614 17:02:03.414804  6907 solver.cpp:291]     Train net output #0: loss = 0.0275023 (* 1 = 0.0275023 loss)
I0614 17:02:03.414813  6907 sgd_solver.cpp:106] Iteration 11300, lr = 1e-07
I0614 17:02:16.034354  6907 solver.cpp:270] Iteration 11350 (3.96223 iter/s, 12.6191s/50 iter), loss = 0.00121358, remaining 0 hours and 2 minutes
I0614 17:02:16.034389  6907 solver.cpp:291]     Train net output #0: loss = 0.00121356 (* 1 = 0.00121356 loss)
I0614 17:02:16.034397  6907 sgd_solver.cpp:106] Iteration 11350, lr = 1e-07
I0614 17:02:28.648864  6907 solver.cpp:270] Iteration 11400 (3.96383 iter/s, 12.6141s/50 iter), loss = 0.000850212, remaining 0 hours and 2 minutes
I0614 17:02:28.648895  6907 solver.cpp:291]     Train net output #0: loss = 0.000850197 (* 1 = 0.000850197 loss)
I0614 17:02:28.648919  6907 sgd_solver.cpp:106] Iteration 11400, lr = 1e-07
I0614 17:02:41.272080  6907 solver.cpp:270] Iteration 11450 (3.96109 iter/s, 12.6228s/50 iter), loss = 0.000963164, remaining 0 hours and 2 minutes
I0614 17:02:41.272275  6907 solver.cpp:291]     Train net output #0: loss = 0.00096315 (* 1 = 0.00096315 loss)
I0614 17:02:41.272284  6907 sgd_solver.cpp:106] Iteration 11450, lr = 1e-07
I0614 17:02:53.893066  6907 solver.cpp:270] Iteration 11500 (3.96184 iter/s, 12.6204s/50 iter), loss = 0.0225314, remaining 0 hours and 2 minutes
I0614 17:02:53.893100  6907 solver.cpp:291]     Train net output #0: loss = 0.0225314 (* 1 = 0.0225314 loss)
I0614 17:02:53.893107  6907 sgd_solver.cpp:106] Iteration 11500, lr = 1e-07
I0614 17:03:06.502161  6907 solver.cpp:270] Iteration 11550 (3.96553 iter/s, 12.6087s/50 iter), loss = 0.00607542, remaining 0 hours and 1 minutes
I0614 17:03:06.502193  6907 solver.cpp:291]     Train net output #0: loss = 0.00607541 (* 1 = 0.00607541 loss)
I0614 17:03:06.502202  6907 sgd_solver.cpp:106] Iteration 11550, lr = 1e-07
I0614 17:03:19.113864  6907 solver.cpp:270] Iteration 11600 (3.96471 iter/s, 12.6113s/50 iter), loss = 0.00599358, remaining 0 hours and 1 minutes
I0614 17:03:19.114197  6907 solver.cpp:291]     Train net output #0: loss = 0.00599357 (* 1 = 0.00599357 loss)
I0614 17:03:19.114223  6907 sgd_solver.cpp:106] Iteration 11600, lr = 1e-07
I0614 17:03:31.741003  6907 solver.cpp:270] Iteration 11650 (3.95996 iter/s, 12.6264s/50 iter), loss = 0.005248, remaining 0 hours and 1 minutes
I0614 17:03:31.741037  6907 solver.cpp:291]     Train net output #0: loss = 0.00524799 (* 1 = 0.00524799 loss)
I0614 17:03:31.741046  6907 sgd_solver.cpp:106] Iteration 11650, lr = 1e-07
I0614 17:03:44.373075  6907 solver.cpp:270] Iteration 11700 (3.95832 iter/s, 12.6316s/50 iter), loss = 0.00345199, remaining 0 hours and 1 minutes
I0614 17:03:44.373106  6907 solver.cpp:291]     Train net output #0: loss = 0.00345197 (* 1 = 0.00345197 loss)
I0614 17:03:44.373114  6907 sgd_solver.cpp:106] Iteration 11700, lr = 1e-07
I0614 17:03:57.003070  6907 solver.cpp:270] Iteration 11750 (3.95897 iter/s, 12.6296s/50 iter), loss = 0.00224994, remaining 0 hours and 1 minutes
I0614 17:03:57.003250  6907 solver.cpp:291]     Train net output #0: loss = 0.00224994 (* 1 = 0.00224994 loss)
I0614 17:03:57.003260  6907 sgd_solver.cpp:106] Iteration 11750, lr = 1e-07
I0614 17:04:09.628818  6907 solver.cpp:270] Iteration 11800 (3.96035 iter/s, 12.6252s/50 iter), loss = 0.0275075, remaining 0 hours and 0 minutes
I0614 17:04:09.628849  6907 solver.cpp:291]     Train net output #0: loss = 0.0275075 (* 1 = 0.0275075 loss)
I0614 17:04:09.628857  6907 sgd_solver.cpp:106] Iteration 11800, lr = 1e-07
I0614 17:04:22.256578  6907 solver.cpp:270] Iteration 11850 (3.95967 iter/s, 12.6273s/50 iter), loss = 0.00145426, remaining 0 hours and 0 minutes
I0614 17:04:22.256611  6907 solver.cpp:291]     Train net output #0: loss = 0.00145426 (* 1 = 0.00145426 loss)
I0614 17:04:22.256620  6907 sgd_solver.cpp:106] Iteration 11850, lr = 1e-07
I0614 17:04:34.896114  6907 solver.cpp:270] Iteration 11900 (3.95598 iter/s, 12.6391s/50 iter), loss = 0.0255027, remaining 0 hours and 0 minutes
I0614 17:04:34.896350  6907 solver.cpp:291]     Train net output #0: loss = 0.0255027 (* 1 = 0.0255027 loss)
I0614 17:04:34.896375  6907 sgd_solver.cpp:106] Iteration 11900, lr = 1e-07
I0614 17:04:47.507858  6907 solver.cpp:270] Iteration 11950 (3.96476 iter/s, 12.6111s/50 iter), loss = 0.00356301, remaining 0 hours and 0 minutes
I0614 17:04:47.507889  6907 solver.cpp:291]     Train net output #0: loss = 0.00356302 (* 1 = 0.00356302 loss)
I0614 17:04:47.507897  6907 sgd_solver.cpp:106] Iteration 11950, lr = 1e-07
I0614 17:04:59.878173  6907 solver.cpp:935] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.4/snapshots/_iter_12000.caffemodel
I0614 17:05:05.674438  6907 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.4/snapshots/_iter_12000.solverstate
I0614 17:05:09.424154  6907 solver.cpp:384] Iteration 12000, loss = 0.0030044
I0614 17:05:09.424180  6907 solver.cpp:424] Iteration 12000, Testing net (#0)
I0614 17:05:10.834033  6907 solver.cpp:523]     Test net output #0: accuracy = 0.95775
I0614 17:05:10.834064  6907 solver.cpp:523]     Test net output #1: loss = 0.215988 (* 1 = 0.215988 loss)
I0614 17:05:10.834069  6907 solver.cpp:523]     Test net output #2: top-1 = 0.95775
I0614 17:05:10.834074  6907 solver.cpp:392] Optimization Done (3.92654 iter/s).
I0614 17:05:10.834077  6907 caffe_interface.cpp:576] Optimization Done.
(c) Copyright 2016â2019 Xilinx, Inc. All rights reserved.

I0614 17:05:11.990473  7004 pruning_runner.cpp:234] Analysis info found.
I0614 17:05:13.715531  7004 pruning_runner.cpp:265] Start pruning, please wait...
I0614 17:05:22.861964  7004 pruning_runner.cpp:312] Compression complete 0%
I0614 17:05:31.846947  7004 pruning_runner.cpp:312] Compression complete 0%
I0614 17:05:40.799050  7004 pruning_runner.cpp:312] Compression complete 0%
I0614 17:05:49.858408  7004 pruning_runner.cpp:312] Compression complete 0%
I0614 17:05:59.031528  7004 pruning_runner.cpp:312] Compression complete 0%
I0614 17:06:07.801595  7004 pruning_runner.cpp:312] Compression complete 0%
I0614 17:06:16.939481  7004 pruning_runner.cpp:312] Compression complete 0%
I0614 17:06:26.028028  7004 pruning_runner.cpp:312] Compression complete 0%
I0614 17:06:35.119585  7004 pruning_runner.cpp:312] Compression complete 50%
I0614 17:06:44.361964  7004 pruning_runner.cpp:312] Compression complete 66.6667%
I0614 17:06:53.208365  7004 pruning_runner.cpp:312] Compression complete 80%
I0614 17:07:02.126852  7004 pruning_runner.cpp:312] Compression complete 95%
I0614 17:07:11.039850  7004 pruning_runner.cpp:312] Compression complete 97.4359%
I0614 17:07:19.980407  7004 pruning_runner.cpp:312] Compression complete 99.6795%
I0614 17:07:29.202450  7004 pruning_runner.cpp:312] Compression complete 99.8395%
I0614 17:07:38.030061  7004 pruning_runner.cpp:312] Compression complete 99.9197%
I0614 17:07:46.975689  7004 pruning_runner.cpp:312] Compression complete 99.9799%
I0614 17:07:55.911106  7004 pruning_runner.cpp:312] Compression complete 99.99%
I0614 17:08:04.672014  7004 pruning_runner.cpp:312] Compression complete 99.9998%
I0614 17:08:13.711184  7004 pruning_runner.cpp:312] Compression complete 99.9999%
I0614 17:08:22.711213  7004 pruning_runner.cpp:312] Compression complete 100%
I0614 17:08:31.725873  7004 pruning_runner.cpp:312] Compression complete 100%
I0614 17:08:40.757269  7004 pruning_runner.cpp:312] Compression complete 100%
I0614 17:08:51.951417  7004 pruning_runner.cpp:365] pruning done, output model: pruning/alexnetBNnoLRN/regular_rate_0.5/sparse.caffemodel
I0614 17:08:51.951683  7004 pruning_runner.cpp:379] summary of REGULAR compression with rate 0.5:
+-------------------------------------------------------------------+
| Item           | Baseline       | Compressed     | Delta          |
+-------------------------------------------------------------------+
| Accuracy       | 0.953499794    | 0.957249761    | 0.00374996662  |
+-------------------------------------------------------------------+
| Weights        | 3.74857903 M   | 767.005005 K   | -79.5387802%   |
+-------------------------------------------------------------------+
| Operations     | 2.05460167 G   | 1.04698479 G   | -49.0419617%   |
+-------------------------------------------------------------------+
To fine-tune the pruned model, please run:
vai_p_caffe finetune -config /workspace/TUTORIALS/VAI2.0bash-Caffe-ML-CATSvsDOGS/files/pruning/alexnetBNnoLRN/config5.prototxt
(c) Copyright 2016â2019 Xilinx, Inc. All rights reserved.

W0614 17:08:52.514562  9229 utils.cpp:207] BVLC BatchNormLayer without ScaleLayer detected: 3, it will be converted to NVCaffe Format.
W0614 17:08:52.543781  9229 utils.cpp:207] BVLC BatchNormLayer without ScaleLayer detected: 7, it will be converted to NVCaffe Format.
W0614 17:08:52.543879  9229 utils.cpp:207] BVLC BatchNormLayer without ScaleLayer detected: 21, it will be converted to NVCaffe Format.
I0614 17:08:52.554697  9229 vai_p_caffe.cpp:287] pruning/alexnetBNnoLRN/regular_rate_0.5/net_finetune.prototxt
I0614 17:08:52.802736  9229 gpu_memory.cpp:53] GPUMemory::Manager initialized with Caching (CUB) GPU Allocator
I0614 17:08:52.802759  9229 gpu_memory.cpp:55] Total memory: 25635127296, Free: 24797970432, dev_info[0]: total=25635127296 free=24797970432
I0614 17:08:52.802889  9229 caffe_interface.cpp:539] Using GPUs 0
I0614 17:08:52.803002  9229 caffe_interface.cpp:544] GPU 0: Quadro P6000
I0614 17:08:53.465997  9229 solver.cpp:51] Initializing solver from parameters: 
test_iter: 80
test_interval: 1000
base_lr: 0.001
display: 50
max_iter: 12000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 2500
snapshot: 6000
snapshot_prefix: "pruning/alexnetBNnoLRN/regular_rate_0.5/snapshots/"
solver_mode: GPU
device_id: 0
random_seed: 1201
net: "pruning/alexnetBNnoLRN/regular_rate_0.5/net_finetune.prototxt"
type: "Adam"
I0614 17:08:53.466773  9229 solver.cpp:99] Creating training net from net file: pruning/alexnetBNnoLRN/regular_rate_0.5/net_finetune.prototxt
I0614 17:08:53.467458  9229 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0614 17:08:53.467473  9229 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0614 17:08:53.467478  9229 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy-top1
I0614 17:08:53.467485  9229 net.cpp:52] Initializing net from parameters: 
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_value: 106
    mean_value: 116
    mean_value: 124
  }
  data_param {
    source: "input/lmdb/train_lmdb"
    batch_size: 256
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 0
    kernel_size: 8
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "bn1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn2"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "bn2"
  top: "relu2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "relu6"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "drop6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn7"
  type: "BatchNorm"
  bottom: "fc7"
  top: "bn7"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "bn7"
  top: "relu7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "relu7"
  top: "drop7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "drop7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0614 17:08:53.467993  9229 layer_factory.hpp:77] Creating layer data
I0614 17:08:53.468137  9229 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0614 17:08:53.470274  9229 net.cpp:94] Creating Layer data
I0614 17:08:53.470290  9229 net.cpp:409] data -> data
I0614 17:08:53.470301  9229 net.cpp:409] data -> label
I0614 17:08:53.472456  9266 db_lmdb.cpp:35] Opened lmdb input/lmdb/train_lmdb
I0614 17:08:53.472488  9266 db_lmdb.cpp:38] Items count: 20000
I0614 17:08:53.472523  9266 data_reader.cpp:124] TRAIN: reading data using 1 channel(s)
I0614 17:08:53.472945  9229 data_layer.cpp:78] ReshapePrefetch 256, 3, 227, 227
I0614 17:08:53.472993  9229 data_layer.cpp:83] output data size: 256,3,227,227
I0614 17:08:54.002943  9229 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0614 17:08:54.003165  9229 net.cpp:144] Setting up data
I0614 17:08:54.003171  9229 net.cpp:151] Top shape: 256 3 227 227 (39574272)
I0614 17:08:54.003180  9229 net.cpp:151] Top shape: 256 (256)
I0614 17:08:54.003185  9229 net.cpp:159] Memory required for data: 158298112
I0614 17:08:54.003190  9229 layer_factory.hpp:77] Creating layer conv1
I0614 17:08:54.003201  9229 net.cpp:94] Creating Layer conv1
I0614 17:08:54.003204  9229 net.cpp:435] conv1 <- data
I0614 17:08:54.003211  9229 net.cpp:409] conv1 -> conv1
I0614 17:08:54.003655  9229 net.cpp:144] Setting up conv1
I0614 17:08:54.003664  9229 net.cpp:151] Top shape: 256 96 55 55 (74342400)
I0614 17:08:54.003669  9229 net.cpp:159] Memory required for data: 455667712
I0614 17:08:54.003680  9229 layer_factory.hpp:77] Creating layer bn1
I0614 17:08:54.003687  9229 net.cpp:94] Creating Layer bn1
I0614 17:08:54.003691  9229 net.cpp:435] bn1 <- conv1
I0614 17:08:54.003697  9229 net.cpp:409] bn1 -> bn1
I0614 17:08:54.003996  9229 net.cpp:144] Setting up bn1
I0614 17:08:54.004002  9229 net.cpp:151] Top shape: 256 96 55 55 (74342400)
I0614 17:08:54.004009  9229 net.cpp:159] Memory required for data: 753037312
I0614 17:08:54.004019  9229 layer_factory.hpp:77] Creating layer relu1
I0614 17:08:54.004025  9229 net.cpp:94] Creating Layer relu1
I0614 17:08:54.004029  9229 net.cpp:435] relu1 <- bn1
I0614 17:08:54.004034  9229 net.cpp:409] relu1 -> relu1
I0614 17:08:54.004045  9229 net.cpp:144] Setting up relu1
I0614 17:08:54.004050  9229 net.cpp:151] Top shape: 256 96 55 55 (74342400)
I0614 17:08:54.004055  9229 net.cpp:159] Memory required for data: 1050406912
I0614 17:08:54.004058  9229 layer_factory.hpp:77] Creating layer pool1
I0614 17:08:54.004063  9229 net.cpp:94] Creating Layer pool1
I0614 17:08:54.004067  9229 net.cpp:435] pool1 <- relu1
I0614 17:08:54.004072  9229 net.cpp:409] pool1 -> pool1
I0614 17:08:54.004093  9229 net.cpp:144] Setting up pool1
I0614 17:08:54.004097  9229 net.cpp:151] Top shape: 256 96 27 27 (17915904)
I0614 17:08:54.004102  9229 net.cpp:159] Memory required for data: 1122070528
I0614 17:08:54.004106  9229 layer_factory.hpp:77] Creating layer conv2
I0614 17:08:54.004112  9229 net.cpp:94] Creating Layer conv2
I0614 17:08:54.004117  9229 net.cpp:435] conv2 <- pool1
I0614 17:08:54.004122  9229 net.cpp:409] conv2 -> conv2
I0614 17:08:54.020646  9229 net.cpp:144] Setting up conv2
I0614 17:08:54.020663  9229 net.cpp:151] Top shape: 256 256 27 27 (47775744)
I0614 17:08:54.020673  9229 net.cpp:159] Memory required for data: 1313173504
I0614 17:08:54.020684  9229 layer_factory.hpp:77] Creating layer bn2
I0614 17:08:54.020692  9229 net.cpp:94] Creating Layer bn2
I0614 17:08:54.020697  9229 net.cpp:435] bn2 <- conv2
I0614 17:08:54.020704  9229 net.cpp:409] bn2 -> bn2
I0614 17:08:54.021010  9229 net.cpp:144] Setting up bn2
I0614 17:08:54.021016  9229 net.cpp:151] Top shape: 256 256 27 27 (47775744)
I0614 17:08:54.021023  9229 net.cpp:159] Memory required for data: 1504276480
I0614 17:08:54.021032  9229 layer_factory.hpp:77] Creating layer relu2
I0614 17:08:54.021039  9229 net.cpp:94] Creating Layer relu2
I0614 17:08:54.021042  9229 net.cpp:435] relu2 <- bn2
I0614 17:08:54.021049  9229 net.cpp:409] relu2 -> relu2
I0614 17:08:54.021064  9229 net.cpp:144] Setting up relu2
I0614 17:08:54.021068  9229 net.cpp:151] Top shape: 256 256 27 27 (47775744)
I0614 17:08:54.021075  9229 net.cpp:159] Memory required for data: 1695379456
I0614 17:08:54.021078  9229 layer_factory.hpp:77] Creating layer pool2
I0614 17:08:54.021085  9229 net.cpp:94] Creating Layer pool2
I0614 17:08:54.021090  9229 net.cpp:435] pool2 <- relu2
I0614 17:08:54.021095  9229 net.cpp:409] pool2 -> pool2
I0614 17:08:54.021112  9229 net.cpp:144] Setting up pool2
I0614 17:08:54.021116  9229 net.cpp:151] Top shape: 256 256 13 13 (11075584)
I0614 17:08:54.021122  9229 net.cpp:159] Memory required for data: 1739681792
I0614 17:08:54.021126  9229 layer_factory.hpp:77] Creating layer conv3
I0614 17:08:54.021545  9229 net.cpp:94] Creating Layer conv3
I0614 17:08:54.021554  9229 net.cpp:435] conv3 <- pool2
I0614 17:08:54.021562  9229 net.cpp:409] conv3 -> conv3
I0614 17:08:54.038014  9229 net.cpp:144] Setting up conv3
I0614 17:08:54.038076  9229 net.cpp:151] Top shape: 256 384 13 13 (16613376)
I0614 17:08:54.038089  9229 net.cpp:159] Memory required for data: 1806135296
I0614 17:08:54.038102  9229 layer_factory.hpp:77] Creating layer relu3
I0614 17:08:54.038111  9229 net.cpp:94] Creating Layer relu3
I0614 17:08:54.038118  9229 net.cpp:435] relu3 <- conv3
I0614 17:08:54.038127  9229 net.cpp:409] relu3 -> relu3
I0614 17:08:54.038170  9229 net.cpp:144] Setting up relu3
I0614 17:08:54.038177  9229 net.cpp:151] Top shape: 256 384 13 13 (16613376)
I0614 17:08:54.038184  9229 net.cpp:159] Memory required for data: 1872588800
I0614 17:08:54.038190  9229 layer_factory.hpp:77] Creating layer conv4
I0614 17:08:54.038200  9229 net.cpp:94] Creating Layer conv4
I0614 17:08:54.038210  9229 net.cpp:435] conv4 <- relu3
I0614 17:08:54.038218  9229 net.cpp:409] conv4 -> conv4
I0614 17:08:54.059046  9229 net.cpp:144] Setting up conv4
I0614 17:08:54.059069  9229 net.cpp:151] Top shape: 256 384 13 13 (16613376)
I0614 17:08:54.059077  9229 net.cpp:159] Memory required for data: 1939042304
I0614 17:08:54.059094  9229 layer_factory.hpp:77] Creating layer relu4
I0614 17:08:54.059101  9229 net.cpp:94] Creating Layer relu4
I0614 17:08:54.059104  9229 net.cpp:435] relu4 <- conv4
I0614 17:08:54.059111  9229 net.cpp:409] relu4 -> relu4
I0614 17:08:54.059127  9229 net.cpp:144] Setting up relu4
I0614 17:08:54.059130  9229 net.cpp:151] Top shape: 256 384 13 13 (16613376)
I0614 17:08:54.059134  9229 net.cpp:159] Memory required for data: 2005495808
I0614 17:08:54.059137  9229 layer_factory.hpp:77] Creating layer conv5
I0614 17:08:54.059145  9229 net.cpp:94] Creating Layer conv5
I0614 17:08:54.059149  9229 net.cpp:435] conv5 <- relu4
I0614 17:08:54.059152  9229 net.cpp:409] conv5 -> conv5
I0614 17:08:54.075047  9229 net.cpp:144] Setting up conv5
I0614 17:08:54.075116  9229 net.cpp:151] Top shape: 256 256 13 13 (11075584)
I0614 17:08:54.075130  9229 net.cpp:159] Memory required for data: 2049798144
I0614 17:08:54.075143  9229 layer_factory.hpp:77] Creating layer relu5
I0614 17:08:54.075152  9229 net.cpp:94] Creating Layer relu5
I0614 17:08:54.075160  9229 net.cpp:435] relu5 <- conv5
I0614 17:08:54.075181  9229 net.cpp:409] relu5 -> relu5
I0614 17:08:54.075217  9229 net.cpp:144] Setting up relu5
I0614 17:08:54.075222  9229 net.cpp:151] Top shape: 256 256 13 13 (11075584)
I0614 17:08:54.075229  9229 net.cpp:159] Memory required for data: 2094100480
I0614 17:08:54.075235  9229 layer_factory.hpp:77] Creating layer pool5
I0614 17:08:54.075243  9229 net.cpp:94] Creating Layer pool5
I0614 17:08:54.075248  9229 net.cpp:435] pool5 <- relu5
I0614 17:08:54.075255  9229 net.cpp:409] pool5 -> pool5
I0614 17:08:54.075302  9229 net.cpp:144] Setting up pool5
I0614 17:08:54.075309  9229 net.cpp:151] Top shape: 256 256 6 6 (2359296)
I0614 17:08:54.075317  9229 net.cpp:159] Memory required for data: 2103537664
I0614 17:08:54.075322  9229 layer_factory.hpp:77] Creating layer fc6
I0614 17:08:54.075333  9229 net.cpp:94] Creating Layer fc6
I0614 17:08:54.075340  9229 net.cpp:435] fc6 <- pool5
I0614 17:08:54.075347  9229 net.cpp:409] fc6 -> fc6
I0614 17:08:54.496152  9229 net.cpp:144] Setting up fc6
I0614 17:08:54.496179  9229 net.cpp:151] Top shape: 256 4096 (1048576)
I0614 17:08:54.496186  9229 net.cpp:159] Memory required for data: 2107731968
I0614 17:08:54.496196  9229 layer_factory.hpp:77] Creating layer relu6
I0614 17:08:54.496202  9229 net.cpp:94] Creating Layer relu6
I0614 17:08:54.496206  9229 net.cpp:435] relu6 <- fc6
I0614 17:08:54.496212  9229 net.cpp:409] relu6 -> relu6
I0614 17:08:54.496227  9229 net.cpp:144] Setting up relu6
I0614 17:08:54.496230  9229 net.cpp:151] Top shape: 256 4096 (1048576)
I0614 17:08:54.496234  9229 net.cpp:159] Memory required for data: 2111926272
I0614 17:08:54.496237  9229 layer_factory.hpp:77] Creating layer drop6
I0614 17:08:54.496243  9229 net.cpp:94] Creating Layer drop6
I0614 17:08:54.496621  9229 net.cpp:435] drop6 <- relu6
I0614 17:08:54.496629  9229 net.cpp:409] drop6 -> drop6
I0614 17:08:54.496651  9229 net.cpp:144] Setting up drop6
I0614 17:08:54.496655  9229 net.cpp:151] Top shape: 256 4096 (1048576)
I0614 17:08:54.496660  9229 net.cpp:159] Memory required for data: 2116120576
I0614 17:08:54.496665  9229 layer_factory.hpp:77] Creating layer fc7
I0614 17:08:54.496670  9229 net.cpp:94] Creating Layer fc7
I0614 17:08:54.496675  9229 net.cpp:435] fc7 <- drop6
I0614 17:08:54.496680  9229 net.cpp:409] fc7 -> fc7
I0614 17:08:54.651739  9229 net.cpp:144] Setting up fc7
I0614 17:08:54.651767  9229 net.cpp:151] Top shape: 256 4096 (1048576)
I0614 17:08:54.651775  9229 net.cpp:159] Memory required for data: 2120314880
I0614 17:08:54.651784  9229 layer_factory.hpp:77] Creating layer bn7
I0614 17:08:54.651793  9229 net.cpp:94] Creating Layer bn7
I0614 17:08:54.651798  9229 net.cpp:435] bn7 <- fc7
I0614 17:08:54.651803  9229 net.cpp:409] bn7 -> bn7
I0614 17:08:54.652069  9229 net.cpp:144] Setting up bn7
I0614 17:08:54.652076  9229 net.cpp:151] Top shape: 256 4096 (1048576)
I0614 17:08:54.652081  9229 net.cpp:159] Memory required for data: 2124509184
I0614 17:08:54.652088  9229 layer_factory.hpp:77] Creating layer relu7
I0614 17:08:54.652093  9229 net.cpp:94] Creating Layer relu7
I0614 17:08:54.652096  9229 net.cpp:435] relu7 <- bn7
I0614 17:08:54.652101  9229 net.cpp:409] relu7 -> relu7
I0614 17:08:54.652112  9229 net.cpp:144] Setting up relu7
I0614 17:08:54.652114  9229 net.cpp:151] Top shape: 256 4096 (1048576)
I0614 17:08:54.652118  9229 net.cpp:159] Memory required for data: 2128703488
I0614 17:08:54.652122  9229 layer_factory.hpp:77] Creating layer drop7
I0614 17:08:54.652127  9229 net.cpp:94] Creating Layer drop7
I0614 17:08:54.652129  9229 net.cpp:435] drop7 <- relu7
I0614 17:08:54.652133  9229 net.cpp:409] drop7 -> drop7
I0614 17:08:54.652146  9229 net.cpp:144] Setting up drop7
I0614 17:08:54.652150  9229 net.cpp:151] Top shape: 256 4096 (1048576)
I0614 17:08:54.652154  9229 net.cpp:159] Memory required for data: 2132897792
I0614 17:08:54.652158  9229 layer_factory.hpp:77] Creating layer fc8
I0614 17:08:54.652163  9229 net.cpp:94] Creating Layer fc8
I0614 17:08:54.652165  9229 net.cpp:435] fc8 <- drop7
I0614 17:08:54.652169  9229 net.cpp:409] fc8 -> fc8
I0614 17:08:54.652302  9229 net.cpp:144] Setting up fc8
I0614 17:08:54.652305  9229 net.cpp:151] Top shape: 256 2 (512)
I0614 17:08:54.652309  9229 net.cpp:159] Memory required for data: 2132899840
I0614 17:08:54.652314  9229 layer_factory.hpp:77] Creating layer loss
I0614 17:08:54.652320  9229 net.cpp:94] Creating Layer loss
I0614 17:08:54.652323  9229 net.cpp:435] loss <- fc8
I0614 17:08:54.652328  9229 net.cpp:435] loss <- label
I0614 17:08:54.652333  9229 net.cpp:409] loss -> loss
I0614 17:08:54.652339  9229 layer_factory.hpp:77] Creating layer loss
I0614 17:08:54.652384  9229 net.cpp:144] Setting up loss
I0614 17:08:54.652390  9229 net.cpp:151] Top shape: (1)
I0614 17:08:54.652395  9229 net.cpp:154]     with loss weight 1
I0614 17:08:54.652410  9229 net.cpp:159] Memory required for data: 2132899844
I0614 17:08:54.652415  9229 net.cpp:220] loss needs backward computation.
I0614 17:08:54.652420  9229 net.cpp:220] fc8 needs backward computation.
I0614 17:08:54.652426  9229 net.cpp:220] drop7 needs backward computation.
I0614 17:08:54.652429  9229 net.cpp:220] relu7 needs backward computation.
I0614 17:08:54.652433  9229 net.cpp:220] bn7 needs backward computation.
I0614 17:08:54.652437  9229 net.cpp:220] fc7 needs backward computation.
I0614 17:08:54.652441  9229 net.cpp:220] drop6 needs backward computation.
I0614 17:08:54.652446  9229 net.cpp:220] relu6 needs backward computation.
I0614 17:08:54.652448  9229 net.cpp:220] fc6 needs backward computation.
I0614 17:08:54.652452  9229 net.cpp:220] pool5 needs backward computation.
I0614 17:08:54.652456  9229 net.cpp:220] relu5 needs backward computation.
I0614 17:08:54.652460  9229 net.cpp:220] conv5 needs backward computation.
I0614 17:08:54.652465  9229 net.cpp:220] relu4 needs backward computation.
I0614 17:08:54.652765  9229 net.cpp:220] conv4 needs backward computation.
I0614 17:08:54.652770  9229 net.cpp:220] relu3 needs backward computation.
I0614 17:08:54.652773  9229 net.cpp:220] conv3 needs backward computation.
I0614 17:08:54.652777  9229 net.cpp:220] pool2 needs backward computation.
I0614 17:08:54.652781  9229 net.cpp:220] relu2 needs backward computation.
I0614 17:08:54.652786  9229 net.cpp:220] bn2 needs backward computation.
I0614 17:08:54.652791  9229 net.cpp:220] conv2 needs backward computation.
I0614 17:08:54.652794  9229 net.cpp:220] pool1 needs backward computation.
I0614 17:08:54.652797  9229 net.cpp:220] relu1 needs backward computation.
I0614 17:08:54.652802  9229 net.cpp:220] bn1 needs backward computation.
I0614 17:08:54.652806  9229 net.cpp:220] conv1 needs backward computation.
I0614 17:08:54.652810  9229 net.cpp:222] data does not need backward computation.
I0614 17:08:54.652814  9229 net.cpp:264] This network produces output loss
I0614 17:08:54.652834  9229 net.cpp:284] Network initialization done.
I0614 17:08:54.653765  9229 solver.cpp:189] Creating test net (#0) specified by net file: pruning/alexnetBNnoLRN/regular_rate_0.5/net_finetune.prototxt
I0614 17:08:54.653802  9229 net.cpp:323] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0614 17:08:54.653817  9229 net.cpp:52] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_value: 106
    mean_value: 116
    mean_value: 124
  }
  data_param {
    source: "input/lmdb/valid_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 0
    kernel_size: 8
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "bn1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn2"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "bn2"
  top: "relu2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "relu6"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "drop6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn7"
  type: "BatchNorm"
  bottom: "fc7"
  top: "bn7"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "bn7"
  top: "relu7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "relu7"
  top: "drop7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "drop7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy-top1"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "top-1"
  include {
    phase: TEST
  }
}
I0614 17:08:54.654325  9229 layer_factory.hpp:77] Creating layer data
I0614 17:08:54.654371  9229 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0614 17:08:54.657552  9229 net.cpp:94] Creating Layer data
I0614 17:08:54.657590  9229 net.cpp:409] data -> data
I0614 17:08:54.657617  9229 net.cpp:409] data -> label
I0614 17:08:54.658812  9296 db_lmdb.cpp:35] Opened lmdb input/lmdb/valid_lmdb
I0614 17:08:54.658844  9296 db_lmdb.cpp:38] Items count: 4000
I0614 17:08:54.658887  9296 data_reader.cpp:124] TEST: reading data using 1 channel(s)
I0614 17:08:54.659332  9229 data_layer.cpp:78] ReshapePrefetch 50, 3, 227, 227
I0614 17:08:54.659543  9229 data_layer.cpp:83] output data size: 50,3,227,227
I0614 17:08:54.783020  9229 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0614 17:08:54.783416  9229 net.cpp:144] Setting up data
I0614 17:08:54.783425  9229 net.cpp:151] Top shape: 50 3 227 227 (7729350)
I0614 17:08:54.783435  9229 net.cpp:151] Top shape: 50 (50)
I0614 17:08:54.783439  9229 net.cpp:159] Memory required for data: 30917600
I0614 17:08:54.783444  9229 layer_factory.hpp:77] Creating layer label_data_1_split
I0614 17:08:54.783453  9229 net.cpp:94] Creating Layer label_data_1_split
I0614 17:08:54.783458  9229 net.cpp:435] label_data_1_split <- label
I0614 17:08:54.783464  9229 net.cpp:409] label_data_1_split -> label_data_1_split_0
I0614 17:08:54.783473  9229 net.cpp:409] label_data_1_split -> label_data_1_split_1
I0614 17:08:54.783480  9229 net.cpp:409] label_data_1_split -> label_data_1_split_2
I0614 17:08:54.783526  9229 net.cpp:144] Setting up label_data_1_split
I0614 17:08:54.783530  9229 net.cpp:151] Top shape: 50 (50)
I0614 17:08:54.783535  9229 net.cpp:151] Top shape: 50 (50)
I0614 17:08:54.783540  9229 net.cpp:151] Top shape: 50 (50)
I0614 17:08:54.783543  9229 net.cpp:159] Memory required for data: 30918200
I0614 17:08:54.783565  9229 layer_factory.hpp:77] Creating layer conv1
I0614 17:08:54.783576  9229 net.cpp:94] Creating Layer conv1
I0614 17:08:54.783579  9229 net.cpp:435] conv1 <- data
I0614 17:08:54.783584  9229 net.cpp:409] conv1 -> conv1
I0614 17:08:54.783975  9229 net.cpp:144] Setting up conv1
I0614 17:08:54.783984  9229 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0614 17:08:54.783991  9229 net.cpp:159] Memory required for data: 88998200
I0614 17:08:54.784001  9229 layer_factory.hpp:77] Creating layer bn1
I0614 17:08:54.784008  9229 net.cpp:94] Creating Layer bn1
I0614 17:08:54.784013  9229 net.cpp:435] bn1 <- conv1
I0614 17:08:54.784018  9229 net.cpp:409] bn1 -> bn1
I0614 17:08:54.784363  9229 net.cpp:144] Setting up bn1
I0614 17:08:54.784369  9229 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0614 17:08:54.784375  9229 net.cpp:159] Memory required for data: 147078200
I0614 17:08:54.784389  9229 layer_factory.hpp:77] Creating layer relu1
I0614 17:08:54.784395  9229 net.cpp:94] Creating Layer relu1
I0614 17:08:54.784399  9229 net.cpp:435] relu1 <- bn1
I0614 17:08:54.784404  9229 net.cpp:409] relu1 -> relu1
I0614 17:08:54.784416  9229 net.cpp:144] Setting up relu1
I0614 17:08:54.784420  9229 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0614 17:08:54.784425  9229 net.cpp:159] Memory required for data: 205158200
I0614 17:08:54.784428  9229 layer_factory.hpp:77] Creating layer pool1
I0614 17:08:54.784435  9229 net.cpp:94] Creating Layer pool1
I0614 17:08:54.784437  9229 net.cpp:435] pool1 <- relu1
I0614 17:08:54.784442  9229 net.cpp:409] pool1 -> pool1
I0614 17:08:54.784461  9229 net.cpp:144] Setting up pool1
I0614 17:08:54.784464  9229 net.cpp:151] Top shape: 50 96 27 27 (3499200)
I0614 17:08:54.784469  9229 net.cpp:159] Memory required for data: 219155000
I0614 17:08:54.784472  9229 layer_factory.hpp:77] Creating layer conv2
I0614 17:08:54.784480  9229 net.cpp:94] Creating Layer conv2
I0614 17:08:54.784484  9229 net.cpp:435] conv2 <- pool1
I0614 17:08:54.784492  9229 net.cpp:409] conv2 -> conv2
I0614 17:08:54.792212  9229 net.cpp:144] Setting up conv2
I0614 17:08:54.792233  9229 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0614 17:08:54.792246  9229 net.cpp:159] Memory required for data: 256479800
I0614 17:08:54.792258  9229 layer_factory.hpp:77] Creating layer bn2
I0614 17:08:54.792306  9229 net.cpp:94] Creating Layer bn2
I0614 17:08:54.792315  9229 net.cpp:435] bn2 <- conv2
I0614 17:08:54.792320  9229 net.cpp:409] bn2 -> bn2
I0614 17:08:54.792802  9229 net.cpp:144] Setting up bn2
I0614 17:08:54.792814  9229 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0614 17:08:54.792826  9229 net.cpp:159] Memory required for data: 293804600
I0614 17:08:54.792840  9229 layer_factory.hpp:77] Creating layer relu2
I0614 17:08:54.792846  9229 net.cpp:94] Creating Layer relu2
I0614 17:08:54.792852  9229 net.cpp:435] relu2 <- bn2
I0614 17:08:54.792860  9229 net.cpp:409] relu2 -> relu2
I0614 17:08:54.792876  9229 net.cpp:144] Setting up relu2
I0614 17:08:54.793417  9229 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0614 17:08:54.793488  9229 net.cpp:159] Memory required for data: 331129400
I0614 17:08:54.793502  9229 layer_factory.hpp:77] Creating layer pool2
I0614 17:08:54.793522  9229 net.cpp:94] Creating Layer pool2
I0614 17:08:54.793535  9229 net.cpp:435] pool2 <- relu2
I0614 17:08:54.793553  9229 net.cpp:409] pool2 -> pool2
I0614 17:08:54.793671  9229 net.cpp:144] Setting up pool2
I0614 17:08:54.793690  9229 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0614 17:08:54.793711  9229 net.cpp:159] Memory required for data: 339782200
I0614 17:08:54.793728  9229 layer_factory.hpp:77] Creating layer conv3
I0614 17:08:54.793761  9229 net.cpp:94] Creating Layer conv3
I0614 17:08:54.793773  9229 net.cpp:435] conv3 <- pool2
I0614 17:08:54.793792  9229 net.cpp:409] conv3 -> conv3
I0614 17:08:54.821822  9229 net.cpp:144] Setting up conv3
I0614 17:08:54.821846  9229 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0614 17:08:54.821856  9229 net.cpp:159] Memory required for data: 352761400
I0614 17:08:54.821868  9229 layer_factory.hpp:77] Creating layer relu3
I0614 17:08:54.821877  9229 net.cpp:94] Creating Layer relu3
I0614 17:08:54.821883  9229 net.cpp:435] relu3 <- conv3
I0614 17:08:54.821892  9229 net.cpp:409] relu3 -> relu3
I0614 17:08:54.821916  9229 net.cpp:144] Setting up relu3
I0614 17:08:54.821921  9229 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0614 17:08:54.821928  9229 net.cpp:159] Memory required for data: 365740600
I0614 17:08:54.821933  9229 layer_factory.hpp:77] Creating layer conv4
I0614 17:08:54.821945  9229 net.cpp:94] Creating Layer conv4
I0614 17:08:54.821950  9229 net.cpp:435] conv4 <- relu3
I0614 17:08:54.821957  9229 net.cpp:409] conv4 -> conv4
I0614 17:08:54.840636  9229 net.cpp:144] Setting up conv4
I0614 17:08:54.840658  9229 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0614 17:08:54.840667  9229 net.cpp:159] Memory required for data: 378719800
I0614 17:08:54.840682  9229 layer_factory.hpp:77] Creating layer relu4
I0614 17:08:54.840688  9229 net.cpp:94] Creating Layer relu4
I0614 17:08:54.840693  9229 net.cpp:435] relu4 <- conv4
I0614 17:08:54.840699  9229 net.cpp:409] relu4 -> relu4
I0614 17:08:54.840724  9229 net.cpp:144] Setting up relu4
I0614 17:08:54.840728  9229 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0614 17:08:54.840734  9229 net.cpp:159] Memory required for data: 391699000
I0614 17:08:54.840736  9229 layer_factory.hpp:77] Creating layer conv5
I0614 17:08:54.840745  9229 net.cpp:94] Creating Layer conv5
I0614 17:08:54.840749  9229 net.cpp:435] conv5 <- relu4
I0614 17:08:54.840755  9229 net.cpp:409] conv5 -> conv5
I0614 17:08:54.851737  9229 net.cpp:144] Setting up conv5
I0614 17:08:54.851758  9229 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0614 17:08:54.851768  9229 net.cpp:159] Memory required for data: 400351800
I0614 17:08:54.851778  9229 layer_factory.hpp:77] Creating layer relu5
I0614 17:08:54.851784  9229 net.cpp:94] Creating Layer relu5
I0614 17:08:54.851789  9229 net.cpp:435] relu5 <- conv5
I0614 17:08:54.851795  9229 net.cpp:409] relu5 -> relu5
I0614 17:08:54.851833  9229 net.cpp:144] Setting up relu5
I0614 17:08:54.851837  9229 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0614 17:08:54.851842  9229 net.cpp:159] Memory required for data: 409004600
I0614 17:08:54.851845  9229 layer_factory.hpp:77] Creating layer pool5
I0614 17:08:54.851853  9229 net.cpp:94] Creating Layer pool5
I0614 17:08:54.851857  9229 net.cpp:435] pool5 <- relu5
I0614 17:08:54.851861  9229 net.cpp:409] pool5 -> pool5
I0614 17:08:54.851899  9229 net.cpp:144] Setting up pool5
I0614 17:08:54.851903  9229 net.cpp:151] Top shape: 50 256 6 6 (460800)
I0614 17:08:54.851908  9229 net.cpp:159] Memory required for data: 410847800
I0614 17:08:54.851912  9229 layer_factory.hpp:77] Creating layer fc6
I0614 17:08:54.851920  9229 net.cpp:94] Creating Layer fc6
I0614 17:08:54.851924  9229 net.cpp:435] fc6 <- pool5
I0614 17:08:54.851928  9229 net.cpp:409] fc6 -> fc6
I0614 17:08:55.201452  9229 net.cpp:144] Setting up fc6
I0614 17:08:55.201475  9229 net.cpp:151] Top shape: 50 4096 (204800)
I0614 17:08:55.201846  9229 net.cpp:159] Memory required for data: 411667000
I0614 17:08:55.201872  9229 layer_factory.hpp:77] Creating layer relu6
I0614 17:08:55.201880  9229 net.cpp:94] Creating Layer relu6
I0614 17:08:55.201884  9229 net.cpp:435] relu6 <- fc6
I0614 17:08:55.201891  9229 net.cpp:409] relu6 -> relu6
I0614 17:08:55.201913  9229 net.cpp:144] Setting up relu6
I0614 17:08:55.201917  9229 net.cpp:151] Top shape: 50 4096 (204800)
I0614 17:08:55.201921  9229 net.cpp:159] Memory required for data: 412486200
I0614 17:08:55.201925  9229 layer_factory.hpp:77] Creating layer drop6
I0614 17:08:55.201930  9229 net.cpp:94] Creating Layer drop6
I0614 17:08:55.201934  9229 net.cpp:435] drop6 <- relu6
I0614 17:08:55.201939  9229 net.cpp:409] drop6 -> drop6
I0614 17:08:55.201956  9229 net.cpp:144] Setting up drop6
I0614 17:08:55.201961  9229 net.cpp:151] Top shape: 50 4096 (204800)
I0614 17:08:55.201964  9229 net.cpp:159] Memory required for data: 413305400
I0614 17:08:55.201967  9229 layer_factory.hpp:77] Creating layer fc7
I0614 17:08:55.201977  9229 net.cpp:94] Creating Layer fc7
I0614 17:08:55.201979  9229 net.cpp:435] fc7 <- drop6
I0614 17:08:55.201984  9229 net.cpp:409] fc7 -> fc7
I0614 17:08:55.357909  9229 net.cpp:144] Setting up fc7
I0614 17:08:55.357934  9229 net.cpp:151] Top shape: 50 4096 (204800)
I0614 17:08:55.357944  9229 net.cpp:159] Memory required for data: 414124600
I0614 17:08:55.357954  9229 layer_factory.hpp:77] Creating layer bn7
I0614 17:08:55.357964  9229 net.cpp:94] Creating Layer bn7
I0614 17:08:55.357968  9229 net.cpp:435] bn7 <- fc7
I0614 17:08:55.357975  9229 net.cpp:409] bn7 -> bn7
I0614 17:08:55.358304  9229 net.cpp:144] Setting up bn7
I0614 17:08:55.358314  9229 net.cpp:151] Top shape: 50 4096 (204800)
I0614 17:08:55.358336  9229 net.cpp:159] Memory required for data: 414943800
I0614 17:08:55.358347  9229 layer_factory.hpp:77] Creating layer relu7
I0614 17:08:55.358355  9229 net.cpp:94] Creating Layer relu7
I0614 17:08:55.358361  9229 net.cpp:435] relu7 <- bn7
I0614 17:08:55.358369  9229 net.cpp:409] relu7 -> relu7
I0614 17:08:55.358392  9229 net.cpp:144] Setting up relu7
I0614 17:08:55.358397  9229 net.cpp:151] Top shape: 50 4096 (204800)
I0614 17:08:55.358402  9229 net.cpp:159] Memory required for data: 415763000
I0614 17:08:55.358407  9229 layer_factory.hpp:77] Creating layer drop7
I0614 17:08:55.358412  9229 net.cpp:94] Creating Layer drop7
I0614 17:08:55.358417  9229 net.cpp:435] drop7 <- relu7
I0614 17:08:55.358422  9229 net.cpp:409] drop7 -> drop7
I0614 17:08:55.358445  9229 net.cpp:144] Setting up drop7
I0614 17:08:55.358451  9229 net.cpp:151] Top shape: 50 4096 (204800)
I0614 17:08:55.358458  9229 net.cpp:159] Memory required for data: 416582200
I0614 17:08:55.358462  9229 layer_factory.hpp:77] Creating layer fc8
I0614 17:08:55.358471  9229 net.cpp:94] Creating Layer fc8
I0614 17:08:55.358475  9229 net.cpp:435] fc8 <- drop7
I0614 17:08:55.358482  9229 net.cpp:409] fc8 -> fc8
I0614 17:08:55.358626  9229 net.cpp:144] Setting up fc8
I0614 17:08:55.358634  9229 net.cpp:151] Top shape: 50 2 (100)
I0614 17:08:55.358639  9229 net.cpp:159] Memory required for data: 416582600
I0614 17:08:55.358645  9229 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0614 17:08:55.358652  9229 net.cpp:94] Creating Layer fc8_fc8_0_split
I0614 17:08:55.358656  9229 net.cpp:435] fc8_fc8_0_split <- fc8
I0614 17:08:55.358662  9229 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0614 17:08:55.358669  9229 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0614 17:08:55.358675  9229 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_2
I0614 17:08:55.358697  9229 net.cpp:144] Setting up fc8_fc8_0_split
I0614 17:08:55.358701  9229 net.cpp:151] Top shape: 50 2 (100)
I0614 17:08:55.358706  9229 net.cpp:151] Top shape: 50 2 (100)
I0614 17:08:55.358711  9229 net.cpp:151] Top shape: 50 2 (100)
I0614 17:08:55.358716  9229 net.cpp:159] Memory required for data: 416583800
I0614 17:08:55.358722  9229 layer_factory.hpp:77] Creating layer accuracy
I0614 17:08:55.358732  9229 net.cpp:94] Creating Layer accuracy
I0614 17:08:55.359026  9229 net.cpp:435] accuracy <- fc8_fc8_0_split_0
I0614 17:08:55.359032  9229 net.cpp:435] accuracy <- label_data_1_split_0
I0614 17:08:55.359037  9229 net.cpp:409] accuracy -> accuracy
I0614 17:08:55.359046  9229 net.cpp:144] Setting up accuracy
I0614 17:08:55.359050  9229 net.cpp:151] Top shape: (1)
I0614 17:08:55.359055  9229 net.cpp:159] Memory required for data: 416583804
I0614 17:08:55.359058  9229 layer_factory.hpp:77] Creating layer loss
I0614 17:08:55.359063  9229 net.cpp:94] Creating Layer loss
I0614 17:08:55.359067  9229 net.cpp:435] loss <- fc8_fc8_0_split_1
I0614 17:08:55.359071  9229 net.cpp:435] loss <- label_data_1_split_1
I0614 17:08:55.359076  9229 net.cpp:409] loss -> loss
I0614 17:08:55.359086  9229 layer_factory.hpp:77] Creating layer loss
I0614 17:08:55.359150  9229 net.cpp:144] Setting up loss
I0614 17:08:55.359158  9229 net.cpp:151] Top shape: (1)
I0614 17:08:55.359164  9229 net.cpp:154]     with loss weight 1
I0614 17:08:55.359180  9229 net.cpp:159] Memory required for data: 416583808
I0614 17:08:55.359186  9229 layer_factory.hpp:77] Creating layer accuracy-top1
I0614 17:08:55.359194  9229 net.cpp:94] Creating Layer accuracy-top1
I0614 17:08:55.359198  9229 net.cpp:435] accuracy-top1 <- fc8_fc8_0_split_2
I0614 17:08:55.359202  9229 net.cpp:435] accuracy-top1 <- label_data_1_split_2
I0614 17:08:55.359210  9229 net.cpp:409] accuracy-top1 -> top-1
I0614 17:08:55.359215  9229 net.cpp:144] Setting up accuracy-top1
I0614 17:08:55.359220  9229 net.cpp:151] Top shape: (1)
I0614 17:08:55.359223  9229 net.cpp:159] Memory required for data: 416583812
I0614 17:08:55.359227  9229 net.cpp:222] accuracy-top1 does not need backward computation.
I0614 17:08:55.359232  9229 net.cpp:220] loss needs backward computation.
I0614 17:08:55.359236  9229 net.cpp:222] accuracy does not need backward computation.
I0614 17:08:55.359241  9229 net.cpp:220] fc8_fc8_0_split needs backward computation.
I0614 17:08:55.359246  9229 net.cpp:220] fc8 needs backward computation.
I0614 17:08:55.359249  9229 net.cpp:220] drop7 needs backward computation.
I0614 17:08:55.359253  9229 net.cpp:220] relu7 needs backward computation.
I0614 17:08:55.359257  9229 net.cpp:220] bn7 needs backward computation.
I0614 17:08:55.359261  9229 net.cpp:220] fc7 needs backward computation.
I0614 17:08:55.359266  9229 net.cpp:220] drop6 needs backward computation.
I0614 17:08:55.359269  9229 net.cpp:220] relu6 needs backward computation.
I0614 17:08:55.359273  9229 net.cpp:220] fc6 needs backward computation.
I0614 17:08:55.359278  9229 net.cpp:220] pool5 needs backward computation.
I0614 17:08:55.359282  9229 net.cpp:220] relu5 needs backward computation.
I0614 17:08:55.359287  9229 net.cpp:220] conv5 needs backward computation.
I0614 17:08:55.359292  9229 net.cpp:220] relu4 needs backward computation.
I0614 17:08:55.359297  9229 net.cpp:220] conv4 needs backward computation.
I0614 17:08:55.359302  9229 net.cpp:220] relu3 needs backward computation.
I0614 17:08:55.359308  9229 net.cpp:220] conv3 needs backward computation.
I0614 17:08:55.359313  9229 net.cpp:220] pool2 needs backward computation.
I0614 17:08:55.359316  9229 net.cpp:220] relu2 needs backward computation.
I0614 17:08:55.359320  9229 net.cpp:220] bn2 needs backward computation.
I0614 17:08:55.359324  9229 net.cpp:220] conv2 needs backward computation.
I0614 17:08:55.359328  9229 net.cpp:220] pool1 needs backward computation.
I0614 17:08:55.359333  9229 net.cpp:220] relu1 needs backward computation.
I0614 17:08:55.359336  9229 net.cpp:220] bn1 needs backward computation.
I0614 17:08:55.359340  9229 net.cpp:220] conv1 needs backward computation.
I0614 17:08:55.359345  9229 net.cpp:222] label_data_1_split does not need backward computation.
I0614 17:08:55.359350  9229 net.cpp:222] data does not need backward computation.
I0614 17:08:55.359354  9229 net.cpp:264] This network produces output accuracy
I0614 17:08:55.359359  9229 net.cpp:264] This network produces output loss
I0614 17:08:55.359364  9229 net.cpp:264] This network produces output top-1
I0614 17:08:55.359674  9229 net.cpp:284] Network initialization done.
I0614 17:08:55.359750  9229 solver.cpp:63] Solver scaffolding done.
I0614 17:08:55.360440  9229 caffe_interface.cpp:139] Finetuning from pruning/alexnetBNnoLRN/regular_rate_0.5/sparse.caffemodel
I0614 17:08:57.831873  9229 caffe_interface.cpp:573] Starting Optimization
I0614 17:08:57.831897  9229 solver.cpp:341] Solving 
I0614 17:08:57.831900  9229 solver.cpp:342] Learning Rate Policy: step
I0614 17:08:57.833181  9229 solver.cpp:424] Iteration 0, Testing net (#0)
I0614 17:08:59.314373  9229 solver.cpp:523]     Test net output #0: accuracy = 0.95725
I0614 17:08:59.314405  9229 solver.cpp:523]     Test net output #1: loss = 0.220848 (* 1 = 0.220848 loss)
I0614 17:08:59.314410  9229 solver.cpp:523]     Test net output #2: top-1 = 0.95725
I0614 17:08:59.573271  9229 solver.cpp:270] Iteration 0 (0 iter/s, 1.74126s/50 iter), loss = 0.00592804, remaining 333333 hours and 20 minutes
I0614 17:08:59.573300  9229 solver.cpp:291]     Train net output #0: loss = 0.00592804 (* 1 = 0.00592804 loss)
I0614 17:08:59.573313  9229 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0614 17:09:11.959004  9229 solver.cpp:270] Iteration 50 (4.03707 iter/s, 12.3852s/50 iter), loss = 0.0591784, remaining 0 hours and 49 minutes
I0614 17:09:11.959035  9229 solver.cpp:291]     Train net output #0: loss = 0.0591784 (* 1 = 0.0591784 loss)
I0614 17:09:11.959043  9229 sgd_solver.cpp:106] Iteration 50, lr = 0.001
I0614 17:09:24.420961  9229 solver.cpp:270] Iteration 100 (4.01237 iter/s, 12.4615s/50 iter), loss = 0.101969, remaining 0 hours and 49 minutes
I0614 17:09:24.421216  9229 solver.cpp:291]     Train net output #0: loss = 0.101969 (* 1 = 0.101969 loss)
I0614 17:09:24.421241  9229 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I0614 17:09:36.977865  9229 solver.cpp:270] Iteration 150 (3.98211 iter/s, 12.5562s/50 iter), loss = 0.0429512, remaining 0 hours and 49 minutes
I0614 17:09:36.977896  9229 solver.cpp:291]     Train net output #0: loss = 0.0429513 (* 1 = 0.0429513 loss)
I0614 17:09:36.977905  9229 sgd_solver.cpp:106] Iteration 150, lr = 0.001
I0614 17:09:49.536672  9229 solver.cpp:270] Iteration 200 (3.98143 iter/s, 12.5583s/50 iter), loss = 0.0400622, remaining 0 hours and 49 minutes
I0614 17:09:49.536703  9229 solver.cpp:291]     Train net output #0: loss = 0.0400622 (* 1 = 0.0400622 loss)
I0614 17:09:49.536710  9229 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I0614 17:10:02.153779  9229 solver.cpp:270] Iteration 250 (3.96301 iter/s, 12.6167s/50 iter), loss = 0.0970818, remaining 0 hours and 49 minutes
I0614 17:10:02.154040  9229 solver.cpp:291]     Train net output #0: loss = 0.0970818 (* 1 = 0.0970818 loss)
I0614 17:10:02.154049  9229 sgd_solver.cpp:106] Iteration 250, lr = 0.001
I0614 17:10:14.772049  9229 solver.cpp:270] Iteration 300 (3.96271 iter/s, 12.6176s/50 iter), loss = 0.0822538, remaining 0 hours and 49 minutes
I0614 17:10:14.772080  9229 solver.cpp:291]     Train net output #0: loss = 0.0822538 (* 1 = 0.0822538 loss)
I0614 17:10:14.772087  9229 sgd_solver.cpp:106] Iteration 300, lr = 0.001
I0614 17:10:27.390220  9229 solver.cpp:270] Iteration 350 (3.96268 iter/s, 12.6177s/50 iter), loss = 0.0626304, remaining 0 hours and 48 minutes
I0614 17:10:27.390251  9229 solver.cpp:291]     Train net output #0: loss = 0.0626304 (* 1 = 0.0626304 loss)
I0614 17:10:27.390259  9229 sgd_solver.cpp:106] Iteration 350, lr = 0.001
I0614 17:10:40.004307  9229 solver.cpp:270] Iteration 400 (3.96396 iter/s, 12.6136s/50 iter), loss = 0.0649653, remaining 0 hours and 48 minutes
I0614 17:10:40.004560  9229 solver.cpp:291]     Train net output #0: loss = 0.0649653 (* 1 = 0.0649653 loss)
I0614 17:10:40.004586  9229 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I0614 17:10:52.648270  9229 solver.cpp:270] Iteration 450 (3.95466 iter/s, 12.6433s/50 iter), loss = 0.0870669, remaining 0 hours and 48 minutes
I0614 17:10:52.648303  9229 solver.cpp:291]     Train net output #0: loss = 0.0870669 (* 1 = 0.0870669 loss)
I0614 17:10:52.648325  9229 sgd_solver.cpp:106] Iteration 450, lr = 0.001
I0614 17:11:05.285995  9229 solver.cpp:270] Iteration 500 (3.95655 iter/s, 12.6373s/50 iter), loss = 0.0739596, remaining 0 hours and 48 minutes
I0614 17:11:05.286026  9229 solver.cpp:291]     Train net output #0: loss = 0.0739596 (* 1 = 0.0739596 loss)
I0614 17:11:05.286048  9229 sgd_solver.cpp:106] Iteration 500, lr = 0.001
I0614 17:11:17.932679  9229 solver.cpp:270] Iteration 550 (3.95374 iter/s, 12.6462s/50 iter), loss = 0.127256, remaining 0 hours and 48 minutes
I0614 17:11:17.932998  9229 solver.cpp:291]     Train net output #0: loss = 0.127256 (* 1 = 0.127256 loss)
I0614 17:11:17.933023  9229 sgd_solver.cpp:106] Iteration 550, lr = 0.001
I0614 17:11:30.568590  9229 solver.cpp:270] Iteration 600 (3.9572 iter/s, 12.6352s/50 iter), loss = 0.0812066, remaining 0 hours and 48 minutes
I0614 17:11:30.568621  9229 solver.cpp:291]     Train net output #0: loss = 0.0812066 (* 1 = 0.0812066 loss)
I0614 17:11:30.568629  9229 sgd_solver.cpp:106] Iteration 600, lr = 0.001
I0614 17:11:43.204638  9229 solver.cpp:270] Iteration 650 (3.95707 iter/s, 12.6356s/50 iter), loss = 0.14061, remaining 0 hours and 47 minutes
I0614 17:11:43.204671  9229 solver.cpp:291]     Train net output #0: loss = 0.14061 (* 1 = 0.14061 loss)
I0614 17:11:43.204680  9229 sgd_solver.cpp:106] Iteration 650, lr = 0.001
I0614 17:11:55.832844  9229 solver.cpp:270] Iteration 700 (3.95953 iter/s, 12.6278s/50 iter), loss = 0.0652365, remaining 0 hours and 47 minutes
I0614 17:11:55.833081  9229 solver.cpp:291]     Train net output #0: loss = 0.0652365 (* 1 = 0.0652365 loss)
I0614 17:11:55.833088  9229 sgd_solver.cpp:106] Iteration 700, lr = 0.001
I0614 17:12:08.449112  9229 solver.cpp:270] Iteration 750 (3.96334 iter/s, 12.6156s/50 iter), loss = 0.0750588, remaining 0 hours and 47 minutes
I0614 17:12:08.449141  9229 solver.cpp:291]     Train net output #0: loss = 0.0750589 (* 1 = 0.0750589 loss)
I0614 17:12:08.449149  9229 sgd_solver.cpp:106] Iteration 750, lr = 0.001
I0614 17:12:21.069880  9229 solver.cpp:270] Iteration 800 (3.96186 iter/s, 12.6203s/50 iter), loss = 0.0913502, remaining 0 hours and 46 minutes
I0614 17:12:21.069911  9229 solver.cpp:291]     Train net output #0: loss = 0.0913502 (* 1 = 0.0913502 loss)
I0614 17:12:21.069918  9229 sgd_solver.cpp:106] Iteration 800, lr = 0.001
I0614 17:12:33.684676  9229 solver.cpp:270] Iteration 850 (3.96374 iter/s, 12.6144s/50 iter), loss = 0.0376683, remaining 0 hours and 46 minutes
I0614 17:12:33.684934  9229 solver.cpp:291]     Train net output #0: loss = 0.0376683 (* 1 = 0.0376683 loss)
I0614 17:12:33.684957  9229 sgd_solver.cpp:106] Iteration 850, lr = 0.001
I0614 17:12:46.282503  9229 solver.cpp:270] Iteration 900 (3.96915 iter/s, 12.5972s/50 iter), loss = 0.0908683, remaining 0 hours and 46 minutes
I0614 17:12:46.282533  9229 solver.cpp:291]     Train net output #0: loss = 0.0908683 (* 1 = 0.0908683 loss)
I0614 17:12:46.282541  9229 sgd_solver.cpp:106] Iteration 900, lr = 0.001
I0614 17:12:58.902380  9229 solver.cpp:270] Iteration 950 (3.96214 iter/s, 12.6194s/50 iter), loss = 0.0621969, remaining 0 hours and 46 minutes
I0614 17:12:58.902412  9229 solver.cpp:291]     Train net output #0: loss = 0.0621969 (* 1 = 0.0621969 loss)
I0614 17:12:58.902436  9229 sgd_solver.cpp:106] Iteration 950, lr = 0.001
I0614 17:13:11.289317  9229 solver.cpp:424] Iteration 1000, Testing net (#0)
I0614 17:13:12.794767  9229 solver.cpp:523]     Test net output #0: accuracy = 0.88625
I0614 17:13:12.794797  9229 solver.cpp:523]     Test net output #1: loss = 0.442243 (* 1 = 0.442243 loss)
I0614 17:13:12.794802  9229 solver.cpp:523]     Test net output #2: top-1 = 0.88625
I0614 17:13:13.040736  9229 solver.cpp:270] Iteration 1000 (3.5366 iter/s, 14.1379s/50 iter), loss = 0.0723655, remaining 0 hours and 51 minutes
I0614 17:13:13.040766  9229 solver.cpp:291]     Train net output #0: loss = 0.0723656 (* 1 = 0.0723656 loss)
I0614 17:13:13.040774  9229 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I0614 17:13:25.652604  9229 solver.cpp:270] Iteration 1050 (3.96466 iter/s, 12.6114s/50 iter), loss = 0.0568782, remaining 0 hours and 45 minutes
I0614 17:13:25.652635  9229 solver.cpp:291]     Train net output #0: loss = 0.0568782 (* 1 = 0.0568782 loss)
I0614 17:13:25.652642  9229 sgd_solver.cpp:106] Iteration 1050, lr = 0.001
I0614 17:13:38.276255  9229 solver.cpp:270] Iteration 1100 (3.96096 iter/s, 12.6232s/50 iter), loss = 0.117762, remaining 0 hours and 45 minutes
I0614 17:13:38.276286  9229 solver.cpp:291]     Train net output #0: loss = 0.117762 (* 1 = 0.117762 loss)
I0614 17:13:38.276293  9229 sgd_solver.cpp:106] Iteration 1100, lr = 0.001
I0614 17:13:50.898433  9229 solver.cpp:270] Iteration 1150 (3.96142 iter/s, 12.6217s/50 iter), loss = 0.0856171, remaining 0 hours and 45 minutes
I0614 17:13:50.898737  9229 solver.cpp:291]     Train net output #0: loss = 0.0856171 (* 1 = 0.0856171 loss)
I0614 17:13:50.898746  9229 sgd_solver.cpp:106] Iteration 1150, lr = 0.001
I0614 17:14:03.512516  9229 solver.cpp:270] Iteration 1200 (3.96405 iter/s, 12.6134s/50 iter), loss = 0.0465335, remaining 0 hours and 45 minutes
I0614 17:14:03.512547  9229 solver.cpp:291]     Train net output #0: loss = 0.0465336 (* 1 = 0.0465336 loss)
I0614 17:14:03.512554  9229 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I0614 17:14:16.143945  9229 solver.cpp:270] Iteration 1250 (3.95852 iter/s, 12.631s/50 iter), loss = 0.0770684, remaining 0 hours and 45 minutes
I0614 17:14:16.143977  9229 solver.cpp:291]     Train net output #0: loss = 0.0770684 (* 1 = 0.0770684 loss)
I0614 17:14:16.143985  9229 sgd_solver.cpp:106] Iteration 1250, lr = 0.001
I0614 17:14:28.782130  9229 solver.cpp:270] Iteration 1300 (3.9564 iter/s, 12.6377s/50 iter), loss = 0.146119, remaining 0 hours and 44 minutes
I0614 17:14:28.782377  9229 solver.cpp:291]     Train net output #0: loss = 0.146119 (* 1 = 0.146119 loss)
I0614 17:14:28.782402  9229 sgd_solver.cpp:106] Iteration 1300, lr = 0.001
I0614 17:14:41.393458  9229 solver.cpp:270] Iteration 1350 (3.9649 iter/s, 12.6107s/50 iter), loss = 0.120685, remaining 0 hours and 44 minutes
I0614 17:14:41.393491  9229 solver.cpp:291]     Train net output #0: loss = 0.120685 (* 1 = 0.120685 loss)
I0614 17:14:41.393501  9229 sgd_solver.cpp:106] Iteration 1350, lr = 0.001
I0614 17:14:54.017632  9229 solver.cpp:270] Iteration 1400 (3.96079 iter/s, 12.6237s/50 iter), loss = 0.10165, remaining 0 hours and 44 minutes
I0614 17:14:54.017663  9229 solver.cpp:291]     Train net output #0: loss = 0.10165 (* 1 = 0.10165 loss)
I0614 17:14:54.017669  9229 sgd_solver.cpp:106] Iteration 1400, lr = 0.001
I0614 17:15:06.659277  9229 solver.cpp:270] Iteration 1450 (3.95532 iter/s, 12.6412s/50 iter), loss = 0.0834101, remaining 0 hours and 44 minutes
I0614 17:15:06.659535  9229 solver.cpp:291]     Train net output #0: loss = 0.0834101 (* 1 = 0.0834101 loss)
I0614 17:15:06.659543  9229 sgd_solver.cpp:106] Iteration 1450, lr = 0.001
I0614 17:15:19.297591  9229 solver.cpp:270] Iteration 1500 (3.95643 iter/s, 12.6376s/50 iter), loss = 0.0568698, remaining 0 hours and 44 minutes
I0614 17:15:19.297624  9229 solver.cpp:291]     Train net output #0: loss = 0.0568698 (* 1 = 0.0568698 loss)
I0614 17:15:19.297631  9229 sgd_solver.cpp:106] Iteration 1500, lr = 0.001
I0614 17:15:31.923506  9229 solver.cpp:270] Iteration 1550 (3.96025 iter/s, 12.6255s/50 iter), loss = 0.0955898, remaining 0 hours and 43 minutes
I0614 17:15:31.923535  9229 solver.cpp:291]     Train net output #0: loss = 0.0955898 (* 1 = 0.0955898 loss)
I0614 17:15:31.923558  9229 sgd_solver.cpp:106] Iteration 1550, lr = 0.001
I0614 17:15:44.536098  9229 solver.cpp:270] Iteration 1600 (3.96443 iter/s, 12.6122s/50 iter), loss = 0.0490433, remaining 0 hours and 43 minutes
I0614 17:15:44.536351  9229 solver.cpp:291]     Train net output #0: loss = 0.0490433 (* 1 = 0.0490433 loss)
I0614 17:15:44.536360  9229 sgd_solver.cpp:106] Iteration 1600, lr = 0.001
I0614 17:15:57.143923  9229 solver.cpp:270] Iteration 1650 (3.966 iter/s, 12.6072s/50 iter), loss = 0.0970457, remaining 0 hours and 43 minutes
I0614 17:15:57.143952  9229 solver.cpp:291]     Train net output #0: loss = 0.0970457 (* 1 = 0.0970457 loss)
I0614 17:15:57.143959  9229 sgd_solver.cpp:106] Iteration 1650, lr = 0.001
I0614 17:16:09.751214  9229 solver.cpp:270] Iteration 1700 (3.9661 iter/s, 12.6069s/50 iter), loss = 0.0747842, remaining 0 hours and 43 minutes
I0614 17:16:09.751245  9229 solver.cpp:291]     Train net output #0: loss = 0.0747842 (* 1 = 0.0747842 loss)
I0614 17:16:09.751251  9229 sgd_solver.cpp:106] Iteration 1700, lr = 0.001
I0614 17:16:22.366466  9229 solver.cpp:270] Iteration 1750 (3.96359 iter/s, 12.6148s/50 iter), loss = 0.0942012, remaining 0 hours and 42 minutes
I0614 17:16:22.366796  9229 solver.cpp:291]     Train net output #0: loss = 0.0942012 (* 1 = 0.0942012 loss)
I0614 17:16:22.366820  9229 sgd_solver.cpp:106] Iteration 1750, lr = 0.001
I0614 17:16:34.990325  9229 solver.cpp:270] Iteration 1800 (3.96099 iter/s, 12.6231s/50 iter), loss = 0.0995337, remaining 0 hours and 42 minutes
I0614 17:16:34.990357  9229 solver.cpp:291]     Train net output #0: loss = 0.0995337 (* 1 = 0.0995337 loss)
I0614 17:16:34.990365  9229 sgd_solver.cpp:106] Iteration 1800, lr = 0.001
I0614 17:16:47.622862  9229 solver.cpp:270] Iteration 1850 (3.95817 iter/s, 12.6321s/50 iter), loss = 0.0884099, remaining 0 hours and 42 minutes
I0614 17:16:47.622893  9229 solver.cpp:291]     Train net output #0: loss = 0.0884099 (* 1 = 0.0884099 loss)
I0614 17:16:47.622900  9229 sgd_solver.cpp:106] Iteration 1850, lr = 0.001
I0614 17:17:00.261718  9229 solver.cpp:270] Iteration 1900 (3.95619 iter/s, 12.6384s/50 iter), loss = 0.077499, remaining 0 hours and 42 minutes
I0614 17:17:00.261973  9229 solver.cpp:291]     Train net output #0: loss = 0.077499 (* 1 = 0.077499 loss)
I0614 17:17:00.261981  9229 sgd_solver.cpp:106] Iteration 1900, lr = 0.001
I0614 17:17:12.904287  9229 solver.cpp:270] Iteration 1950 (3.9551 iter/s, 12.6419s/50 iter), loss = 0.071787, remaining 0 hours and 42 minutes
I0614 17:17:12.904318  9229 solver.cpp:291]     Train net output #0: loss = 0.071787 (* 1 = 0.071787 loss)
I0614 17:17:12.904326  9229 sgd_solver.cpp:106] Iteration 1950, lr = 0.001
I0614 17:17:25.286653  9229 solver.cpp:424] Iteration 2000, Testing net (#0)
I0614 17:17:26.794268  9229 solver.cpp:523]     Test net output #0: accuracy = 0.8675
I0614 17:17:26.794296  9229 solver.cpp:523]     Test net output #1: loss = 0.375452 (* 1 = 0.375452 loss)
I0614 17:17:26.794301  9229 solver.cpp:523]     Test net output #2: top-1 = 0.8675
I0614 17:17:27.041266  9229 solver.cpp:270] Iteration 2000 (3.53695 iter/s, 14.1365s/50 iter), loss = 0.0849064, remaining 0 hours and 46 minutes
I0614 17:17:27.041297  9229 solver.cpp:291]     Train net output #0: loss = 0.0849064 (* 1 = 0.0849064 loss)
I0614 17:17:27.041304  9229 sgd_solver.cpp:106] Iteration 2000, lr = 0.001
I0614 17:17:39.669430  9229 solver.cpp:270] Iteration 2050 (3.95954 iter/s, 12.6277s/50 iter), loss = 0.0736246, remaining 0 hours and 41 minutes
I0614 17:17:39.669648  9229 solver.cpp:291]     Train net output #0: loss = 0.0736246 (* 1 = 0.0736246 loss)
I0614 17:17:39.669672  9229 sgd_solver.cpp:106] Iteration 2050, lr = 0.001
I0614 17:17:52.296838  9229 solver.cpp:270] Iteration 2100 (3.95984 iter/s, 12.6268s/50 iter), loss = 0.0315595, remaining 0 hours and 41 minutes
I0614 17:17:52.296870  9229 solver.cpp:291]     Train net output #0: loss = 0.0315595 (* 1 = 0.0315595 loss)
I0614 17:17:52.296877  9229 sgd_solver.cpp:106] Iteration 2100, lr = 0.001
I0614 17:18:04.925057  9229 solver.cpp:270] Iteration 2150 (3.95953 iter/s, 12.6278s/50 iter), loss = 0.113609, remaining 0 hours and 41 minutes
I0614 17:18:04.925088  9229 solver.cpp:291]     Train net output #0: loss = 0.113609 (* 1 = 0.113609 loss)
I0614 17:18:04.925096  9229 sgd_solver.cpp:106] Iteration 2150, lr = 0.001
I0614 17:18:17.548298  9229 solver.cpp:270] Iteration 2200 (3.96109 iter/s, 12.6228s/50 iter), loss = 0.102099, remaining 0 hours and 41 minutes
I0614 17:18:17.548558  9229 solver.cpp:291]     Train net output #0: loss = 0.102099 (* 1 = 0.102099 loss)
I0614 17:18:17.548566  9229 sgd_solver.cpp:106] Iteration 2200, lr = 0.001
I0614 17:18:30.166275  9229 solver.cpp:270] Iteration 2250 (3.96281 iter/s, 12.6173s/50 iter), loss = 0.0297009, remaining 0 hours and 40 minutes
I0614 17:18:30.166306  9229 solver.cpp:291]     Train net output #0: loss = 0.0297009 (* 1 = 0.0297009 loss)
I0614 17:18:30.166314  9229 sgd_solver.cpp:106] Iteration 2250, lr = 0.001
I0614 17:18:42.797122  9229 solver.cpp:270] Iteration 2300 (3.9587 iter/s, 12.6304s/50 iter), loss = 0.0531884, remaining 0 hours and 40 minutes
I0614 17:18:42.797153  9229 solver.cpp:291]     Train net output #0: loss = 0.0531884 (* 1 = 0.0531884 loss)
I0614 17:18:42.797163  9229 sgd_solver.cpp:106] Iteration 2300, lr = 0.001
I0614 17:18:55.413856  9229 solver.cpp:270] Iteration 2350 (3.96313 iter/s, 12.6163s/50 iter), loss = 0.127739, remaining 0 hours and 40 minutes
I0614 17:18:55.414108  9229 solver.cpp:291]     Train net output #0: loss = 0.127739 (* 1 = 0.127739 loss)
I0614 17:18:55.414116  9229 sgd_solver.cpp:106] Iteration 2350, lr = 0.001
I0614 17:19:08.044917  9229 solver.cpp:270] Iteration 2400 (3.9587 iter/s, 12.6304s/50 iter), loss = 0.0527478, remaining 0 hours and 40 minutes
I0614 17:19:08.044950  9229 solver.cpp:291]     Train net output #0: loss = 0.0527478 (* 1 = 0.0527478 loss)
I0614 17:19:08.044956  9229 sgd_solver.cpp:106] Iteration 2400, lr = 0.001
I0614 17:19:20.692057  9229 solver.cpp:270] Iteration 2450 (3.9536 iter/s, 12.6467s/50 iter), loss = 0.0728784, remaining 0 hours and 40 minutes
I0614 17:19:20.692090  9229 solver.cpp:291]     Train net output #0: loss = 0.0728784 (* 1 = 0.0728784 loss)
I0614 17:19:20.692096  9229 sgd_solver.cpp:106] Iteration 2450, lr = 0.001
I0614 17:19:33.321667  9229 solver.cpp:270] Iteration 2500 (3.95909 iter/s, 12.6292s/50 iter), loss = 0.136449, remaining 0 hours and 39 minutes
I0614 17:19:33.321864  9229 solver.cpp:291]     Train net output #0: loss = 0.136449 (* 1 = 0.136449 loss)
I0614 17:19:33.321888  9229 sgd_solver.cpp:106] Iteration 2500, lr = 0.0001
I0614 17:19:45.939556  9229 solver.cpp:270] Iteration 2550 (3.96282 iter/s, 12.6173s/50 iter), loss = 0.0823605, remaining 0 hours and 39 minutes
I0614 17:19:45.939587  9229 solver.cpp:291]     Train net output #0: loss = 0.0823605 (* 1 = 0.0823605 loss)
I0614 17:19:45.939594  9229 sgd_solver.cpp:106] Iteration 2550, lr = 0.0001
I0614 17:19:58.556851  9229 solver.cpp:270] Iteration 2600 (3.96295 iter/s, 12.6169s/50 iter), loss = 0.043683, remaining 0 hours and 39 minutes
I0614 17:19:58.556883  9229 solver.cpp:291]     Train net output #0: loss = 0.043683 (* 1 = 0.043683 loss)
I0614 17:19:58.556891  9229 sgd_solver.cpp:106] Iteration 2600, lr = 0.0001
I0614 17:20:11.190610  9229 solver.cpp:270] Iteration 2650 (3.95779 iter/s, 12.6333s/50 iter), loss = 0.0232288, remaining 0 hours and 39 minutes
I0614 17:20:11.190866  9229 solver.cpp:291]     Train net output #0: loss = 0.0232288 (* 1 = 0.0232288 loss)
I0614 17:20:11.190873  9229 sgd_solver.cpp:106] Iteration 2650, lr = 0.0001
I0614 17:20:23.819072  9229 solver.cpp:270] Iteration 2700 (3.95952 iter/s, 12.6278s/50 iter), loss = 0.0382397, remaining 0 hours and 39 minutes
I0614 17:20:23.819103  9229 solver.cpp:291]     Train net output #0: loss = 0.0382397 (* 1 = 0.0382397 loss)
I0614 17:20:23.819109  9229 sgd_solver.cpp:106] Iteration 2700, lr = 0.0001
I0614 17:20:36.439113  9229 solver.cpp:270] Iteration 2750 (3.96209 iter/s, 12.6196s/50 iter), loss = 0.0425269, remaining 0 hours and 38 minutes
I0614 17:20:36.439146  9229 solver.cpp:291]     Train net output #0: loss = 0.0425269 (* 1 = 0.0425269 loss)
I0614 17:20:36.439153  9229 sgd_solver.cpp:106] Iteration 2750, lr = 0.0001
I0614 17:20:49.057360  9229 solver.cpp:270] Iteration 2800 (3.96265 iter/s, 12.6178s/50 iter), loss = 0.0264635, remaining 0 hours and 38 minutes
I0614 17:20:49.057598  9229 solver.cpp:291]     Train net output #0: loss = 0.0264635 (* 1 = 0.0264635 loss)
I0614 17:20:49.057606  9229 sgd_solver.cpp:106] Iteration 2800, lr = 0.0001
I0614 17:21:01.676828  9229 solver.cpp:270] Iteration 2850 (3.96233 iter/s, 12.6188s/50 iter), loss = 0.0342982, remaining 0 hours and 38 minutes
I0614 17:21:01.676860  9229 solver.cpp:291]     Train net output #0: loss = 0.0342982 (* 1 = 0.0342982 loss)
I0614 17:21:01.676867  9229 sgd_solver.cpp:106] Iteration 2850, lr = 0.0001
I0614 17:21:14.283533  9229 solver.cpp:270] Iteration 2900 (3.96628 iter/s, 12.6063s/50 iter), loss = 0.0592551, remaining 0 hours and 38 minutes
I0614 17:21:14.283565  9229 solver.cpp:291]     Train net output #0: loss = 0.0592551 (* 1 = 0.0592551 loss)
I0614 17:21:14.283572  9229 sgd_solver.cpp:106] Iteration 2900, lr = 0.0001
I0614 17:21:26.904311  9229 solver.cpp:270] Iteration 2950 (3.96186 iter/s, 12.6203s/50 iter), loss = 0.0428653, remaining 0 hours and 37 minutes
I0614 17:21:26.904651  9229 solver.cpp:291]     Train net output #0: loss = 0.0428653 (* 1 = 0.0428653 loss)
I0614 17:21:26.904659  9229 sgd_solver.cpp:106] Iteration 2950, lr = 0.0001
I0614 17:21:39.291286  9229 solver.cpp:424] Iteration 3000, Testing net (#0)
I0614 17:21:40.794106  9229 solver.cpp:523]     Test net output #0: accuracy = 0.94575
I0614 17:21:40.794133  9229 solver.cpp:523]     Test net output #1: loss = 0.127911 (* 1 = 0.127911 loss)
I0614 17:21:40.794138  9229 solver.cpp:523]     Test net output #2: top-1 = 0.94575
I0614 17:21:41.040797  9229 solver.cpp:270] Iteration 3000 (3.53715 iter/s, 14.1357s/50 iter), loss = 0.0243702, remaining 0 hours and 42 minutes
I0614 17:21:41.040828  9229 solver.cpp:291]     Train net output #0: loss = 0.0243702 (* 1 = 0.0243702 loss)
I0614 17:21:41.040851  9229 sgd_solver.cpp:106] Iteration 3000, lr = 0.0001
I0614 17:21:53.670858  9229 solver.cpp:270] Iteration 3050 (3.95895 iter/s, 12.6296s/50 iter), loss = 0.0756375, remaining 0 hours and 37 minutes
I0614 17:21:53.670889  9229 solver.cpp:291]     Train net output #0: loss = 0.0756375 (* 1 = 0.0756375 loss)
I0614 17:21:53.670897  9229 sgd_solver.cpp:106] Iteration 3050, lr = 0.0001
I0614 17:22:06.289471  9229 solver.cpp:270] Iteration 3100 (3.96254 iter/s, 12.6182s/50 iter), loss = 0.0120353, remaining 0 hours and 37 minutes
I0614 17:22:06.289724  9229 solver.cpp:291]     Train net output #0: loss = 0.0120353 (* 1 = 0.0120353 loss)
I0614 17:22:06.289732  9229 sgd_solver.cpp:106] Iteration 3100, lr = 0.0001
I0614 17:22:18.917253  9229 solver.cpp:270] Iteration 3150 (3.95973 iter/s, 12.6271s/50 iter), loss = 0.0696223, remaining 0 hours and 37 minutes
I0614 17:22:18.917285  9229 solver.cpp:291]     Train net output #0: loss = 0.0696223 (* 1 = 0.0696223 loss)
I0614 17:22:18.917292  9229 sgd_solver.cpp:106] Iteration 3150, lr = 0.0001
I0614 17:22:31.561193  9229 solver.cpp:270] Iteration 3200 (3.9546 iter/s, 12.6435s/50 iter), loss = 0.012167, remaining 0 hours and 36 minutes
I0614 17:22:31.561225  9229 solver.cpp:291]     Train net output #0: loss = 0.0121671 (* 1 = 0.0121671 loss)
I0614 17:22:31.561233  9229 sgd_solver.cpp:106] Iteration 3200, lr = 0.0001
I0614 17:22:44.188338  9229 solver.cpp:270] Iteration 3250 (3.95986 iter/s, 12.6267s/50 iter), loss = 0.0304064, remaining 0 hours and 36 minutes
I0614 17:22:44.188597  9229 solver.cpp:291]     Train net output #0: loss = 0.0304064 (* 1 = 0.0304064 loss)
I0614 17:22:44.188622  9229 sgd_solver.cpp:106] Iteration 3250, lr = 0.0001
I0614 17:22:56.804167  9229 solver.cpp:270] Iteration 3300 (3.96349 iter/s, 12.6152s/50 iter), loss = 0.0189364, remaining 0 hours and 36 minutes
I0614 17:22:56.804199  9229 solver.cpp:291]     Train net output #0: loss = 0.0189365 (* 1 = 0.0189365 loss)
I0614 17:22:56.804222  9229 sgd_solver.cpp:106] Iteration 3300, lr = 0.0001
I0614 17:23:09.433444  9229 solver.cpp:270] Iteration 3350 (3.95919 iter/s, 12.6288s/50 iter), loss = 0.0184153, remaining 0 hours and 36 minutes
I0614 17:23:09.433476  9229 solver.cpp:291]     Train net output #0: loss = 0.0184154 (* 1 = 0.0184154 loss)
I0614 17:23:09.433483  9229 sgd_solver.cpp:106] Iteration 3350, lr = 0.0001
I0614 17:23:22.057368  9229 solver.cpp:270] Iteration 3400 (3.96087 iter/s, 12.6235s/50 iter), loss = 0.0440544, remaining 0 hours and 36 minutes
I0614 17:23:22.057695  9229 solver.cpp:291]     Train net output #0: loss = 0.0440544 (* 1 = 0.0440544 loss)
I0614 17:23:22.057703  9229 sgd_solver.cpp:106] Iteration 3400, lr = 0.0001
I0614 17:23:34.668273  9229 solver.cpp:270] Iteration 3450 (3.96505 iter/s, 12.6102s/50 iter), loss = 0.0179626, remaining 0 hours and 35 minutes
I0614 17:23:34.668306  9229 solver.cpp:291]     Train net output #0: loss = 0.0179626 (* 1 = 0.0179626 loss)
I0614 17:23:34.668314  9229 sgd_solver.cpp:106] Iteration 3450, lr = 0.0001
I0614 17:23:47.295097  9229 solver.cpp:270] Iteration 3500 (3.95996 iter/s, 12.6264s/50 iter), loss = 0.0183581, remaining 0 hours and 35 minutes
I0614 17:23:47.295126  9229 solver.cpp:291]     Train net output #0: loss = 0.0183582 (* 1 = 0.0183582 loss)
I0614 17:23:47.295133  9229 sgd_solver.cpp:106] Iteration 3500, lr = 0.0001
I0614 17:23:59.903666  9229 solver.cpp:270] Iteration 3550 (3.96569 iter/s, 12.6081s/50 iter), loss = 0.0390715, remaining 0 hours and 35 minutes
I0614 17:23:59.903928  9229 solver.cpp:291]     Train net output #0: loss = 0.0390715 (* 1 = 0.0390715 loss)
I0614 17:23:59.903934  9229 sgd_solver.cpp:106] Iteration 3550, lr = 0.0001
I0614 17:24:12.538997  9229 solver.cpp:270] Iteration 3600 (3.95737 iter/s, 12.6347s/50 iter), loss = 0.0235478, remaining 0 hours and 35 minutes
I0614 17:24:12.539029  9229 solver.cpp:291]     Train net output #0: loss = 0.0235478 (* 1 = 0.0235478 loss)
I0614 17:24:12.539036  9229 sgd_solver.cpp:106] Iteration 3600, lr = 0.0001
I0614 17:24:25.171306  9229 solver.cpp:270] Iteration 3650 (3.95824 iter/s, 12.6319s/50 iter), loss = 0.0109697, remaining 0 hours and 35 minutes
I0614 17:24:25.171339  9229 solver.cpp:291]     Train net output #0: loss = 0.0109697 (* 1 = 0.0109697 loss)
I0614 17:24:25.171345  9229 sgd_solver.cpp:106] Iteration 3650, lr = 0.0001
I0614 17:24:37.794718  9229 solver.cpp:270] Iteration 3700 (3.96103 iter/s, 12.623s/50 iter), loss = 0.00433635, remaining 0 hours and 34 minutes
I0614 17:24:37.794972  9229 solver.cpp:291]     Train net output #0: loss = 0.00433636 (* 1 = 0.00433636 loss)
I0614 17:24:37.794996  9229 sgd_solver.cpp:106] Iteration 3700, lr = 0.0001
I0614 17:24:50.414711  9229 solver.cpp:270] Iteration 3750 (3.96218 iter/s, 12.6193s/50 iter), loss = 0.0179199, remaining 0 hours and 34 minutes
I0614 17:24:50.414742  9229 solver.cpp:291]     Train net output #0: loss = 0.0179199 (* 1 = 0.0179199 loss)
I0614 17:24:50.414748  9229 sgd_solver.cpp:106] Iteration 3750, lr = 0.0001
I0614 17:25:03.035526  9229 solver.cpp:270] Iteration 3800 (3.96185 iter/s, 12.6204s/50 iter), loss = 0.0241443, remaining 0 hours and 34 minutes
I0614 17:25:03.035558  9229 solver.cpp:291]     Train net output #0: loss = 0.0241443 (* 1 = 0.0241443 loss)
I0614 17:25:03.035565  9229 sgd_solver.cpp:106] Iteration 3800, lr = 0.0001
I0614 17:25:15.668864  9229 solver.cpp:270] Iteration 3850 (3.95792 iter/s, 12.6329s/50 iter), loss = 0.0222292, remaining 0 hours and 34 minutes
I0614 17:25:15.669111  9229 solver.cpp:291]     Train net output #0: loss = 0.0222292 (* 1 = 0.0222292 loss)
I0614 17:25:15.669134  9229 sgd_solver.cpp:106] Iteration 3850, lr = 0.0001
I0614 17:25:28.293238  9229 solver.cpp:270] Iteration 3900 (3.9608 iter/s, 12.6237s/50 iter), loss = 0.00414616, remaining 0 hours and 34 minutes
I0614 17:25:28.293270  9229 solver.cpp:291]     Train net output #0: loss = 0.00414617 (* 1 = 0.00414617 loss)
I0614 17:25:28.293277  9229 sgd_solver.cpp:106] Iteration 3900, lr = 0.0001
I0614 17:25:40.906428  9229 solver.cpp:270] Iteration 3950 (3.96424 iter/s, 12.6127s/50 iter), loss = 0.00835623, remaining 0 hours and 33 minutes
I0614 17:25:40.906461  9229 solver.cpp:291]     Train net output #0: loss = 0.00835625 (* 1 = 0.00835625 loss)
I0614 17:25:40.906483  9229 sgd_solver.cpp:106] Iteration 3950, lr = 0.0001
I0614 17:25:53.275229  9229 solver.cpp:424] Iteration 4000, Testing net (#0)
I0614 17:25:54.756570  9229 solver.cpp:523]     Test net output #0: accuracy = 0.95625
I0614 17:25:54.756598  9229 solver.cpp:523]     Test net output #1: loss = 0.114107 (* 1 = 0.114107 loss)
I0614 17:25:54.756603  9229 solver.cpp:523]     Test net output #2: top-1 = 0.95625
I0614 17:25:55.003536  9229 solver.cpp:270] Iteration 4000 (3.54695 iter/s, 14.0966s/50 iter), loss = 0.0155353, remaining 0 hours and 37 minutes
I0614 17:25:55.003567  9229 solver.cpp:291]     Train net output #0: loss = 0.0155353 (* 1 = 0.0155353 loss)
I0614 17:25:55.003574  9229 sgd_solver.cpp:106] Iteration 4000, lr = 0.0001
I0614 17:26:07.639948  9229 solver.cpp:270] Iteration 4050 (3.95696 iter/s, 12.636s/50 iter), loss = 0.0166527, remaining 0 hours and 33 minutes
I0614 17:26:07.639978  9229 solver.cpp:291]     Train net output #0: loss = 0.0166528 (* 1 = 0.0166528 loss)
I0614 17:26:07.639986  9229 sgd_solver.cpp:106] Iteration 4050, lr = 0.0001
I0614 17:26:20.293710  9229 solver.cpp:270] Iteration 4100 (3.95153 iter/s, 12.6533s/50 iter), loss = 0.0102296, remaining 0 hours and 33 minutes
I0614 17:26:20.293742  9229 solver.cpp:291]     Train net output #0: loss = 0.0102296 (* 1 = 0.0102296 loss)
I0614 17:26:20.293749  9229 sgd_solver.cpp:106] Iteration 4100, lr = 0.0001
I0614 17:26:32.925247  9229 solver.cpp:270] Iteration 4150 (3.95848 iter/s, 12.6311s/50 iter), loss = 0.0516527, remaining 0 hours and 32 minutes
I0614 17:26:32.925596  9229 solver.cpp:291]     Train net output #0: loss = 0.0516528 (* 1 = 0.0516528 loss)
I0614 17:26:32.925621  9229 sgd_solver.cpp:106] Iteration 4150, lr = 0.0001
I0614 17:26:45.549443  9229 solver.cpp:270] Iteration 4200 (3.96089 iter/s, 12.6234s/50 iter), loss = 0.00605866, remaining 0 hours and 32 minutes
I0614 17:26:45.549472  9229 solver.cpp:291]     Train net output #0: loss = 0.00605868 (* 1 = 0.00605868 loss)
I0614 17:26:45.549479  9229 sgd_solver.cpp:106] Iteration 4200, lr = 0.0001
I0614 17:26:58.153235  9229 solver.cpp:270] Iteration 4250 (3.9672 iter/s, 12.6034s/50 iter), loss = 0.0336945, remaining 0 hours and 32 minutes
I0614 17:26:58.153267  9229 solver.cpp:291]     Train net output #0: loss = 0.0336946 (* 1 = 0.0336946 loss)
I0614 17:26:58.153275  9229 sgd_solver.cpp:106] Iteration 4250, lr = 0.0001
I0614 17:27:10.764643  9229 solver.cpp:270] Iteration 4300 (3.9648 iter/s, 12.611s/50 iter), loss = 0.0124752, remaining 0 hours and 32 minutes
I0614 17:27:10.764891  9229 solver.cpp:291]     Train net output #0: loss = 0.0124752 (* 1 = 0.0124752 loss)
I0614 17:27:10.764915  9229 sgd_solver.cpp:106] Iteration 4300, lr = 0.0001
I0614 17:27:23.401419  9229 solver.cpp:270] Iteration 4350 (3.95691 iter/s, 12.6361s/50 iter), loss = 0.0139646, remaining 0 hours and 32 minutes
I0614 17:27:23.401450  9229 solver.cpp:291]     Train net output #0: loss = 0.0139646 (* 1 = 0.0139646 loss)
I0614 17:27:23.401458  9229 sgd_solver.cpp:106] Iteration 4350, lr = 0.0001
I0614 17:27:36.050489  9229 solver.cpp:270] Iteration 4400 (3.953 iter/s, 12.6486s/50 iter), loss = 0.0148622, remaining 0 hours and 31 minutes
I0614 17:27:36.050521  9229 solver.cpp:291]     Train net output #0: loss = 0.0148622 (* 1 = 0.0148622 loss)
I0614 17:27:36.050544  9229 sgd_solver.cpp:106] Iteration 4400, lr = 0.0001
I0614 17:27:48.676496  9229 solver.cpp:270] Iteration 4450 (3.96022 iter/s, 12.6256s/50 iter), loss = 0.00416069, remaining 0 hours and 31 minutes
I0614 17:27:48.676756  9229 solver.cpp:291]     Train net output #0: loss = 0.00416072 (* 1 = 0.00416072 loss)
I0614 17:27:48.676780  9229 sgd_solver.cpp:106] Iteration 4450, lr = 0.0001
I0614 17:28:01.296299  9229 solver.cpp:270] Iteration 4500 (3.96224 iter/s, 12.6191s/50 iter), loss = 0.0154601, remaining 0 hours and 31 minutes
I0614 17:28:01.296330  9229 solver.cpp:291]     Train net output #0: loss = 0.0154601 (* 1 = 0.0154601 loss)
I0614 17:28:01.296337  9229 sgd_solver.cpp:106] Iteration 4500, lr = 0.0001
I0614 17:28:13.932957  9229 solver.cpp:270] Iteration 4550 (3.95688 iter/s, 12.6362s/50 iter), loss = 0.0115053, remaining 0 hours and 31 minutes
I0614 17:28:13.932987  9229 solver.cpp:291]     Train net output #0: loss = 0.0115053 (* 1 = 0.0115053 loss)
I0614 17:28:13.932994  9229 sgd_solver.cpp:106] Iteration 4550, lr = 0.0001
I0614 17:28:26.559352  9229 solver.cpp:270] Iteration 4600 (3.9601 iter/s, 12.626s/50 iter), loss = 0.0116733, remaining 0 hours and 31 minutes
I0614 17:28:26.559690  9229 solver.cpp:291]     Train net output #0: loss = 0.0116733 (* 1 = 0.0116733 loss)
I0614 17:28:26.559698  9229 sgd_solver.cpp:106] Iteration 4600, lr = 0.0001
I0614 17:28:39.192482  9229 solver.cpp:270] Iteration 4650 (3.95808 iter/s, 12.6324s/50 iter), loss = 0.0283316, remaining 0 hours and 30 minutes
I0614 17:28:39.192512  9229 solver.cpp:291]     Train net output #0: loss = 0.0283316 (* 1 = 0.0283316 loss)
I0614 17:28:39.192520  9229 sgd_solver.cpp:106] Iteration 4650, lr = 0.0001
I0614 17:28:51.794098  9229 solver.cpp:270] Iteration 4700 (3.96788 iter/s, 12.6012s/50 iter), loss = 0.0213922, remaining 0 hours and 30 minutes
I0614 17:28:51.794129  9229 solver.cpp:291]     Train net output #0: loss = 0.0213922 (* 1 = 0.0213922 loss)
I0614 17:28:51.794137  9229 sgd_solver.cpp:106] Iteration 4700, lr = 0.0001
I0614 17:29:04.436885  9229 solver.cpp:270] Iteration 4750 (3.95496 iter/s, 12.6423s/50 iter), loss = 0.0237902, remaining 0 hours and 30 minutes
I0614 17:29:04.437103  9229 solver.cpp:291]     Train net output #0: loss = 0.0237902 (* 1 = 0.0237902 loss)
I0614 17:29:04.437126  9229 sgd_solver.cpp:106] Iteration 4750, lr = 0.0001
I0614 17:29:17.075830  9229 solver.cpp:270] Iteration 4800 (3.95622 iter/s, 12.6383s/50 iter), loss = 0.0118218, remaining 0 hours and 30 minutes
I0614 17:29:17.075861  9229 solver.cpp:291]     Train net output #0: loss = 0.0118218 (* 1 = 0.0118218 loss)
I0614 17:29:17.075868  9229 sgd_solver.cpp:106] Iteration 4800, lr = 0.0001
I0614 17:29:29.687793  9229 solver.cpp:270] Iteration 4850 (3.96463 iter/s, 12.6115s/50 iter), loss = 0.0119467, remaining 0 hours and 30 minutes
I0614 17:29:29.687824  9229 solver.cpp:291]     Train net output #0: loss = 0.0119468 (* 1 = 0.0119468 loss)
I0614 17:29:29.687846  9229 sgd_solver.cpp:106] Iteration 4850, lr = 0.0001
I0614 17:29:42.308259  9229 solver.cpp:270] Iteration 4900 (3.96196 iter/s, 12.62s/50 iter), loss = 0.0108733, remaining 0 hours and 29 minutes
I0614 17:29:42.308517  9229 solver.cpp:291]     Train net output #0: loss = 0.0108734 (* 1 = 0.0108734 loss)
I0614 17:29:42.308526  9229 sgd_solver.cpp:106] Iteration 4900, lr = 0.0001
I0614 17:29:54.952841  9229 solver.cpp:270] Iteration 4950 (3.95447 iter/s, 12.6439s/50 iter), loss = 0.0177511, remaining 0 hours and 29 minutes
I0614 17:29:54.952872  9229 solver.cpp:291]     Train net output #0: loss = 0.0177511 (* 1 = 0.0177511 loss)
I0614 17:29:54.952880  9229 sgd_solver.cpp:106] Iteration 4950, lr = 0.0001
I0614 17:30:07.323640  9229 solver.cpp:424] Iteration 5000, Testing net (#0)
I0614 17:30:08.828361  9229 solver.cpp:523]     Test net output #0: accuracy = 0.9575
I0614 17:30:08.828389  9229 solver.cpp:523]     Test net output #1: loss = 0.138403 (* 1 = 0.138403 loss)
I0614 17:30:08.828394  9229 solver.cpp:523]     Test net output #2: top-1 = 0.9575
I0614 17:30:09.074949  9229 solver.cpp:270] Iteration 5000 (3.54067 iter/s, 14.1216s/50 iter), loss = 0.0267817, remaining 0 hours and 32 minutes
I0614 17:30:09.074978  9229 solver.cpp:291]     Train net output #0: loss = 0.0267817 (* 1 = 0.0267817 loss)
I0614 17:30:09.074986  9229 sgd_solver.cpp:106] Iteration 5000, lr = 1e-05
I0614 17:30:21.694141  9229 solver.cpp:270] Iteration 5050 (3.96236 iter/s, 12.6188s/50 iter), loss = 0.0343208, remaining 0 hours and 29 minutes
I0614 17:30:21.694357  9229 solver.cpp:291]     Train net output #0: loss = 0.0343208 (* 1 = 0.0343208 loss)
I0614 17:30:21.694381  9229 sgd_solver.cpp:106] Iteration 5050, lr = 1e-05
I0614 17:30:34.313848  9229 solver.cpp:270] Iteration 5100 (3.96225 iter/s, 12.6191s/50 iter), loss = 0.0272238, remaining 0 hours and 29 minutes
I0614 17:30:34.313880  9229 solver.cpp:291]     Train net output #0: loss = 0.0272239 (* 1 = 0.0272239 loss)
I0614 17:30:34.313903  9229 sgd_solver.cpp:106] Iteration 5100, lr = 1e-05
I0614 17:30:46.930660  9229 solver.cpp:270] Iteration 5150 (3.96311 iter/s, 12.6164s/50 iter), loss = 0.00523238, remaining 0 hours and 28 minutes
I0614 17:30:46.930691  9229 solver.cpp:291]     Train net output #0: loss = 0.00523239 (* 1 = 0.00523239 loss)
I0614 17:30:46.930698  9229 sgd_solver.cpp:106] Iteration 5150, lr = 1e-05
I0614 17:30:59.538853  9229 solver.cpp:270] Iteration 5200 (3.96581 iter/s, 12.6078s/50 iter), loss = 0.0161554, remaining 0 hours and 28 minutes
I0614 17:30:59.539186  9229 solver.cpp:291]     Train net output #0: loss = 0.0161555 (* 1 = 0.0161555 loss)
I0614 17:30:59.539209  9229 sgd_solver.cpp:106] Iteration 5200, lr = 1e-05
I0614 17:31:12.186125  9229 solver.cpp:270] Iteration 5250 (3.95365 iter/s, 12.6465s/50 iter), loss = 0.0112517, remaining 0 hours and 28 minutes
I0614 17:31:12.186156  9229 solver.cpp:291]     Train net output #0: loss = 0.0112517 (* 1 = 0.0112517 loss)
I0614 17:31:12.186162  9229 sgd_solver.cpp:106] Iteration 5250, lr = 1e-05
I0614 17:31:24.821892  9229 solver.cpp:270] Iteration 5300 (3.95716 iter/s, 12.6353s/50 iter), loss = 0.00491457, remaining 0 hours and 28 minutes
I0614 17:31:24.821923  9229 solver.cpp:291]     Train net output #0: loss = 0.00491459 (* 1 = 0.00491459 loss)
I0614 17:31:24.821930  9229 sgd_solver.cpp:106] Iteration 5300, lr = 1e-05
I0614 17:31:37.439180  9229 solver.cpp:270] Iteration 5350 (3.96295 iter/s, 12.6168s/50 iter), loss = 0.00551269, remaining 0 hours and 27 minutes
I0614 17:31:37.439433  9229 solver.cpp:291]     Train net output #0: loss = 0.00551271 (* 1 = 0.00551271 loss)
I0614 17:31:37.439443  9229 sgd_solver.cpp:106] Iteration 5350, lr = 1e-05
I0614 17:31:50.077226  9229 solver.cpp:270] Iteration 5400 (3.95652 iter/s, 12.6374s/50 iter), loss = 0.013137, remaining 0 hours and 27 minutes
I0614 17:31:50.077256  9229 solver.cpp:291]     Train net output #0: loss = 0.0131371 (* 1 = 0.0131371 loss)
I0614 17:31:50.077263  9229 sgd_solver.cpp:106] Iteration 5400, lr = 1e-05
I0614 17:32:02.720672  9229 solver.cpp:270] Iteration 5450 (3.95476 iter/s, 12.643s/50 iter), loss = 0.0107369, remaining 0 hours and 27 minutes
I0614 17:32:02.720705  9229 solver.cpp:291]     Train net output #0: loss = 0.0107369 (* 1 = 0.0107369 loss)
I0614 17:32:02.720727  9229 sgd_solver.cpp:106] Iteration 5450, lr = 1e-05
I0614 17:32:15.324797  9229 solver.cpp:270] Iteration 5500 (3.96709 iter/s, 12.6037s/50 iter), loss = 0.0274723, remaining 0 hours and 27 minutes
I0614 17:32:15.325050  9229 solver.cpp:291]     Train net output #0: loss = 0.0274723 (* 1 = 0.0274723 loss)
I0614 17:32:15.325073  9229 sgd_solver.cpp:106] Iteration 5500, lr = 1e-05
I0614 17:32:27.948388  9229 solver.cpp:270] Iteration 5550 (3.96105 iter/s, 12.6229s/50 iter), loss = 0.0472588, remaining 0 hours and 27 minutes
I0614 17:32:27.948418  9229 solver.cpp:291]     Train net output #0: loss = 0.0472588 (* 1 = 0.0472588 loss)
I0614 17:32:27.948426  9229 sgd_solver.cpp:106] Iteration 5550, lr = 1e-05
I0614 17:32:40.553380  9229 solver.cpp:270] Iteration 5600 (3.96682 iter/s, 12.6045s/50 iter), loss = 0.0166654, remaining 0 hours and 26 minutes
I0614 17:32:40.553411  9229 solver.cpp:291]     Train net output #0: loss = 0.0166655 (* 1 = 0.0166655 loss)
I0614 17:32:40.553434  9229 sgd_solver.cpp:106] Iteration 5600, lr = 1e-05
I0614 17:32:53.170676  9229 solver.cpp:270] Iteration 5650 (3.96295 iter/s, 12.6169s/50 iter), loss = 0.00908584, remaining 0 hours and 26 minutes
I0614 17:32:53.170934  9229 solver.cpp:291]     Train net output #0: loss = 0.00908587 (* 1 = 0.00908587 loss)
I0614 17:32:53.170958  9229 sgd_solver.cpp:106] Iteration 5650, lr = 1e-05
I0614 17:33:05.787472  9229 solver.cpp:270] Iteration 5700 (3.96318 iter/s, 12.6161s/50 iter), loss = 0.00204903, remaining 0 hours and 26 minutes
I0614 17:33:05.787503  9229 solver.cpp:291]     Train net output #0: loss = 0.00204907 (* 1 = 0.00204907 loss)
I0614 17:33:05.787509  9229 sgd_solver.cpp:106] Iteration 5700, lr = 1e-05
I0614 17:33:18.411681  9229 solver.cpp:270] Iteration 5750 (3.96078 iter/s, 12.6238s/50 iter), loss = 0.0163907, remaining 0 hours and 26 minutes
I0614 17:33:18.411711  9229 solver.cpp:291]     Train net output #0: loss = 0.0163907 (* 1 = 0.0163907 loss)
I0614 17:33:18.411720  9229 sgd_solver.cpp:106] Iteration 5750, lr = 1e-05
I0614 17:33:31.045976  9229 solver.cpp:270] Iteration 5800 (3.95762 iter/s, 12.6339s/50 iter), loss = 0.00464841, remaining 0 hours and 26 minutes
I0614 17:33:31.046308  9229 solver.cpp:291]     Train net output #0: loss = 0.00464844 (* 1 = 0.00464844 loss)
I0614 17:33:31.046315  9229 sgd_solver.cpp:106] Iteration 5800, lr = 1e-05
I0614 17:33:43.675877  9229 solver.cpp:270] Iteration 5850 (3.95909 iter/s, 12.6292s/50 iter), loss = 0.00510556, remaining 0 hours and 25 minutes
I0614 17:33:43.675909  9229 solver.cpp:291]     Train net output #0: loss = 0.0051056 (* 1 = 0.0051056 loss)
I0614 17:33:43.675915  9229 sgd_solver.cpp:106] Iteration 5850, lr = 1e-05
I0614 17:33:56.301796  9229 solver.cpp:270] Iteration 5900 (3.96025 iter/s, 12.6255s/50 iter), loss = 0.0137868, remaining 0 hours and 25 minutes
I0614 17:33:56.301826  9229 solver.cpp:291]     Train net output #0: loss = 0.0137868 (* 1 = 0.0137868 loss)
I0614 17:33:56.301833  9229 sgd_solver.cpp:106] Iteration 5900, lr = 1e-05
I0614 17:34:08.941623  9229 solver.cpp:270] Iteration 5950 (3.95589 iter/s, 12.6394s/50 iter), loss = 0.0147735, remaining 0 hours and 25 minutes
I0614 17:34:08.941861  9229 solver.cpp:291]     Train net output #0: loss = 0.0147736 (* 1 = 0.0147736 loss)
I0614 17:34:08.941870  9229 sgd_solver.cpp:106] Iteration 5950, lr = 1e-05
I0614 17:34:21.315786  9229 solver.cpp:935] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.5/snapshots/_iter_6000.caffemodel
I0614 17:34:27.116420  9229 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.5/snapshots/_iter_6000.solverstate
I0614 17:34:30.582015  9229 solver.cpp:424] Iteration 6000, Testing net (#0)
I0614 17:34:31.992409  9229 solver.cpp:523]     Test net output #0: accuracy = 0.95875
I0614 17:34:31.992439  9229 solver.cpp:523]     Test net output #1: loss = 0.145358 (* 1 = 0.145358 loss)
I0614 17:34:31.992444  9229 solver.cpp:523]     Test net output #2: top-1 = 0.95875
I0614 17:34:32.228824  9229 solver.cpp:270] Iteration 6000 (2.14719 iter/s, 23.2862s/50 iter), loss = 0.00443532, remaining 0 hours and 46 minutes
I0614 17:34:32.228857  9229 solver.cpp:291]     Train net output #0: loss = 0.00443535 (* 1 = 0.00443535 loss)
I0614 17:34:32.228863  9229 sgd_solver.cpp:106] Iteration 6000, lr = 1e-05
I0614 17:34:44.781594  9229 solver.cpp:270] Iteration 6050 (3.98332 iter/s, 12.5523s/50 iter), loss = 0.0182139, remaining 0 hours and 24 minutes
I0614 17:34:44.781805  9229 solver.cpp:291]     Train net output #0: loss = 0.018214 (* 1 = 0.018214 loss)
I0614 17:34:44.781827  9229 sgd_solver.cpp:106] Iteration 6050, lr = 1e-05
I0614 17:34:57.362929  9229 solver.cpp:270] Iteration 6100 (3.97434 iter/s, 12.5807s/50 iter), loss = 0.0118566, remaining 0 hours and 24 minutes
I0614 17:34:57.362962  9229 solver.cpp:291]     Train net output #0: loss = 0.0118566 (* 1 = 0.0118566 loss)
I0614 17:34:57.362972  9229 sgd_solver.cpp:106] Iteration 6100, lr = 1e-05
I0614 17:35:09.938827  9229 solver.cpp:270] Iteration 6150 (3.976 iter/s, 12.5755s/50 iter), loss = 0.0277668, remaining 0 hours and 24 minutes
I0614 17:35:09.938859  9229 solver.cpp:291]     Train net output #0: loss = 0.0277668 (* 1 = 0.0277668 loss)
I0614 17:35:09.938867  9229 sgd_solver.cpp:106] Iteration 6150, lr = 1e-05
I0614 17:35:22.523360  9229 solver.cpp:270] Iteration 6200 (3.97327 iter/s, 12.5841s/50 iter), loss = 0.0040593, remaining 0 hours and 24 minutes
I0614 17:35:22.523593  9229 solver.cpp:291]     Train net output #0: loss = 0.00405934 (* 1 = 0.00405934 loss)
I0614 17:35:22.523617  9229 sgd_solver.cpp:106] Iteration 6200, lr = 1e-05
I0614 17:35:35.160373  9229 solver.cpp:270] Iteration 6250 (3.95683 iter/s, 12.6364s/50 iter), loss = 0.00285948, remaining 0 hours and 24 minutes
I0614 17:35:35.160403  9229 solver.cpp:291]     Train net output #0: loss = 0.00285952 (* 1 = 0.00285952 loss)
I0614 17:35:35.160411  9229 sgd_solver.cpp:106] Iteration 6250, lr = 1e-05
I0614 17:35:47.796689  9229 solver.cpp:270] Iteration 6300 (3.95699 iter/s, 12.6359s/50 iter), loss = 0.0131493, remaining 0 hours and 24 minutes
I0614 17:35:47.796720  9229 solver.cpp:291]     Train net output #0: loss = 0.0131493 (* 1 = 0.0131493 loss)
I0614 17:35:47.796743  9229 sgd_solver.cpp:106] Iteration 6300, lr = 1e-05
I0614 17:36:00.444728  9229 solver.cpp:270] Iteration 6350 (3.95332 iter/s, 12.6476s/50 iter), loss = 0.00958602, remaining 0 hours and 23 minutes
I0614 17:36:00.445008  9229 solver.cpp:291]     Train net output #0: loss = 0.00958606 (* 1 = 0.00958606 loss)
I0614 17:36:00.445034  9229 sgd_solver.cpp:106] Iteration 6350, lr = 1e-05
I0614 17:36:13.065296  9229 solver.cpp:270] Iteration 6400 (3.962 iter/s, 12.6199s/50 iter), loss = 0.00135624, remaining 0 hours and 23 minutes
I0614 17:36:13.065330  9229 solver.cpp:291]     Train net output #0: loss = 0.00135628 (* 1 = 0.00135628 loss)
I0614 17:36:13.065352  9229 sgd_solver.cpp:106] Iteration 6400, lr = 1e-05
I0614 17:36:25.703840  9229 solver.cpp:270] Iteration 6450 (3.95629 iter/s, 12.6381s/50 iter), loss = 0.000805881, remaining 0 hours and 23 minutes
I0614 17:36:25.703871  9229 solver.cpp:291]     Train net output #0: loss = 0.000805914 (* 1 = 0.000805914 loss)
I0614 17:36:25.703895  9229 sgd_solver.cpp:106] Iteration 6450, lr = 1e-05
I0614 17:36:38.339602  9229 solver.cpp:270] Iteration 6500 (3.95716 iter/s, 12.6353s/50 iter), loss = 0.0128846, remaining 0 hours and 22 minutes
I0614 17:36:38.339804  9229 solver.cpp:291]     Train net output #0: loss = 0.0128847 (* 1 = 0.0128847 loss)
I0614 17:36:38.339828  9229 sgd_solver.cpp:106] Iteration 6500, lr = 1e-05
I0614 17:36:50.986601  9229 solver.cpp:270] Iteration 6550 (3.9537 iter/s, 12.6464s/50 iter), loss = 0.0115765, remaining 0 hours and 22 minutes
I0614 17:36:50.986634  9229 solver.cpp:291]     Train net output #0: loss = 0.0115766 (* 1 = 0.0115766 loss)
I0614 17:36:50.986640  9229 sgd_solver.cpp:106] Iteration 6550, lr = 1e-05
I0614 17:37:03.638847  9229 solver.cpp:270] Iteration 6600 (3.95201 iter/s, 12.6518s/50 iter), loss = 0.0175261, remaining 0 hours and 22 minutes
I0614 17:37:03.638880  9229 solver.cpp:291]     Train net output #0: loss = 0.0175262 (* 1 = 0.0175262 loss)
I0614 17:37:03.638887  9229 sgd_solver.cpp:106] Iteration 6600, lr = 1e-05
I0614 17:37:16.289100  9229 solver.cpp:270] Iteration 6650 (3.95263 iter/s, 12.6498s/50 iter), loss = 0.001287, remaining 0 hours and 22 minutes
I0614 17:37:16.289309  9229 solver.cpp:291]     Train net output #0: loss = 0.00128704 (* 1 = 0.00128704 loss)
I0614 17:37:16.289316  9229 sgd_solver.cpp:106] Iteration 6650, lr = 1e-05
I0614 17:37:28.904237  9229 solver.cpp:270] Iteration 6700 (3.96369 iter/s, 12.6145s/50 iter), loss = 0.00701572, remaining 0 hours and 22 minutes
I0614 17:37:28.904269  9229 solver.cpp:291]     Train net output #0: loss = 0.00701576 (* 1 = 0.00701576 loss)
I0614 17:37:28.904278  9229 sgd_solver.cpp:106] Iteration 6700, lr = 1e-05
I0614 17:37:41.538688  9229 solver.cpp:270] Iteration 6750 (3.95757 iter/s, 12.634s/50 iter), loss = 0.014015, remaining 0 hours and 21 minutes
I0614 17:37:41.538719  9229 solver.cpp:291]     Train net output #0: loss = 0.0140151 (* 1 = 0.0140151 loss)
I0614 17:37:41.538726  9229 sgd_solver.cpp:106] Iteration 6750, lr = 1e-05
I0614 17:37:54.177075  9229 solver.cpp:270] Iteration 6800 (3.95634 iter/s, 12.6379s/50 iter), loss = 0.00741968, remaining 0 hours and 21 minutes
I0614 17:37:54.177316  9229 solver.cpp:291]     Train net output #0: loss = 0.00741972 (* 1 = 0.00741972 loss)
I0614 17:37:54.177340  9229 sgd_solver.cpp:106] Iteration 6800, lr = 1e-05
I0614 17:38:06.818564  9229 solver.cpp:270] Iteration 6850 (3.95543 iter/s, 12.6408s/50 iter), loss = 0.000796653, remaining 0 hours and 21 minutes
I0614 17:38:06.818595  9229 solver.cpp:291]     Train net output #0: loss = 0.000796694 (* 1 = 0.000796694 loss)
I0614 17:38:06.818603  9229 sgd_solver.cpp:106] Iteration 6850, lr = 1e-05
I0614 17:38:19.454164  9229 solver.cpp:270] Iteration 6900 (3.95721 iter/s, 12.6352s/50 iter), loss = 0.00347628, remaining 0 hours and 21 minutes
I0614 17:38:19.454195  9229 solver.cpp:291]     Train net output #0: loss = 0.00347632 (* 1 = 0.00347632 loss)
I0614 17:38:19.454203  9229 sgd_solver.cpp:106] Iteration 6900, lr = 1e-05
I0614 17:38:32.077616  9229 solver.cpp:270] Iteration 6950 (3.96102 iter/s, 12.623s/50 iter), loss = 0.00646386, remaining 0 hours and 21 minutes
I0614 17:38:32.077952  9229 solver.cpp:291]     Train net output #0: loss = 0.0064639 (* 1 = 0.0064639 loss)
I0614 17:38:32.077960  9229 sgd_solver.cpp:106] Iteration 6950, lr = 1e-05
I0614 17:38:44.457906  9229 solver.cpp:424] Iteration 7000, Testing net (#0)
I0614 17:38:45.954792  9229 solver.cpp:523]     Test net output #0: accuracy = 0.95875
I0614 17:38:45.954821  9229 solver.cpp:523]     Test net output #1: loss = 0.167884 (* 1 = 0.167884 loss)
I0614 17:38:45.954826  9229 solver.cpp:523]     Test net output #2: top-1 = 0.95875
I0614 17:38:46.201628  9229 solver.cpp:270] Iteration 7000 (3.54027 iter/s, 14.1232s/50 iter), loss = 0.0199586, remaining 0 hours and 23 minutes
I0614 17:38:46.201660  9229 solver.cpp:291]     Train net output #0: loss = 0.0199586 (* 1 = 0.0199586 loss)
I0614 17:38:46.201668  9229 sgd_solver.cpp:106] Iteration 7000, lr = 1e-05
I0614 17:38:58.828753  9229 solver.cpp:270] Iteration 7050 (3.95987 iter/s, 12.6267s/50 iter), loss = 0.00221595, remaining 0 hours and 20 minutes
I0614 17:38:58.828784  9229 solver.cpp:291]     Train net output #0: loss = 0.00221599 (* 1 = 0.00221599 loss)
I0614 17:38:58.828792  9229 sgd_solver.cpp:106] Iteration 7050, lr = 1e-05
I0614 17:39:11.450806  9229 solver.cpp:270] Iteration 7100 (3.96146 iter/s, 12.6216s/50 iter), loss = 0.000870341, remaining 0 hours and 20 minutes
I0614 17:39:11.451061  9229 solver.cpp:291]     Train net output #0: loss = 0.000870383 (* 1 = 0.000870383 loss)
I0614 17:39:11.451085  9229 sgd_solver.cpp:106] Iteration 7100, lr = 1e-05
I0614 17:39:24.073560  9229 solver.cpp:270] Iteration 7150 (3.96131 iter/s, 12.6221s/50 iter), loss = 0.0351546, remaining 0 hours and 20 minutes
I0614 17:39:24.073591  9229 solver.cpp:291]     Train net output #0: loss = 0.0351546 (* 1 = 0.0351546 loss)
I0614 17:39:24.073598  9229 sgd_solver.cpp:106] Iteration 7150, lr = 1e-05
I0614 17:39:36.689123  9229 solver.cpp:270] Iteration 7200 (3.9635 iter/s, 12.6151s/50 iter), loss = 0.0103644, remaining 0 hours and 20 minutes
I0614 17:39:36.689155  9229 solver.cpp:291]     Train net output #0: loss = 0.0103644 (* 1 = 0.0103644 loss)
I0614 17:39:36.689163  9229 sgd_solver.cpp:106] Iteration 7200, lr = 1e-05
I0614 17:39:49.297992  9229 solver.cpp:270] Iteration 7250 (3.9656 iter/s, 12.6084s/50 iter), loss = 0.0157176, remaining 0 hours and 19 minutes
I0614 17:39:49.298255  9229 solver.cpp:291]     Train net output #0: loss = 0.0157176 (* 1 = 0.0157176 loss)
I0614 17:39:49.298280  9229 sgd_solver.cpp:106] Iteration 7250, lr = 1e-05
I0614 17:40:01.922896  9229 solver.cpp:270] Iteration 7300 (3.96064 iter/s, 12.6242s/50 iter), loss = 0.00401537, remaining 0 hours and 19 minutes
I0614 17:40:01.922928  9229 solver.cpp:291]     Train net output #0: loss = 0.00401543 (* 1 = 0.00401543 loss)
I0614 17:40:01.922936  9229 sgd_solver.cpp:106] Iteration 7300, lr = 1e-05
I0614 17:40:14.558709  9229 solver.cpp:270] Iteration 7350 (3.95715 iter/s, 12.6354s/50 iter), loss = 0.00644933, remaining 0 hours and 19 minutes
I0614 17:40:14.558740  9229 solver.cpp:291]     Train net output #0: loss = 0.00644937 (* 1 = 0.00644937 loss)
I0614 17:40:14.558763  9229 sgd_solver.cpp:106] Iteration 7350, lr = 1e-05
I0614 17:40:27.185412  9229 solver.cpp:270] Iteration 7400 (3.96 iter/s, 12.6263s/50 iter), loss = 0.0057322, remaining 0 hours and 19 minutes
I0614 17:40:27.185683  9229 solver.cpp:291]     Train net output #0: loss = 0.00573225 (* 1 = 0.00573225 loss)
I0614 17:40:27.185691  9229 sgd_solver.cpp:106] Iteration 7400, lr = 1e-05
I0614 17:40:39.822376  9229 solver.cpp:270] Iteration 7450 (3.95686 iter/s, 12.6363s/50 iter), loss = 0.0116212, remaining 0 hours and 18 minutes
I0614 17:40:39.822407  9229 solver.cpp:291]     Train net output #0: loss = 0.0116212 (* 1 = 0.0116212 loss)
I0614 17:40:39.822430  9229 sgd_solver.cpp:106] Iteration 7450, lr = 1e-05
I0614 17:40:52.456022  9229 solver.cpp:270] Iteration 7500 (3.95782 iter/s, 12.6332s/50 iter), loss = 0.00880135, remaining 0 hours and 18 minutes
I0614 17:40:52.456053  9229 solver.cpp:291]     Train net output #0: loss = 0.0088014 (* 1 = 0.0088014 loss)
I0614 17:40:52.456061  9229 sgd_solver.cpp:106] Iteration 7500, lr = 1e-06
I0614 17:41:05.072211  9229 solver.cpp:270] Iteration 7550 (3.9633 iter/s, 12.6157s/50 iter), loss = 0.0135832, remaining 0 hours and 18 minutes
I0614 17:41:05.072495  9229 solver.cpp:291]     Train net output #0: loss = 0.0135833 (* 1 = 0.0135833 loss)
I0614 17:41:05.072504  9229 sgd_solver.cpp:106] Iteration 7550, lr = 1e-06
I0614 17:41:17.690099  9229 solver.cpp:270] Iteration 7600 (3.96285 iter/s, 12.6172s/50 iter), loss = 0.0058505, remaining 0 hours and 18 minutes
I0614 17:41:17.690132  9229 solver.cpp:291]     Train net output #0: loss = 0.00585055 (* 1 = 0.00585055 loss)
I0614 17:41:17.690140  9229 sgd_solver.cpp:106] Iteration 7600, lr = 1e-06
I0614 17:41:30.321681  9229 solver.cpp:270] Iteration 7650 (3.95847 iter/s, 12.6311s/50 iter), loss = 0.00229839, remaining 0 hours and 18 minutes
I0614 17:41:30.321712  9229 solver.cpp:291]     Train net output #0: loss = 0.00229845 (* 1 = 0.00229845 loss)
I0614 17:41:30.321720  9229 sgd_solver.cpp:106] Iteration 7650, lr = 1e-06
I0614 17:41:42.953565  9229 solver.cpp:270] Iteration 7700 (3.95838 iter/s, 12.6314s/50 iter), loss = 0.0080591, remaining 0 hours and 17 minutes
I0614 17:41:42.953871  9229 solver.cpp:291]     Train net output #0: loss = 0.00805916 (* 1 = 0.00805916 loss)
I0614 17:41:42.953897  9229 sgd_solver.cpp:106] Iteration 7700, lr = 1e-06
I0614 17:41:55.589911  9229 solver.cpp:270] Iteration 7750 (3.95706 iter/s, 12.6356s/50 iter), loss = 0.00420879, remaining 0 hours and 17 minutes
I0614 17:41:55.589944  9229 solver.cpp:291]     Train net output #0: loss = 0.00420885 (* 1 = 0.00420885 loss)
I0614 17:41:55.589967  9229 sgd_solver.cpp:106] Iteration 7750, lr = 1e-06
I0614 17:42:08.230567  9229 solver.cpp:270] Iteration 7800 (3.95563 iter/s, 12.6402s/50 iter), loss = 0.0130952, remaining 0 hours and 17 minutes
I0614 17:42:08.230599  9229 solver.cpp:291]     Train net output #0: loss = 0.0130952 (* 1 = 0.0130952 loss)
I0614 17:42:08.230623  9229 sgd_solver.cpp:106] Iteration 7800, lr = 1e-06
I0614 17:42:20.879976  9229 solver.cpp:270] Iteration 7850 (3.95289 iter/s, 12.649s/50 iter), loss = 0.0187748, remaining 0 hours and 17 minutes
I0614 17:42:20.880229  9229 solver.cpp:291]     Train net output #0: loss = 0.0187749 (* 1 = 0.0187749 loss)
I0614 17:42:20.880254  9229 sgd_solver.cpp:106] Iteration 7850, lr = 1e-06
I0614 17:42:33.497084  9229 solver.cpp:270] Iteration 7900 (3.96308 iter/s, 12.6164s/50 iter), loss = 0.000930648, remaining 0 hours and 17 minutes
I0614 17:42:33.497117  9229 solver.cpp:291]     Train net output #0: loss = 0.000930707 (* 1 = 0.000930707 loss)
I0614 17:42:33.497124  9229 sgd_solver.cpp:106] Iteration 7900, lr = 1e-06
I0614 17:42:46.134502  9229 solver.cpp:270] Iteration 7950 (3.95664 iter/s, 12.637s/50 iter), loss = 0.00374141, remaining 0 hours and 16 minutes
I0614 17:42:46.134532  9229 solver.cpp:291]     Train net output #0: loss = 0.00374147 (* 1 = 0.00374147 loss)
I0614 17:42:46.134557  9229 sgd_solver.cpp:106] Iteration 7950, lr = 1e-06
I0614 17:42:58.518405  9229 solver.cpp:424] Iteration 8000, Testing net (#0)
I0614 17:43:00.005144  9229 solver.cpp:523]     Test net output #0: accuracy = 0.95875
I0614 17:43:00.005174  9229 solver.cpp:523]     Test net output #1: loss = 0.184365 (* 1 = 0.184365 loss)
I0614 17:43:00.005179  9229 solver.cpp:523]     Test net output #2: top-1 = 0.95875
I0614 17:43:00.255293  9229 solver.cpp:270] Iteration 8000 (3.541 iter/s, 14.1203s/50 iter), loss = 0.00692529, remaining 0 hours and 18 minutes
I0614 17:43:00.255324  9229 solver.cpp:291]     Train net output #0: loss = 0.00692535 (* 1 = 0.00692535 loss)
I0614 17:43:00.255333  9229 sgd_solver.cpp:106] Iteration 8000, lr = 1e-06
I0614 17:43:12.884855  9229 solver.cpp:270] Iteration 8050 (3.9591 iter/s, 12.6291s/50 iter), loss = 0.0240647, remaining 0 hours and 16 minutes
I0614 17:43:12.884886  9229 solver.cpp:291]     Train net output #0: loss = 0.0240648 (* 1 = 0.0240648 loss)
I0614 17:43:12.884896  9229 sgd_solver.cpp:106] Iteration 8050, lr = 1e-06
I0614 17:43:25.486212  9229 solver.cpp:270] Iteration 8100 (3.96796 iter/s, 12.6009s/50 iter), loss = 0.0152769, remaining 0 hours and 16 minutes
I0614 17:43:25.486244  9229 solver.cpp:291]     Train net output #0: loss = 0.0152769 (* 1 = 0.0152769 loss)
I0614 17:43:25.486253  9229 sgd_solver.cpp:106] Iteration 8100, lr = 1e-06
I0614 17:43:38.098596  9229 solver.cpp:270] Iteration 8150 (3.9645 iter/s, 12.6119s/50 iter), loss = 0.00964078, remaining 0 hours and 16 minutes
I0614 17:43:38.098935  9229 solver.cpp:291]     Train net output #0: loss = 0.00964084 (* 1 = 0.00964084 loss)
I0614 17:43:38.098944  9229 sgd_solver.cpp:106] Iteration 8150, lr = 1e-06
I0614 17:43:50.723942  9229 solver.cpp:270] Iteration 8200 (3.96052 iter/s, 12.6246s/50 iter), loss = 0.00485929, remaining 0 hours and 15 minutes
I0614 17:43:50.723971  9229 solver.cpp:291]     Train net output #0: loss = 0.00485935 (* 1 = 0.00485935 loss)
I0614 17:43:50.723979  9229 sgd_solver.cpp:106] Iteration 8200, lr = 1e-06
I0614 17:44:03.351766  9229 solver.cpp:270] Iteration 8250 (3.95965 iter/s, 12.6274s/50 iter), loss = 0.00679711, remaining 0 hours and 15 minutes
I0614 17:44:03.351799  9229 solver.cpp:291]     Train net output #0: loss = 0.00679717 (* 1 = 0.00679717 loss)
I0614 17:44:03.351822  9229 sgd_solver.cpp:106] Iteration 8250, lr = 1e-06
I0614 17:44:15.997977  9229 solver.cpp:270] Iteration 8300 (3.95389 iter/s, 12.6458s/50 iter), loss = 0.00778588, remaining 0 hours and 15 minutes
I0614 17:44:15.998224  9229 solver.cpp:291]     Train net output #0: loss = 0.00778594 (* 1 = 0.00778594 loss)
I0614 17:44:15.998234  9229 sgd_solver.cpp:106] Iteration 8300, lr = 1e-06
I0614 17:44:28.618746  9229 solver.cpp:270] Iteration 8350 (3.96193 iter/s, 12.6201s/50 iter), loss = 0.00352134, remaining 0 hours and 15 minutes
I0614 17:44:28.618779  9229 solver.cpp:291]     Train net output #0: loss = 0.0035214 (* 1 = 0.0035214 loss)
I0614 17:44:28.618788  9229 sgd_solver.cpp:106] Iteration 8350, lr = 1e-06
I0614 17:44:41.250908  9229 solver.cpp:270] Iteration 8400 (3.95829 iter/s, 12.6317s/50 iter), loss = 0.0087819, remaining 0 hours and 15 minutes
I0614 17:44:41.250941  9229 solver.cpp:291]     Train net output #0: loss = 0.00878196 (* 1 = 0.00878196 loss)
I0614 17:44:41.250949  9229 sgd_solver.cpp:106] Iteration 8400, lr = 1e-06
I0614 17:44:53.890010  9229 solver.cpp:270] Iteration 8450 (3.95612 iter/s, 12.6387s/50 iter), loss = 0.0233545, remaining 0 hours and 14 minutes
I0614 17:44:53.890221  9229 solver.cpp:291]     Train net output #0: loss = 0.0233546 (* 1 = 0.0233546 loss)
I0614 17:44:53.890230  9229 sgd_solver.cpp:106] Iteration 8450, lr = 1e-06
I0614 17:45:06.513427  9229 solver.cpp:270] Iteration 8500 (3.96109 iter/s, 12.6228s/50 iter), loss = 0.00533091, remaining 0 hours and 14 minutes
I0614 17:45:06.513459  9229 solver.cpp:291]     Train net output #0: loss = 0.00533097 (* 1 = 0.00533097 loss)
I0614 17:45:06.513468  9229 sgd_solver.cpp:106] Iteration 8500, lr = 1e-06
I0614 17:45:19.133627  9229 solver.cpp:270] Iteration 8550 (3.96204 iter/s, 12.6198s/50 iter), loss = 0.0104831, remaining 0 hours and 14 minutes
I0614 17:45:19.133659  9229 solver.cpp:291]     Train net output #0: loss = 0.0104832 (* 1 = 0.0104832 loss)
I0614 17:45:19.133667  9229 sgd_solver.cpp:106] Iteration 8550, lr = 1e-06
I0614 17:45:31.781415  9229 solver.cpp:270] Iteration 8600 (3.9534 iter/s, 12.6473s/50 iter), loss = 0.00332725, remaining 0 hours and 14 minutes
I0614 17:45:31.781608  9229 solver.cpp:291]     Train net output #0: loss = 0.00332731 (* 1 = 0.00332731 loss)
I0614 17:45:31.781618  9229 sgd_solver.cpp:106] Iteration 8600, lr = 1e-06
I0614 17:45:44.422617  9229 solver.cpp:270] Iteration 8650 (3.95551 iter/s, 12.6406s/50 iter), loss = 0.00166387, remaining 0 hours and 13 minutes
I0614 17:45:44.422649  9229 solver.cpp:291]     Train net output #0: loss = 0.00166394 (* 1 = 0.00166394 loss)
I0614 17:45:44.422658  9229 sgd_solver.cpp:106] Iteration 8650, lr = 1e-06
I0614 17:45:57.036808  9229 solver.cpp:270] Iteration 8700 (3.96393 iter/s, 12.6138s/50 iter), loss = 0.00449838, remaining 0 hours and 13 minutes
I0614 17:45:57.036839  9229 solver.cpp:291]     Train net output #0: loss = 0.00449844 (* 1 = 0.00449844 loss)
I0614 17:45:57.036864  9229 sgd_solver.cpp:106] Iteration 8700, lr = 1e-06
I0614 17:46:09.656430  9229 solver.cpp:270] Iteration 8750 (3.96222 iter/s, 12.6192s/50 iter), loss = 0.0201239, remaining 0 hours and 13 minutes
I0614 17:46:09.656772  9229 solver.cpp:291]     Train net output #0: loss = 0.0201239 (* 1 = 0.0201239 loss)
I0614 17:46:09.656781  9229 sgd_solver.cpp:106] Iteration 8750, lr = 1e-06
I0614 17:46:22.296584  9229 solver.cpp:270] Iteration 8800 (3.95588 iter/s, 12.6394s/50 iter), loss = 0.0033209, remaining 0 hours and 13 minutes
I0614 17:46:22.296617  9229 solver.cpp:291]     Train net output #0: loss = 0.00332096 (* 1 = 0.00332096 loss)
I0614 17:46:22.296626  9229 sgd_solver.cpp:106] Iteration 8800, lr = 1e-06
I0614 17:46:34.934100  9229 solver.cpp:270] Iteration 8850 (3.95661 iter/s, 12.6371s/50 iter), loss = 0.00596998, remaining 0 hours and 13 minutes
I0614 17:46:34.934132  9229 solver.cpp:291]     Train net output #0: loss = 0.00597004 (* 1 = 0.00597004 loss)
I0614 17:46:34.934155  9229 sgd_solver.cpp:106] Iteration 8850, lr = 1e-06
I0614 17:46:47.571735  9229 solver.cpp:270] Iteration 8900 (3.95657 iter/s, 12.6372s/50 iter), loss = 0.00249498, remaining 0 hours and 12 minutes
I0614 17:46:47.571998  9229 solver.cpp:291]     Train net output #0: loss = 0.00249505 (* 1 = 0.00249505 loss)
I0614 17:46:47.572007  9229 sgd_solver.cpp:106] Iteration 8900, lr = 1e-06
I0614 17:47:00.215549  9229 solver.cpp:270] Iteration 8950 (3.95471 iter/s, 12.6431s/50 iter), loss = 0.000411434, remaining 0 hours and 12 minutes
I0614 17:47:00.215581  9229 solver.cpp:291]     Train net output #0: loss = 0.000411502 (* 1 = 0.000411502 loss)
I0614 17:47:00.215590  9229 sgd_solver.cpp:106] Iteration 8950, lr = 1e-06
I0614 17:47:12.582247  9229 solver.cpp:424] Iteration 9000, Testing net (#0)
I0614 17:47:14.075587  9229 solver.cpp:523]     Test net output #0: accuracy = 0.96
I0614 17:47:14.075616  9229 solver.cpp:523]     Test net output #1: loss = 0.202089 (* 1 = 0.202089 loss)
I0614 17:47:14.075621  9229 solver.cpp:523]     Test net output #2: top-1 = 0.96
I0614 17:47:14.322293  9229 solver.cpp:270] Iteration 9000 (3.54453 iter/s, 14.1063s/50 iter), loss = 0.013713, remaining 0 hours and 14 minutes
I0614 17:47:14.322322  9229 solver.cpp:291]     Train net output #0: loss = 0.0137131 (* 1 = 0.0137131 loss)
I0614 17:47:14.322345  9229 sgd_solver.cpp:106] Iteration 9000, lr = 1e-06
I0614 17:47:26.939720  9229 solver.cpp:270] Iteration 9050 (3.96291 iter/s, 12.617s/50 iter), loss = 0.0114295, remaining 0 hours and 12 minutes
I0614 17:47:26.939962  9229 solver.cpp:291]     Train net output #0: loss = 0.0114295 (* 1 = 0.0114295 loss)
I0614 17:47:26.939986  9229 sgd_solver.cpp:106] Iteration 9050, lr = 1e-06
I0614 17:47:39.554805  9229 solver.cpp:270] Iteration 9100 (3.96371 iter/s, 12.6144s/50 iter), loss = 0.018609, remaining 0 hours and 12 minutes
I0614 17:47:39.554836  9229 solver.cpp:291]     Train net output #0: loss = 0.018609 (* 1 = 0.018609 loss)
I0614 17:47:39.554845  9229 sgd_solver.cpp:106] Iteration 9100, lr = 1e-06
I0614 17:47:52.187069  9229 solver.cpp:270] Iteration 9150 (3.95826 iter/s, 12.6318s/50 iter), loss = 0.00444328, remaining 0 hours and 11 minutes
I0614 17:47:52.187103  9229 solver.cpp:291]     Train net output #0: loss = 0.00444335 (* 1 = 0.00444335 loss)
I0614 17:47:52.187126  9229 sgd_solver.cpp:106] Iteration 9150, lr = 1e-06
I0614 17:48:04.825253  9229 solver.cpp:270] Iteration 9200 (3.9564 iter/s, 12.6377s/50 iter), loss = 0.0154221, remaining 0 hours and 11 minutes
I0614 17:48:04.825503  9229 solver.cpp:291]     Train net output #0: loss = 0.0154222 (* 1 = 0.0154222 loss)
I0614 17:48:04.825513  9229 sgd_solver.cpp:106] Iteration 9200, lr = 1e-06
I0614 17:48:17.443780  9229 solver.cpp:270] Iteration 9250 (3.96263 iter/s, 12.6179s/50 iter), loss = 0.00787413, remaining 0 hours and 11 minutes
I0614 17:48:17.443810  9229 solver.cpp:291]     Train net output #0: loss = 0.00787419 (* 1 = 0.00787419 loss)
I0614 17:48:17.443835  9229 sgd_solver.cpp:106] Iteration 9250, lr = 1e-06
I0614 17:48:30.073122  9229 solver.cpp:270] Iteration 9300 (3.95917 iter/s, 12.6289s/50 iter), loss = 0.0334779, remaining 0 hours and 11 minutes
I0614 17:48:30.073151  9229 solver.cpp:291]     Train net output #0: loss = 0.033478 (* 1 = 0.033478 loss)
I0614 17:48:30.073159  9229 sgd_solver.cpp:106] Iteration 9300, lr = 1e-06
I0614 17:48:42.708364  9229 solver.cpp:270] Iteration 9350 (3.95732 iter/s, 12.6348s/50 iter), loss = 0.0014499, remaining 0 hours and 11 minutes
I0614 17:48:42.708678  9229 solver.cpp:291]     Train net output #0: loss = 0.00144996 (* 1 = 0.00144996 loss)
I0614 17:48:42.708686  9229 sgd_solver.cpp:106] Iteration 9350, lr = 1e-06
I0614 17:48:55.326047  9229 solver.cpp:270] Iteration 9400 (3.96292 iter/s, 12.617s/50 iter), loss = 0.00677555, remaining 0 hours and 10 minutes
I0614 17:48:55.326081  9229 solver.cpp:291]     Train net output #0: loss = 0.0067756 (* 1 = 0.0067756 loss)
I0614 17:48:55.326088  9229 sgd_solver.cpp:106] Iteration 9400, lr = 1e-06
I0614 17:49:07.950879  9229 solver.cpp:270] Iteration 9450 (3.96059 iter/s, 12.6244s/50 iter), loss = 0.00047889, remaining 0 hours and 10 minutes
I0614 17:49:07.950910  9229 solver.cpp:291]     Train net output #0: loss = 0.000478946 (* 1 = 0.000478946 loss)
I0614 17:49:07.950918  9229 sgd_solver.cpp:106] Iteration 9450, lr = 1e-06
I0614 17:49:20.558621  9229 solver.cpp:270] Iteration 9500 (3.96595 iter/s, 12.6073s/50 iter), loss = 0.00863359, remaining 0 hours and 10 minutes
I0614 17:49:20.558840  9229 solver.cpp:291]     Train net output #0: loss = 0.00863365 (* 1 = 0.00863365 loss)
I0614 17:49:20.558847  9229 sgd_solver.cpp:106] Iteration 9500, lr = 1e-06
I0614 17:49:33.165472  9229 solver.cpp:270] Iteration 9550 (3.96629 iter/s, 12.6062s/50 iter), loss = 0.000672578, remaining 0 hours and 10 minutes
I0614 17:49:33.165503  9229 solver.cpp:291]     Train net output #0: loss = 0.000672628 (* 1 = 0.000672628 loss)
I0614 17:49:33.165511  9229 sgd_solver.cpp:106] Iteration 9550, lr = 1e-06
I0614 17:49:45.776578  9229 solver.cpp:270] Iteration 9600 (3.9649 iter/s, 12.6107s/50 iter), loss = 0.00144194, remaining 0 hours and 10 minutes
I0614 17:49:45.776610  9229 solver.cpp:291]     Train net output #0: loss = 0.00144199 (* 1 = 0.00144199 loss)
I0614 17:49:45.776634  9229 sgd_solver.cpp:106] Iteration 9600, lr = 1e-06
I0614 17:49:58.401815  9229 solver.cpp:270] Iteration 9650 (3.96046 iter/s, 12.6248s/50 iter), loss = 0.0145254, remaining 0 hours and 9 minutes
I0614 17:49:58.402077  9229 solver.cpp:291]     Train net output #0: loss = 0.0145254 (* 1 = 0.0145254 loss)
I0614 17:49:58.402086  9229 sgd_solver.cpp:106] Iteration 9650, lr = 1e-06
I0614 17:50:11.044591  9229 solver.cpp:270] Iteration 9700 (3.95504 iter/s, 12.6421s/50 iter), loss = 0.00412306, remaining 0 hours and 9 minutes
I0614 17:50:11.044623  9229 solver.cpp:291]     Train net output #0: loss = 0.00412311 (* 1 = 0.00412311 loss)
I0614 17:50:11.044631  9229 sgd_solver.cpp:106] Iteration 9700, lr = 1e-06
I0614 17:50:23.677026  9229 solver.cpp:270] Iteration 9750 (3.9582 iter/s, 12.632s/50 iter), loss = 0.00547159, remaining 0 hours and 9 minutes
I0614 17:50:23.677057  9229 solver.cpp:291]     Train net output #0: loss = 0.00547163 (* 1 = 0.00547163 loss)
I0614 17:50:23.677065  9229 sgd_solver.cpp:106] Iteration 9750, lr = 1e-06
I0614 17:50:36.303335  9229 solver.cpp:270] Iteration 9800 (3.96012 iter/s, 12.6259s/50 iter), loss = 0.00469072, remaining 0 hours and 9 minutes
I0614 17:50:36.303527  9229 solver.cpp:291]     Train net output #0: loss = 0.00469076 (* 1 = 0.00469076 loss)
I0614 17:50:36.303536  9229 sgd_solver.cpp:106] Iteration 9800, lr = 1e-06
I0614 17:50:48.941471  9229 solver.cpp:270] Iteration 9850 (3.95647 iter/s, 12.6375s/50 iter), loss = 0.00962972, remaining 0 hours and 8 minutes
I0614 17:50:48.941504  9229 solver.cpp:291]     Train net output #0: loss = 0.00962977 (* 1 = 0.00962977 loss)
I0614 17:50:48.941529  9229 sgd_solver.cpp:106] Iteration 9850, lr = 1e-06
I0614 17:51:01.574262  9229 solver.cpp:270] Iteration 9900 (3.95809 iter/s, 12.6324s/50 iter), loss = 0.00281933, remaining 0 hours and 8 minutes
I0614 17:51:01.574293  9229 solver.cpp:291]     Train net output #0: loss = 0.00281938 (* 1 = 0.00281938 loss)
I0614 17:51:01.574301  9229 sgd_solver.cpp:106] Iteration 9900, lr = 1e-06
I0614 17:51:14.224781  9229 solver.cpp:270] Iteration 9950 (3.95255 iter/s, 12.6501s/50 iter), loss = 0.00632702, remaining 0 hours and 8 minutes
I0614 17:51:14.225114  9229 solver.cpp:291]     Train net output #0: loss = 0.00632708 (* 1 = 0.00632708 loss)
I0614 17:51:14.225123  9229 sgd_solver.cpp:106] Iteration 9950, lr = 1e-06
I0614 17:51:26.595554  9229 solver.cpp:424] Iteration 10000, Testing net (#0)
I0614 17:51:28.102564  9229 solver.cpp:523]     Test net output #0: accuracy = 0.96025
I0614 17:51:28.102593  9229 solver.cpp:523]     Test net output #1: loss = 0.21133 (* 1 = 0.21133 loss)
I0614 17:51:28.102598  9229 solver.cpp:523]     Test net output #2: top-1 = 0.96025
I0614 17:51:28.348987  9229 solver.cpp:270] Iteration 10000 (3.54022 iter/s, 14.1234s/50 iter), loss = 0.00447414, remaining 0 hours and 9 minutes
I0614 17:51:28.349020  9229 solver.cpp:291]     Train net output #0: loss = 0.00447419 (* 1 = 0.00447419 loss)
I0614 17:51:28.349028  9229 sgd_solver.cpp:106] Iteration 10000, lr = 1e-07
I0614 17:51:40.994725  9229 solver.cpp:270] Iteration 10050 (3.95404 iter/s, 12.6453s/50 iter), loss = 0.00828488, remaining 0 hours and 8 minutes
I0614 17:51:40.994756  9229 solver.cpp:291]     Train net output #0: loss = 0.00828493 (* 1 = 0.00828493 loss)
I0614 17:51:40.994765  9229 sgd_solver.cpp:106] Iteration 10050, lr = 1e-07
I0614 17:51:53.620080  9229 solver.cpp:270] Iteration 10100 (3.96042 iter/s, 12.6249s/50 iter), loss = 0.00617816, remaining 0 hours and 7 minutes
I0614 17:51:53.620337  9229 solver.cpp:291]     Train net output #0: loss = 0.00617821 (* 1 = 0.00617821 loss)
I0614 17:51:53.620345  9229 sgd_solver.cpp:106] Iteration 10100, lr = 1e-07
I0614 17:52:06.261467  9229 solver.cpp:270] Iteration 10150 (3.95547 iter/s, 12.6407s/50 iter), loss = 0.00288958, remaining 0 hours and 7 minutes
I0614 17:52:06.261498  9229 solver.cpp:291]     Train net output #0: loss = 0.00288963 (* 1 = 0.00288963 loss)
I0614 17:52:06.261507  9229 sgd_solver.cpp:106] Iteration 10150, lr = 1e-07
I0614 17:52:18.903019  9229 solver.cpp:270] Iteration 10200 (3.95535 iter/s, 12.6411s/50 iter), loss = 0.00388345, remaining 0 hours and 7 minutes
I0614 17:52:18.903051  9229 solver.cpp:291]     Train net output #0: loss = 0.00388351 (* 1 = 0.00388351 loss)
I0614 17:52:18.903060  9229 sgd_solver.cpp:106] Iteration 10200, lr = 1e-07
I0614 17:52:31.516230  9229 solver.cpp:270] Iteration 10250 (3.96424 iter/s, 12.6128s/50 iter), loss = 0.00389598, remaining 0 hours and 7 minutes
I0614 17:52:31.516485  9229 solver.cpp:291]     Train net output #0: loss = 0.00389604 (* 1 = 0.00389604 loss)
I0614 17:52:31.516497  9229 sgd_solver.cpp:106] Iteration 10250, lr = 1e-07
I0614 17:52:44.129060  9229 solver.cpp:270] Iteration 10300 (3.96443 iter/s, 12.6122s/50 iter), loss = 0.0131466, remaining 0 hours and 7 minutes
I0614 17:52:44.129093  9229 solver.cpp:291]     Train net output #0: loss = 0.0131466 (* 1 = 0.0131466 loss)
I0614 17:52:44.129102  9229 sgd_solver.cpp:106] Iteration 10300, lr = 1e-07
I0614 17:52:56.762334  9229 solver.cpp:270] Iteration 10350 (3.95794 iter/s, 12.6328s/50 iter), loss = 0.00248821, remaining 0 hours and 6 minutes
I0614 17:52:56.762367  9229 solver.cpp:291]     Train net output #0: loss = 0.00248826 (* 1 = 0.00248826 loss)
I0614 17:52:56.762374  9229 sgd_solver.cpp:106] Iteration 10350, lr = 1e-07
I0614 17:53:09.398229  9229 solver.cpp:270] Iteration 10400 (3.95712 iter/s, 12.6355s/50 iter), loss = 0.00145586, remaining 0 hours and 6 minutes
I0614 17:53:09.398572  9229 solver.cpp:291]     Train net output #0: loss = 0.00145591 (* 1 = 0.00145591 loss)
I0614 17:53:09.398581  9229 sgd_solver.cpp:106] Iteration 10400, lr = 1e-07
I0614 17:53:22.031549  9229 solver.cpp:270] Iteration 10450 (3.95802 iter/s, 12.6326s/50 iter), loss = 0.00791091, remaining 0 hours and 6 minutes
I0614 17:53:22.031579  9229 solver.cpp:291]     Train net output #0: loss = 0.00791096 (* 1 = 0.00791096 loss)
I0614 17:53:22.031587  9229 sgd_solver.cpp:106] Iteration 10450, lr = 1e-07
I0614 17:53:34.676795  9229 solver.cpp:270] Iteration 10500 (3.95419 iter/s, 12.6448s/50 iter), loss = 0.00171893, remaining 0 hours and 6 minutes
I0614 17:53:34.676827  9229 solver.cpp:291]     Train net output #0: loss = 0.00171898 (* 1 = 0.00171898 loss)
I0614 17:53:34.676851  9229 sgd_solver.cpp:106] Iteration 10500, lr = 1e-07
I0614 17:53:47.321297  9229 solver.cpp:270] Iteration 10550 (3.95443 iter/s, 12.6441s/50 iter), loss = 0.0334118, remaining 0 hours and 6 minutes
I0614 17:53:47.321578  9229 solver.cpp:291]     Train net output #0: loss = 0.0334119 (* 1 = 0.0334119 loss)
I0614 17:53:47.321588  9229 sgd_solver.cpp:106] Iteration 10550, lr = 1e-07
I0614 17:53:59.948518  9229 solver.cpp:270] Iteration 10600 (3.95992 iter/s, 12.6265s/50 iter), loss = 0.00115939, remaining 0 hours and 5 minutes
I0614 17:53:59.948549  9229 solver.cpp:291]     Train net output #0: loss = 0.00115944 (* 1 = 0.00115944 loss)
I0614 17:53:59.948556  9229 sgd_solver.cpp:106] Iteration 10600, lr = 1e-07
I0614 17:54:12.589840  9229 solver.cpp:270] Iteration 10650 (3.95542 iter/s, 12.6409s/50 iter), loss = 0.00899988, remaining 0 hours and 5 minutes
I0614 17:54:12.589872  9229 solver.cpp:291]     Train net output #0: loss = 0.00899993 (* 1 = 0.00899993 loss)
I0614 17:54:12.589880  9229 sgd_solver.cpp:106] Iteration 10650, lr = 1e-07
I0614 17:54:25.217450  9229 solver.cpp:270] Iteration 10700 (3.95972 iter/s, 12.6272s/50 iter), loss = 0.00695953, remaining 0 hours and 5 minutes
I0614 17:54:25.217691  9229 solver.cpp:291]     Train net output #0: loss = 0.00695958 (* 1 = 0.00695958 loss)
I0614 17:54:25.217716  9229 sgd_solver.cpp:106] Iteration 10700, lr = 1e-07
I0614 17:54:37.851471  9229 solver.cpp:270] Iteration 10750 (3.95777 iter/s, 12.6334s/50 iter), loss = 0.00822805, remaining 0 hours and 5 minutes
I0614 17:54:37.851502  9229 solver.cpp:291]     Train net output #0: loss = 0.0082281 (* 1 = 0.0082281 loss)
I0614 17:54:37.851526  9229 sgd_solver.cpp:106] Iteration 10750, lr = 1e-07
I0614 17:54:50.500504  9229 solver.cpp:270] Iteration 10800 (3.95301 iter/s, 12.6486s/50 iter), loss = 0.00531021, remaining 0 hours and 5 minutes
I0614 17:54:50.500537  9229 solver.cpp:291]     Train net output #0: loss = 0.00531026 (* 1 = 0.00531026 loss)
I0614 17:54:50.500545  9229 sgd_solver.cpp:106] Iteration 10800, lr = 1e-07
I0614 17:55:03.139750  9229 solver.cpp:270] Iteration 10850 (3.95607 iter/s, 12.6388s/50 iter), loss = 0.0329088, remaining 0 hours and 4 minutes
I0614 17:55:03.140020  9229 solver.cpp:291]     Train net output #0: loss = 0.0329089 (* 1 = 0.0329089 loss)
I0614 17:55:03.140029  9229 sgd_solver.cpp:106] Iteration 10850, lr = 1e-07
I0614 17:55:15.764819  9229 solver.cpp:270] Iteration 10900 (3.96059 iter/s, 12.6244s/50 iter), loss = 0.0261467, remaining 0 hours and 4 minutes
I0614 17:55:15.764851  9229 solver.cpp:291]     Train net output #0: loss = 0.0261468 (* 1 = 0.0261468 loss)
I0614 17:55:15.764875  9229 sgd_solver.cpp:106] Iteration 10900, lr = 1e-07
I0614 17:55:28.378887  9229 solver.cpp:270] Iteration 10950 (3.96397 iter/s, 12.6136s/50 iter), loss = 0.0192183, remaining 0 hours and 4 minutes
I0614 17:55:28.378918  9229 solver.cpp:291]     Train net output #0: loss = 0.0192183 (* 1 = 0.0192183 loss)
I0614 17:55:28.378942  9229 sgd_solver.cpp:106] Iteration 10950, lr = 1e-07
I0614 17:55:40.747596  9229 solver.cpp:424] Iteration 11000, Testing net (#0)
I0614 17:55:42.254205  9229 solver.cpp:523]     Test net output #0: accuracy = 0.96025
I0614 17:55:42.254232  9229 solver.cpp:523]     Test net output #1: loss = 0.2156 (* 1 = 0.2156 loss)
I0614 17:55:42.254236  9229 solver.cpp:523]     Test net output #2: top-1 = 0.96025
I0614 17:55:42.500541  9229 solver.cpp:270] Iteration 11000 (3.54078 iter/s, 14.1212s/50 iter), loss = 0.000612506, remaining 0 hours and 4 minutes
I0614 17:55:42.500573  9229 solver.cpp:291]     Train net output #0: loss = 0.000612554 (* 1 = 0.000612554 loss)
I0614 17:55:42.500581  9229 sgd_solver.cpp:106] Iteration 11000, lr = 1e-07
I0614 17:55:55.133589  9229 solver.cpp:270] Iteration 11050 (3.95801 iter/s, 12.6326s/50 iter), loss = 0.00489483, remaining 0 hours and 3 minutes
I0614 17:55:55.133618  9229 solver.cpp:291]     Train net output #0: loss = 0.00489488 (* 1 = 0.00489488 loss)
I0614 17:55:55.133642  9229 sgd_solver.cpp:106] Iteration 11050, lr = 1e-07
I0614 17:56:07.757861  9229 solver.cpp:270] Iteration 11100 (3.96076 iter/s, 12.6238s/50 iter), loss = 0.0014889, remaining 0 hours and 3 minutes
I0614 17:56:07.757894  9229 solver.cpp:291]     Train net output #0: loss = 0.00148895 (* 1 = 0.00148895 loss)
I0614 17:56:07.757900  9229 sgd_solver.cpp:106] Iteration 11100, lr = 1e-07
I0614 17:56:20.388713  9229 solver.cpp:270] Iteration 11150 (3.9587 iter/s, 12.6304s/50 iter), loss = 0.000992738, remaining 0 hours and 3 minutes
I0614 17:56:20.389081  9229 solver.cpp:291]     Train net output #0: loss = 0.000992787 (* 1 = 0.000992787 loss)
I0614 17:56:20.389106  9229 sgd_solver.cpp:106] Iteration 11150, lr = 1e-07
I0614 17:56:33.001325  9229 solver.cpp:270] Iteration 11200 (3.96453 iter/s, 12.6118s/50 iter), loss = 0.00158821, remaining 0 hours and 3 minutes
I0614 17:56:33.001358  9229 solver.cpp:291]     Train net output #0: loss = 0.00158826 (* 1 = 0.00158826 loss)
I0614 17:56:33.001384  9229 sgd_solver.cpp:106] Iteration 11200, lr = 1e-07
I0614 17:56:45.614457  9229 solver.cpp:270] Iteration 11250 (3.96426 iter/s, 12.6127s/50 iter), loss = 0.0144072, remaining 0 hours and 3 minutes
I0614 17:56:45.614495  9229 solver.cpp:291]     Train net output #0: loss = 0.0144073 (* 1 = 0.0144073 loss)
I0614 17:56:45.614522  9229 sgd_solver.cpp:106] Iteration 11250, lr = 1e-07
I0614 17:56:58.252496  9229 solver.cpp:270] Iteration 11300 (3.95645 iter/s, 12.6376s/50 iter), loss = 0.0196496, remaining 0 hours and 2 minutes
I0614 17:56:58.252755  9229 solver.cpp:291]     Train net output #0: loss = 0.0196496 (* 1 = 0.0196496 loss)
I0614 17:56:58.252780  9229 sgd_solver.cpp:106] Iteration 11300, lr = 1e-07
I0614 17:57:10.893879  9229 solver.cpp:270] Iteration 11350 (3.95547 iter/s, 12.6407s/50 iter), loss = 0.00181883, remaining 0 hours and 2 minutes
I0614 17:57:10.893913  9229 solver.cpp:291]     Train net output #0: loss = 0.00181888 (* 1 = 0.00181888 loss)
I0614 17:57:10.893923  9229 sgd_solver.cpp:106] Iteration 11350, lr = 1e-07
I0614 17:57:23.513056  9229 solver.cpp:270] Iteration 11400 (3.96236 iter/s, 12.6187s/50 iter), loss = 0.00235108, remaining 0 hours and 2 minutes
I0614 17:57:23.513087  9229 solver.cpp:291]     Train net output #0: loss = 0.00235113 (* 1 = 0.00235113 loss)
I0614 17:57:23.513110  9229 sgd_solver.cpp:106] Iteration 11400, lr = 1e-07
I0614 17:57:36.149008  9229 solver.cpp:270] Iteration 11450 (3.9571 iter/s, 12.6355s/50 iter), loss = 0.00434231, remaining 0 hours and 2 minutes
I0614 17:57:36.149274  9229 solver.cpp:291]     Train net output #0: loss = 0.00434237 (* 1 = 0.00434237 loss)
I0614 17:57:36.149286  9229 sgd_solver.cpp:106] Iteration 11450, lr = 1e-07
I0614 17:57:48.794785  9229 solver.cpp:270] Iteration 11500 (3.9541 iter/s, 12.6451s/50 iter), loss = 0.0145477, remaining 0 hours and 2 minutes
I0614 17:57:48.794817  9229 solver.cpp:291]     Train net output #0: loss = 0.0145477 (* 1 = 0.0145477 loss)
I0614 17:57:48.794826  9229 sgd_solver.cpp:106] Iteration 11500, lr = 1e-07
I0614 17:58:01.426110  9229 solver.cpp:270] Iteration 11550 (3.95855 iter/s, 12.6309s/50 iter), loss = 0.00104144, remaining 0 hours and 1 minutes
I0614 17:58:01.426139  9229 solver.cpp:291]     Train net output #0: loss = 0.00104149 (* 1 = 0.00104149 loss)
I0614 17:58:01.426148  9229 sgd_solver.cpp:106] Iteration 11550, lr = 1e-07
I0614 17:58:14.069267  9229 solver.cpp:270] Iteration 11600 (3.95485 iter/s, 12.6427s/50 iter), loss = 0.000774773, remaining 0 hours and 1 minutes
I0614 17:58:14.069617  9229 solver.cpp:291]     Train net output #0: loss = 0.000774825 (* 1 = 0.000774825 loss)
I0614 17:58:14.069625  9229 sgd_solver.cpp:106] Iteration 11600, lr = 1e-07
I0614 17:58:26.717379  9229 solver.cpp:270] Iteration 11650 (3.9534 iter/s, 12.6474s/50 iter), loss = 0.00990611, remaining 0 hours and 1 minutes
I0614 17:58:26.717411  9229 solver.cpp:291]     Train net output #0: loss = 0.00990616 (* 1 = 0.00990616 loss)
I0614 17:58:26.717434  9229 sgd_solver.cpp:106] Iteration 11650, lr = 1e-07
I0614 17:58:39.363586  9229 solver.cpp:270] Iteration 11700 (3.95389 iter/s, 12.6458s/50 iter), loss = 0.00230249, remaining 0 hours and 1 minutes
I0614 17:58:39.363617  9229 solver.cpp:291]     Train net output #0: loss = 0.00230254 (* 1 = 0.00230254 loss)
I0614 17:58:39.363624  9229 sgd_solver.cpp:106] Iteration 11700, lr = 1e-07
I0614 17:58:51.991765  9229 solver.cpp:270] Iteration 11750 (3.95954 iter/s, 12.6277s/50 iter), loss = 0.00747055, remaining 0 hours and 1 minutes
I0614 17:58:51.992029  9229 solver.cpp:291]     Train net output #0: loss = 0.0074706 (* 1 = 0.0074706 loss)
I0614 17:58:51.992054  9229 sgd_solver.cpp:106] Iteration 11750, lr = 1e-07
I0614 17:59:04.612092  9229 solver.cpp:270] Iteration 11800 (3.96207 iter/s, 12.6197s/50 iter), loss = 0.0497301, remaining 0 hours and 0 minutes
I0614 17:59:04.612123  9229 solver.cpp:291]     Train net output #0: loss = 0.0497301 (* 1 = 0.0497301 loss)
I0614 17:59:04.612131  9229 sgd_solver.cpp:106] Iteration 11800, lr = 1e-07
I0614 17:59:17.259497  9229 solver.cpp:270] Iteration 11850 (3.95352 iter/s, 12.647s/50 iter), loss = 0.00368947, remaining 0 hours and 0 minutes
I0614 17:59:17.259528  9229 solver.cpp:291]     Train net output #0: loss = 0.00368951 (* 1 = 0.00368951 loss)
I0614 17:59:17.259536  9229 sgd_solver.cpp:106] Iteration 11850, lr = 1e-07
I0614 17:59:29.894626  9229 solver.cpp:270] Iteration 11900 (3.95736 iter/s, 12.6347s/50 iter), loss = 0.0216312, remaining 0 hours and 0 minutes
I0614 17:59:29.894891  9229 solver.cpp:291]     Train net output #0: loss = 0.0216312 (* 1 = 0.0216312 loss)
I0614 17:59:29.894914  9229 sgd_solver.cpp:106] Iteration 11900, lr = 1e-07
I0614 17:59:42.504602  9229 solver.cpp:270] Iteration 11950 (3.96533 iter/s, 12.6093s/50 iter), loss = 0.00183268, remaining 0 hours and 0 minutes
I0614 17:59:42.504637  9229 solver.cpp:291]     Train net output #0: loss = 0.00183272 (* 1 = 0.00183272 loss)
I0614 17:59:42.504644  9229 sgd_solver.cpp:106] Iteration 11950, lr = 1e-07
I0614 17:59:54.855803  9229 solver.cpp:935] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.5/snapshots/_iter_12000.caffemodel
I0614 18:00:00.685305  9229 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.5/snapshots/_iter_12000.solverstate
I0614 18:00:04.375458  9229 solver.cpp:384] Iteration 12000, loss = 0.00315691
I0614 18:00:04.375483  9229 solver.cpp:424] Iteration 12000, Testing net (#0)
I0614 18:00:05.782800  9229 solver.cpp:523]     Test net output #0: accuracy = 0.96
I0614 18:00:05.782829  9229 solver.cpp:523]     Test net output #1: loss = 0.21753 (* 1 = 0.21753 loss)
I0614 18:00:05.782835  9229 solver.cpp:523]     Test net output #2: top-1 = 0.96
I0614 18:00:05.782838  9229 solver.cpp:392] Optimization Done (3.94147 iter/s).
I0614 18:00:05.782842  9229 caffe_interface.cpp:576] Optimization Done.
(c) Copyright 2016â2019 Xilinx, Inc. All rights reserved.

I0614 18:00:06.584013  9326 pruning_runner.cpp:234] Analysis info found.
I0614 18:00:08.317636  9326 pruning_runner.cpp:265] Start pruning, please wait...
I0614 18:00:17.795778  9326 pruning_runner.cpp:312] Compression complete 0%
I0614 18:00:26.788550  9326 pruning_runner.cpp:312] Compression complete 0%
I0614 18:00:35.784888  9326 pruning_runner.cpp:312] Compression complete 0%
I0614 18:00:44.569413  9326 pruning_runner.cpp:312] Compression complete 0%
I0614 18:00:53.365281  9326 pruning_runner.cpp:312] Compression complete 0%
I0614 18:01:02.203938  9326 pruning_runner.cpp:312] Compression complete 0%
I0614 18:01:11.070158  9326 pruning_runner.cpp:312] Compression complete 0%
I0614 18:01:19.853312  9326 pruning_runner.cpp:312] Compression complete 50%
I0614 18:01:28.720314  9326 pruning_runner.cpp:312] Compression complete 88.8889%
I0614 18:01:37.646112  9326 pruning_runner.cpp:312] Compression complete 99.3055%
I0614 18:01:46.448612  9326 pruning_runner.cpp:312] Compression complete 99.6516%
I0614 18:01:55.376863  9326 pruning_runner.cpp:312] Compression complete 99.8258%
I0614 18:02:04.414535  9326 pruning_runner.cpp:312] Compression complete 99.9128%
I0614 18:02:13.219113  9326 pruning_runner.cpp:312] Compression complete 99.9891%
I0614 18:02:22.268323  9326 pruning_runner.cpp:312] Compression complete 99.9946%
I0614 18:02:31.122892  9326 pruning_runner.cpp:312] Compression complete 99.9973%
I0614 18:02:40.035655  9326 pruning_runner.cpp:312] Compression complete 99.9986%
I0614 18:02:48.832258  9326 pruning_runner.cpp:312] Compression complete 99.9993%
I0614 18:02:57.627245  9326 pruning_runner.cpp:312] Compression complete 99.9998%
I0614 18:03:06.565055  9326 pruning_runner.cpp:312] Compression complete 99.9999%
I0614 18:03:15.358352  9326 pruning_runner.cpp:312] Compression complete 100%
I0614 18:03:24.371960  9326 pruning_runner.cpp:312] Compression complete 100%
I0614 18:03:33.209287  9326 pruning_runner.cpp:312] Compression complete 100%
I0614 18:03:44.572294  9326 pruning_runner.cpp:365] pruning done, output model: pruning/alexnetBNnoLRN/regular_rate_0.6/sparse.caffemodel
I0614 18:03:44.572556  9326 pruning_runner.cpp:379] summary of REGULAR compression with rate 0.6:
+-------------------------------------------------------------------+
| Item           | Baseline       | Compressed     | Delta          |
+-------------------------------------------------------------------+
| Accuracy       | 0.953499794    | 0.958499789    | 0.00499999523  |
+-------------------------------------------------------------------+
| Weights        | 3.74857903 M   | 652.669006 K   | -82.5888977%   |
+-------------------------------------------------------------------+
| Operations     | 2.05460167 G   | 883.0979 M     | -57.0185356%   |
+-------------------------------------------------------------------+
To fine-tune the pruned model, please run:
vai_p_caffe finetune -config /workspace/TUTORIALS/VAI2.0bash-Caffe-ML-CATSvsDOGS/files/pruning/alexnetBNnoLRN/config6.prototxt
(c) Copyright 2016â2019 Xilinx, Inc. All rights reserved.

W0614 18:03:45.126257 11551 utils.cpp:207] BVLC BatchNormLayer without ScaleLayer detected: 3, it will be converted to NVCaffe Format.
W0614 18:03:45.158035 11551 utils.cpp:207] BVLC BatchNormLayer without ScaleLayer detected: 7, it will be converted to NVCaffe Format.
W0614 18:03:45.158133 11551 utils.cpp:207] BVLC BatchNormLayer without ScaleLayer detected: 21, it will be converted to NVCaffe Format.
I0614 18:03:45.168931 11551 vai_p_caffe.cpp:287] pruning/alexnetBNnoLRN/regular_rate_0.6/net_finetune.prototxt
I0614 18:03:45.412146 11551 gpu_memory.cpp:53] GPUMemory::Manager initialized with Caching (CUB) GPU Allocator
I0614 18:03:45.412168 11551 gpu_memory.cpp:55] Total memory: 25635127296, Free: 24796921856, dev_info[0]: total=25635127296 free=24796921856
I0614 18:03:45.412318 11551 caffe_interface.cpp:539] Using GPUs 0
I0614 18:03:45.412416 11551 caffe_interface.cpp:544] GPU 0: Quadro P6000
I0614 18:03:46.059758 11551 solver.cpp:51] Initializing solver from parameters: 
test_iter: 80
test_interval: 1000
base_lr: 0.001
display: 50
max_iter: 12000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 2500
snapshot: 6000
snapshot_prefix: "pruning/alexnetBNnoLRN/regular_rate_0.6/snapshots/"
solver_mode: GPU
device_id: 0
random_seed: 1201
net: "pruning/alexnetBNnoLRN/regular_rate_0.6/net_finetune.prototxt"
type: "Adam"
I0614 18:03:46.060521 11551 solver.cpp:99] Creating training net from net file: pruning/alexnetBNnoLRN/regular_rate_0.6/net_finetune.prototxt
I0614 18:03:46.061169 11551 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0614 18:03:46.061185 11551 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0614 18:03:46.061189 11551 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy-top1
I0614 18:03:46.061197 11551 net.cpp:52] Initializing net from parameters: 
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_value: 106
    mean_value: 116
    mean_value: 124
  }
  data_param {
    source: "input/lmdb/train_lmdb"
    batch_size: 256
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 0
    kernel_size: 8
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "bn1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn2"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "bn2"
  top: "relu2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "relu6"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "drop6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn7"
  type: "BatchNorm"
  bottom: "fc7"
  top: "bn7"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "bn7"
  top: "relu7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "relu7"
  top: "drop7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "drop7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0614 18:03:46.061739 11551 layer_factory.hpp:77] Creating layer data
I0614 18:03:46.061884 11551 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0614 18:03:46.064472 11551 net.cpp:94] Creating Layer data
I0614 18:03:46.064512 11551 net.cpp:409] data -> data
I0614 18:03:46.064540 11551 net.cpp:409] data -> label
I0614 18:03:46.066036 11588 db_lmdb.cpp:35] Opened lmdb input/lmdb/train_lmdb
I0614 18:03:46.066067 11588 db_lmdb.cpp:38] Items count: 20000
I0614 18:03:46.066098 11588 data_reader.cpp:124] TRAIN: reading data using 1 channel(s)
I0614 18:03:46.066525 11551 data_layer.cpp:78] ReshapePrefetch 256, 3, 227, 227
I0614 18:03:46.066694 11551 data_layer.cpp:83] output data size: 256,3,227,227
I0614 18:03:46.612167 11551 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0614 18:03:46.612274 11551 net.cpp:144] Setting up data
I0614 18:03:46.612279 11551 net.cpp:151] Top shape: 256 3 227 227 (39574272)
I0614 18:03:46.612288 11551 net.cpp:151] Top shape: 256 (256)
I0614 18:03:46.612293 11551 net.cpp:159] Memory required for data: 158298112
I0614 18:03:46.612298 11551 layer_factory.hpp:77] Creating layer conv1
I0614 18:03:46.612308 11551 net.cpp:94] Creating Layer conv1
I0614 18:03:46.612313 11551 net.cpp:435] conv1 <- data
I0614 18:03:46.612318 11551 net.cpp:409] conv1 -> conv1
I0614 18:03:46.612723 11551 net.cpp:144] Setting up conv1
I0614 18:03:46.612731 11551 net.cpp:151] Top shape: 256 96 55 55 (74342400)
I0614 18:03:46.612737 11551 net.cpp:159] Memory required for data: 455667712
I0614 18:03:46.612748 11551 layer_factory.hpp:77] Creating layer bn1
I0614 18:03:46.612756 11551 net.cpp:94] Creating Layer bn1
I0614 18:03:46.612761 11551 net.cpp:435] bn1 <- conv1
I0614 18:03:46.612764 11551 net.cpp:409] bn1 -> bn1
I0614 18:03:46.613068 11551 net.cpp:144] Setting up bn1
I0614 18:03:46.613075 11551 net.cpp:151] Top shape: 256 96 55 55 (74342400)
I0614 18:03:46.613080 11551 net.cpp:159] Memory required for data: 753037312
I0614 18:03:46.613090 11551 layer_factory.hpp:77] Creating layer relu1
I0614 18:03:46.613096 11551 net.cpp:94] Creating Layer relu1
I0614 18:03:46.613101 11551 net.cpp:435] relu1 <- bn1
I0614 18:03:46.613104 11551 net.cpp:409] relu1 -> relu1
I0614 18:03:46.613116 11551 net.cpp:144] Setting up relu1
I0614 18:03:46.613121 11551 net.cpp:151] Top shape: 256 96 55 55 (74342400)
I0614 18:03:46.613124 11551 net.cpp:159] Memory required for data: 1050406912
I0614 18:03:46.613128 11551 layer_factory.hpp:77] Creating layer pool1
I0614 18:03:46.613133 11551 net.cpp:94] Creating Layer pool1
I0614 18:03:46.613137 11551 net.cpp:435] pool1 <- relu1
I0614 18:03:46.613142 11551 net.cpp:409] pool1 -> pool1
I0614 18:03:46.613166 11551 net.cpp:144] Setting up pool1
I0614 18:03:46.613170 11551 net.cpp:151] Top shape: 256 96 27 27 (17915904)
I0614 18:03:46.613174 11551 net.cpp:159] Memory required for data: 1122070528
I0614 18:03:46.613178 11551 layer_factory.hpp:77] Creating layer conv2
I0614 18:03:46.613184 11551 net.cpp:94] Creating Layer conv2
I0614 18:03:46.613188 11551 net.cpp:435] conv2 <- pool1
I0614 18:03:46.613193 11551 net.cpp:409] conv2 -> conv2
I0614 18:03:46.629776 11551 net.cpp:144] Setting up conv2
I0614 18:03:46.629791 11551 net.cpp:151] Top shape: 256 256 27 27 (47775744)
I0614 18:03:46.629801 11551 net.cpp:159] Memory required for data: 1313173504
I0614 18:03:46.629812 11551 layer_factory.hpp:77] Creating layer bn2
I0614 18:03:46.629822 11551 net.cpp:94] Creating Layer bn2
I0614 18:03:46.629827 11551 net.cpp:435] bn2 <- conv2
I0614 18:03:46.629839 11551 net.cpp:409] bn2 -> bn2
I0614 18:03:46.630199 11551 net.cpp:144] Setting up bn2
I0614 18:03:46.630210 11551 net.cpp:151] Top shape: 256 256 27 27 (47775744)
I0614 18:03:46.630218 11551 net.cpp:159] Memory required for data: 1504276480
I0614 18:03:46.630228 11551 layer_factory.hpp:77] Creating layer relu2
I0614 18:03:46.630234 11551 net.cpp:94] Creating Layer relu2
I0614 18:03:46.630239 11551 net.cpp:435] relu2 <- bn2
I0614 18:03:46.630245 11551 net.cpp:409] relu2 -> relu2
I0614 18:03:46.630261 11551 net.cpp:144] Setting up relu2
I0614 18:03:46.630266 11551 net.cpp:151] Top shape: 256 256 27 27 (47775744)
I0614 18:03:46.630275 11551 net.cpp:159] Memory required for data: 1695379456
I0614 18:03:46.630281 11551 layer_factory.hpp:77] Creating layer pool2
I0614 18:03:46.630288 11551 net.cpp:94] Creating Layer pool2
I0614 18:03:46.630293 11551 net.cpp:435] pool2 <- relu2
I0614 18:03:46.630298 11551 net.cpp:409] pool2 -> pool2
I0614 18:03:46.630317 11551 net.cpp:144] Setting up pool2
I0614 18:03:46.630322 11551 net.cpp:151] Top shape: 256 256 13 13 (11075584)
I0614 18:03:46.630328 11551 net.cpp:159] Memory required for data: 1739681792
I0614 18:03:46.630332 11551 layer_factory.hpp:77] Creating layer conv3
I0614 18:03:46.630743 11551 net.cpp:94] Creating Layer conv3
I0614 18:03:46.630751 11551 net.cpp:435] conv3 <- pool2
I0614 18:03:46.630762 11551 net.cpp:409] conv3 -> conv3
I0614 18:03:46.651314 11551 net.cpp:144] Setting up conv3
I0614 18:03:46.651335 11551 net.cpp:151] Top shape: 256 384 13 13 (16613376)
I0614 18:03:46.651345 11551 net.cpp:159] Memory required for data: 1806135296
I0614 18:03:46.651355 11551 layer_factory.hpp:77] Creating layer relu3
I0614 18:03:46.651361 11551 net.cpp:94] Creating Layer relu3
I0614 18:03:46.651366 11551 net.cpp:435] relu3 <- conv3
I0614 18:03:46.651373 11551 net.cpp:409] relu3 -> relu3
I0614 18:03:46.651392 11551 net.cpp:144] Setting up relu3
I0614 18:03:46.651396 11551 net.cpp:151] Top shape: 256 384 13 13 (16613376)
I0614 18:03:46.651401 11551 net.cpp:159] Memory required for data: 1872588800
I0614 18:03:46.651404 11551 layer_factory.hpp:77] Creating layer conv4
I0614 18:03:46.651413 11551 net.cpp:94] Creating Layer conv4
I0614 18:03:46.651417 11551 net.cpp:435] conv4 <- relu3
I0614 18:03:46.651422 11551 net.cpp:409] conv4 -> conv4
I0614 18:03:46.678350 11551 net.cpp:144] Setting up conv4
I0614 18:03:46.678424 11551 net.cpp:151] Top shape: 256 384 13 13 (16613376)
I0614 18:03:46.678442 11551 net.cpp:159] Memory required for data: 1939042304
I0614 18:03:46.678467 11551 layer_factory.hpp:77] Creating layer relu4
I0614 18:03:46.678479 11551 net.cpp:94] Creating Layer relu4
I0614 18:03:46.678488 11551 net.cpp:435] relu4 <- conv4
I0614 18:03:46.678498 11551 net.cpp:409] relu4 -> relu4
I0614 18:03:46.678535 11551 net.cpp:144] Setting up relu4
I0614 18:03:46.678541 11551 net.cpp:151] Top shape: 256 384 13 13 (16613376)
I0614 18:03:46.678550 11551 net.cpp:159] Memory required for data: 2005495808
I0614 18:03:46.678556 11551 layer_factory.hpp:77] Creating layer conv5
I0614 18:03:46.678570 11551 net.cpp:94] Creating Layer conv5
I0614 18:03:46.678576 11551 net.cpp:435] conv5 <- relu4
I0614 18:03:46.678586 11551 net.cpp:409] conv5 -> conv5
I0614 18:03:46.695912 11551 net.cpp:144] Setting up conv5
I0614 18:03:46.695933 11551 net.cpp:151] Top shape: 256 256 13 13 (11075584)
I0614 18:03:46.695945 11551 net.cpp:159] Memory required for data: 2049798144
I0614 18:03:46.695955 11551 layer_factory.hpp:77] Creating layer relu5
I0614 18:03:46.695963 11551 net.cpp:94] Creating Layer relu5
I0614 18:03:46.695969 11551 net.cpp:435] relu5 <- conv5
I0614 18:03:46.695976 11551 net.cpp:409] relu5 -> relu5
I0614 18:03:46.695996 11551 net.cpp:144] Setting up relu5
I0614 18:03:46.696000 11551 net.cpp:151] Top shape: 256 256 13 13 (11075584)
I0614 18:03:46.696007 11551 net.cpp:159] Memory required for data: 2094100480
I0614 18:03:46.696009 11551 layer_factory.hpp:77] Creating layer pool5
I0614 18:03:46.696017 11551 net.cpp:94] Creating Layer pool5
I0614 18:03:46.696019 11551 net.cpp:435] pool5 <- relu5
I0614 18:03:46.696024 11551 net.cpp:409] pool5 -> pool5
I0614 18:03:46.696044 11551 net.cpp:144] Setting up pool5
I0614 18:03:46.696048 11551 net.cpp:151] Top shape: 256 256 6 6 (2359296)
I0614 18:03:46.696054 11551 net.cpp:159] Memory required for data: 2103537664
I0614 18:03:46.696058 11551 layer_factory.hpp:77] Creating layer fc6
I0614 18:03:46.696067 11551 net.cpp:94] Creating Layer fc6
I0614 18:03:46.696070 11551 net.cpp:435] fc6 <- pool5
I0614 18:03:46.696076 11551 net.cpp:409] fc6 -> fc6
I0614 18:03:47.100409 11551 net.cpp:144] Setting up fc6
I0614 18:03:47.100435 11551 net.cpp:151] Top shape: 256 4096 (1048576)
I0614 18:03:47.100442 11551 net.cpp:159] Memory required for data: 2107731968
I0614 18:03:47.100467 11551 layer_factory.hpp:77] Creating layer relu6
I0614 18:03:47.100474 11551 net.cpp:94] Creating Layer relu6
I0614 18:03:47.100478 11551 net.cpp:435] relu6 <- fc6
I0614 18:03:47.100483 11551 net.cpp:409] relu6 -> relu6
I0614 18:03:47.100497 11551 net.cpp:144] Setting up relu6
I0614 18:03:47.100502 11551 net.cpp:151] Top shape: 256 4096 (1048576)
I0614 18:03:47.100505 11551 net.cpp:159] Memory required for data: 2111926272
I0614 18:03:47.100508 11551 layer_factory.hpp:77] Creating layer drop6
I0614 18:03:47.100513 11551 net.cpp:94] Creating Layer drop6
I0614 18:03:47.100946 11551 net.cpp:435] drop6 <- relu6
I0614 18:03:47.100952 11551 net.cpp:409] drop6 -> drop6
I0614 18:03:47.100968 11551 net.cpp:144] Setting up drop6
I0614 18:03:47.100972 11551 net.cpp:151] Top shape: 256 4096 (1048576)
I0614 18:03:47.100976 11551 net.cpp:159] Memory required for data: 2116120576
I0614 18:03:47.100980 11551 layer_factory.hpp:77] Creating layer fc7
I0614 18:03:47.100986 11551 net.cpp:94] Creating Layer fc7
I0614 18:03:47.100991 11551 net.cpp:435] fc7 <- drop6
I0614 18:03:47.100996 11551 net.cpp:409] fc7 -> fc7
I0614 18:03:47.260493 11551 net.cpp:144] Setting up fc7
I0614 18:03:47.260519 11551 net.cpp:151] Top shape: 256 4096 (1048576)
I0614 18:03:47.260527 11551 net.cpp:159] Memory required for data: 2120314880
I0614 18:03:47.260536 11551 layer_factory.hpp:77] Creating layer bn7
I0614 18:03:47.260545 11551 net.cpp:94] Creating Layer bn7
I0614 18:03:47.260550 11551 net.cpp:435] bn7 <- fc7
I0614 18:03:47.260555 11551 net.cpp:409] bn7 -> bn7
I0614 18:03:47.260840 11551 net.cpp:144] Setting up bn7
I0614 18:03:47.260847 11551 net.cpp:151] Top shape: 256 4096 (1048576)
I0614 18:03:47.260852 11551 net.cpp:159] Memory required for data: 2124509184
I0614 18:03:47.260860 11551 layer_factory.hpp:77] Creating layer relu7
I0614 18:03:47.260865 11551 net.cpp:94] Creating Layer relu7
I0614 18:03:47.260869 11551 net.cpp:435] relu7 <- bn7
I0614 18:03:47.260874 11551 net.cpp:409] relu7 -> relu7
I0614 18:03:47.260886 11551 net.cpp:144] Setting up relu7
I0614 18:03:47.260890 11551 net.cpp:151] Top shape: 256 4096 (1048576)
I0614 18:03:47.260895 11551 net.cpp:159] Memory required for data: 2128703488
I0614 18:03:47.260897 11551 layer_factory.hpp:77] Creating layer drop7
I0614 18:03:47.260913 11551 net.cpp:94] Creating Layer drop7
I0614 18:03:47.260916 11551 net.cpp:435] drop7 <- relu7
I0614 18:03:47.260921 11551 net.cpp:409] drop7 -> drop7
I0614 18:03:47.260938 11551 net.cpp:144] Setting up drop7
I0614 18:03:47.260941 11551 net.cpp:151] Top shape: 256 4096 (1048576)
I0614 18:03:47.260946 11551 net.cpp:159] Memory required for data: 2132897792
I0614 18:03:47.260949 11551 layer_factory.hpp:77] Creating layer fc8
I0614 18:03:47.260955 11551 net.cpp:94] Creating Layer fc8
I0614 18:03:47.260959 11551 net.cpp:435] fc8 <- drop7
I0614 18:03:47.260963 11551 net.cpp:409] fc8 -> fc8
I0614 18:03:47.261111 11551 net.cpp:144] Setting up fc8
I0614 18:03:47.261116 11551 net.cpp:151] Top shape: 256 2 (512)
I0614 18:03:47.261121 11551 net.cpp:159] Memory required for data: 2132899840
I0614 18:03:47.261126 11551 layer_factory.hpp:77] Creating layer loss
I0614 18:03:47.261132 11551 net.cpp:94] Creating Layer loss
I0614 18:03:47.261135 11551 net.cpp:435] loss <- fc8
I0614 18:03:47.261140 11551 net.cpp:435] loss <- label
I0614 18:03:47.261144 11551 net.cpp:409] loss -> loss
I0614 18:03:47.261152 11551 layer_factory.hpp:77] Creating layer loss
I0614 18:03:47.261196 11551 net.cpp:144] Setting up loss
I0614 18:03:47.261200 11551 net.cpp:151] Top shape: (1)
I0614 18:03:47.261204 11551 net.cpp:154]     with loss weight 1
I0614 18:03:47.261216 11551 net.cpp:159] Memory required for data: 2132899844
I0614 18:03:47.261219 11551 net.cpp:220] loss needs backward computation.
I0614 18:03:47.261224 11551 net.cpp:220] fc8 needs backward computation.
I0614 18:03:47.261227 11551 net.cpp:220] drop7 needs backward computation.
I0614 18:03:47.261231 11551 net.cpp:220] relu7 needs backward computation.
I0614 18:03:47.261235 11551 net.cpp:220] bn7 needs backward computation.
I0614 18:03:47.261238 11551 net.cpp:220] fc7 needs backward computation.
I0614 18:03:47.261242 11551 net.cpp:220] drop6 needs backward computation.
I0614 18:03:47.261246 11551 net.cpp:220] relu6 needs backward computation.
I0614 18:03:47.261250 11551 net.cpp:220] fc6 needs backward computation.
I0614 18:03:47.261255 11551 net.cpp:220] pool5 needs backward computation.
I0614 18:03:47.261258 11551 net.cpp:220] relu5 needs backward computation.
I0614 18:03:47.261262 11551 net.cpp:220] conv5 needs backward computation.
I0614 18:03:47.261266 11551 net.cpp:220] relu4 needs backward computation.
I0614 18:03:47.261595 11551 net.cpp:220] conv4 needs backward computation.
I0614 18:03:47.261602 11551 net.cpp:220] relu3 needs backward computation.
I0614 18:03:47.261606 11551 net.cpp:220] conv3 needs backward computation.
I0614 18:03:47.261610 11551 net.cpp:220] pool2 needs backward computation.
I0614 18:03:47.261615 11551 net.cpp:220] relu2 needs backward computation.
I0614 18:03:47.261618 11551 net.cpp:220] bn2 needs backward computation.
I0614 18:03:47.261622 11551 net.cpp:220] conv2 needs backward computation.
I0614 18:03:47.261626 11551 net.cpp:220] pool1 needs backward computation.
I0614 18:03:47.261631 11551 net.cpp:220] relu1 needs backward computation.
I0614 18:03:47.261634 11551 net.cpp:220] bn1 needs backward computation.
I0614 18:03:47.261638 11551 net.cpp:220] conv1 needs backward computation.
I0614 18:03:47.261642 11551 net.cpp:222] data does not need backward computation.
I0614 18:03:47.261646 11551 net.cpp:264] This network produces output loss
I0614 18:03:47.261667 11551 net.cpp:284] Network initialization done.
I0614 18:03:47.262526 11551 solver.cpp:189] Creating test net (#0) specified by net file: pruning/alexnetBNnoLRN/regular_rate_0.6/net_finetune.prototxt
I0614 18:03:47.262562 11551 net.cpp:323] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0614 18:03:47.262576 11551 net.cpp:52] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_value: 106
    mean_value: 116
    mean_value: 124
  }
  data_param {
    source: "input/lmdb/valid_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 0
    kernel_size: 8
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "bn1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn2"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "bn2"
  top: "relu2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "relu6"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "drop6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn7"
  type: "BatchNorm"
  bottom: "fc7"
  top: "bn7"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "bn7"
  top: "relu7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "relu7"
  top: "drop7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "drop7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy-top1"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "top-1"
  include {
    phase: TEST
  }
}
I0614 18:03:47.263032 11551 layer_factory.hpp:77] Creating layer data
I0614 18:03:47.263079 11551 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0614 18:03:47.265101 11551 net.cpp:94] Creating Layer data
I0614 18:03:47.265117 11551 net.cpp:409] data -> data
I0614 18:03:47.265127 11551 net.cpp:409] data -> label
I0614 18:03:47.267261 11618 db_lmdb.cpp:35] Opened lmdb input/lmdb/valid_lmdb
I0614 18:03:47.267290 11618 db_lmdb.cpp:38] Items count: 4000
I0614 18:03:47.267329 11618 data_reader.cpp:124] TEST: reading data using 1 channel(s)
I0614 18:03:47.267722 11551 data_layer.cpp:78] ReshapePrefetch 50, 3, 227, 227
I0614 18:03:47.267788 11551 data_layer.cpp:83] output data size: 50,3,227,227
I0614 18:03:47.374402 11551 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0614 18:03:47.374789 11551 net.cpp:144] Setting up data
I0614 18:03:47.374797 11551 net.cpp:151] Top shape: 50 3 227 227 (7729350)
I0614 18:03:47.374806 11551 net.cpp:151] Top shape: 50 (50)
I0614 18:03:47.374810 11551 net.cpp:159] Memory required for data: 30917600
I0614 18:03:47.374814 11551 layer_factory.hpp:77] Creating layer label_data_1_split
I0614 18:03:47.374822 11551 net.cpp:94] Creating Layer label_data_1_split
I0614 18:03:47.374826 11551 net.cpp:435] label_data_1_split <- label
I0614 18:03:47.374848 11551 net.cpp:409] label_data_1_split -> label_data_1_split_0
I0614 18:03:47.374857 11551 net.cpp:409] label_data_1_split -> label_data_1_split_1
I0614 18:03:47.374862 11551 net.cpp:409] label_data_1_split -> label_data_1_split_2
I0614 18:03:47.374910 11551 net.cpp:144] Setting up label_data_1_split
I0614 18:03:47.374914 11551 net.cpp:151] Top shape: 50 (50)
I0614 18:03:47.374918 11551 net.cpp:151] Top shape: 50 (50)
I0614 18:03:47.374922 11551 net.cpp:151] Top shape: 50 (50)
I0614 18:03:47.374927 11551 net.cpp:159] Memory required for data: 30918200
I0614 18:03:47.374930 11551 layer_factory.hpp:77] Creating layer conv1
I0614 18:03:47.374941 11551 net.cpp:94] Creating Layer conv1
I0614 18:03:47.374946 11551 net.cpp:435] conv1 <- data
I0614 18:03:47.374951 11551 net.cpp:409] conv1 -> conv1
I0614 18:03:47.375294 11551 net.cpp:144] Setting up conv1
I0614 18:03:47.375301 11551 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0614 18:03:47.375306 11551 net.cpp:159] Memory required for data: 88998200
I0614 18:03:47.375317 11551 layer_factory.hpp:77] Creating layer bn1
I0614 18:03:47.375324 11551 net.cpp:94] Creating Layer bn1
I0614 18:03:47.375327 11551 net.cpp:435] bn1 <- conv1
I0614 18:03:47.375332 11551 net.cpp:409] bn1 -> bn1
I0614 18:03:47.375675 11551 net.cpp:144] Setting up bn1
I0614 18:03:47.375682 11551 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0614 18:03:47.375689 11551 net.cpp:159] Memory required for data: 147078200
I0614 18:03:47.375697 11551 layer_factory.hpp:77] Creating layer relu1
I0614 18:03:47.375705 11551 net.cpp:94] Creating Layer relu1
I0614 18:03:47.375708 11551 net.cpp:435] relu1 <- bn1
I0614 18:03:47.375713 11551 net.cpp:409] relu1 -> relu1
I0614 18:03:47.375727 11551 net.cpp:144] Setting up relu1
I0614 18:03:47.375730 11551 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0614 18:03:47.375735 11551 net.cpp:159] Memory required for data: 205158200
I0614 18:03:47.375739 11551 layer_factory.hpp:77] Creating layer pool1
I0614 18:03:47.375744 11551 net.cpp:94] Creating Layer pool1
I0614 18:03:47.375748 11551 net.cpp:435] pool1 <- relu1
I0614 18:03:47.375752 11551 net.cpp:409] pool1 -> pool1
I0614 18:03:47.375770 11551 net.cpp:144] Setting up pool1
I0614 18:03:47.375774 11551 net.cpp:151] Top shape: 50 96 27 27 (3499200)
I0614 18:03:47.375778 11551 net.cpp:159] Memory required for data: 219155000
I0614 18:03:47.375782 11551 layer_factory.hpp:77] Creating layer conv2
I0614 18:03:47.375792 11551 net.cpp:94] Creating Layer conv2
I0614 18:03:47.375795 11551 net.cpp:435] conv2 <- pool1
I0614 18:03:47.375799 11551 net.cpp:409] conv2 -> conv2
I0614 18:03:47.382881 11551 net.cpp:144] Setting up conv2
I0614 18:03:47.382897 11551 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0614 18:03:47.382905 11551 net.cpp:159] Memory required for data: 256479800
I0614 18:03:47.382915 11551 layer_factory.hpp:77] Creating layer bn2
I0614 18:03:47.382923 11551 net.cpp:94] Creating Layer bn2
I0614 18:03:47.382927 11551 net.cpp:435] bn2 <- conv2
I0614 18:03:47.382933 11551 net.cpp:409] bn2 -> bn2
I0614 18:03:47.383618 11551 net.cpp:144] Setting up bn2
I0614 18:03:47.383626 11551 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0614 18:03:47.383632 11551 net.cpp:159] Memory required for data: 293804600
I0614 18:03:47.383641 11551 layer_factory.hpp:77] Creating layer relu2
I0614 18:03:47.383647 11551 net.cpp:94] Creating Layer relu2
I0614 18:03:47.383651 11551 net.cpp:435] relu2 <- bn2
I0614 18:03:47.383656 11551 net.cpp:409] relu2 -> relu2
I0614 18:03:47.383703 11551 net.cpp:144] Setting up relu2
I0614 18:03:47.384222 11551 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0614 18:03:47.384232 11551 net.cpp:159] Memory required for data: 331129400
I0614 18:03:47.384238 11551 layer_factory.hpp:77] Creating layer pool2
I0614 18:03:47.384245 11551 net.cpp:94] Creating Layer pool2
I0614 18:03:47.384250 11551 net.cpp:435] pool2 <- relu2
I0614 18:03:47.384258 11551 net.cpp:409] pool2 -> pool2
I0614 18:03:47.384347 11551 net.cpp:144] Setting up pool2
I0614 18:03:47.384354 11551 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0614 18:03:47.384362 11551 net.cpp:159] Memory required for data: 339782200
I0614 18:03:47.384367 11551 layer_factory.hpp:77] Creating layer conv3
I0614 18:03:47.384454 11551 net.cpp:94] Creating Layer conv3
I0614 18:03:47.384461 11551 net.cpp:435] conv3 <- pool2
I0614 18:03:47.384469 11551 net.cpp:409] conv3 -> conv3
I0614 18:03:47.397763 11551 net.cpp:144] Setting up conv3
I0614 18:03:47.397781 11551 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0614 18:03:47.397790 11551 net.cpp:159] Memory required for data: 352761400
I0614 18:03:47.397799 11551 layer_factory.hpp:77] Creating layer relu3
I0614 18:03:47.397806 11551 net.cpp:94] Creating Layer relu3
I0614 18:03:47.397811 11551 net.cpp:435] relu3 <- conv3
I0614 18:03:47.397817 11551 net.cpp:409] relu3 -> relu3
I0614 18:03:47.397853 11551 net.cpp:144] Setting up relu3
I0614 18:03:47.397856 11551 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0614 18:03:47.397861 11551 net.cpp:159] Memory required for data: 365740600
I0614 18:03:47.397866 11551 layer_factory.hpp:77] Creating layer conv4
I0614 18:03:47.397876 11551 net.cpp:94] Creating Layer conv4
I0614 18:03:47.397882 11551 net.cpp:435] conv4 <- relu3
I0614 18:03:47.397890 11551 net.cpp:409] conv4 -> conv4
I0614 18:03:47.415591 11551 net.cpp:144] Setting up conv4
I0614 18:03:47.415611 11551 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0614 18:03:47.415619 11551 net.cpp:159] Memory required for data: 378719800
I0614 18:03:47.415645 11551 layer_factory.hpp:77] Creating layer relu4
I0614 18:03:47.415652 11551 net.cpp:94] Creating Layer relu4
I0614 18:03:47.415658 11551 net.cpp:435] relu4 <- conv4
I0614 18:03:47.415664 11551 net.cpp:409] relu4 -> relu4
I0614 18:03:47.415689 11551 net.cpp:144] Setting up relu4
I0614 18:03:47.415692 11551 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0614 18:03:47.415697 11551 net.cpp:159] Memory required for data: 391699000
I0614 18:03:47.415700 11551 layer_factory.hpp:77] Creating layer conv5
I0614 18:03:47.415709 11551 net.cpp:94] Creating Layer conv5
I0614 18:03:47.415714 11551 net.cpp:435] conv5 <- relu4
I0614 18:03:47.415719 11551 net.cpp:409] conv5 -> conv5
I0614 18:03:47.430797 11551 net.cpp:144] Setting up conv5
I0614 18:03:47.430816 11551 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0614 18:03:47.430825 11551 net.cpp:159] Memory required for data: 400351800
I0614 18:03:47.430836 11551 layer_factory.hpp:77] Creating layer relu5
I0614 18:03:47.430843 11551 net.cpp:94] Creating Layer relu5
I0614 18:03:47.430850 11551 net.cpp:435] relu5 <- conv5
I0614 18:03:47.430860 11551 net.cpp:409] relu5 -> relu5
I0614 18:03:47.430888 11551 net.cpp:144] Setting up relu5
I0614 18:03:47.430893 11551 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0614 18:03:47.430899 11551 net.cpp:159] Memory required for data: 409004600
I0614 18:03:47.430904 11551 layer_factory.hpp:77] Creating layer pool5
I0614 18:03:47.430914 11551 net.cpp:94] Creating Layer pool5
I0614 18:03:47.430919 11551 net.cpp:435] pool5 <- relu5
I0614 18:03:47.430925 11551 net.cpp:409] pool5 -> pool5
I0614 18:03:47.430979 11551 net.cpp:144] Setting up pool5
I0614 18:03:47.430984 11551 net.cpp:151] Top shape: 50 256 6 6 (460800)
I0614 18:03:47.430991 11551 net.cpp:159] Memory required for data: 410847800
I0614 18:03:47.430996 11551 layer_factory.hpp:77] Creating layer fc6
I0614 18:03:47.431005 11551 net.cpp:94] Creating Layer fc6
I0614 18:03:47.431010 11551 net.cpp:435] fc6 <- pool5
I0614 18:03:47.431017 11551 net.cpp:409] fc6 -> fc6
I0614 18:03:47.783561 11551 net.cpp:144] Setting up fc6
I0614 18:03:47.783584 11551 net.cpp:151] Top shape: 50 4096 (204800)
I0614 18:03:47.784106 11551 net.cpp:159] Memory required for data: 411667000
I0614 18:03:47.784119 11551 layer_factory.hpp:77] Creating layer relu6
I0614 18:03:47.784129 11551 net.cpp:94] Creating Layer relu6
I0614 18:03:47.784137 11551 net.cpp:435] relu6 <- fc6
I0614 18:03:47.784144 11551 net.cpp:409] relu6 -> relu6
I0614 18:03:47.784169 11551 net.cpp:144] Setting up relu6
I0614 18:03:47.784173 11551 net.cpp:151] Top shape: 50 4096 (204800)
I0614 18:03:47.784178 11551 net.cpp:159] Memory required for data: 412486200
I0614 18:03:47.784180 11551 layer_factory.hpp:77] Creating layer drop6
I0614 18:03:47.784189 11551 net.cpp:94] Creating Layer drop6
I0614 18:03:47.784193 11551 net.cpp:435] drop6 <- relu6
I0614 18:03:47.784197 11551 net.cpp:409] drop6 -> drop6
I0614 18:03:47.784215 11551 net.cpp:144] Setting up drop6
I0614 18:03:47.784219 11551 net.cpp:151] Top shape: 50 4096 (204800)
I0614 18:03:47.784224 11551 net.cpp:159] Memory required for data: 413305400
I0614 18:03:47.784227 11551 layer_factory.hpp:77] Creating layer fc7
I0614 18:03:47.784233 11551 net.cpp:94] Creating Layer fc7
I0614 18:03:47.784237 11551 net.cpp:435] fc7 <- drop6
I0614 18:03:47.784242 11551 net.cpp:409] fc7 -> fc7
I0614 18:03:47.939678 11551 net.cpp:144] Setting up fc7
I0614 18:03:47.939704 11551 net.cpp:151] Top shape: 50 4096 (204800)
I0614 18:03:47.939713 11551 net.cpp:159] Memory required for data: 414124600
I0614 18:03:47.939723 11551 layer_factory.hpp:77] Creating layer bn7
I0614 18:03:47.939733 11551 net.cpp:94] Creating Layer bn7
I0614 18:03:47.939738 11551 net.cpp:435] bn7 <- fc7
I0614 18:03:47.939743 11551 net.cpp:409] bn7 -> bn7
I0614 18:03:47.940068 11551 net.cpp:144] Setting up bn7
I0614 18:03:47.940074 11551 net.cpp:151] Top shape: 50 4096 (204800)
I0614 18:03:47.940079 11551 net.cpp:159] Memory required for data: 414943800
I0614 18:03:47.940088 11551 layer_factory.hpp:77] Creating layer relu7
I0614 18:03:47.940093 11551 net.cpp:94] Creating Layer relu7
I0614 18:03:47.940096 11551 net.cpp:435] relu7 <- bn7
I0614 18:03:47.940102 11551 net.cpp:409] relu7 -> relu7
I0614 18:03:47.940114 11551 net.cpp:144] Setting up relu7
I0614 18:03:47.940119 11551 net.cpp:151] Top shape: 50 4096 (204800)
I0614 18:03:47.940122 11551 net.cpp:159] Memory required for data: 415763000
I0614 18:03:47.940125 11551 layer_factory.hpp:77] Creating layer drop7
I0614 18:03:47.940131 11551 net.cpp:94] Creating Layer drop7
I0614 18:03:47.940150 11551 net.cpp:435] drop7 <- relu7
I0614 18:03:47.940155 11551 net.cpp:409] drop7 -> drop7
I0614 18:03:47.940174 11551 net.cpp:144] Setting up drop7
I0614 18:03:47.940178 11551 net.cpp:151] Top shape: 50 4096 (204800)
I0614 18:03:47.940182 11551 net.cpp:159] Memory required for data: 416582200
I0614 18:03:47.940186 11551 layer_factory.hpp:77] Creating layer fc8
I0614 18:03:47.940194 11551 net.cpp:94] Creating Layer fc8
I0614 18:03:47.940197 11551 net.cpp:435] fc8 <- drop7
I0614 18:03:47.940202 11551 net.cpp:409] fc8 -> fc8
I0614 18:03:47.940358 11551 net.cpp:144] Setting up fc8
I0614 18:03:47.940364 11551 net.cpp:151] Top shape: 50 2 (100)
I0614 18:03:47.940368 11551 net.cpp:159] Memory required for data: 416582600
I0614 18:03:47.940374 11551 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0614 18:03:47.940382 11551 net.cpp:94] Creating Layer fc8_fc8_0_split
I0614 18:03:47.940387 11551 net.cpp:435] fc8_fc8_0_split <- fc8
I0614 18:03:47.940394 11551 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0614 18:03:47.940402 11551 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0614 18:03:47.940408 11551 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_2
I0614 18:03:47.940434 11551 net.cpp:144] Setting up fc8_fc8_0_split
I0614 18:03:47.940438 11551 net.cpp:151] Top shape: 50 2 (100)
I0614 18:03:47.940443 11551 net.cpp:151] Top shape: 50 2 (100)
I0614 18:03:47.940446 11551 net.cpp:151] Top shape: 50 2 (100)
I0614 18:03:47.940450 11551 net.cpp:159] Memory required for data: 416583800
I0614 18:03:47.940454 11551 layer_factory.hpp:77] Creating layer accuracy
I0614 18:03:47.940469 11551 net.cpp:94] Creating Layer accuracy
I0614 18:03:47.940843 11551 net.cpp:435] accuracy <- fc8_fc8_0_split_0
I0614 18:03:47.940850 11551 net.cpp:435] accuracy <- label_data_1_split_0
I0614 18:03:47.940855 11551 net.cpp:409] accuracy -> accuracy
I0614 18:03:47.940862 11551 net.cpp:144] Setting up accuracy
I0614 18:03:47.940866 11551 net.cpp:151] Top shape: (1)
I0614 18:03:47.940871 11551 net.cpp:159] Memory required for data: 416583804
I0614 18:03:47.940873 11551 layer_factory.hpp:77] Creating layer loss
I0614 18:03:47.940881 11551 net.cpp:94] Creating Layer loss
I0614 18:03:47.940884 11551 net.cpp:435] loss <- fc8_fc8_0_split_1
I0614 18:03:47.940888 11551 net.cpp:435] loss <- label_data_1_split_1
I0614 18:03:47.940893 11551 net.cpp:409] loss -> loss
I0614 18:03:47.940902 11551 layer_factory.hpp:77] Creating layer loss
I0614 18:03:47.940955 11551 net.cpp:144] Setting up loss
I0614 18:03:47.940959 11551 net.cpp:151] Top shape: (1)
I0614 18:03:47.940963 11551 net.cpp:154]     with loss weight 1
I0614 18:03:47.940976 11551 net.cpp:159] Memory required for data: 416583808
I0614 18:03:47.940979 11551 layer_factory.hpp:77] Creating layer accuracy-top1
I0614 18:03:47.940984 11551 net.cpp:94] Creating Layer accuracy-top1
I0614 18:03:47.940989 11551 net.cpp:435] accuracy-top1 <- fc8_fc8_0_split_2
I0614 18:03:47.940992 11551 net.cpp:435] accuracy-top1 <- label_data_1_split_2
I0614 18:03:47.940997 11551 net.cpp:409] accuracy-top1 -> top-1
I0614 18:03:47.941004 11551 net.cpp:144] Setting up accuracy-top1
I0614 18:03:47.941007 11551 net.cpp:151] Top shape: (1)
I0614 18:03:47.941012 11551 net.cpp:159] Memory required for data: 416583812
I0614 18:03:47.941017 11551 net.cpp:222] accuracy-top1 does not need backward computation.
I0614 18:03:47.941023 11551 net.cpp:220] loss needs backward computation.
I0614 18:03:47.941030 11551 net.cpp:222] accuracy does not need backward computation.
I0614 18:03:47.941036 11551 net.cpp:220] fc8_fc8_0_split needs backward computation.
I0614 18:03:47.941040 11551 net.cpp:220] fc8 needs backward computation.
I0614 18:03:47.941044 11551 net.cpp:220] drop7 needs backward computation.
I0614 18:03:47.941048 11551 net.cpp:220] relu7 needs backward computation.
I0614 18:03:47.941051 11551 net.cpp:220] bn7 needs backward computation.
I0614 18:03:47.941056 11551 net.cpp:220] fc7 needs backward computation.
I0614 18:03:47.941059 11551 net.cpp:220] drop6 needs backward computation.
I0614 18:03:47.941063 11551 net.cpp:220] relu6 needs backward computation.
I0614 18:03:47.941067 11551 net.cpp:220] fc6 needs backward computation.
I0614 18:03:47.941073 11551 net.cpp:220] pool5 needs backward computation.
I0614 18:03:47.941076 11551 net.cpp:220] relu5 needs backward computation.
I0614 18:03:47.941080 11551 net.cpp:220] conv5 needs backward computation.
I0614 18:03:47.941084 11551 net.cpp:220] relu4 needs backward computation.
I0614 18:03:47.941088 11551 net.cpp:220] conv4 needs backward computation.
I0614 18:03:47.941092 11551 net.cpp:220] relu3 needs backward computation.
I0614 18:03:47.941097 11551 net.cpp:220] conv3 needs backward computation.
I0614 18:03:47.941100 11551 net.cpp:220] pool2 needs backward computation.
I0614 18:03:47.941104 11551 net.cpp:220] relu2 needs backward computation.
I0614 18:03:47.941108 11551 net.cpp:220] bn2 needs backward computation.
I0614 18:03:47.941112 11551 net.cpp:220] conv2 needs backward computation.
I0614 18:03:47.941116 11551 net.cpp:220] pool1 needs backward computation.
I0614 18:03:47.941119 11551 net.cpp:220] relu1 needs backward computation.
I0614 18:03:47.941123 11551 net.cpp:220] bn1 needs backward computation.
I0614 18:03:47.941128 11551 net.cpp:220] conv1 needs backward computation.
I0614 18:03:47.941133 11551 net.cpp:222] label_data_1_split does not need backward computation.
I0614 18:03:47.941138 11551 net.cpp:222] data does not need backward computation.
I0614 18:03:47.941140 11551 net.cpp:264] This network produces output accuracy
I0614 18:03:47.941144 11551 net.cpp:264] This network produces output loss
I0614 18:03:47.941148 11551 net.cpp:264] This network produces output top-1
I0614 18:03:47.941511 11551 net.cpp:284] Network initialization done.
I0614 18:03:47.941586 11551 solver.cpp:63] Solver scaffolding done.
I0614 18:03:47.942227 11551 caffe_interface.cpp:139] Finetuning from pruning/alexnetBNnoLRN/regular_rate_0.6/sparse.caffemodel
I0614 18:03:50.321581 11551 caffe_interface.cpp:573] Starting Optimization
I0614 18:03:50.321604 11551 solver.cpp:341] Solving 
I0614 18:03:50.321606 11551 solver.cpp:342] Learning Rate Policy: step
I0614 18:03:50.322865 11551 solver.cpp:424] Iteration 0, Testing net (#0)
I0614 18:03:51.786618 11551 solver.cpp:523]     Test net output #0: accuracy = 0.9585
I0614 18:03:51.786650 11551 solver.cpp:523]     Test net output #1: loss = 0.223834 (* 1 = 0.223834 loss)
I0614 18:03:51.786655 11551 solver.cpp:523]     Test net output #2: top-1 = 0.9585
I0614 18:03:52.040851 11551 solver.cpp:270] Iteration 0 (0 iter/s, 1.71913s/50 iter), loss = 0.0112644, remaining 333333 hours and 20 minutes
I0614 18:03:52.040881 11551 solver.cpp:291]     Train net output #0: loss = 0.0112644 (* 1 = 0.0112644 loss)
I0614 18:03:52.040889 11551 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0614 18:04:04.361425 11551 solver.cpp:270] Iteration 50 (4.05842 iter/s, 12.3201s/50 iter), loss = 0.0358551, remaining 0 hours and 49 minutes
I0614 18:04:04.361457 11551 solver.cpp:291]     Train net output #0: loss = 0.0358551 (* 1 = 0.0358551 loss)
I0614 18:04:04.361464 11551 sgd_solver.cpp:106] Iteration 50, lr = 0.001
I0614 18:04:16.766151 11551 solver.cpp:270] Iteration 100 (4.03089 iter/s, 12.4042s/50 iter), loss = 0.0303328, remaining 0 hours and 49 minutes
I0614 18:04:16.766371 11551 solver.cpp:291]     Train net output #0: loss = 0.0303328 (* 1 = 0.0303328 loss)
I0614 18:04:16.766379 11551 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I0614 18:04:29.232136 11551 solver.cpp:270] Iteration 150 (4.01114 iter/s, 12.4653s/50 iter), loss = 0.0712392, remaining 0 hours and 49 minutes
I0614 18:04:29.232167 11551 solver.cpp:291]     Train net output #0: loss = 0.0712392 (* 1 = 0.0712392 loss)
I0614 18:04:29.232174 11551 sgd_solver.cpp:106] Iteration 150, lr = 0.001
I0614 18:04:41.786482 11551 solver.cpp:270] Iteration 200 (3.98284 iter/s, 12.5539s/50 iter), loss = 0.0527224, remaining 0 hours and 49 minutes
I0614 18:04:41.786514 11551 solver.cpp:291]     Train net output #0: loss = 0.0527224 (* 1 = 0.0527224 loss)
I0614 18:04:41.786521 11551 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I0614 18:04:54.398264 11551 solver.cpp:270] Iteration 250 (3.96468 iter/s, 12.6114s/50 iter), loss = 0.133029, remaining 0 hours and 49 minutes
I0614 18:04:54.398540 11551 solver.cpp:291]     Train net output #0: loss = 0.133029 (* 1 = 0.133029 loss)
I0614 18:04:54.398546 11551 sgd_solver.cpp:106] Iteration 250, lr = 0.001
I0614 18:05:07.012076 11551 solver.cpp:270] Iteration 300 (3.96412 iter/s, 12.6131s/50 iter), loss = 0.100001, remaining 0 hours and 49 minutes
I0614 18:05:07.012107 11551 solver.cpp:291]     Train net output #0: loss = 0.100001 (* 1 = 0.100001 loss)
I0614 18:05:07.012115 11551 sgd_solver.cpp:106] Iteration 300, lr = 0.001
I0614 18:05:19.621999 11551 solver.cpp:270] Iteration 350 (3.96527 iter/s, 12.6095s/50 iter), loss = 0.0646533, remaining 0 hours and 48 minutes
I0614 18:05:19.622030 11551 solver.cpp:291]     Train net output #0: loss = 0.0646533 (* 1 = 0.0646533 loss)
I0614 18:05:19.622037 11551 sgd_solver.cpp:106] Iteration 350, lr = 0.001
I0614 18:05:32.219652 11551 solver.cpp:270] Iteration 400 (3.96913 iter/s, 12.5972s/50 iter), loss = 0.0517528, remaining 0 hours and 48 minutes
I0614 18:05:32.219921 11551 solver.cpp:291]     Train net output #0: loss = 0.0517528 (* 1 = 0.0517528 loss)
I0614 18:05:32.219928 11551 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I0614 18:05:44.830473 11551 solver.cpp:270] Iteration 450 (3.96506 iter/s, 12.6101s/50 iter), loss = 0.0866683, remaining 0 hours and 48 minutes
I0614 18:05:44.830507 11551 solver.cpp:291]     Train net output #0: loss = 0.0866683 (* 1 = 0.0866683 loss)
I0614 18:05:44.830530 11551 sgd_solver.cpp:106] Iteration 450, lr = 0.001
I0614 18:05:57.431403 11551 solver.cpp:270] Iteration 500 (3.9681 iter/s, 12.6005s/50 iter), loss = 0.0925798, remaining 0 hours and 48 minutes
I0614 18:05:57.431434 11551 solver.cpp:291]     Train net output #0: loss = 0.0925798 (* 1 = 0.0925798 loss)
I0614 18:05:57.431457 11551 sgd_solver.cpp:106] Iteration 500, lr = 0.001
I0614 18:06:10.041937 11551 solver.cpp:270] Iteration 550 (3.96508 iter/s, 12.6101s/50 iter), loss = 0.172316, remaining 0 hours and 47 minutes
I0614 18:06:10.042297 11551 solver.cpp:291]     Train net output #0: loss = 0.172316 (* 1 = 0.172316 loss)
I0614 18:06:10.042321 11551 sgd_solver.cpp:106] Iteration 550, lr = 0.001
I0614 18:06:22.639533 11551 solver.cpp:270] Iteration 600 (3.96925 iter/s, 12.5968s/50 iter), loss = 0.0437515, remaining 0 hours and 47 minutes
I0614 18:06:22.639567 11551 solver.cpp:291]     Train net output #0: loss = 0.0437515 (* 1 = 0.0437515 loss)
I0614 18:06:22.639590 11551 sgd_solver.cpp:106] Iteration 600, lr = 0.001
I0614 18:06:35.247413 11551 solver.cpp:270] Iteration 650 (3.96591 iter/s, 12.6074s/50 iter), loss = 0.0799219, remaining 0 hours and 47 minutes
I0614 18:06:35.247445 11551 solver.cpp:291]     Train net output #0: loss = 0.0799219 (* 1 = 0.0799219 loss)
I0614 18:06:35.247453 11551 sgd_solver.cpp:106] Iteration 650, lr = 0.001
I0614 18:06:47.852074 11551 solver.cpp:270] Iteration 700 (3.96693 iter/s, 12.6042s/50 iter), loss = 0.072155, remaining 0 hours and 47 minutes
I0614 18:06:47.852330 11551 solver.cpp:291]     Train net output #0: loss = 0.072155 (* 1 = 0.072155 loss)
I0614 18:06:47.852355 11551 sgd_solver.cpp:106] Iteration 700, lr = 0.001
I0614 18:07:00.455617 11551 solver.cpp:270] Iteration 750 (3.96735 iter/s, 12.6029s/50 iter), loss = 0.0762752, remaining 0 hours and 47 minutes
I0614 18:07:00.455649 11551 solver.cpp:291]     Train net output #0: loss = 0.0762752 (* 1 = 0.0762752 loss)
I0614 18:07:00.455657 11551 sgd_solver.cpp:106] Iteration 750, lr = 0.001
I0614 18:07:13.060272 11551 solver.cpp:270] Iteration 800 (3.96693 iter/s, 12.6042s/50 iter), loss = 0.0880626, remaining 0 hours and 46 minutes
I0614 18:07:13.060303 11551 solver.cpp:291]     Train net output #0: loss = 0.0880626 (* 1 = 0.0880626 loss)
I0614 18:07:13.060326 11551 sgd_solver.cpp:106] Iteration 800, lr = 0.001
I0614 18:07:25.674597 11551 solver.cpp:270] Iteration 850 (3.96389 iter/s, 12.6139s/50 iter), loss = 0.0675239, remaining 0 hours and 46 minutes
I0614 18:07:25.674810 11551 solver.cpp:291]     Train net output #0: loss = 0.0675239 (* 1 = 0.0675239 loss)
I0614 18:07:25.674818 11551 sgd_solver.cpp:106] Iteration 850, lr = 0.001
I0614 18:07:38.291564 11551 solver.cpp:270] Iteration 900 (3.96311 iter/s, 12.6163s/50 iter), loss = 0.115874, remaining 0 hours and 46 minutes
I0614 18:07:38.291594 11551 solver.cpp:291]     Train net output #0: loss = 0.115874 (* 1 = 0.115874 loss)
I0614 18:07:38.291601 11551 sgd_solver.cpp:106] Iteration 900, lr = 0.001
I0614 18:07:50.885093 11551 solver.cpp:270] Iteration 950 (3.97043 iter/s, 12.5931s/50 iter), loss = 0.072546, remaining 0 hours and 46 minutes
I0614 18:07:50.885128 11551 solver.cpp:291]     Train net output #0: loss = 0.072546 (* 1 = 0.072546 loss)
I0614 18:07:50.885135 11551 sgd_solver.cpp:106] Iteration 950, lr = 0.001
I0614 18:08:03.233947 11551 solver.cpp:424] Iteration 1000, Testing net (#0)
I0614 18:08:04.718295 11551 solver.cpp:523]     Test net output #0: accuracy = 0.872
I0614 18:08:04.718324 11551 solver.cpp:523]     Test net output #1: loss = 0.606421 (* 1 = 0.606421 loss)
I0614 18:08:04.718328 11551 solver.cpp:523]     Test net output #2: top-1 = 0.872
I0614 18:08:04.964800 11551 solver.cpp:270] Iteration 1000 (3.55133 iter/s, 14.0792s/50 iter), loss = 0.0968876, remaining 0 hours and 51 minutes
I0614 18:08:04.964833 11551 solver.cpp:291]     Train net output #0: loss = 0.0968876 (* 1 = 0.0968876 loss)
I0614 18:08:04.964843 11551 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I0614 18:08:17.583484 11551 solver.cpp:270] Iteration 1050 (3.96252 iter/s, 12.6182s/50 iter), loss = 0.0557649, remaining 0 hours and 45 minutes
I0614 18:08:17.583515 11551 solver.cpp:291]     Train net output #0: loss = 0.0557649 (* 1 = 0.0557649 loss)
I0614 18:08:17.583523 11551 sgd_solver.cpp:106] Iteration 1050, lr = 0.001
I0614 18:08:30.191381 11551 solver.cpp:270] Iteration 1100 (3.96591 iter/s, 12.6075s/50 iter), loss = 0.0801564, remaining 0 hours and 45 minutes
I0614 18:08:30.191412 11551 solver.cpp:291]     Train net output #0: loss = 0.0801564 (* 1 = 0.0801564 loss)
I0614 18:08:30.191421 11551 sgd_solver.cpp:106] Iteration 1100, lr = 0.001
I0614 18:08:42.791637 11551 solver.cpp:270] Iteration 1150 (3.96831 iter/s, 12.5998s/50 iter), loss = 0.0651968, remaining 0 hours and 45 minutes
I0614 18:08:42.791867 11551 solver.cpp:291]     Train net output #0: loss = 0.0651968 (* 1 = 0.0651968 loss)
I0614 18:08:42.791893 11551 sgd_solver.cpp:106] Iteration 1150, lr = 0.001
I0614 18:08:55.395498 11551 solver.cpp:270] Iteration 1200 (3.96724 iter/s, 12.6032s/50 iter), loss = 0.153291, remaining 0 hours and 45 minutes
I0614 18:08:55.395529 11551 solver.cpp:291]     Train net output #0: loss = 0.153291 (* 1 = 0.153291 loss)
I0614 18:08:55.395552 11551 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I0614 18:09:08.015848 11551 solver.cpp:270] Iteration 1250 (3.96199 iter/s, 12.6199s/50 iter), loss = 0.114538, remaining 0 hours and 45 minutes
I0614 18:09:08.015882 11551 solver.cpp:291]     Train net output #0: loss = 0.114538 (* 1 = 0.114538 loss)
I0614 18:09:08.015903 11551 sgd_solver.cpp:106] Iteration 1250, lr = 0.001
I0614 18:09:20.632792 11551 solver.cpp:270] Iteration 1300 (3.96306 iter/s, 12.6165s/50 iter), loss = 0.0752783, remaining 0 hours and 44 minutes
I0614 18:09:20.633006 11551 solver.cpp:291]     Train net output #0: loss = 0.0752783 (* 1 = 0.0752783 loss)
I0614 18:09:20.633013 11551 sgd_solver.cpp:106] Iteration 1300, lr = 0.001
I0614 18:09:33.237900 11551 solver.cpp:270] Iteration 1350 (3.96684 iter/s, 12.6045s/50 iter), loss = 0.0659827, remaining 0 hours and 44 minutes
I0614 18:09:33.237933 11551 solver.cpp:291]     Train net output #0: loss = 0.0659827 (* 1 = 0.0659827 loss)
I0614 18:09:33.237957 11551 sgd_solver.cpp:106] Iteration 1350, lr = 0.001
I0614 18:09:45.870123 11551 solver.cpp:270] Iteration 1400 (3.95827 iter/s, 12.6318s/50 iter), loss = 0.0846112, remaining 0 hours and 44 minutes
I0614 18:09:45.870157 11551 solver.cpp:291]     Train net output #0: loss = 0.0846112 (* 1 = 0.0846112 loss)
I0614 18:09:45.870180 11551 sgd_solver.cpp:106] Iteration 1400, lr = 0.001
I0614 18:09:58.471150 11551 solver.cpp:270] Iteration 1450 (3.96807 iter/s, 12.6006s/50 iter), loss = 0.0670437, remaining 0 hours and 44 minutes
I0614 18:09:58.471381 11551 solver.cpp:291]     Train net output #0: loss = 0.0670437 (* 1 = 0.0670437 loss)
I0614 18:09:58.471405 11551 sgd_solver.cpp:106] Iteration 1450, lr = 0.001
I0614 18:10:11.086040 11551 solver.cpp:270] Iteration 1500 (3.96377 iter/s, 12.6143s/50 iter), loss = 0.085296, remaining 0 hours and 44 minutes
I0614 18:10:11.086071 11551 solver.cpp:291]     Train net output #0: loss = 0.085296 (* 1 = 0.085296 loss)
I0614 18:10:11.086078 11551 sgd_solver.cpp:106] Iteration 1500, lr = 0.001
I0614 18:10:23.673198 11551 solver.cpp:270] Iteration 1550 (3.97244 iter/s, 12.5867s/50 iter), loss = 0.0815135, remaining 0 hours and 43 minutes
I0614 18:10:23.673230 11551 solver.cpp:291]     Train net output #0: loss = 0.0815135 (* 1 = 0.0815135 loss)
I0614 18:10:23.673238 11551 sgd_solver.cpp:106] Iteration 1550, lr = 0.001
I0614 18:10:36.280109 11551 solver.cpp:270] Iteration 1600 (3.96622 iter/s, 12.6065s/50 iter), loss = 0.0518521, remaining 0 hours and 43 minutes
I0614 18:10:36.280372 11551 solver.cpp:291]     Train net output #0: loss = 0.0518521 (* 1 = 0.0518521 loss)
I0614 18:10:36.280380 11551 sgd_solver.cpp:106] Iteration 1600, lr = 0.001
I0614 18:10:48.880178 11551 solver.cpp:270] Iteration 1650 (3.96844 iter/s, 12.5994s/50 iter), loss = 0.0655541, remaining 0 hours and 43 minutes
I0614 18:10:48.880209 11551 solver.cpp:291]     Train net output #0: loss = 0.0655541 (* 1 = 0.0655541 loss)
I0614 18:10:48.880216 11551 sgd_solver.cpp:106] Iteration 1650, lr = 0.001
I0614 18:11:01.492933 11551 solver.cpp:270] Iteration 1700 (3.96438 iter/s, 12.6123s/50 iter), loss = 0.127788, remaining 0 hours and 43 minutes
I0614 18:11:01.492964 11551 solver.cpp:291]     Train net output #0: loss = 0.127788 (* 1 = 0.127788 loss)
I0614 18:11:01.492986 11551 sgd_solver.cpp:106] Iteration 1700, lr = 0.001
I0614 18:11:14.096261 11551 solver.cpp:270] Iteration 1750 (3.96734 iter/s, 12.6029s/50 iter), loss = 0.0991708, remaining 0 hours and 42 minutes
I0614 18:11:14.096603 11551 solver.cpp:291]     Train net output #0: loss = 0.0991708 (* 1 = 0.0991708 loss)
I0614 18:11:14.096611 11551 sgd_solver.cpp:106] Iteration 1750, lr = 0.001
I0614 18:11:26.704171 11551 solver.cpp:270] Iteration 1800 (3.966 iter/s, 12.6072s/50 iter), loss = 0.0943008, remaining 0 hours and 42 minutes
I0614 18:11:26.704201 11551 solver.cpp:291]     Train net output #0: loss = 0.0943008 (* 1 = 0.0943008 loss)
I0614 18:11:26.704208 11551 sgd_solver.cpp:106] Iteration 1800, lr = 0.001
I0614 18:11:39.317831 11551 solver.cpp:270] Iteration 1850 (3.96409 iter/s, 12.6132s/50 iter), loss = 0.052613, remaining 0 hours and 42 minutes
I0614 18:11:39.317862 11551 solver.cpp:291]     Train net output #0: loss = 0.052613 (* 1 = 0.052613 loss)
I0614 18:11:39.317884 11551 sgd_solver.cpp:106] Iteration 1850, lr = 0.001
I0614 18:11:51.930155 11551 solver.cpp:270] Iteration 1900 (3.96451 iter/s, 12.6119s/50 iter), loss = 0.0901181, remaining 0 hours and 42 minutes
I0614 18:11:51.930426 11551 solver.cpp:291]     Train net output #0: loss = 0.0901181 (* 1 = 0.0901181 loss)
I0614 18:11:51.930451 11551 sgd_solver.cpp:106] Iteration 1900, lr = 0.001
I0614 18:12:04.538033 11551 solver.cpp:270] Iteration 1950 (3.96599 iter/s, 12.6072s/50 iter), loss = 0.0545978, remaining 0 hours and 42 minutes
I0614 18:12:04.538062 11551 solver.cpp:291]     Train net output #0: loss = 0.0545978 (* 1 = 0.0545978 loss)
I0614 18:12:04.538085 11551 sgd_solver.cpp:106] Iteration 1950, lr = 0.001
I0614 18:12:16.902146 11551 solver.cpp:424] Iteration 2000, Testing net (#0)
I0614 18:12:18.403841 11551 solver.cpp:523]     Test net output #0: accuracy = 0.94725
I0614 18:12:18.403867 11551 solver.cpp:523]     Test net output #1: loss = 0.174193 (* 1 = 0.174193 loss)
I0614 18:12:18.403872 11551 solver.cpp:523]     Test net output #2: top-1 = 0.94725
I0614 18:12:18.650460 11551 solver.cpp:270] Iteration 2000 (3.5431 iter/s, 14.1119s/50 iter), loss = 0.0540391, remaining 0 hours and 46 minutes
I0614 18:12:18.650491 11551 solver.cpp:291]     Train net output #0: loss = 0.054039 (* 1 = 0.054039 loss)
I0614 18:12:18.650498 11551 sgd_solver.cpp:106] Iteration 2000, lr = 0.001
I0614 18:12:31.264523 11551 solver.cpp:270] Iteration 2050 (3.96397 iter/s, 12.6136s/50 iter), loss = 0.0999295, remaining 0 hours and 41 minutes
I0614 18:12:31.264770 11551 solver.cpp:291]     Train net output #0: loss = 0.0999295 (* 1 = 0.0999295 loss)
I0614 18:12:31.264793 11551 sgd_solver.cpp:106] Iteration 2050, lr = 0.001
I0614 18:12:43.880100 11551 solver.cpp:270] Iteration 2100 (3.96356 iter/s, 12.6149s/50 iter), loss = 0.0639642, remaining 0 hours and 41 minutes
I0614 18:12:43.880131 11551 solver.cpp:291]     Train net output #0: loss = 0.0639642 (* 1 = 0.0639642 loss)
I0614 18:12:43.880138 11551 sgd_solver.cpp:106] Iteration 2100, lr = 0.001
I0614 18:12:56.487717 11551 solver.cpp:270] Iteration 2150 (3.96599 iter/s, 12.6072s/50 iter), loss = 0.0937566, remaining 0 hours and 41 minutes
I0614 18:12:56.487749 11551 solver.cpp:291]     Train net output #0: loss = 0.0937566 (* 1 = 0.0937566 loss)
I0614 18:12:56.487757 11551 sgd_solver.cpp:106] Iteration 2150, lr = 0.001
I0614 18:13:09.093227 11551 solver.cpp:270] Iteration 2200 (3.96666 iter/s, 12.6051s/50 iter), loss = 0.0720156, remaining 0 hours and 41 minutes
I0614 18:13:09.093515 11551 solver.cpp:291]     Train net output #0: loss = 0.0720156 (* 1 = 0.0720156 loss)
I0614 18:13:09.093523 11551 sgd_solver.cpp:106] Iteration 2200, lr = 0.001
I0614 18:13:21.704208 11551 solver.cpp:270] Iteration 2250 (3.96502 iter/s, 12.6103s/50 iter), loss = 0.0584061, remaining 0 hours and 40 minutes
I0614 18:13:21.704238 11551 solver.cpp:291]     Train net output #0: loss = 0.0584061 (* 1 = 0.0584061 loss)
I0614 18:13:21.704246 11551 sgd_solver.cpp:106] Iteration 2250, lr = 0.001
I0614 18:13:34.302963 11551 solver.cpp:270] Iteration 2300 (3.96878 iter/s, 12.5983s/50 iter), loss = 0.0640961, remaining 0 hours and 40 minutes
I0614 18:13:34.302994 11551 solver.cpp:291]     Train net output #0: loss = 0.0640961 (* 1 = 0.0640961 loss)
I0614 18:13:34.303001 11551 sgd_solver.cpp:106] Iteration 2300, lr = 0.001
I0614 18:13:46.905812 11551 solver.cpp:270] Iteration 2350 (3.96749 iter/s, 12.6024s/50 iter), loss = 0.0951827, remaining 0 hours and 40 minutes
I0614 18:13:46.906035 11551 solver.cpp:291]     Train net output #0: loss = 0.0951827 (* 1 = 0.0951827 loss)
I0614 18:13:46.906059 11551 sgd_solver.cpp:106] Iteration 2350, lr = 0.001
I0614 18:13:59.509375 11551 solver.cpp:270] Iteration 2400 (3.96733 iter/s, 12.6029s/50 iter), loss = 0.0787138, remaining 0 hours and 40 minutes
I0614 18:13:59.509408 11551 solver.cpp:291]     Train net output #0: loss = 0.0787138 (* 1 = 0.0787138 loss)
I0614 18:13:59.509415 11551 sgd_solver.cpp:106] Iteration 2400, lr = 0.001
I0614 18:14:12.121394 11551 solver.cpp:270] Iteration 2450 (3.96461 iter/s, 12.6116s/50 iter), loss = 0.0802197, remaining 0 hours and 40 minutes
I0614 18:14:12.121441 11551 solver.cpp:291]     Train net output #0: loss = 0.0802197 (* 1 = 0.0802197 loss)
I0614 18:14:12.121448 11551 sgd_solver.cpp:106] Iteration 2450, lr = 0.001
I0614 18:14:24.722232 11551 solver.cpp:270] Iteration 2500 (3.96813 iter/s, 12.6004s/50 iter), loss = 0.114834, remaining 0 hours and 39 minutes
I0614 18:14:24.722440 11551 solver.cpp:291]     Train net output #0: loss = 0.114834 (* 1 = 0.114834 loss)
I0614 18:14:24.722463 11551 sgd_solver.cpp:106] Iteration 2500, lr = 0.0001
I0614 18:14:37.330377 11551 solver.cpp:270] Iteration 2550 (3.96588 iter/s, 12.6075s/50 iter), loss = 0.0832302, remaining 0 hours and 39 minutes
I0614 18:14:37.330410 11551 solver.cpp:291]     Train net output #0: loss = 0.0832302 (* 1 = 0.0832302 loss)
I0614 18:14:37.330417 11551 sgd_solver.cpp:106] Iteration 2550, lr = 0.0001
I0614 18:14:49.930934 11551 solver.cpp:270] Iteration 2600 (3.96822 iter/s, 12.6001s/50 iter), loss = 0.0509229, remaining 0 hours and 39 minutes
I0614 18:14:49.930966 11551 solver.cpp:291]     Train net output #0: loss = 0.0509229 (* 1 = 0.0509229 loss)
I0614 18:14:49.930974 11551 sgd_solver.cpp:106] Iteration 2600, lr = 0.0001
I0614 18:15:02.529814 11551 solver.cpp:270] Iteration 2650 (3.96875 iter/s, 12.5984s/50 iter), loss = 0.0238971, remaining 0 hours and 39 minutes
I0614 18:15:02.530084 11551 solver.cpp:291]     Train net output #0: loss = 0.0238971 (* 1 = 0.0238971 loss)
I0614 18:15:02.530109 11551 sgd_solver.cpp:106] Iteration 2650, lr = 0.0001
I0614 18:15:15.129060 11551 solver.cpp:270] Iteration 2700 (3.9687 iter/s, 12.5986s/50 iter), loss = 0.0168447, remaining 0 hours and 39 minutes
I0614 18:15:15.129088 11551 solver.cpp:291]     Train net output #0: loss = 0.0168447 (* 1 = 0.0168447 loss)
I0614 18:15:15.129096 11551 sgd_solver.cpp:106] Iteration 2700, lr = 0.0001
I0614 18:15:27.746516 11551 solver.cpp:270] Iteration 2750 (3.9629 iter/s, 12.617s/50 iter), loss = 0.0390666, remaining 0 hours and 38 minutes
I0614 18:15:27.746551 11551 solver.cpp:291]     Train net output #0: loss = 0.0390665 (* 1 = 0.0390665 loss)
I0614 18:15:27.746557 11551 sgd_solver.cpp:106] Iteration 2750, lr = 0.0001
I0614 18:15:40.336838 11551 solver.cpp:270] Iteration 2800 (3.97144 iter/s, 12.5899s/50 iter), loss = 0.0392639, remaining 0 hours and 38 minutes
I0614 18:15:40.337087 11551 solver.cpp:291]     Train net output #0: loss = 0.0392639 (* 1 = 0.0392639 loss)
I0614 18:15:40.337111 11551 sgd_solver.cpp:106] Iteration 2800, lr = 0.0001
I0614 18:15:52.950606 11551 solver.cpp:270] Iteration 2850 (3.96413 iter/s, 12.6131s/50 iter), loss = 0.0363121, remaining 0 hours and 38 minutes
I0614 18:15:52.950639 11551 solver.cpp:291]     Train net output #0: loss = 0.0363121 (* 1 = 0.0363121 loss)
I0614 18:15:52.950645 11551 sgd_solver.cpp:106] Iteration 2850, lr = 0.0001
I0614 18:16:05.554562 11551 solver.cpp:270] Iteration 2900 (3.96715 iter/s, 12.6035s/50 iter), loss = 0.0272662, remaining 0 hours and 38 minutes
I0614 18:16:05.554594 11551 solver.cpp:291]     Train net output #0: loss = 0.0272662 (* 1 = 0.0272662 loss)
I0614 18:16:05.554600 11551 sgd_solver.cpp:106] Iteration 2900, lr = 0.0001
I0614 18:16:18.155278 11551 solver.cpp:270] Iteration 2950 (3.96817 iter/s, 12.6003s/50 iter), loss = 0.02756, remaining 0 hours and 37 minutes
I0614 18:16:18.155623 11551 solver.cpp:291]     Train net output #0: loss = 0.02756 (* 1 = 0.02756 loss)
I0614 18:16:18.155632 11551 sgd_solver.cpp:106] Iteration 2950, lr = 0.0001
I0614 18:16:30.521373 11551 solver.cpp:424] Iteration 3000, Testing net (#0)
I0614 18:16:32.024322 11551 solver.cpp:523]     Test net output #0: accuracy = 0.95275
I0614 18:16:32.024351 11551 solver.cpp:523]     Test net output #1: loss = 0.117912 (* 1 = 0.117912 loss)
I0614 18:16:32.024356 11551 solver.cpp:523]     Test net output #2: top-1 = 0.95275
I0614 18:16:32.270532 11551 solver.cpp:270] Iteration 3000 (3.54247 iter/s, 14.1145s/50 iter), loss = 0.0182513, remaining 0 hours and 42 minutes
I0614 18:16:32.270563 11551 solver.cpp:291]     Train net output #0: loss = 0.0182512 (* 1 = 0.0182512 loss)
I0614 18:16:32.270571 11551 sgd_solver.cpp:106] Iteration 3000, lr = 0.0001
I0614 18:16:44.888064 11551 solver.cpp:270] Iteration 3050 (3.96288 iter/s, 12.6171s/50 iter), loss = 0.0572903, remaining 0 hours and 37 minutes
I0614 18:16:44.888095 11551 solver.cpp:291]     Train net output #0: loss = 0.0572903 (* 1 = 0.0572903 loss)
I0614 18:16:44.888103 11551 sgd_solver.cpp:106] Iteration 3050, lr = 0.0001
I0614 18:16:57.494417 11551 solver.cpp:270] Iteration 3100 (3.96639 iter/s, 12.6059s/50 iter), loss = 0.0090602, remaining 0 hours and 37 minutes
I0614 18:16:57.494686 11551 solver.cpp:291]     Train net output #0: loss = 0.00906018 (* 1 = 0.00906018 loss)
I0614 18:16:57.494694 11551 sgd_solver.cpp:106] Iteration 3100, lr = 0.0001
I0614 18:17:10.114500 11551 solver.cpp:270] Iteration 3150 (3.96215 iter/s, 12.6194s/50 iter), loss = 0.052598, remaining 0 hours and 37 minutes
I0614 18:17:10.114531 11551 solver.cpp:291]     Train net output #0: loss = 0.052598 (* 1 = 0.052598 loss)
I0614 18:17:10.114538 11551 sgd_solver.cpp:106] Iteration 3150, lr = 0.0001
I0614 18:17:22.724728 11551 solver.cpp:270] Iteration 3200 (3.96517 iter/s, 12.6098s/50 iter), loss = 0.0130673, remaining 0 hours and 36 minutes
I0614 18:17:22.724759 11551 solver.cpp:291]     Train net output #0: loss = 0.0130673 (* 1 = 0.0130673 loss)
I0614 18:17:22.724767 11551 sgd_solver.cpp:106] Iteration 3200, lr = 0.0001
I0614 18:17:35.331629 11551 solver.cpp:270] Iteration 3250 (3.96622 iter/s, 12.6065s/50 iter), loss = 0.0379608, remaining 0 hours and 36 minutes
I0614 18:17:35.331885 11551 solver.cpp:291]     Train net output #0: loss = 0.0379608 (* 1 = 0.0379608 loss)
I0614 18:17:35.331908 11551 sgd_solver.cpp:106] Iteration 3250, lr = 0.0001
I0614 18:17:47.934505 11551 solver.cpp:270] Iteration 3300 (3.96756 iter/s, 12.6022s/50 iter), loss = 0.0442796, remaining 0 hours and 36 minutes
I0614 18:17:47.934537 11551 solver.cpp:291]     Train net output #0: loss = 0.0442796 (* 1 = 0.0442796 loss)
I0614 18:17:47.934545 11551 sgd_solver.cpp:106] Iteration 3300, lr = 0.0001
I0614 18:18:00.544365 11551 solver.cpp:270] Iteration 3350 (3.96529 iter/s, 12.6094s/50 iter), loss = 0.0145386, remaining 0 hours and 36 minutes
I0614 18:18:00.544399 11551 solver.cpp:291]     Train net output #0: loss = 0.0145386 (* 1 = 0.0145386 loss)
I0614 18:18:00.544405 11551 sgd_solver.cpp:106] Iteration 3350, lr = 0.0001
I0614 18:18:13.169692 11551 solver.cpp:270] Iteration 3400 (3.96043 iter/s, 12.6249s/50 iter), loss = 0.0548406, remaining 0 hours and 36 minutes
I0614 18:18:13.170051 11551 solver.cpp:291]     Train net output #0: loss = 0.0548406 (* 1 = 0.0548406 loss)
I0614 18:18:13.170075 11551 sgd_solver.cpp:106] Iteration 3400, lr = 0.0001
I0614 18:18:25.792500 11551 solver.cpp:270] Iteration 3450 (3.96132 iter/s, 12.622s/50 iter), loss = 0.022561, remaining 0 hours and 35 minutes
I0614 18:18:25.792532 11551 solver.cpp:291]     Train net output #0: loss = 0.022561 (* 1 = 0.022561 loss)
I0614 18:18:25.792539 11551 sgd_solver.cpp:106] Iteration 3450, lr = 0.0001
I0614 18:18:38.410499 11551 solver.cpp:270] Iteration 3500 (3.96273 iter/s, 12.6176s/50 iter), loss = 0.0138475, remaining 0 hours and 35 minutes
I0614 18:18:38.410532 11551 solver.cpp:291]     Train net output #0: loss = 0.0138475 (* 1 = 0.0138475 loss)
I0614 18:18:38.410550 11551 sgd_solver.cpp:106] Iteration 3500, lr = 0.0001
I0614 18:18:51.013422 11551 solver.cpp:270] Iteration 3550 (3.96747 iter/s, 12.6025s/50 iter), loss = 0.0353753, remaining 0 hours and 35 minutes
I0614 18:18:51.013569 11551 solver.cpp:291]     Train net output #0: loss = 0.0353753 (* 1 = 0.0353753 loss)
I0614 18:18:51.013579 11551 sgd_solver.cpp:106] Iteration 3550, lr = 0.0001
I0614 18:19:03.636488 11551 solver.cpp:270] Iteration 3600 (3.96117 iter/s, 12.6225s/50 iter), loss = 0.0380956, remaining 0 hours and 35 minutes
I0614 18:19:03.636519 11551 solver.cpp:291]     Train net output #0: loss = 0.0380956 (* 1 = 0.0380956 loss)
I0614 18:19:03.636525 11551 sgd_solver.cpp:106] Iteration 3600, lr = 0.0001
I0614 18:19:16.250639 11551 solver.cpp:270] Iteration 3650 (3.96394 iter/s, 12.6137s/50 iter), loss = 0.0110834, remaining 0 hours and 35 minutes
I0614 18:19:16.250671 11551 solver.cpp:291]     Train net output #0: loss = 0.0110834 (* 1 = 0.0110834 loss)
I0614 18:19:16.250679 11551 sgd_solver.cpp:106] Iteration 3650, lr = 0.0001
I0614 18:19:28.855922 11551 solver.cpp:270] Iteration 3700 (3.96673 iter/s, 12.6048s/50 iter), loss = 0.00761901, remaining 0 hours and 34 minutes
I0614 18:19:28.856227 11551 solver.cpp:291]     Train net output #0: loss = 0.007619 (* 1 = 0.007619 loss)
I0614 18:19:28.856236 11551 sgd_solver.cpp:106] Iteration 3700, lr = 0.0001
I0614 18:19:41.465432 11551 solver.cpp:270] Iteration 3750 (3.96548 iter/s, 12.6088s/50 iter), loss = 0.0145891, remaining 0 hours and 34 minutes
I0614 18:19:41.465462 11551 solver.cpp:291]     Train net output #0: loss = 0.0145891 (* 1 = 0.0145891 loss)
I0614 18:19:41.465468 11551 sgd_solver.cpp:106] Iteration 3750, lr = 0.0001
I0614 18:19:54.061220 11551 solver.cpp:270] Iteration 3800 (3.96972 iter/s, 12.5954s/50 iter), loss = 0.0248051, remaining 0 hours and 34 minutes
I0614 18:19:54.061250 11551 solver.cpp:291]     Train net output #0: loss = 0.024805 (* 1 = 0.024805 loss)
I0614 18:19:54.061259 11551 sgd_solver.cpp:106] Iteration 3800, lr = 0.0001
I0614 18:20:06.672016 11551 solver.cpp:270] Iteration 3850 (3.96499 iter/s, 12.6104s/50 iter), loss = 0.00868114, remaining 0 hours and 34 minutes
I0614 18:20:06.672250 11551 solver.cpp:291]     Train net output #0: loss = 0.00868112 (* 1 = 0.00868112 loss)
I0614 18:20:06.672258 11551 sgd_solver.cpp:106] Iteration 3850, lr = 0.0001
I0614 18:20:19.269033 11551 solver.cpp:270] Iteration 3900 (3.9694 iter/s, 12.5964s/50 iter), loss = 0.00711585, remaining 0 hours and 34 minutes
I0614 18:20:19.269066 11551 solver.cpp:291]     Train net output #0: loss = 0.00711584 (* 1 = 0.00711584 loss)
I0614 18:20:19.269073 11551 sgd_solver.cpp:106] Iteration 3900, lr = 0.0001
I0614 18:20:31.886222 11551 solver.cpp:270] Iteration 3950 (3.96299 iter/s, 12.6167s/50 iter), loss = 0.0120722, remaining 0 hours and 33 minutes
I0614 18:20:31.886253 11551 solver.cpp:291]     Train net output #0: loss = 0.0120722 (* 1 = 0.0120722 loss)
I0614 18:20:31.886261 11551 sgd_solver.cpp:106] Iteration 3950, lr = 0.0001
I0614 18:20:44.233989 11551 solver.cpp:424] Iteration 4000, Testing net (#0)
I0614 18:20:45.739936 11551 solver.cpp:523]     Test net output #0: accuracy = 0.9565
I0614 18:20:45.739965 11551 solver.cpp:523]     Test net output #1: loss = 0.114735 (* 1 = 0.114735 loss)
I0614 18:20:45.739970 11551 solver.cpp:523]     Test net output #2: top-1 = 0.9565
I0614 18:20:45.986375 11551 solver.cpp:270] Iteration 4000 (3.54618 iter/s, 14.0997s/50 iter), loss = 0.0148195, remaining 0 hours and 37 minutes
I0614 18:20:45.986405 11551 solver.cpp:291]     Train net output #0: loss = 0.0148195 (* 1 = 0.0148195 loss)
I0614 18:20:45.986428 11551 sgd_solver.cpp:106] Iteration 4000, lr = 0.0001
I0614 18:20:58.594375 11551 solver.cpp:270] Iteration 4050 (3.96587 iter/s, 12.6076s/50 iter), loss = 0.00641453, remaining 0 hours and 33 minutes
I0614 18:20:58.594408 11551 solver.cpp:291]     Train net output #0: loss = 0.00641452 (* 1 = 0.00641452 loss)
I0614 18:20:58.594414 11551 sgd_solver.cpp:106] Iteration 4050, lr = 0.0001
I0614 18:21:11.209327 11551 solver.cpp:270] Iteration 4100 (3.96369 iter/s, 12.6145s/50 iter), loss = 0.0129227, remaining 0 hours and 33 minutes
I0614 18:21:11.209360 11551 solver.cpp:291]     Train net output #0: loss = 0.0129227 (* 1 = 0.0129227 loss)
I0614 18:21:11.209368 11551 sgd_solver.cpp:106] Iteration 4100, lr = 0.0001
I0614 18:21:23.805486 11551 solver.cpp:270] Iteration 4150 (3.9696 iter/s, 12.5957s/50 iter), loss = 0.0234076, remaining 0 hours and 32 minutes
I0614 18:21:23.805819 11551 solver.cpp:291]     Train net output #0: loss = 0.0234076 (* 1 = 0.0234076 loss)
I0614 18:21:23.805827 11551 sgd_solver.cpp:106] Iteration 4150, lr = 0.0001
I0614 18:21:36.421607 11551 solver.cpp:270] Iteration 4200 (3.96342 iter/s, 12.6154s/50 iter), loss = 0.0153704, remaining 0 hours and 32 minutes
I0614 18:21:36.421638 11551 solver.cpp:291]     Train net output #0: loss = 0.0153704 (* 1 = 0.0153704 loss)
I0614 18:21:36.421645 11551 sgd_solver.cpp:106] Iteration 4200, lr = 0.0001
I0614 18:21:49.034035 11551 solver.cpp:270] Iteration 4250 (3.96448 iter/s, 12.612s/50 iter), loss = 0.0225857, remaining 0 hours and 32 minutes
I0614 18:21:49.034066 11551 solver.cpp:291]     Train net output #0: loss = 0.0225857 (* 1 = 0.0225857 loss)
I0614 18:21:49.034073 11551 sgd_solver.cpp:106] Iteration 4250, lr = 0.0001
I0614 18:22:01.656625 11551 solver.cpp:270] Iteration 4300 (3.96129 iter/s, 12.6221s/50 iter), loss = 0.0167434, remaining 0 hours and 32 minutes
I0614 18:22:01.656888 11551 solver.cpp:291]     Train net output #0: loss = 0.0167434 (* 1 = 0.0167434 loss)
I0614 18:22:01.656896 11551 sgd_solver.cpp:106] Iteration 4300, lr = 0.0001
I0614 18:22:14.266142 11551 solver.cpp:270] Iteration 4350 (3.96547 iter/s, 12.6088s/50 iter), loss = 0.0155622, remaining 0 hours and 32 minutes
I0614 18:22:14.266173 11551 solver.cpp:291]     Train net output #0: loss = 0.0155622 (* 1 = 0.0155622 loss)
I0614 18:22:14.266180 11551 sgd_solver.cpp:106] Iteration 4350, lr = 0.0001
I0614 18:22:26.874411 11551 solver.cpp:270] Iteration 4400 (3.96579 iter/s, 12.6078s/50 iter), loss = 0.0192487, remaining 0 hours and 31 minutes
I0614 18:22:26.874441 11551 solver.cpp:291]     Train net output #0: loss = 0.0192487 (* 1 = 0.0192487 loss)
I0614 18:22:26.874449 11551 sgd_solver.cpp:106] Iteration 4400, lr = 0.0001
I0614 18:22:39.499337 11551 solver.cpp:270] Iteration 4450 (3.96056 iter/s, 12.6245s/50 iter), loss = 0.0026167, remaining 0 hours and 31 minutes
I0614 18:22:39.499583 11551 solver.cpp:291]     Train net output #0: loss = 0.0026167 (* 1 = 0.0026167 loss)
I0614 18:22:39.499608 11551 sgd_solver.cpp:106] Iteration 4450, lr = 0.0001
I0614 18:22:52.114435 11551 solver.cpp:270] Iteration 4500 (3.96371 iter/s, 12.6144s/50 iter), loss = 0.0303517, remaining 0 hours and 31 minutes
I0614 18:22:52.114466 11551 solver.cpp:291]     Train net output #0: loss = 0.0303517 (* 1 = 0.0303517 loss)
I0614 18:22:52.114475 11551 sgd_solver.cpp:106] Iteration 4500, lr = 0.0001
I0614 18:23:04.724926 11551 solver.cpp:270] Iteration 4550 (3.96509 iter/s, 12.6101s/50 iter), loss = 0.0172695, remaining 0 hours and 31 minutes
I0614 18:23:04.724956 11551 solver.cpp:291]     Train net output #0: loss = 0.0172695 (* 1 = 0.0172695 loss)
I0614 18:23:04.724964 11551 sgd_solver.cpp:106] Iteration 4550, lr = 0.0001
I0614 18:23:17.322866 11551 solver.cpp:270] Iteration 4600 (3.96904 iter/s, 12.5975s/50 iter), loss = 0.0157097, remaining 0 hours and 30 minutes
I0614 18:23:17.323184 11551 solver.cpp:291]     Train net output #0: loss = 0.0157097 (* 1 = 0.0157097 loss)
I0614 18:23:17.323191 11551 sgd_solver.cpp:106] Iteration 4600, lr = 0.0001
I0614 18:23:29.919447 11551 solver.cpp:270] Iteration 4650 (3.96956 iter/s, 12.5959s/50 iter), loss = 0.027468, remaining 0 hours and 30 minutes
I0614 18:23:29.919479 11551 solver.cpp:291]     Train net output #0: loss = 0.027468 (* 1 = 0.027468 loss)
I0614 18:23:29.919486 11551 sgd_solver.cpp:106] Iteration 4650, lr = 0.0001
I0614 18:23:42.533951 11551 solver.cpp:270] Iteration 4700 (3.96383 iter/s, 12.6141s/50 iter), loss = 0.0348889, remaining 0 hours and 30 minutes
I0614 18:23:42.533982 11551 solver.cpp:291]     Train net output #0: loss = 0.0348889 (* 1 = 0.0348889 loss)
I0614 18:23:42.534005 11551 sgd_solver.cpp:106] Iteration 4700, lr = 0.0001
I0614 18:23:55.130462 11551 solver.cpp:270] Iteration 4750 (3.96949 iter/s, 12.5961s/50 iter), loss = 0.022162, remaining 0 hours and 30 minutes
I0614 18:23:55.130681 11551 solver.cpp:291]     Train net output #0: loss = 0.022162 (* 1 = 0.022162 loss)
I0614 18:23:55.130703 11551 sgd_solver.cpp:106] Iteration 4750, lr = 0.0001
I0614 18:24:07.735137 11551 solver.cpp:270] Iteration 4800 (3.96698 iter/s, 12.6041s/50 iter), loss = 0.0147362, remaining 0 hours and 30 minutes
I0614 18:24:07.735169 11551 solver.cpp:291]     Train net output #0: loss = 0.0147362 (* 1 = 0.0147362 loss)
I0614 18:24:07.735177 11551 sgd_solver.cpp:106] Iteration 4800, lr = 0.0001
I0614 18:24:20.345602 11551 solver.cpp:270] Iteration 4850 (3.9651 iter/s, 12.61s/50 iter), loss = 0.0185269, remaining 0 hours and 30 minutes
I0614 18:24:20.345633 11551 solver.cpp:291]     Train net output #0: loss = 0.0185269 (* 1 = 0.0185269 loss)
I0614 18:24:20.345655 11551 sgd_solver.cpp:106] Iteration 4850, lr = 0.0001
I0614 18:24:32.961906 11551 solver.cpp:270] Iteration 4900 (3.96326 iter/s, 12.6159s/50 iter), loss = 0.0125291, remaining 0 hours and 29 minutes
I0614 18:24:32.962139 11551 solver.cpp:291]     Train net output #0: loss = 0.0125292 (* 1 = 0.0125292 loss)
I0614 18:24:32.962146 11551 sgd_solver.cpp:106] Iteration 4900, lr = 0.0001
I0614 18:24:45.581862 11551 solver.cpp:270] Iteration 4950 (3.96218 iter/s, 12.6193s/50 iter), loss = 0.013065, remaining 0 hours and 29 minutes
I0614 18:24:45.581894 11551 solver.cpp:291]     Train net output #0: loss = 0.013065 (* 1 = 0.013065 loss)
I0614 18:24:45.581902 11551 sgd_solver.cpp:106] Iteration 4950, lr = 0.0001
I0614 18:24:57.925818 11551 solver.cpp:424] Iteration 5000, Testing net (#0)
I0614 18:24:59.405792 11551 solver.cpp:523]     Test net output #0: accuracy = 0.9595
I0614 18:24:59.405820 11551 solver.cpp:523]     Test net output #1: loss = 0.12325 (* 1 = 0.12325 loss)
I0614 18:24:59.405824 11551 solver.cpp:523]     Test net output #2: top-1 = 0.9595
I0614 18:24:59.652619 11551 solver.cpp:270] Iteration 5000 (3.55359 iter/s, 14.0703s/50 iter), loss = 0.0187127, remaining 0 hours and 32 minutes
I0614 18:24:59.652650 11551 solver.cpp:291]     Train net output #0: loss = 0.0187127 (* 1 = 0.0187127 loss)
I0614 18:24:59.652657 11551 sgd_solver.cpp:106] Iteration 5000, lr = 1e-05
I0614 18:25:12.266229 11551 solver.cpp:270] Iteration 5050 (3.96411 iter/s, 12.6132s/50 iter), loss = 0.0119613, remaining 0 hours and 29 minutes
I0614 18:25:12.266492 11551 solver.cpp:291]     Train net output #0: loss = 0.0119613 (* 1 = 0.0119613 loss)
I0614 18:25:12.266500 11551 sgd_solver.cpp:106] Iteration 5050, lr = 1e-05
I0614 18:25:24.870311 11551 solver.cpp:270] Iteration 5100 (3.96718 iter/s, 12.6034s/50 iter), loss = 0.0182915, remaining 0 hours and 28 minutes
I0614 18:25:24.870342 11551 solver.cpp:291]     Train net output #0: loss = 0.0182915 (* 1 = 0.0182915 loss)
I0614 18:25:24.870348 11551 sgd_solver.cpp:106] Iteration 5100, lr = 1e-05
I0614 18:25:37.478842 11551 solver.cpp:270] Iteration 5150 (3.96571 iter/s, 12.6081s/50 iter), loss = 0.0226498, remaining 0 hours and 28 minutes
I0614 18:25:37.478873 11551 solver.cpp:291]     Train net output #0: loss = 0.0226499 (* 1 = 0.0226499 loss)
I0614 18:25:37.478880 11551 sgd_solver.cpp:106] Iteration 5150, lr = 1e-05
I0614 18:25:50.098978 11551 solver.cpp:270] Iteration 5200 (3.96206 iter/s, 12.6197s/50 iter), loss = 0.00260999, remaining 0 hours and 28 minutes
I0614 18:25:50.099305 11551 solver.cpp:291]     Train net output #0: loss = 0.00261001 (* 1 = 0.00261001 loss)
I0614 18:25:50.099313 11551 sgd_solver.cpp:106] Iteration 5200, lr = 1e-05
I0614 18:26:02.713763 11551 solver.cpp:270] Iteration 5250 (3.96383 iter/s, 12.6141s/50 iter), loss = 0.00360188, remaining 0 hours and 28 minutes
I0614 18:26:02.713794 11551 solver.cpp:291]     Train net output #0: loss = 0.0036019 (* 1 = 0.0036019 loss)
I0614 18:26:02.713801 11551 sgd_solver.cpp:106] Iteration 5250, lr = 1e-05
I0614 18:26:15.332695 11551 solver.cpp:270] Iteration 5300 (3.96244 iter/s, 12.6185s/50 iter), loss = 0.00376641, remaining 0 hours and 28 minutes
I0614 18:26:15.332726 11551 solver.cpp:291]     Train net output #0: loss = 0.00376642 (* 1 = 0.00376642 loss)
I0614 18:26:15.332748 11551 sgd_solver.cpp:106] Iteration 5300, lr = 1e-05
I0614 18:26:27.958303 11551 solver.cpp:270] Iteration 5350 (3.96034 iter/s, 12.6252s/50 iter), loss = 0.00425401, remaining 0 hours and 27 minutes
I0614 18:26:27.958549 11551 solver.cpp:291]     Train net output #0: loss = 0.00425402 (* 1 = 0.00425402 loss)
I0614 18:26:27.958573 11551 sgd_solver.cpp:106] Iteration 5350, lr = 1e-05
I0614 18:26:40.566534 11551 solver.cpp:270] Iteration 5400 (3.96587 iter/s, 12.6076s/50 iter), loss = 0.0154847, remaining 0 hours and 27 minutes
I0614 18:26:40.566566 11551 solver.cpp:291]     Train net output #0: loss = 0.0154848 (* 1 = 0.0154848 loss)
I0614 18:26:40.566573 11551 sgd_solver.cpp:106] Iteration 5400, lr = 1e-05
I0614 18:26:53.165549 11551 solver.cpp:270] Iteration 5450 (3.9687 iter/s, 12.5986s/50 iter), loss = 0.0201668, remaining 0 hours and 27 minutes
I0614 18:26:53.165578 11551 solver.cpp:291]     Train net output #0: loss = 0.0201668 (* 1 = 0.0201668 loss)
I0614 18:26:53.165585 11551 sgd_solver.cpp:106] Iteration 5450, lr = 1e-05
I0614 18:27:05.772614 11551 solver.cpp:270] Iteration 5500 (3.96617 iter/s, 12.6066s/50 iter), loss = 0.0151853, remaining 0 hours and 27 minutes
I0614 18:27:05.772881 11551 solver.cpp:291]     Train net output #0: loss = 0.0151853 (* 1 = 0.0151853 loss)
I0614 18:27:05.772904 11551 sgd_solver.cpp:106] Iteration 5500, lr = 1e-05
I0614 18:27:18.377871 11551 solver.cpp:270] Iteration 5550 (3.96681 iter/s, 12.6046s/50 iter), loss = 0.0139982, remaining 0 hours and 26 minutes
I0614 18:27:18.377902 11551 solver.cpp:291]     Train net output #0: loss = 0.0139982 (* 1 = 0.0139982 loss)
I0614 18:27:18.377909 11551 sgd_solver.cpp:106] Iteration 5550, lr = 1e-05
I0614 18:27:30.993367 11551 solver.cpp:270] Iteration 5600 (3.96352 iter/s, 12.6151s/50 iter), loss = 0.0323969, remaining 0 hours and 26 minutes
I0614 18:27:30.993400 11551 solver.cpp:291]     Train net output #0: loss = 0.0323969 (* 1 = 0.0323969 loss)
I0614 18:27:30.993407 11551 sgd_solver.cpp:106] Iteration 5600, lr = 1e-05
I0614 18:27:43.606802 11551 solver.cpp:270] Iteration 5650 (3.96417 iter/s, 12.613s/50 iter), loss = 0.0210902, remaining 0 hours and 26 minutes
I0614 18:27:43.607074 11551 solver.cpp:291]     Train net output #0: loss = 0.0210902 (* 1 = 0.0210902 loss)
I0614 18:27:43.607097 11551 sgd_solver.cpp:106] Iteration 5650, lr = 1e-05
I0614 18:27:56.221885 11551 solver.cpp:270] Iteration 5700 (3.96372 iter/s, 12.6144s/50 iter), loss = 0.00339535, remaining 0 hours and 26 minutes
I0614 18:27:56.221916 11551 solver.cpp:291]     Train net output #0: loss = 0.00339536 (* 1 = 0.00339536 loss)
I0614 18:27:56.221925 11551 sgd_solver.cpp:106] Iteration 5700, lr = 1e-05
I0614 18:28:08.827004 11551 solver.cpp:270] Iteration 5750 (3.96678 iter/s, 12.6047s/50 iter), loss = 0.0154429, remaining 0 hours and 26 minutes
I0614 18:28:08.827037 11551 solver.cpp:291]     Train net output #0: loss = 0.0154429 (* 1 = 0.0154429 loss)
I0614 18:28:08.827044 11551 sgd_solver.cpp:106] Iteration 5750, lr = 1e-05
I0614 18:28:21.447791 11551 solver.cpp:270] Iteration 5800 (3.96186 iter/s, 12.6203s/50 iter), loss = 0.00966697, remaining 0 hours and 25 minutes
I0614 18:28:21.448123 11551 solver.cpp:291]     Train net output #0: loss = 0.00966698 (* 1 = 0.00966698 loss)
I0614 18:28:21.448148 11551 sgd_solver.cpp:106] Iteration 5800, lr = 1e-05
I0614 18:28:34.045431 11551 solver.cpp:270] Iteration 5850 (3.96923 iter/s, 12.5969s/50 iter), loss = 0.00547981, remaining 0 hours and 25 minutes
I0614 18:28:34.045462 11551 solver.cpp:291]     Train net output #0: loss = 0.00547982 (* 1 = 0.00547982 loss)
I0614 18:28:34.045470 11551 sgd_solver.cpp:106] Iteration 5850, lr = 1e-05
I0614 18:28:46.662355 11551 solver.cpp:270] Iteration 5900 (3.96307 iter/s, 12.6165s/50 iter), loss = 0.00143776, remaining 0 hours and 25 minutes
I0614 18:28:46.662386 11551 solver.cpp:291]     Train net output #0: loss = 0.00143777 (* 1 = 0.00143777 loss)
I0614 18:28:46.662395 11551 sgd_solver.cpp:106] Iteration 5900, lr = 1e-05
I0614 18:28:59.258607 11551 solver.cpp:270] Iteration 5950 (3.96957 iter/s, 12.5958s/50 iter), loss = 0.0196116, remaining 0 hours and 25 minutes
I0614 18:28:59.258872 11551 solver.cpp:291]     Train net output #0: loss = 0.0196116 (* 1 = 0.0196116 loss)
I0614 18:28:59.258895 11551 sgd_solver.cpp:106] Iteration 5950, lr = 1e-05
I0614 18:29:11.624403 11551 solver.cpp:935] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.6/snapshots/_iter_6000.caffemodel
I0614 18:29:17.627866 11551 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.6/snapshots/_iter_6000.solverstate
I0614 18:29:21.143559 11551 solver.cpp:424] Iteration 6000, Testing net (#0)
I0614 18:29:22.560395 11551 solver.cpp:523]     Test net output #0: accuracy = 0.9595
I0614 18:29:22.560423 11551 solver.cpp:523]     Test net output #1: loss = 0.139029 (* 1 = 0.139029 loss)
I0614 18:29:22.560428 11551 solver.cpp:523]     Test net output #2: top-1 = 0.9595
I0614 18:29:22.798900 11551 solver.cpp:270] Iteration 6000 (2.12411 iter/s, 23.5393s/50 iter), loss = 0.0112834, remaining 0 hours and 47 minutes
I0614 18:29:22.798934 11551 solver.cpp:291]     Train net output #0: loss = 0.0112834 (* 1 = 0.0112834 loss)
I0614 18:29:22.798943 11551 sgd_solver.cpp:106] Iteration 6000, lr = 1e-05
I0614 18:29:35.292755 11551 solver.cpp:270] Iteration 6050 (4.00211 iter/s, 12.4934s/50 iter), loss = 0.00255923, remaining 0 hours and 24 minutes
I0614 18:29:35.293016 11551 solver.cpp:291]     Train net output #0: loss = 0.00255924 (* 1 = 0.00255924 loss)
I0614 18:29:35.293025 11551 sgd_solver.cpp:106] Iteration 6050, lr = 1e-05
I0614 18:29:47.802155 11551 solver.cpp:270] Iteration 6100 (3.99721 iter/s, 12.5087s/50 iter), loss = 0.00584307, remaining 0 hours and 24 minutes
I0614 18:29:47.802186 11551 solver.cpp:291]     Train net output #0: loss = 0.00584307 (* 1 = 0.00584307 loss)
I0614 18:29:47.802192 11551 sgd_solver.cpp:106] Iteration 6100, lr = 1e-05
I0614 18:30:00.361769 11551 solver.cpp:270] Iteration 6150 (3.98115 iter/s, 12.5592s/50 iter), loss = 0.0358741, remaining 0 hours and 24 minutes
I0614 18:30:00.361801 11551 solver.cpp:291]     Train net output #0: loss = 0.0358741 (* 1 = 0.0358741 loss)
I0614 18:30:00.361809 11551 sgd_solver.cpp:106] Iteration 6150, lr = 1e-05
I0614 18:30:12.913816 11551 solver.cpp:270] Iteration 6200 (3.98355 iter/s, 12.5516s/50 iter), loss = 0.00538148, remaining 0 hours and 24 minutes
I0614 18:30:12.914078 11551 solver.cpp:291]     Train net output #0: loss = 0.00538149 (* 1 = 0.00538149 loss)
I0614 18:30:12.914086 11551 sgd_solver.cpp:106] Iteration 6200, lr = 1e-05
I0614 18:30:25.529624 11551 solver.cpp:270] Iteration 6250 (3.96349 iter/s, 12.6151s/50 iter), loss = 0.0024811, remaining 0 hours and 23 minutes
I0614 18:30:25.529656 11551 solver.cpp:291]     Train net output #0: loss = 0.00248111 (* 1 = 0.00248111 loss)
I0614 18:30:25.529664 11551 sgd_solver.cpp:106] Iteration 6250, lr = 1e-05
I0614 18:30:38.145206 11551 solver.cpp:270] Iteration 6300 (3.96349 iter/s, 12.6151s/50 iter), loss = 0.00653648, remaining 0 hours and 23 minutes
I0614 18:30:38.145238 11551 solver.cpp:291]     Train net output #0: loss = 0.00653648 (* 1 = 0.00653648 loss)
I0614 18:30:38.145246 11551 sgd_solver.cpp:106] Iteration 6300, lr = 1e-05
I0614 18:30:50.766526 11551 solver.cpp:270] Iteration 6350 (3.96169 iter/s, 12.6209s/50 iter), loss = 0.00560299, remaining 0 hours and 23 minutes
I0614 18:30:50.766870 11551 solver.cpp:291]     Train net output #0: loss = 0.00560299 (* 1 = 0.00560299 loss)
I0614 18:30:50.766880 11551 sgd_solver.cpp:106] Iteration 6350, lr = 1e-05
I0614 18:31:03.376487 11551 solver.cpp:270] Iteration 6400 (3.96536 iter/s, 12.6092s/50 iter), loss = 0.000467676, remaining 0 hours and 23 minutes
I0614 18:31:03.376518 11551 solver.cpp:291]     Train net output #0: loss = 0.000467676 (* 1 = 0.000467676 loss)
I0614 18:31:03.376526 11551 sgd_solver.cpp:106] Iteration 6400, lr = 1e-05
I0614 18:31:15.995447 11551 solver.cpp:270] Iteration 6450 (3.96243 iter/s, 12.6185s/50 iter), loss = 0.00227194, remaining 0 hours and 23 minutes
I0614 18:31:15.995483 11551 solver.cpp:291]     Train net output #0: loss = 0.00227193 (* 1 = 0.00227193 loss)
I0614 18:31:15.995491 11551 sgd_solver.cpp:106] Iteration 6450, lr = 1e-05
I0614 18:31:28.595131 11551 solver.cpp:270] Iteration 6500 (3.96849 iter/s, 12.5992s/50 iter), loss = 0.010466, remaining 0 hours and 22 minutes
I0614 18:31:28.595398 11551 solver.cpp:291]     Train net output #0: loss = 0.010466 (* 1 = 0.010466 loss)
I0614 18:31:28.595422 11551 sgd_solver.cpp:106] Iteration 6500, lr = 1e-05
I0614 18:31:41.186290 11551 solver.cpp:270] Iteration 6550 (3.97125 iter/s, 12.5905s/50 iter), loss = 0.00582712, remaining 0 hours and 22 minutes
I0614 18:31:41.186323 11551 solver.cpp:291]     Train net output #0: loss = 0.00582711 (* 1 = 0.00582711 loss)
I0614 18:31:41.186331 11551 sgd_solver.cpp:106] Iteration 6550, lr = 1e-05
I0614 18:31:53.786357 11551 solver.cpp:270] Iteration 6600 (3.96837 iter/s, 12.5996s/50 iter), loss = 0.0273617, remaining 0 hours and 22 minutes
I0614 18:31:53.786389 11551 solver.cpp:291]     Train net output #0: loss = 0.0273617 (* 1 = 0.0273617 loss)
I0614 18:31:53.786396 11551 sgd_solver.cpp:106] Iteration 6600, lr = 1e-05
I0614 18:32:06.408318 11551 solver.cpp:270] Iteration 6650 (3.96149 iter/s, 12.6215s/50 iter), loss = 0.00761506, remaining 0 hours and 22 minutes
I0614 18:32:06.408582 11551 solver.cpp:291]     Train net output #0: loss = 0.00761505 (* 1 = 0.00761505 loss)
I0614 18:32:06.408605 11551 sgd_solver.cpp:106] Iteration 6650, lr = 1e-05
I0614 18:32:19.013005 11551 solver.cpp:270] Iteration 6700 (3.96699 iter/s, 12.604s/50 iter), loss = 0.00625386, remaining 0 hours and 22 minutes
I0614 18:32:19.013036 11551 solver.cpp:291]     Train net output #0: loss = 0.00625385 (* 1 = 0.00625385 loss)
I0614 18:32:19.013043 11551 sgd_solver.cpp:106] Iteration 6700, lr = 1e-05
I0614 18:32:31.620193 11551 solver.cpp:270] Iteration 6750 (3.96613 iter/s, 12.6067s/50 iter), loss = 0.0110721, remaining 0 hours and 21 minutes
I0614 18:32:31.620224 11551 solver.cpp:291]     Train net output #0: loss = 0.011072 (* 1 = 0.011072 loss)
I0614 18:32:31.620231 11551 sgd_solver.cpp:106] Iteration 6750, lr = 1e-05
I0614 18:32:44.220583 11551 solver.cpp:270] Iteration 6800 (3.96827 iter/s, 12.6s/50 iter), loss = 0.00846934, remaining 0 hours and 21 minutes
I0614 18:32:44.220837 11551 solver.cpp:291]     Train net output #0: loss = 0.00846933 (* 1 = 0.00846933 loss)
I0614 18:32:44.220845 11551 sgd_solver.cpp:106] Iteration 6800, lr = 1e-05
I0614 18:32:56.825011 11551 solver.cpp:270] Iteration 6850 (3.96707 iter/s, 12.6038s/50 iter), loss = 0.000689587, remaining 0 hours and 21 minutes
I0614 18:32:56.825040 11551 solver.cpp:291]     Train net output #0: loss = 0.000689576 (* 1 = 0.000689576 loss)
I0614 18:32:56.825048 11551 sgd_solver.cpp:106] Iteration 6850, lr = 1e-05
I0614 18:33:09.434917 11551 solver.cpp:270] Iteration 6900 (3.96527 iter/s, 12.6095s/50 iter), loss = 0.0114008, remaining 0 hours and 21 minutes
I0614 18:33:09.434948 11551 solver.cpp:291]     Train net output #0: loss = 0.0114008 (* 1 = 0.0114008 loss)
I0614 18:33:09.434957 11551 sgd_solver.cpp:106] Iteration 6900, lr = 1e-05
I0614 18:33:22.029292 11551 solver.cpp:270] Iteration 6950 (3.97016 iter/s, 12.5939s/50 iter), loss = 0.00436918, remaining 0 hours and 21 minutes
I0614 18:33:22.029649 11551 solver.cpp:291]     Train net output #0: loss = 0.00436917 (* 1 = 0.00436917 loss)
I0614 18:33:22.029672 11551 sgd_solver.cpp:106] Iteration 6950, lr = 1e-05
I0614 18:33:34.394470 11551 solver.cpp:424] Iteration 7000, Testing net (#0)
I0614 18:33:35.879680 11551 solver.cpp:523]     Test net output #0: accuracy = 0.961
I0614 18:33:35.879709 11551 solver.cpp:523]     Test net output #1: loss = 0.156745 (* 1 = 0.156745 loss)
I0614 18:33:35.879714 11551 solver.cpp:523]     Test net output #2: top-1 = 0.961
I0614 18:33:36.125667 11551 solver.cpp:270] Iteration 7000 (3.54721 iter/s, 14.0956s/50 iter), loss = 0.0134593, remaining 0 hours and 23 minutes
I0614 18:33:36.125701 11551 solver.cpp:291]     Train net output #0: loss = 0.0134593 (* 1 = 0.0134593 loss)
I0614 18:33:36.125708 11551 sgd_solver.cpp:106] Iteration 7000, lr = 1e-05
I0614 18:33:48.726595 11551 solver.cpp:270] Iteration 7050 (3.9681 iter/s, 12.6005s/50 iter), loss = 0.00346218, remaining 0 hours and 20 minutes
I0614 18:33:48.726627 11551 solver.cpp:291]     Train net output #0: loss = 0.00346217 (* 1 = 0.00346217 loss)
I0614 18:33:48.726650 11551 sgd_solver.cpp:106] Iteration 7050, lr = 1e-05
I0614 18:34:01.344807 11551 solver.cpp:270] Iteration 7100 (3.96266 iter/s, 12.6178s/50 iter), loss = 0.00106963, remaining 0 hours and 20 minutes
I0614 18:34:01.344944 11551 solver.cpp:291]     Train net output #0: loss = 0.00106963 (* 1 = 0.00106963 loss)
I0614 18:34:01.344952 11551 sgd_solver.cpp:106] Iteration 7100, lr = 1e-05
I0614 18:34:13.942512 11551 solver.cpp:270] Iteration 7150 (3.96915 iter/s, 12.5972s/50 iter), loss = 0.0261296, remaining 0 hours and 20 minutes
I0614 18:34:13.942543 11551 solver.cpp:291]     Train net output #0: loss = 0.0261296 (* 1 = 0.0261296 loss)
I0614 18:34:13.942565 11551 sgd_solver.cpp:106] Iteration 7150, lr = 1e-05
I0614 18:34:26.542851 11551 solver.cpp:270] Iteration 7200 (3.96828 iter/s, 12.5999s/50 iter), loss = 0.0113225, remaining 0 hours and 20 minutes
I0614 18:34:26.542882 11551 solver.cpp:291]     Train net output #0: loss = 0.0113225 (* 1 = 0.0113225 loss)
I0614 18:34:26.542891 11551 sgd_solver.cpp:106] Iteration 7200, lr = 1e-05
I0614 18:34:39.152556 11551 solver.cpp:270] Iteration 7250 (3.96534 iter/s, 12.6093s/50 iter), loss = 0.00281364, remaining 0 hours and 19 minutes
I0614 18:34:39.152693 11551 solver.cpp:291]     Train net output #0: loss = 0.00281364 (* 1 = 0.00281364 loss)
I0614 18:34:39.152702 11551 sgd_solver.cpp:106] Iteration 7250, lr = 1e-05
I0614 18:34:51.760485 11551 solver.cpp:270] Iteration 7300 (3.96593 iter/s, 12.6074s/50 iter), loss = 0.00396612, remaining 0 hours and 19 minutes
I0614 18:34:51.760517 11551 solver.cpp:291]     Train net output #0: loss = 0.00396611 (* 1 = 0.00396611 loss)
I0614 18:34:51.760525 11551 sgd_solver.cpp:106] Iteration 7300, lr = 1e-05
I0614 18:35:04.368458 11551 solver.cpp:270] Iteration 7350 (3.96588 iter/s, 12.6075s/50 iter), loss = 0.0179118, remaining 0 hours and 19 minutes
I0614 18:35:04.368489 11551 solver.cpp:291]     Train net output #0: loss = 0.0179118 (* 1 = 0.0179118 loss)
I0614 18:35:04.368497 11551 sgd_solver.cpp:106] Iteration 7350, lr = 1e-05
I0614 18:35:16.978929 11551 solver.cpp:270] Iteration 7400 (3.9651 iter/s, 12.61s/50 iter), loss = 0.00754371, remaining 0 hours and 19 minutes
I0614 18:35:16.979081 11551 solver.cpp:291]     Train net output #0: loss = 0.0075437 (* 1 = 0.0075437 loss)
I0614 18:35:16.979091 11551 sgd_solver.cpp:106] Iteration 7400, lr = 1e-05
I0614 18:35:29.597541 11551 solver.cpp:270] Iteration 7450 (3.96257 iter/s, 12.6181s/50 iter), loss = 0.00398546, remaining 0 hours and 18 minutes
I0614 18:35:29.597574 11551 solver.cpp:291]     Train net output #0: loss = 0.00398545 (* 1 = 0.00398545 loss)
I0614 18:35:29.597584 11551 sgd_solver.cpp:106] Iteration 7450, lr = 1e-05
I0614 18:35:42.226936 11551 solver.cpp:270] Iteration 7500 (3.95916 iter/s, 12.629s/50 iter), loss = 0.0185158, remaining 0 hours and 18 minutes
I0614 18:35:42.226967 11551 solver.cpp:291]     Train net output #0: loss = 0.0185158 (* 1 = 0.0185158 loss)
I0614 18:35:42.226975 11551 sgd_solver.cpp:106] Iteration 7500, lr = 1e-06
I0614 18:35:54.826485 11551 solver.cpp:270] Iteration 7550 (3.96853 iter/s, 12.5991s/50 iter), loss = 0.00351443, remaining 0 hours and 18 minutes
I0614 18:35:54.826656 11551 solver.cpp:291]     Train net output #0: loss = 0.00351442 (* 1 = 0.00351442 loss)
I0614 18:35:54.826666 11551 sgd_solver.cpp:106] Iteration 7550, lr = 1e-06
I0614 18:36:07.441371 11551 solver.cpp:270] Iteration 7600 (3.96375 iter/s, 12.6143s/50 iter), loss = 0.0021242, remaining 0 hours and 18 minutes
I0614 18:36:07.441407 11551 solver.cpp:291]     Train net output #0: loss = 0.0021242 (* 1 = 0.0021242 loss)
I0614 18:36:07.441416 11551 sgd_solver.cpp:106] Iteration 7600, lr = 1e-06
I0614 18:36:20.047675 11551 solver.cpp:270] Iteration 7650 (3.96641 iter/s, 12.6059s/50 iter), loss = 0.0013902, remaining 0 hours and 18 minutes
I0614 18:36:20.047708 11551 solver.cpp:291]     Train net output #0: loss = 0.00139019 (* 1 = 0.00139019 loss)
I0614 18:36:20.047731 11551 sgd_solver.cpp:106] Iteration 7650, lr = 1e-06
I0614 18:36:32.648654 11551 solver.cpp:270] Iteration 7700 (3.96808 iter/s, 12.6005s/50 iter), loss = 0.00416342, remaining 0 hours and 17 minutes
I0614 18:36:32.648800 11551 solver.cpp:291]     Train net output #0: loss = 0.00416342 (* 1 = 0.00416342 loss)
I0614 18:36:32.648810 11551 sgd_solver.cpp:106] Iteration 7700, lr = 1e-06
I0614 18:36:45.259220 11551 solver.cpp:270] Iteration 7750 (3.9651 iter/s, 12.61s/50 iter), loss = 0.010573, remaining 0 hours and 17 minutes
I0614 18:36:45.259253 11551 solver.cpp:291]     Train net output #0: loss = 0.010573 (* 1 = 0.010573 loss)
I0614 18:36:45.259261 11551 sgd_solver.cpp:106] Iteration 7750, lr = 1e-06
I0614 18:36:57.862565 11551 solver.cpp:270] Iteration 7800 (3.96734 iter/s, 12.6029s/50 iter), loss = 0.00776916, remaining 0 hours and 17 minutes
I0614 18:36:57.862596 11551 solver.cpp:291]     Train net output #0: loss = 0.00776916 (* 1 = 0.00776916 loss)
I0614 18:36:57.862604 11551 sgd_solver.cpp:106] Iteration 7800, lr = 1e-06
I0614 18:37:10.476739 11551 solver.cpp:270] Iteration 7850 (3.96393 iter/s, 12.6137s/50 iter), loss = 0.0216394, remaining 0 hours and 17 minutes
I0614 18:37:10.476867 11551 solver.cpp:291]     Train net output #0: loss = 0.0216394 (* 1 = 0.0216394 loss)
I0614 18:37:10.476876 11551 sgd_solver.cpp:106] Iteration 7850, lr = 1e-06
I0614 18:37:23.084261 11551 solver.cpp:270] Iteration 7900 (3.96605 iter/s, 12.607s/50 iter), loss = 0.000363481, remaining 0 hours and 17 minutes
I0614 18:37:23.084295 11551 solver.cpp:291]     Train net output #0: loss = 0.000363478 (* 1 = 0.000363478 loss)
I0614 18:37:23.084318 11551 sgd_solver.cpp:106] Iteration 7900, lr = 1e-06
I0614 18:37:35.690295 11551 solver.cpp:270] Iteration 7950 (3.96649 iter/s, 12.6056s/50 iter), loss = 0.00348693, remaining 0 hours and 16 minutes
I0614 18:37:35.690326 11551 solver.cpp:291]     Train net output #0: loss = 0.00348693 (* 1 = 0.00348693 loss)
I0614 18:37:35.690335 11551 sgd_solver.cpp:106] Iteration 7950, lr = 1e-06
I0614 18:37:48.035432 11551 solver.cpp:424] Iteration 8000, Testing net (#0)
I0614 18:37:49.543296 11551 solver.cpp:523]     Test net output #0: accuracy = 0.96225
I0614 18:37:49.543324 11551 solver.cpp:523]     Test net output #1: loss = 0.176195 (* 1 = 0.176195 loss)
I0614 18:37:49.543329 11551 solver.cpp:523]     Test net output #2: top-1 = 0.96225
I0614 18:37:49.789685 11551 solver.cpp:270] Iteration 8000 (3.54637 iter/s, 14.0989s/50 iter), loss = 0.00215454, remaining 0 hours and 18 minutes
I0614 18:37:49.789716 11551 solver.cpp:291]     Train net output #0: loss = 0.00215453 (* 1 = 0.00215453 loss)
I0614 18:37:49.789724 11551 sgd_solver.cpp:106] Iteration 8000, lr = 1e-06
I0614 18:38:02.403479 11551 solver.cpp:270] Iteration 8050 (3.96405 iter/s, 12.6134s/50 iter), loss = 0.0143676, remaining 0 hours and 16 minutes
I0614 18:38:02.403510 11551 solver.cpp:291]     Train net output #0: loss = 0.0143676 (* 1 = 0.0143676 loss)
I0614 18:38:02.403518 11551 sgd_solver.cpp:106] Iteration 8050, lr = 1e-06
I0614 18:38:15.012192 11551 solver.cpp:270] Iteration 8100 (3.96565 iter/s, 12.6083s/50 iter), loss = 0.00279006, remaining 0 hours and 16 minutes
I0614 18:38:15.012224 11551 solver.cpp:291]     Train net output #0: loss = 0.00279006 (* 1 = 0.00279006 loss)
I0614 18:38:15.012233 11551 sgd_solver.cpp:106] Iteration 8100, lr = 1e-06
I0614 18:38:27.620292 11551 solver.cpp:270] Iteration 8150 (3.96584 iter/s, 12.6077s/50 iter), loss = 0.014498, remaining 0 hours and 16 minutes
I0614 18:38:27.620648 11551 solver.cpp:291]     Train net output #0: loss = 0.0144979 (* 1 = 0.0144979 loss)
I0614 18:38:27.620657 11551 sgd_solver.cpp:106] Iteration 8150, lr = 1e-06
I0614 18:38:40.249248 11551 solver.cpp:270] Iteration 8200 (3.95939 iter/s, 12.6282s/50 iter), loss = 0.00108337, remaining 0 hours and 15 minutes
I0614 18:38:40.249280 11551 solver.cpp:291]     Train net output #0: loss = 0.00108336 (* 1 = 0.00108336 loss)
I0614 18:38:40.249289 11551 sgd_solver.cpp:106] Iteration 8200, lr = 1e-06
I0614 18:38:52.869684 11551 solver.cpp:270] Iteration 8250 (3.96197 iter/s, 12.62s/50 iter), loss = 0.00946941, remaining 0 hours and 15 minutes
I0614 18:38:52.869719 11551 solver.cpp:291]     Train net output #0: loss = 0.00946941 (* 1 = 0.00946941 loss)
I0614 18:38:52.869742 11551 sgd_solver.cpp:106] Iteration 8250, lr = 1e-06
I0614 18:39:05.469460 11551 solver.cpp:270] Iteration 8300 (3.96846 iter/s, 12.5993s/50 iter), loss = 0.00301229, remaining 0 hours and 15 minutes
I0614 18:39:05.469691 11551 solver.cpp:291]     Train net output #0: loss = 0.00301228 (* 1 = 0.00301228 loss)
I0614 18:39:05.469714 11551 sgd_solver.cpp:106] Iteration 8300, lr = 1e-06
I0614 18:39:18.081804 11551 solver.cpp:270] Iteration 8350 (3.96457 iter/s, 12.6117s/50 iter), loss = 0.0136029, remaining 0 hours and 15 minutes
I0614 18:39:18.081833 11551 solver.cpp:291]     Train net output #0: loss = 0.0136029 (* 1 = 0.0136029 loss)
I0614 18:39:18.081857 11551 sgd_solver.cpp:106] Iteration 8350, lr = 1e-06
I0614 18:39:30.679598 11551 solver.cpp:270] Iteration 8400 (3.96909 iter/s, 12.5974s/50 iter), loss = 0.00934901, remaining 0 hours and 15 minutes
I0614 18:39:30.679630 11551 solver.cpp:291]     Train net output #0: loss = 0.009349 (* 1 = 0.009349 loss)
I0614 18:39:30.679636 11551 sgd_solver.cpp:106] Iteration 8400, lr = 1e-06
I0614 18:39:43.291532 11551 solver.cpp:270] Iteration 8450 (3.96464 iter/s, 12.6115s/50 iter), loss = 0.00837789, remaining 0 hours and 14 minutes
I0614 18:39:43.291810 11551 solver.cpp:291]     Train net output #0: loss = 0.00837788 (* 1 = 0.00837788 loss)
I0614 18:39:43.291818 11551 sgd_solver.cpp:106] Iteration 8450, lr = 1e-06
I0614 18:39:55.884894 11551 solver.cpp:270] Iteration 8500 (3.97056 iter/s, 12.5927s/50 iter), loss = 0.00116929, remaining 0 hours and 14 minutes
I0614 18:39:55.884925 11551 solver.cpp:291]     Train net output #0: loss = 0.00116929 (* 1 = 0.00116929 loss)
I0614 18:39:55.884933 11551 sgd_solver.cpp:106] Iteration 8500, lr = 1e-06
I0614 18:40:08.493870 11551 solver.cpp:270] Iteration 8550 (3.96557 iter/s, 12.6085s/50 iter), loss = 0.0059072, remaining 0 hours and 14 minutes
I0614 18:40:08.493901 11551 solver.cpp:291]     Train net output #0: loss = 0.00590719 (* 1 = 0.00590719 loss)
I0614 18:40:08.493909 11551 sgd_solver.cpp:106] Iteration 8550, lr = 1e-06
I0614 18:40:21.113562 11551 solver.cpp:270] Iteration 8600 (3.9622 iter/s, 12.6193s/50 iter), loss = 0.00331762, remaining 0 hours and 14 minutes
I0614 18:40:21.113832 11551 solver.cpp:291]     Train net output #0: loss = 0.00331761 (* 1 = 0.00331761 loss)
I0614 18:40:21.113842 11551 sgd_solver.cpp:106] Iteration 8600, lr = 1e-06
I0614 18:40:33.715773 11551 solver.cpp:270] Iteration 8650 (3.96777 iter/s, 12.6015s/50 iter), loss = 0.00227242, remaining 0 hours and 13 minutes
I0614 18:40:33.715803 11551 solver.cpp:291]     Train net output #0: loss = 0.00227241 (* 1 = 0.00227241 loss)
I0614 18:40:33.715811 11551 sgd_solver.cpp:106] Iteration 8650, lr = 1e-06
I0614 18:40:46.329227 11551 solver.cpp:270] Iteration 8700 (3.96416 iter/s, 12.613s/50 iter), loss = 0.00379827, remaining 0 hours and 13 minutes
I0614 18:40:46.329259 11551 solver.cpp:291]     Train net output #0: loss = 0.00379826 (* 1 = 0.00379826 loss)
I0614 18:40:46.329283 11551 sgd_solver.cpp:106] Iteration 8700, lr = 1e-06
I0614 18:40:58.932216 11551 solver.cpp:270] Iteration 8750 (3.96745 iter/s, 12.6025s/50 iter), loss = 0.00642944, remaining 0 hours and 13 minutes
I0614 18:40:58.932580 11551 solver.cpp:291]     Train net output #0: loss = 0.00642943 (* 1 = 0.00642943 loss)
I0614 18:40:58.932590 11551 sgd_solver.cpp:106] Iteration 8750, lr = 1e-06
I0614 18:41:11.524426 11551 solver.cpp:270] Iteration 8800 (3.97095 iter/s, 12.5914s/50 iter), loss = 0.00520299, remaining 0 hours and 13 minutes
I0614 18:41:11.524459 11551 solver.cpp:291]     Train net output #0: loss = 0.00520299 (* 1 = 0.00520299 loss)
I0614 18:41:11.524483 11551 sgd_solver.cpp:106] Iteration 8800, lr = 1e-06
I0614 18:41:24.134172 11551 solver.cpp:270] Iteration 8850 (3.96533 iter/s, 12.6093s/50 iter), loss = 0.00204857, remaining 0 hours and 13 minutes
I0614 18:41:24.134203 11551 solver.cpp:291]     Train net output #0: loss = 0.00204856 (* 1 = 0.00204856 loss)
I0614 18:41:24.134227 11551 sgd_solver.cpp:106] Iteration 8850, lr = 1e-06
I0614 18:41:36.743891 11551 solver.cpp:270] Iteration 8900 (3.96533 iter/s, 12.6093s/50 iter), loss = 0.0178735, remaining 0 hours and 12 minutes
I0614 18:41:36.744166 11551 solver.cpp:291]     Train net output #0: loss = 0.0178735 (* 1 = 0.0178735 loss)
I0614 18:41:36.744174 11551 sgd_solver.cpp:106] Iteration 8900, lr = 1e-06
I0614 18:41:49.367441 11551 solver.cpp:270] Iteration 8950 (3.96106 iter/s, 12.6229s/50 iter), loss = 0.00117049, remaining 0 hours and 12 minutes
I0614 18:41:49.367472 11551 solver.cpp:291]     Train net output #0: loss = 0.00117048 (* 1 = 0.00117048 loss)
I0614 18:41:49.367496 11551 sgd_solver.cpp:106] Iteration 8950, lr = 1e-06
I0614 18:42:01.730454 11551 solver.cpp:424] Iteration 9000, Testing net (#0)
I0614 18:42:03.224279 11551 solver.cpp:523]     Test net output #0: accuracy = 0.96275
I0614 18:42:03.224308 11551 solver.cpp:523]     Test net output #1: loss = 0.193494 (* 1 = 0.193494 loss)
I0614 18:42:03.224313 11551 solver.cpp:523]     Test net output #2: top-1 = 0.96275
I0614 18:42:03.471462 11551 solver.cpp:270] Iteration 9000 (3.54521 iter/s, 14.1035s/50 iter), loss = 0.00856946, remaining 0 hours and 14 minutes
I0614 18:42:03.471493 11551 solver.cpp:291]     Train net output #0: loss = 0.00856944 (* 1 = 0.00856944 loss)
I0614 18:42:03.471516 11551 sgd_solver.cpp:106] Iteration 9000, lr = 1e-06
I0614 18:42:16.086289 11551 solver.cpp:270] Iteration 9050 (3.96373 iter/s, 12.6144s/50 iter), loss = 0.0021458, remaining 0 hours and 12 minutes
I0614 18:42:16.086537 11551 solver.cpp:291]     Train net output #0: loss = 0.00214579 (* 1 = 0.00214579 loss)
I0614 18:42:16.086546 11551 sgd_solver.cpp:106] Iteration 9050, lr = 1e-06
I0614 18:42:28.694553 11551 solver.cpp:270] Iteration 9100 (3.96586 iter/s, 12.6076s/50 iter), loss = 0.00829083, remaining 0 hours and 12 minutes
I0614 18:42:28.694586 11551 solver.cpp:291]     Train net output #0: loss = 0.00829081 (* 1 = 0.00829081 loss)
I0614 18:42:28.694593 11551 sgd_solver.cpp:106] Iteration 9100, lr = 1e-06
I0614 18:42:41.293464 11551 solver.cpp:270] Iteration 9150 (3.96874 iter/s, 12.5985s/50 iter), loss = 0.00740921, remaining 0 hours and 11 minutes
I0614 18:42:41.293496 11551 solver.cpp:291]     Train net output #0: loss = 0.00740919 (* 1 = 0.00740919 loss)
I0614 18:42:41.293520 11551 sgd_solver.cpp:106] Iteration 9150, lr = 1e-06
I0614 18:42:53.892483 11551 solver.cpp:270] Iteration 9200 (3.9687 iter/s, 12.5986s/50 iter), loss = 0.0128094, remaining 0 hours and 11 minutes
I0614 18:42:53.892756 11551 solver.cpp:291]     Train net output #0: loss = 0.0128094 (* 1 = 0.0128094 loss)
I0614 18:42:53.892765 11551 sgd_solver.cpp:106] Iteration 9200, lr = 1e-06
I0614 18:43:06.503897 11551 solver.cpp:270] Iteration 9250 (3.96488 iter/s, 12.6107s/50 iter), loss = 0.00497094, remaining 0 hours and 11 minutes
I0614 18:43:06.503927 11551 solver.cpp:291]     Train net output #0: loss = 0.00497093 (* 1 = 0.00497093 loss)
I0614 18:43:06.503935 11551 sgd_solver.cpp:106] Iteration 9250, lr = 1e-06
I0614 18:43:19.114288 11551 solver.cpp:270] Iteration 9300 (3.96512 iter/s, 12.61s/50 iter), loss = 0.0368218, remaining 0 hours and 11 minutes
I0614 18:43:19.114320 11551 solver.cpp:291]     Train net output #0: loss = 0.0368218 (* 1 = 0.0368218 loss)
I0614 18:43:19.114327 11551 sgd_solver.cpp:106] Iteration 9300, lr = 1e-06
I0614 18:43:31.709532 11551 solver.cpp:270] Iteration 9350 (3.96989 iter/s, 12.5948s/50 iter), loss = 0.0103028, remaining 0 hours and 11 minutes
I0614 18:43:31.709865 11551 solver.cpp:291]     Train net output #0: loss = 0.0103028 (* 1 = 0.0103028 loss)
I0614 18:43:31.709874 11551 sgd_solver.cpp:106] Iteration 9350, lr = 1e-06
I0614 18:43:44.329057 11551 solver.cpp:270] Iteration 9400 (3.96235 iter/s, 12.6188s/50 iter), loss = 0.00521263, remaining 0 hours and 10 minutes
I0614 18:43:44.329089 11551 solver.cpp:291]     Train net output #0: loss = 0.00521262 (* 1 = 0.00521262 loss)
I0614 18:43:44.329113 11551 sgd_solver.cpp:106] Iteration 9400, lr = 1e-06
I0614 18:43:56.934504 11551 solver.cpp:270] Iteration 9450 (3.96668 iter/s, 12.605s/50 iter), loss = 0.00837126, remaining 0 hours and 10 minutes
I0614 18:43:56.934535 11551 solver.cpp:291]     Train net output #0: loss = 0.00837125 (* 1 = 0.00837125 loss)
I0614 18:43:56.934558 11551 sgd_solver.cpp:106] Iteration 9450, lr = 1e-06
I0614 18:44:09.545044 11551 solver.cpp:270] Iteration 9500 (3.96507 iter/s, 12.6101s/50 iter), loss = 0.00428451, remaining 0 hours and 10 minutes
I0614 18:44:09.545317 11551 solver.cpp:291]     Train net output #0: loss = 0.00428449 (* 1 = 0.00428449 loss)
I0614 18:44:09.545326 11551 sgd_solver.cpp:106] Iteration 9500, lr = 1e-06
I0614 18:44:22.147047 11551 solver.cpp:270] Iteration 9550 (3.96784 iter/s, 12.6013s/50 iter), loss = 0.00203183, remaining 0 hours and 10 minutes
I0614 18:44:22.147078 11551 solver.cpp:291]     Train net output #0: loss = 0.00203181 (* 1 = 0.00203181 loss)
I0614 18:44:22.147102 11551 sgd_solver.cpp:106] Iteration 9550, lr = 1e-06
I0614 18:44:34.753583 11551 solver.cpp:270] Iteration 9600 (3.96633 iter/s, 12.6061s/50 iter), loss = 0.000929077, remaining 0 hours and 10 minutes
I0614 18:44:34.753618 11551 solver.cpp:291]     Train net output #0: loss = 0.000929068 (* 1 = 0.000929068 loss)
I0614 18:44:34.753626 11551 sgd_solver.cpp:106] Iteration 9600, lr = 1e-06
I0614 18:44:47.355729 11551 solver.cpp:270] Iteration 9650 (3.96772 iter/s, 12.6017s/50 iter), loss = 0.00827225, remaining 0 hours and 9 minutes
I0614 18:44:47.356000 11551 solver.cpp:291]     Train net output #0: loss = 0.00827223 (* 1 = 0.00827223 loss)
I0614 18:44:47.356025 11551 sgd_solver.cpp:106] Iteration 9650, lr = 1e-06
I0614 18:44:59.954530 11551 solver.cpp:270] Iteration 9700 (3.96885 iter/s, 12.5981s/50 iter), loss = 0.0123345, remaining 0 hours and 9 minutes
I0614 18:44:59.954560 11551 solver.cpp:291]     Train net output #0: loss = 0.0123345 (* 1 = 0.0123345 loss)
I0614 18:44:59.954569 11551 sgd_solver.cpp:106] Iteration 9700, lr = 1e-06
I0614 18:45:12.551543 11551 solver.cpp:270] Iteration 9750 (3.96933 iter/s, 12.5966s/50 iter), loss = 0.0019749, remaining 0 hours and 9 minutes
I0614 18:45:12.551576 11551 solver.cpp:291]     Train net output #0: loss = 0.00197488 (* 1 = 0.00197488 loss)
I0614 18:45:12.551584 11551 sgd_solver.cpp:106] Iteration 9750, lr = 1e-06
I0614 18:45:25.158097 11551 solver.cpp:270] Iteration 9800 (3.96633 iter/s, 12.6061s/50 iter), loss = 0.00262573, remaining 0 hours and 9 minutes
I0614 18:45:25.158322 11551 solver.cpp:291]     Train net output #0: loss = 0.00262572 (* 1 = 0.00262572 loss)
I0614 18:45:25.158347 11551 sgd_solver.cpp:106] Iteration 9800, lr = 1e-06
I0614 18:45:37.769721 11551 solver.cpp:270] Iteration 9850 (3.9648 iter/s, 12.611s/50 iter), loss = 0.00897729, remaining 0 hours and 8 minutes
I0614 18:45:37.769750 11551 solver.cpp:291]     Train net output #0: loss = 0.00897727 (* 1 = 0.00897727 loss)
I0614 18:45:37.769758 11551 sgd_solver.cpp:106] Iteration 9850, lr = 1e-06
I0614 18:45:50.374258 11551 solver.cpp:270] Iteration 9900 (3.96696 iter/s, 12.6041s/50 iter), loss = 0.00108712, remaining 0 hours and 8 minutes
I0614 18:45:50.374287 11551 solver.cpp:291]     Train net output #0: loss = 0.0010871 (* 1 = 0.0010871 loss)
I0614 18:45:50.374295 11551 sgd_solver.cpp:106] Iteration 9900, lr = 1e-06
I0614 18:46:03.004259 11551 solver.cpp:270] Iteration 9950 (3.95896 iter/s, 12.6296s/50 iter), loss = 0.00374939, remaining 0 hours and 8 minutes
I0614 18:46:03.004546 11551 solver.cpp:291]     Train net output #0: loss = 0.00374937 (* 1 = 0.00374937 loss)
I0614 18:46:03.004555 11551 sgd_solver.cpp:106] Iteration 9950, lr = 1e-06
I0614 18:46:15.356719 11551 solver.cpp:424] Iteration 10000, Testing net (#0)
I0614 18:46:16.863119 11551 solver.cpp:523]     Test net output #0: accuracy = 0.96175
I0614 18:46:16.863150 11551 solver.cpp:523]     Test net output #1: loss = 0.201389 (* 1 = 0.201389 loss)
I0614 18:46:16.863154 11551 solver.cpp:523]     Test net output #2: top-1 = 0.96175
I0614 18:46:17.109401 11551 solver.cpp:270] Iteration 10000 (3.54499 iter/s, 14.1044s/50 iter), loss = 0.00186711, remaining 0 hours and 9 minutes
I0614 18:46:17.109433 11551 solver.cpp:291]     Train net output #0: loss = 0.00186709 (* 1 = 0.00186709 loss)
I0614 18:46:17.109442 11551 sgd_solver.cpp:106] Iteration 10000, lr = 1e-07
I0614 18:46:29.733248 11551 solver.cpp:270] Iteration 10050 (3.9609 iter/s, 12.6234s/50 iter), loss = 0.00355737, remaining 0 hours and 8 minutes
I0614 18:46:29.733281 11551 solver.cpp:291]     Train net output #0: loss = 0.00355735 (* 1 = 0.00355735 loss)
I0614 18:46:29.733289 11551 sgd_solver.cpp:106] Iteration 10050, lr = 1e-07
I0614 18:46:42.340694 11551 solver.cpp:270] Iteration 10100 (3.96605 iter/s, 12.607s/50 iter), loss = 0.00790159, remaining 0 hours and 7 minutes
I0614 18:46:42.340962 11551 solver.cpp:291]     Train net output #0: loss = 0.00790157 (* 1 = 0.00790157 loss)
I0614 18:46:42.340971 11551 sgd_solver.cpp:106] Iteration 10100, lr = 1e-07
I0614 18:46:54.955642 11551 solver.cpp:270] Iteration 10150 (3.96376 iter/s, 12.6143s/50 iter), loss = 0.000885315, remaining 0 hours and 7 minutes
I0614 18:46:54.955675 11551 solver.cpp:291]     Train net output #0: loss = 0.000885291 (* 1 = 0.000885291 loss)
I0614 18:46:54.955684 11551 sgd_solver.cpp:106] Iteration 10150, lr = 1e-07
I0614 18:47:07.552443 11551 solver.cpp:270] Iteration 10200 (3.9694 iter/s, 12.5964s/50 iter), loss = 0.00271498, remaining 0 hours and 7 minutes
I0614 18:47:07.552474 11551 solver.cpp:291]     Train net output #0: loss = 0.00271495 (* 1 = 0.00271495 loss)
I0614 18:47:07.552498 11551 sgd_solver.cpp:106] Iteration 10200, lr = 1e-07
I0614 18:47:20.155921 11551 solver.cpp:270] Iteration 10250 (3.9673 iter/s, 12.603s/50 iter), loss = 0.00779295, remaining 0 hours and 7 minutes
I0614 18:47:20.156173 11551 solver.cpp:291]     Train net output #0: loss = 0.00779293 (* 1 = 0.00779293 loss)
I0614 18:47:20.156183 11551 sgd_solver.cpp:106] Iteration 10250, lr = 1e-07
I0614 18:47:32.754330 11551 solver.cpp:270] Iteration 10300 (3.96896 iter/s, 12.5978s/50 iter), loss = 0.00507923, remaining 0 hours and 7 minutes
I0614 18:47:32.754364 11551 solver.cpp:291]     Train net output #0: loss = 0.00507921 (* 1 = 0.00507921 loss)
I0614 18:47:32.754371 11551 sgd_solver.cpp:106] Iteration 10300, lr = 1e-07
I0614 18:47:45.371702 11551 solver.cpp:270] Iteration 10350 (3.96293 iter/s, 12.6169s/50 iter), loss = 0.000835242, remaining 0 hours and 6 minutes
I0614 18:47:45.371732 11551 solver.cpp:291]     Train net output #0: loss = 0.00083522 (* 1 = 0.00083522 loss)
I0614 18:47:45.371740 11551 sgd_solver.cpp:106] Iteration 10350, lr = 1e-07
I0614 18:47:57.967943 11551 solver.cpp:270] Iteration 10400 (3.96958 iter/s, 12.5958s/50 iter), loss = 0.000470165, remaining 0 hours and 6 minutes
I0614 18:47:57.968283 11551 solver.cpp:291]     Train net output #0: loss = 0.000470143 (* 1 = 0.000470143 loss)
I0614 18:47:57.968307 11551 sgd_solver.cpp:106] Iteration 10400, lr = 1e-07
I0614 18:48:10.577476 11551 solver.cpp:270] Iteration 10450 (3.96549 iter/s, 12.6088s/50 iter), loss = 0.00954213, remaining 0 hours and 6 minutes
I0614 18:48:10.577507 11551 solver.cpp:291]     Train net output #0: loss = 0.00954211 (* 1 = 0.00954211 loss)
I0614 18:48:10.577531 11551 sgd_solver.cpp:106] Iteration 10450, lr = 1e-07
I0614 18:48:23.182711 11551 solver.cpp:270] Iteration 10500 (3.96674 iter/s, 12.6048s/50 iter), loss = 0.00174292, remaining 0 hours and 6 minutes
I0614 18:48:23.182744 11551 solver.cpp:291]     Train net output #0: loss = 0.0017429 (* 1 = 0.0017429 loss)
I0614 18:48:23.182767 11551 sgd_solver.cpp:106] Iteration 10500, lr = 1e-07
I0614 18:48:35.789244 11551 solver.cpp:270] Iteration 10550 (3.96634 iter/s, 12.6061s/50 iter), loss = 0.0190391, remaining 0 hours and 6 minutes
I0614 18:48:35.789515 11551 solver.cpp:291]     Train net output #0: loss = 0.0190391 (* 1 = 0.0190391 loss)
I0614 18:48:35.789523 11551 sgd_solver.cpp:106] Iteration 10550, lr = 1e-07
I0614 18:48:48.407294 11551 solver.cpp:270] Iteration 10600 (3.96279 iter/s, 12.6174s/50 iter), loss = 0.000913233, remaining 0 hours and 5 minutes
I0614 18:48:48.407326 11551 solver.cpp:291]     Train net output #0: loss = 0.000913215 (* 1 = 0.000913215 loss)
I0614 18:48:48.407351 11551 sgd_solver.cpp:106] Iteration 10600, lr = 1e-07
I0614 18:49:01.014997 11551 solver.cpp:270] Iteration 10650 (3.96597 iter/s, 12.6073s/50 iter), loss = 0.00303465, remaining 0 hours and 5 minutes
I0614 18:49:01.015029 11551 solver.cpp:291]     Train net output #0: loss = 0.00303462 (* 1 = 0.00303462 loss)
I0614 18:49:01.015038 11551 sgd_solver.cpp:106] Iteration 10650, lr = 1e-07
I0614 18:49:13.629951 11551 solver.cpp:270] Iteration 10700 (3.96369 iter/s, 12.6145s/50 iter), loss = 0.00531661, remaining 0 hours and 5 minutes
I0614 18:49:13.630220 11551 solver.cpp:291]     Train net output #0: loss = 0.00531658 (* 1 = 0.00531658 loss)
I0614 18:49:13.630228 11551 sgd_solver.cpp:106] Iteration 10700, lr = 1e-07
I0614 18:49:26.219676 11551 solver.cpp:270] Iteration 10750 (3.9717 iter/s, 12.5891s/50 iter), loss = 0.0105387, remaining 0 hours and 5 minutes
I0614 18:49:26.219708 11551 solver.cpp:291]     Train net output #0: loss = 0.0105387 (* 1 = 0.0105387 loss)
I0614 18:49:26.219717 11551 sgd_solver.cpp:106] Iteration 10750, lr = 1e-07
I0614 18:49:38.843019 11551 solver.cpp:270] Iteration 10800 (3.96105 iter/s, 12.6229s/50 iter), loss = 0.0325072, remaining 0 hours and 5 minutes
I0614 18:49:38.843050 11551 solver.cpp:291]     Train net output #0: loss = 0.0325072 (* 1 = 0.0325072 loss)
I0614 18:49:38.843058 11551 sgd_solver.cpp:106] Iteration 10800, lr = 1e-07
I0614 18:49:51.437773 11551 solver.cpp:270] Iteration 10850 (3.97004 iter/s, 12.5943s/50 iter), loss = 0.0205066, remaining 0 hours and 4 minutes
I0614 18:49:51.438046 11551 solver.cpp:291]     Train net output #0: loss = 0.0205066 (* 1 = 0.0205066 loss)
I0614 18:49:51.438071 11551 sgd_solver.cpp:106] Iteration 10850, lr = 1e-07
I0614 18:50:04.046953 11551 solver.cpp:270] Iteration 10900 (3.96558 iter/s, 12.6085s/50 iter), loss = 0.0144144, remaining 0 hours and 4 minutes
I0614 18:50:04.046983 11551 solver.cpp:291]     Train net output #0: loss = 0.0144144 (* 1 = 0.0144144 loss)
I0614 18:50:04.046991 11551 sgd_solver.cpp:106] Iteration 10900, lr = 1e-07
I0614 18:50:16.642179 11551 solver.cpp:270] Iteration 10950 (3.9699 iter/s, 12.5948s/50 iter), loss = 0.00890115, remaining 0 hours and 4 minutes
I0614 18:50:16.642210 11551 solver.cpp:291]     Train net output #0: loss = 0.00890112 (* 1 = 0.00890112 loss)
I0614 18:50:16.642220 11551 sgd_solver.cpp:106] Iteration 10950, lr = 1e-07
I0614 18:50:29.000025 11551 solver.cpp:424] Iteration 11000, Testing net (#0)
I0614 18:50:30.477871 11551 solver.cpp:523]     Test net output #0: accuracy = 0.96175
I0614 18:50:30.477902 11551 solver.cpp:523]     Test net output #1: loss = 0.205663 (* 1 = 0.205663 loss)
I0614 18:50:30.477907 11551 solver.cpp:523]     Test net output #2: top-1 = 0.96175
I0614 18:50:30.724238 11551 solver.cpp:270] Iteration 11000 (3.55074 iter/s, 14.0816s/50 iter), loss = 0.00120688, remaining 0 hours and 4 minutes
I0614 18:50:30.724269 11551 solver.cpp:291]     Train net output #0: loss = 0.00120685 (* 1 = 0.00120685 loss)
I0614 18:50:30.724278 11551 sgd_solver.cpp:106] Iteration 11000, lr = 1e-07
I0614 18:50:43.335969 11551 solver.cpp:270] Iteration 11050 (3.9647 iter/s, 12.6113s/50 iter), loss = 0.0131264, remaining 0 hours and 3 minutes
I0614 18:50:43.336002 11551 solver.cpp:291]     Train net output #0: loss = 0.0131264 (* 1 = 0.0131264 loss)
I0614 18:50:43.336026 11551 sgd_solver.cpp:106] Iteration 11050, lr = 1e-07
I0614 18:50:55.951052 11551 solver.cpp:270] Iteration 11100 (3.96365 iter/s, 12.6146s/50 iter), loss = 0.0110263, remaining 0 hours and 3 minutes
I0614 18:50:55.951083 11551 solver.cpp:291]     Train net output #0: loss = 0.0110263 (* 1 = 0.0110263 loss)
I0614 18:50:55.951092 11551 sgd_solver.cpp:106] Iteration 11100, lr = 1e-07
I0614 18:51:08.566546 11551 solver.cpp:270] Iteration 11150 (3.96352 iter/s, 12.6151s/50 iter), loss = 0.00115752, remaining 0 hours and 3 minutes
I0614 18:51:08.566707 11551 solver.cpp:291]     Train net output #0: loss = 0.00115749 (* 1 = 0.00115749 loss)
I0614 18:51:08.566718 11551 sgd_solver.cpp:106] Iteration 11150, lr = 1e-07
I0614 18:51:21.164685 11551 solver.cpp:270] Iteration 11200 (3.96902 iter/s, 12.5976s/50 iter), loss = 0.00141354, remaining 0 hours and 3 minutes
I0614 18:51:21.164717 11551 solver.cpp:291]     Train net output #0: loss = 0.00141351 (* 1 = 0.00141351 loss)
I0614 18:51:21.164741 11551 sgd_solver.cpp:106] Iteration 11200, lr = 1e-07
I0614 18:51:33.773566 11551 solver.cpp:270] Iteration 11250 (3.9656 iter/s, 12.6084s/50 iter), loss = 0.00147068, remaining 0 hours and 3 minutes
I0614 18:51:33.773597 11551 solver.cpp:291]     Train net output #0: loss = 0.00147065 (* 1 = 0.00147065 loss)
I0614 18:51:33.773604 11551 sgd_solver.cpp:106] Iteration 11250, lr = 1e-07
I0614 18:51:46.373317 11551 solver.cpp:270] Iteration 11300 (3.96847 iter/s, 12.5993s/50 iter), loss = 0.0134668, remaining 0 hours and 2 minutes
I0614 18:51:46.373466 11551 solver.cpp:291]     Train net output #0: loss = 0.0134668 (* 1 = 0.0134668 loss)
I0614 18:51:46.373476 11551 sgd_solver.cpp:106] Iteration 11300, lr = 1e-07
I0614 18:51:58.989989 11551 solver.cpp:270] Iteration 11350 (3.96318 iter/s, 12.6161s/50 iter), loss = 0.00710557, remaining 0 hours and 2 minutes
I0614 18:51:58.990021 11551 solver.cpp:291]     Train net output #0: loss = 0.00710553 (* 1 = 0.00710553 loss)
I0614 18:51:58.990043 11551 sgd_solver.cpp:106] Iteration 11350, lr = 1e-07
I0614 18:52:11.605582 11551 solver.cpp:270] Iteration 11400 (3.96349 iter/s, 12.6152s/50 iter), loss = 0.00255471, remaining 0 hours and 2 minutes
I0614 18:52:11.605613 11551 solver.cpp:291]     Train net output #0: loss = 0.00255467 (* 1 = 0.00255467 loss)
I0614 18:52:11.605638 11551 sgd_solver.cpp:106] Iteration 11400, lr = 1e-07
I0614 18:52:24.203742 11551 solver.cpp:270] Iteration 11450 (3.96897 iter/s, 12.5977s/50 iter), loss = 0.0029507, remaining 0 hours and 2 minutes
I0614 18:52:24.203877 11551 solver.cpp:291]     Train net output #0: loss = 0.00295066 (* 1 = 0.00295066 loss)
I0614 18:52:24.203887 11551 sgd_solver.cpp:106] Iteration 11450, lr = 1e-07
I0614 18:52:36.805958 11551 solver.cpp:270] Iteration 11500 (3.96773 iter/s, 12.6017s/50 iter), loss = 0.0041844, remaining 0 hours and 2 minutes
I0614 18:52:36.805989 11551 solver.cpp:291]     Train net output #0: loss = 0.00418435 (* 1 = 0.00418435 loss)
I0614 18:52:36.806011 11551 sgd_solver.cpp:106] Iteration 11500, lr = 1e-07
I0614 18:52:49.409305 11551 solver.cpp:270] Iteration 11550 (3.96734 iter/s, 12.6029s/50 iter), loss = 0.000740489, remaining 0 hours and 1 minutes
I0614 18:52:49.409337 11551 solver.cpp:291]     Train net output #0: loss = 0.000740444 (* 1 = 0.000740444 loss)
I0614 18:52:49.409345 11551 sgd_solver.cpp:106] Iteration 11550, lr = 1e-07
I0614 18:53:02.020480 11551 solver.cpp:270] Iteration 11600 (3.96488 iter/s, 12.6107s/50 iter), loss = 0.00265213, remaining 0 hours and 1 minutes
I0614 18:53:02.020797 11551 solver.cpp:291]     Train net output #0: loss = 0.00265208 (* 1 = 0.00265208 loss)
I0614 18:53:02.020807 11551 sgd_solver.cpp:106] Iteration 11600, lr = 1e-07
I0614 18:53:14.618582 11551 solver.cpp:270] Iteration 11650 (3.96908 iter/s, 12.5974s/50 iter), loss = 0.0130487, remaining 0 hours and 1 minutes
I0614 18:53:14.618615 11551 solver.cpp:291]     Train net output #0: loss = 0.0130486 (* 1 = 0.0130486 loss)
I0614 18:53:14.618623 11551 sgd_solver.cpp:106] Iteration 11650, lr = 1e-07
I0614 18:53:27.224012 11551 solver.cpp:270] Iteration 11700 (3.96669 iter/s, 12.605s/50 iter), loss = 0.00347075, remaining 0 hours and 1 minutes
I0614 18:53:27.224043 11551 solver.cpp:291]     Train net output #0: loss = 0.00347071 (* 1 = 0.00347071 loss)
I0614 18:53:27.224067 11551 sgd_solver.cpp:106] Iteration 11700, lr = 1e-07
I0614 18:53:39.822880 11551 solver.cpp:270] Iteration 11750 (3.96875 iter/s, 12.5984s/50 iter), loss = 0.004745, remaining 0 hours and 1 minutes
I0614 18:53:39.823155 11551 solver.cpp:291]     Train net output #0: loss = 0.00474496 (* 1 = 0.00474496 loss)
I0614 18:53:39.823179 11551 sgd_solver.cpp:106] Iteration 11750, lr = 1e-07
I0614 18:53:52.425642 11551 solver.cpp:270] Iteration 11800 (3.9676 iter/s, 12.6021s/50 iter), loss = 0.0370046, remaining 0 hours and 0 minutes
I0614 18:53:52.425673 11551 solver.cpp:291]     Train net output #0: loss = 0.0370046 (* 1 = 0.0370046 loss)
I0614 18:53:52.425683 11551 sgd_solver.cpp:106] Iteration 11800, lr = 1e-07
I0614 18:54:05.051048 11551 solver.cpp:270] Iteration 11850 (3.96041 iter/s, 12.625s/50 iter), loss = 0.00322042, remaining 0 hours and 0 minutes
I0614 18:54:05.051079 11551 solver.cpp:291]     Train net output #0: loss = 0.00322038 (* 1 = 0.00322038 loss)
I0614 18:54:05.051087 11551 sgd_solver.cpp:106] Iteration 11850, lr = 1e-07
I0614 18:54:17.657641 11551 solver.cpp:270] Iteration 11900 (3.96632 iter/s, 12.6062s/50 iter), loss = 0.0221864, remaining 0 hours and 0 minutes
I0614 18:54:17.657914 11551 solver.cpp:291]     Train net output #0: loss = 0.0221863 (* 1 = 0.0221863 loss)
I0614 18:54:17.657922 11551 sgd_solver.cpp:106] Iteration 11900, lr = 1e-07
I0614 18:54:30.266620 11551 solver.cpp:270] Iteration 11950 (3.96564 iter/s, 12.6083s/50 iter), loss = 0.0133973, remaining 0 hours and 0 minutes
I0614 18:54:30.266651 11551 solver.cpp:291]     Train net output #0: loss = 0.0133972 (* 1 = 0.0133972 loss)
I0614 18:54:30.266659 11551 sgd_solver.cpp:106] Iteration 11950, lr = 1e-07
I0614 18:54:42.623912 11551 solver.cpp:935] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.6/snapshots/_iter_12000.caffemodel
I0614 18:54:48.403657 11551 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.6/snapshots/_iter_12000.solverstate
I0614 18:54:52.273062 11551 solver.cpp:384] Iteration 12000, loss = 0.00286007
I0614 18:54:52.273087 11551 solver.cpp:424] Iteration 12000, Testing net (#0)
I0614 18:54:53.676499 11551 solver.cpp:523]     Test net output #0: accuracy = 0.96175
I0614 18:54:53.676527 11551 solver.cpp:523]     Test net output #1: loss = 0.207423 (* 1 = 0.207423 loss)
I0614 18:54:53.676532 11551 solver.cpp:523]     Test net output #2: top-1 = 0.96175
I0614 18:54:53.676553 11551 solver.cpp:392] Optimization Done (3.9476 iter/s).
I0614 18:54:53.676555 11551 caffe_interface.cpp:576] Optimization Done.
(c) Copyright 2016â2019 Xilinx, Inc. All rights reserved.

I0614 18:54:54.469828 11648 pruning_runner.cpp:234] Analysis info found.
I0614 18:54:56.192584 11648 pruning_runner.cpp:265] Start pruning, please wait...
I0614 18:55:05.459599 11648 pruning_runner.cpp:312] Compression complete 0%
I0614 18:55:14.383390 11648 pruning_runner.cpp:312] Compression complete 0%
I0614 18:55:23.369115 11648 pruning_runner.cpp:312] Compression complete 0%
I0614 18:55:32.189736 11648 pruning_runner.cpp:312] Compression complete 0%
I0614 18:55:41.250977 11648 pruning_runner.cpp:312] Compression complete 0%
I0614 18:55:50.209673 11648 pruning_runner.cpp:312] Compression complete 50%
I0614 18:55:59.150477 11648 pruning_runner.cpp:312] Compression complete 66.6667%
I0614 18:56:08.118865 11648 pruning_runner.cpp:312] Compression complete 80%
I0614 18:56:17.103756 11648 pruning_runner.cpp:312] Compression complete 97.5%
I0614 18:56:26.105489 11648 pruning_runner.cpp:312] Compression complete 99.3631%
I0614 18:56:34.954702 11648 pruning_runner.cpp:312] Compression complete 99.6815%
I0614 18:56:43.734068 11648 pruning_runner.cpp:312] Compression complete 99.8405%
I0614 18:56:52.640571 11648 pruning_runner.cpp:312] Compression complete 99.9203%
I0614 18:57:01.688504 11648 pruning_runner.cpp:312] Compression complete 99.9601%
I0614 18:57:10.585794 11648 pruning_runner.cpp:312] Compression complete 99.99%
I0614 18:57:19.453157 11648 pruning_runner.cpp:312] Compression complete 99.9994%
I0614 18:57:28.273763 11648 pruning_runner.cpp:312] Compression complete 99.9997%
I0614 18:57:37.062633 11648 pruning_runner.cpp:312] Compression complete 99.9998%
I0614 18:57:45.822602 11648 pruning_runner.cpp:312] Compression complete 99.9999%
I0614 18:57:54.795347 11648 pruning_runner.cpp:312] Compression complete 100%
I0614 18:58:03.732591 11648 pruning_runner.cpp:312] Compression complete 100%
I0614 18:58:12.735121 11648 pruning_runner.cpp:312] Compression complete 100%
I0614 18:58:24.056147 11648 pruning_runner.cpp:365] pruning done, output model: pruning/alexnetBNnoLRN/regular_rate_0.7/sparse.caffemodel
I0614 18:58:24.056175 11648 pruning_runner.cpp:379] summary of REGULAR compression with rate 0.7:
+-------------------------------------------------------------------+
| Item           | Baseline       | Compressed     | Delta          |
+-------------------------------------------------------------------+
| Accuracy       | 0.953499794    | 0.957749963    | 0.0042501688   |
+-------------------------------------------------------------------+
| Weights        | 3.74857903 M   | 472.319 K      | -87.4000549%   |
+-------------------------------------------------------------------+
| Operations     | 2.05460167 G   | 632.681152 M   | -69.2066269%   |
+-------------------------------------------------------------------+
To fine-tune the pruned model, please run:
vai_p_caffe finetune -config /workspace/TUTORIALS/VAI2.0bash-Caffe-ML-CATSvsDOGS/files/pruning/alexnetBNnoLRN/config7.prototxt
(c) Copyright 2016â2019 Xilinx, Inc. All rights reserved.

W0614 18:58:24.268676 13783 utils.cpp:207] BVLC BatchNormLayer without ScaleLayer detected: 3, it will be converted to NVCaffe Format.
W0614 18:58:24.272996 13783 utils.cpp:207] BVLC BatchNormLayer without ScaleLayer detected: 7, it will be converted to NVCaffe Format.
W0614 18:58:24.273041 13783 utils.cpp:207] BVLC BatchNormLayer without ScaleLayer detected: 21, it will be converted to NVCaffe Format.
I0614 18:58:24.279225 13783 vai_p_caffe.cpp:287] pruning/alexnetBNnoLRN/regular_rate_0.7/net_finetune.prototxt
I0614 18:58:24.509922 13783 gpu_memory.cpp:53] GPUMemory::Manager initialized with Caching (CUB) GPU Allocator
I0614 18:58:24.509944 13783 gpu_memory.cpp:55] Total memory: 25635127296, Free: 24796659712, dev_info[0]: total=25635127296 free=24796659712
I0614 18:58:24.510079 13783 caffe_interface.cpp:539] Using GPUs 0
I0614 18:58:24.510179 13783 caffe_interface.cpp:544] GPU 0: Quadro P6000
I0614 18:58:25.263482 13783 solver.cpp:51] Initializing solver from parameters: 
test_iter: 80
test_interval: 1000
base_lr: 0.001
display: 50
max_iter: 12000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 2500
snapshot: 6000
snapshot_prefix: "pruning/alexnetBNnoLRN/regular_rate_0.7/snapshots/"
solver_mode: GPU
device_id: 0
random_seed: 1201
net: "pruning/alexnetBNnoLRN/regular_rate_0.7/net_finetune.prototxt"
type: "Adam"
I0614 18:58:25.264401 13783 solver.cpp:99] Creating training net from net file: pruning/alexnetBNnoLRN/regular_rate_0.7/net_finetune.prototxt
I0614 18:58:25.265071 13783 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0614 18:58:25.265086 13783 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0614 18:58:25.265090 13783 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy-top1
I0614 18:58:25.265098 13783 net.cpp:52] Initializing net from parameters: 
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_value: 106
    mean_value: 116
    mean_value: 124
  }
  data_param {
    source: "input/lmdb/train_lmdb"
    batch_size: 256
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 0
    kernel_size: 8
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "bn1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn2"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "bn2"
  top: "relu2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "relu6"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "drop6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn7"
  type: "BatchNorm"
  bottom: "fc7"
  top: "bn7"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "bn7"
  top: "relu7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "relu7"
  top: "drop7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "drop7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0614 18:58:25.265609 13783 layer_factory.hpp:77] Creating layer data
I0614 18:58:25.265743 13783 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0614 18:58:25.268277 13783 net.cpp:94] Creating Layer data
I0614 18:58:25.268316 13783 net.cpp:409] data -> data
I0614 18:58:25.268354 13783 net.cpp:409] data -> label
I0614 18:58:25.269583 13820 db_lmdb.cpp:35] Opened lmdb input/lmdb/train_lmdb
I0614 18:58:25.269615 13820 db_lmdb.cpp:38] Items count: 20000
I0614 18:58:25.269645 13820 data_reader.cpp:124] TRAIN: reading data using 1 channel(s)
I0614 18:58:25.270078 13783 data_layer.cpp:78] ReshapePrefetch 256, 3, 227, 227
I0614 18:58:25.270267 13783 data_layer.cpp:83] output data size: 256,3,227,227
I0614 18:58:25.827594 13783 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0614 18:58:25.827821 13783 net.cpp:144] Setting up data
I0614 18:58:25.827827 13783 net.cpp:151] Top shape: 256 3 227 227 (39574272)
I0614 18:58:25.827836 13783 net.cpp:151] Top shape: 256 (256)
I0614 18:58:25.827842 13783 net.cpp:159] Memory required for data: 158298112
I0614 18:58:25.827847 13783 layer_factory.hpp:77] Creating layer conv1
I0614 18:58:25.827862 13783 net.cpp:94] Creating Layer conv1
I0614 18:58:25.827867 13783 net.cpp:435] conv1 <- data
I0614 18:58:25.827874 13783 net.cpp:409] conv1 -> conv1
I0614 18:58:25.828297 13783 net.cpp:144] Setting up conv1
I0614 18:58:25.828305 13783 net.cpp:151] Top shape: 256 96 55 55 (74342400)
I0614 18:58:25.828311 13783 net.cpp:159] Memory required for data: 455667712
I0614 18:58:25.828322 13783 layer_factory.hpp:77] Creating layer bn1
I0614 18:58:25.828330 13783 net.cpp:94] Creating Layer bn1
I0614 18:58:25.828333 13783 net.cpp:435] bn1 <- conv1
I0614 18:58:25.828338 13783 net.cpp:409] bn1 -> bn1
I0614 18:58:25.828647 13783 net.cpp:144] Setting up bn1
I0614 18:58:25.828655 13783 net.cpp:151] Top shape: 256 96 55 55 (74342400)
I0614 18:58:25.828660 13783 net.cpp:159] Memory required for data: 753037312
I0614 18:58:25.828670 13783 layer_factory.hpp:77] Creating layer relu1
I0614 18:58:25.828675 13783 net.cpp:94] Creating Layer relu1
I0614 18:58:25.828680 13783 net.cpp:435] relu1 <- bn1
I0614 18:58:25.828683 13783 net.cpp:409] relu1 -> relu1
I0614 18:58:25.828696 13783 net.cpp:144] Setting up relu1
I0614 18:58:25.828701 13783 net.cpp:151] Top shape: 256 96 55 55 (74342400)
I0614 18:58:25.828706 13783 net.cpp:159] Memory required for data: 1050406912
I0614 18:58:25.828712 13783 layer_factory.hpp:77] Creating layer pool1
I0614 18:58:25.828722 13783 net.cpp:94] Creating Layer pool1
I0614 18:58:25.828727 13783 net.cpp:435] pool1 <- relu1
I0614 18:58:25.828732 13783 net.cpp:409] pool1 -> pool1
I0614 18:58:25.828749 13783 net.cpp:144] Setting up pool1
I0614 18:58:25.828753 13783 net.cpp:151] Top shape: 256 96 27 27 (17915904)
I0614 18:58:25.828758 13783 net.cpp:159] Memory required for data: 1122070528
I0614 18:58:25.828763 13783 layer_factory.hpp:77] Creating layer conv2
I0614 18:58:25.828768 13783 net.cpp:94] Creating Layer conv2
I0614 18:58:25.828773 13783 net.cpp:435] conv2 <- pool1
I0614 18:58:25.828778 13783 net.cpp:409] conv2 -> conv2
I0614 18:58:25.845201 13783 net.cpp:144] Setting up conv2
I0614 18:58:25.845216 13783 net.cpp:151] Top shape: 256 256 27 27 (47775744)
I0614 18:58:25.845223 13783 net.cpp:159] Memory required for data: 1313173504
I0614 18:58:25.845233 13783 layer_factory.hpp:77] Creating layer bn2
I0614 18:58:25.845242 13783 net.cpp:94] Creating Layer bn2
I0614 18:58:25.845247 13783 net.cpp:435] bn2 <- conv2
I0614 18:58:25.845252 13783 net.cpp:409] bn2 -> bn2
I0614 18:58:25.845530 13783 net.cpp:144] Setting up bn2
I0614 18:58:25.845536 13783 net.cpp:151] Top shape: 256 256 27 27 (47775744)
I0614 18:58:25.845541 13783 net.cpp:159] Memory required for data: 1504276480
I0614 18:58:25.845549 13783 layer_factory.hpp:77] Creating layer relu2
I0614 18:58:25.845556 13783 net.cpp:94] Creating Layer relu2
I0614 18:58:25.845558 13783 net.cpp:435] relu2 <- bn2
I0614 18:58:25.845563 13783 net.cpp:409] relu2 -> relu2
I0614 18:58:25.845577 13783 net.cpp:144] Setting up relu2
I0614 18:58:25.845579 13783 net.cpp:151] Top shape: 256 256 27 27 (47775744)
I0614 18:58:25.845584 13783 net.cpp:159] Memory required for data: 1695379456
I0614 18:58:25.845588 13783 layer_factory.hpp:77] Creating layer pool2
I0614 18:58:25.845593 13783 net.cpp:94] Creating Layer pool2
I0614 18:58:25.845597 13783 net.cpp:435] pool2 <- relu2
I0614 18:58:25.845602 13783 net.cpp:409] pool2 -> pool2
I0614 18:58:25.845620 13783 net.cpp:144] Setting up pool2
I0614 18:58:25.845636 13783 net.cpp:151] Top shape: 256 256 13 13 (11075584)
I0614 18:58:25.845643 13783 net.cpp:159] Memory required for data: 1739681792
I0614 18:58:25.845647 13783 layer_factory.hpp:77] Creating layer conv3
I0614 18:58:25.845986 13783 net.cpp:94] Creating Layer conv3
I0614 18:58:25.846009 13783 net.cpp:435] conv3 <- pool2
I0614 18:58:25.846029 13783 net.cpp:409] conv3 -> conv3
I0614 18:58:25.878758 13783 net.cpp:144] Setting up conv3
I0614 18:58:25.878782 13783 net.cpp:151] Top shape: 256 384 13 13 (16613376)
I0614 18:58:25.878791 13783 net.cpp:159] Memory required for data: 1806135296
I0614 18:58:25.878801 13783 layer_factory.hpp:77] Creating layer relu3
I0614 18:58:25.878809 13783 net.cpp:94] Creating Layer relu3
I0614 18:58:25.878815 13783 net.cpp:435] relu3 <- conv3
I0614 18:58:25.878823 13783 net.cpp:409] relu3 -> relu3
I0614 18:58:25.878842 13783 net.cpp:144] Setting up relu3
I0614 18:58:25.878846 13783 net.cpp:151] Top shape: 256 384 13 13 (16613376)
I0614 18:58:25.878852 13783 net.cpp:159] Memory required for data: 1872588800
I0614 18:58:25.878856 13783 layer_factory.hpp:77] Creating layer conv4
I0614 18:58:25.878865 13783 net.cpp:94] Creating Layer conv4
I0614 18:58:25.878868 13783 net.cpp:435] conv4 <- relu3
I0614 18:58:25.878873 13783 net.cpp:409] conv4 -> conv4
I0614 18:58:25.898406 13783 net.cpp:144] Setting up conv4
I0614 18:58:25.898432 13783 net.cpp:151] Top shape: 256 384 13 13 (16613376)
I0614 18:58:25.898442 13783 net.cpp:159] Memory required for data: 1939042304
I0614 18:58:25.898463 13783 layer_factory.hpp:77] Creating layer relu4
I0614 18:58:25.898473 13783 net.cpp:94] Creating Layer relu4
I0614 18:58:25.898478 13783 net.cpp:435] relu4 <- conv4
I0614 18:58:25.898486 13783 net.cpp:409] relu4 -> relu4
I0614 18:58:25.898512 13783 net.cpp:144] Setting up relu4
I0614 18:58:25.898516 13783 net.cpp:151] Top shape: 256 384 13 13 (16613376)
I0614 18:58:25.898523 13783 net.cpp:159] Memory required for data: 2005495808
I0614 18:58:25.898528 13783 layer_factory.hpp:77] Creating layer conv5
I0614 18:58:25.898538 13783 net.cpp:94] Creating Layer conv5
I0614 18:58:25.898543 13783 net.cpp:435] conv5 <- relu4
I0614 18:58:25.898550 13783 net.cpp:409] conv5 -> conv5
I0614 18:58:25.914752 13783 net.cpp:144] Setting up conv5
I0614 18:58:25.914822 13783 net.cpp:151] Top shape: 256 256 13 13 (11075584)
I0614 18:58:25.914835 13783 net.cpp:159] Memory required for data: 2049798144
I0614 18:58:25.914849 13783 layer_factory.hpp:77] Creating layer relu5
I0614 18:58:25.914870 13783 net.cpp:94] Creating Layer relu5
I0614 18:58:25.914878 13783 net.cpp:435] relu5 <- conv5
I0614 18:58:25.914888 13783 net.cpp:409] relu5 -> relu5
I0614 18:58:25.914920 13783 net.cpp:144] Setting up relu5
I0614 18:58:25.914925 13783 net.cpp:151] Top shape: 256 256 13 13 (11075584)
I0614 18:58:25.914932 13783 net.cpp:159] Memory required for data: 2094100480
I0614 18:58:25.914937 13783 layer_factory.hpp:77] Creating layer pool5
I0614 18:58:25.914945 13783 net.cpp:94] Creating Layer pool5
I0614 18:58:25.914950 13783 net.cpp:435] pool5 <- relu5
I0614 18:58:25.914956 13783 net.cpp:409] pool5 -> pool5
I0614 18:58:25.914984 13783 net.cpp:144] Setting up pool5
I0614 18:58:25.914989 13783 net.cpp:151] Top shape: 256 256 6 6 (2359296)
I0614 18:58:25.914996 13783 net.cpp:159] Memory required for data: 2103537664
I0614 18:58:25.915001 13783 layer_factory.hpp:77] Creating layer fc6
I0614 18:58:25.915011 13783 net.cpp:94] Creating Layer fc6
I0614 18:58:25.915016 13783 net.cpp:435] fc6 <- pool5
I0614 18:58:25.915024 13783 net.cpp:409] fc6 -> fc6
I0614 18:58:26.327785 13783 net.cpp:144] Setting up fc6
I0614 18:58:26.327808 13783 net.cpp:151] Top shape: 256 4096 (1048576)
I0614 18:58:26.327817 13783 net.cpp:159] Memory required for data: 2107731968
I0614 18:58:26.327826 13783 layer_factory.hpp:77] Creating layer relu6
I0614 18:58:26.327832 13783 net.cpp:94] Creating Layer relu6
I0614 18:58:26.327836 13783 net.cpp:435] relu6 <- fc6
I0614 18:58:26.327842 13783 net.cpp:409] relu6 -> relu6
I0614 18:58:26.327855 13783 net.cpp:144] Setting up relu6
I0614 18:58:26.327858 13783 net.cpp:151] Top shape: 256 4096 (1048576)
I0614 18:58:26.327862 13783 net.cpp:159] Memory required for data: 2111926272
I0614 18:58:26.327864 13783 layer_factory.hpp:77] Creating layer drop6
I0614 18:58:26.327885 13783 net.cpp:94] Creating Layer drop6
I0614 18:58:26.328259 13783 net.cpp:435] drop6 <- relu6
I0614 18:58:26.328264 13783 net.cpp:409] drop6 -> drop6
I0614 18:58:26.328281 13783 net.cpp:144] Setting up drop6
I0614 18:58:26.328284 13783 net.cpp:151] Top shape: 256 4096 (1048576)
I0614 18:58:26.328289 13783 net.cpp:159] Memory required for data: 2116120576
I0614 18:58:26.328292 13783 layer_factory.hpp:77] Creating layer fc7
I0614 18:58:26.328299 13783 net.cpp:94] Creating Layer fc7
I0614 18:58:26.328303 13783 net.cpp:435] fc7 <- drop6
I0614 18:58:26.328307 13783 net.cpp:409] fc7 -> fc7
I0614 18:58:26.486052 13783 net.cpp:144] Setting up fc7
I0614 18:58:26.486076 13783 net.cpp:151] Top shape: 256 4096 (1048576)
I0614 18:58:26.486084 13783 net.cpp:159] Memory required for data: 2120314880
I0614 18:58:26.486109 13783 layer_factory.hpp:77] Creating layer bn7
I0614 18:58:26.486119 13783 net.cpp:94] Creating Layer bn7
I0614 18:58:26.486122 13783 net.cpp:435] bn7 <- fc7
I0614 18:58:26.486128 13783 net.cpp:409] bn7 -> bn7
I0614 18:58:26.486380 13783 net.cpp:144] Setting up bn7
I0614 18:58:26.486387 13783 net.cpp:151] Top shape: 256 4096 (1048576)
I0614 18:58:26.486390 13783 net.cpp:159] Memory required for data: 2124509184
I0614 18:58:26.486397 13783 layer_factory.hpp:77] Creating layer relu7
I0614 18:58:26.486402 13783 net.cpp:94] Creating Layer relu7
I0614 18:58:26.486420 13783 net.cpp:435] relu7 <- bn7
I0614 18:58:26.486425 13783 net.cpp:409] relu7 -> relu7
I0614 18:58:26.486438 13783 net.cpp:144] Setting up relu7
I0614 18:58:26.486441 13783 net.cpp:151] Top shape: 256 4096 (1048576)
I0614 18:58:26.486445 13783 net.cpp:159] Memory required for data: 2128703488
I0614 18:58:26.486449 13783 layer_factory.hpp:77] Creating layer drop7
I0614 18:58:26.486454 13783 net.cpp:94] Creating Layer drop7
I0614 18:58:26.486457 13783 net.cpp:435] drop7 <- relu7
I0614 18:58:26.486462 13783 net.cpp:409] drop7 -> drop7
I0614 18:58:26.486477 13783 net.cpp:144] Setting up drop7
I0614 18:58:26.486480 13783 net.cpp:151] Top shape: 256 4096 (1048576)
I0614 18:58:26.486485 13783 net.cpp:159] Memory required for data: 2132897792
I0614 18:58:26.486487 13783 layer_factory.hpp:77] Creating layer fc8
I0614 18:58:26.486493 13783 net.cpp:94] Creating Layer fc8
I0614 18:58:26.486497 13783 net.cpp:435] fc8 <- drop7
I0614 18:58:26.486501 13783 net.cpp:409] fc8 -> fc8
I0614 18:58:26.486635 13783 net.cpp:144] Setting up fc8
I0614 18:58:26.486639 13783 net.cpp:151] Top shape: 256 2 (512)
I0614 18:58:26.486644 13783 net.cpp:159] Memory required for data: 2132899840
I0614 18:58:26.486649 13783 layer_factory.hpp:77] Creating layer loss
I0614 18:58:26.486654 13783 net.cpp:94] Creating Layer loss
I0614 18:58:26.486658 13783 net.cpp:435] loss <- fc8
I0614 18:58:26.486662 13783 net.cpp:435] loss <- label
I0614 18:58:26.486667 13783 net.cpp:409] loss -> loss
I0614 18:58:26.486675 13783 layer_factory.hpp:77] Creating layer loss
I0614 18:58:26.486716 13783 net.cpp:144] Setting up loss
I0614 18:58:26.486721 13783 net.cpp:151] Top shape: (1)
I0614 18:58:26.486724 13783 net.cpp:154]     with loss weight 1
I0614 18:58:26.486737 13783 net.cpp:159] Memory required for data: 2132899844
I0614 18:58:26.486740 13783 net.cpp:220] loss needs backward computation.
I0614 18:58:26.486744 13783 net.cpp:220] fc8 needs backward computation.
I0614 18:58:26.486748 13783 net.cpp:220] drop7 needs backward computation.
I0614 18:58:26.486752 13783 net.cpp:220] relu7 needs backward computation.
I0614 18:58:26.486755 13783 net.cpp:220] bn7 needs backward computation.
I0614 18:58:26.486759 13783 net.cpp:220] fc7 needs backward computation.
I0614 18:58:26.486763 13783 net.cpp:220] drop6 needs backward computation.
I0614 18:58:26.486768 13783 net.cpp:220] relu6 needs backward computation.
I0614 18:58:26.486771 13783 net.cpp:220] fc6 needs backward computation.
I0614 18:58:26.486775 13783 net.cpp:220] pool5 needs backward computation.
I0614 18:58:26.486778 13783 net.cpp:220] relu5 needs backward computation.
I0614 18:58:26.486783 13783 net.cpp:220] conv5 needs backward computation.
I0614 18:58:26.486786 13783 net.cpp:220] relu4 needs backward computation.
I0614 18:58:26.487062 13783 net.cpp:220] conv4 needs backward computation.
I0614 18:58:26.487067 13783 net.cpp:220] relu3 needs backward computation.
I0614 18:58:26.487071 13783 net.cpp:220] conv3 needs backward computation.
I0614 18:58:26.487076 13783 net.cpp:220] pool2 needs backward computation.
I0614 18:58:26.487079 13783 net.cpp:220] relu2 needs backward computation.
I0614 18:58:26.487083 13783 net.cpp:220] bn2 needs backward computation.
I0614 18:58:26.487087 13783 net.cpp:220] conv2 needs backward computation.
I0614 18:58:26.487092 13783 net.cpp:220] pool1 needs backward computation.
I0614 18:58:26.487095 13783 net.cpp:220] relu1 needs backward computation.
I0614 18:58:26.487099 13783 net.cpp:220] bn1 needs backward computation.
I0614 18:58:26.487103 13783 net.cpp:220] conv1 needs backward computation.
I0614 18:58:26.487107 13783 net.cpp:222] data does not need backward computation.
I0614 18:58:26.487111 13783 net.cpp:264] This network produces output loss
I0614 18:58:26.487131 13783 net.cpp:284] Network initialization done.
I0614 18:58:26.488091 13783 solver.cpp:189] Creating test net (#0) specified by net file: pruning/alexnetBNnoLRN/regular_rate_0.7/net_finetune.prototxt
I0614 18:58:26.488126 13783 net.cpp:323] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0614 18:58:26.488140 13783 net.cpp:52] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_value: 106
    mean_value: 116
    mean_value: 124
  }
  data_param {
    source: "input/lmdb/valid_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 0
    kernel_size: 8
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "bn1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn2"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "bn2"
  top: "relu2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "relu6"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "drop6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn7"
  type: "BatchNorm"
  bottom: "fc7"
  top: "bn7"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "bn7"
  top: "relu7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "relu7"
  top: "drop7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "drop7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy-top1"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "top-1"
  include {
    phase: TEST
  }
}
I0614 18:58:26.488660 13783 layer_factory.hpp:77] Creating layer data
I0614 18:58:26.488713 13783 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0614 18:58:26.491968 13783 net.cpp:94] Creating Layer data
I0614 18:58:26.492007 13783 net.cpp:409] data -> data
I0614 18:58:26.492034 13783 net.cpp:409] data -> label
I0614 18:58:26.493186 13850 db_lmdb.cpp:35] Opened lmdb input/lmdb/valid_lmdb
I0614 18:58:26.493219 13850 db_lmdb.cpp:38] Items count: 4000
I0614 18:58:26.493259 13850 data_reader.cpp:124] TEST: reading data using 1 channel(s)
I0614 18:58:26.493834 13783 data_layer.cpp:78] ReshapePrefetch 50, 3, 227, 227
I0614 18:58:26.494081 13783 data_layer.cpp:83] output data size: 50,3,227,227
I0614 18:58:26.620275 13783 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0614 18:58:26.620663 13783 net.cpp:144] Setting up data
I0614 18:58:26.620672 13783 net.cpp:151] Top shape: 50 3 227 227 (7729350)
I0614 18:58:26.620680 13783 net.cpp:151] Top shape: 50 (50)
I0614 18:58:26.620684 13783 net.cpp:159] Memory required for data: 30917600
I0614 18:58:26.620688 13783 layer_factory.hpp:77] Creating layer label_data_1_split
I0614 18:58:26.620698 13783 net.cpp:94] Creating Layer label_data_1_split
I0614 18:58:26.620702 13783 net.cpp:435] label_data_1_split <- label
I0614 18:58:26.620723 13783 net.cpp:409] label_data_1_split -> label_data_1_split_0
I0614 18:58:26.620733 13783 net.cpp:409] label_data_1_split -> label_data_1_split_1
I0614 18:58:26.620738 13783 net.cpp:409] label_data_1_split -> label_data_1_split_2
I0614 18:58:26.620784 13783 net.cpp:144] Setting up label_data_1_split
I0614 18:58:26.620788 13783 net.cpp:151] Top shape: 50 (50)
I0614 18:58:26.620792 13783 net.cpp:151] Top shape: 50 (50)
I0614 18:58:26.620796 13783 net.cpp:151] Top shape: 50 (50)
I0614 18:58:26.620800 13783 net.cpp:159] Memory required for data: 30918200
I0614 18:58:26.620803 13783 layer_factory.hpp:77] Creating layer conv1
I0614 18:58:26.620813 13783 net.cpp:94] Creating Layer conv1
I0614 18:58:26.620816 13783 net.cpp:435] conv1 <- data
I0614 18:58:26.620821 13783 net.cpp:409] conv1 -> conv1
I0614 18:58:26.621258 13783 net.cpp:144] Setting up conv1
I0614 18:58:26.621265 13783 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0614 18:58:26.621273 13783 net.cpp:159] Memory required for data: 88998200
I0614 18:58:26.621282 13783 layer_factory.hpp:77] Creating layer bn1
I0614 18:58:26.621289 13783 net.cpp:94] Creating Layer bn1
I0614 18:58:26.621294 13783 net.cpp:435] bn1 <- conv1
I0614 18:58:26.621299 13783 net.cpp:409] bn1 -> bn1
I0614 18:58:26.621673 13783 net.cpp:144] Setting up bn1
I0614 18:58:26.621682 13783 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0614 18:58:26.621688 13783 net.cpp:159] Memory required for data: 147078200
I0614 18:58:26.621698 13783 layer_factory.hpp:77] Creating layer relu1
I0614 18:58:26.621704 13783 net.cpp:94] Creating Layer relu1
I0614 18:58:26.621708 13783 net.cpp:435] relu1 <- bn1
I0614 18:58:26.621713 13783 net.cpp:409] relu1 -> relu1
I0614 18:58:26.621727 13783 net.cpp:144] Setting up relu1
I0614 18:58:26.621731 13783 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0614 18:58:26.621737 13783 net.cpp:159] Memory required for data: 205158200
I0614 18:58:26.621739 13783 layer_factory.hpp:77] Creating layer pool1
I0614 18:58:26.621745 13783 net.cpp:94] Creating Layer pool1
I0614 18:58:26.621749 13783 net.cpp:435] pool1 <- relu1
I0614 18:58:26.621753 13783 net.cpp:409] pool1 -> pool1
I0614 18:58:26.621771 13783 net.cpp:144] Setting up pool1
I0614 18:58:26.621775 13783 net.cpp:151] Top shape: 50 96 27 27 (3499200)
I0614 18:58:26.621780 13783 net.cpp:159] Memory required for data: 219155000
I0614 18:58:26.621783 13783 layer_factory.hpp:77] Creating layer conv2
I0614 18:58:26.621793 13783 net.cpp:94] Creating Layer conv2
I0614 18:58:26.621796 13783 net.cpp:435] conv2 <- pool1
I0614 18:58:26.621801 13783 net.cpp:409] conv2 -> conv2
I0614 18:58:26.628903 13783 net.cpp:144] Setting up conv2
I0614 18:58:26.628919 13783 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0614 18:58:26.628927 13783 net.cpp:159] Memory required for data: 256479800
I0614 18:58:26.628937 13783 layer_factory.hpp:77] Creating layer bn2
I0614 18:58:26.628945 13783 net.cpp:94] Creating Layer bn2
I0614 18:58:26.628949 13783 net.cpp:435] bn2 <- conv2
I0614 18:58:26.628955 13783 net.cpp:409] bn2 -> bn2
I0614 18:58:26.629700 13783 net.cpp:144] Setting up bn2
I0614 18:58:26.629714 13783 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0614 18:58:26.629724 13783 net.cpp:159] Memory required for data: 293804600
I0614 18:58:26.629736 13783 layer_factory.hpp:77] Creating layer relu2
I0614 18:58:26.629743 13783 net.cpp:94] Creating Layer relu2
I0614 18:58:26.629747 13783 net.cpp:435] relu2 <- bn2
I0614 18:58:26.629753 13783 net.cpp:409] relu2 -> relu2
I0614 18:58:26.629781 13783 net.cpp:144] Setting up relu2
I0614 18:58:26.630278 13783 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0614 18:58:26.630307 13783 net.cpp:159] Memory required for data: 331129400
I0614 18:58:26.630321 13783 layer_factory.hpp:77] Creating layer pool2
I0614 18:58:26.630338 13783 net.cpp:94] Creating Layer pool2
I0614 18:58:26.630352 13783 net.cpp:435] pool2 <- relu2
I0614 18:58:26.630369 13783 net.cpp:409] pool2 -> pool2
I0614 18:58:26.630515 13783 net.cpp:144] Setting up pool2
I0614 18:58:26.630534 13783 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0614 18:58:26.630558 13783 net.cpp:159] Memory required for data: 339782200
I0614 18:58:26.630574 13783 layer_factory.hpp:77] Creating layer conv3
I0614 18:58:26.630728 13783 net.cpp:94] Creating Layer conv3
I0614 18:58:26.630751 13783 net.cpp:435] conv3 <- pool2
I0614 18:58:26.630775 13783 net.cpp:409] conv3 -> conv3
I0614 18:58:26.656040 13783 net.cpp:144] Setting up conv3
I0614 18:58:26.656067 13783 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0614 18:58:26.656080 13783 net.cpp:159] Memory required for data: 352761400
I0614 18:58:26.656090 13783 layer_factory.hpp:77] Creating layer relu3
I0614 18:58:26.656102 13783 net.cpp:94] Creating Layer relu3
I0614 18:58:26.656109 13783 net.cpp:435] relu3 <- conv3
I0614 18:58:26.656118 13783 net.cpp:409] relu3 -> relu3
I0614 18:58:26.656142 13783 net.cpp:144] Setting up relu3
I0614 18:58:26.656147 13783 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0614 18:58:26.656154 13783 net.cpp:159] Memory required for data: 365740600
I0614 18:58:26.656159 13783 layer_factory.hpp:77] Creating layer conv4
I0614 18:58:26.656172 13783 net.cpp:94] Creating Layer conv4
I0614 18:58:26.656177 13783 net.cpp:435] conv4 <- relu3
I0614 18:58:26.656185 13783 net.cpp:409] conv4 -> conv4
I0614 18:58:26.674883 13783 net.cpp:144] Setting up conv4
I0614 18:58:26.674908 13783 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0614 18:58:26.674918 13783 net.cpp:159] Memory required for data: 378719800
I0614 18:58:26.674934 13783 layer_factory.hpp:77] Creating layer relu4
I0614 18:58:26.674943 13783 net.cpp:94] Creating Layer relu4
I0614 18:58:26.674949 13783 net.cpp:435] relu4 <- conv4
I0614 18:58:26.674957 13783 net.cpp:409] relu4 -> relu4
I0614 18:58:26.675004 13783 net.cpp:144] Setting up relu4
I0614 18:58:26.675009 13783 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0614 18:58:26.675016 13783 net.cpp:159] Memory required for data: 391699000
I0614 18:58:26.675021 13783 layer_factory.hpp:77] Creating layer conv5
I0614 18:58:26.675033 13783 net.cpp:94] Creating Layer conv5
I0614 18:58:26.675038 13783 net.cpp:435] conv5 <- relu4
I0614 18:58:26.675046 13783 net.cpp:409] conv5 -> conv5
I0614 18:58:26.686796 13783 net.cpp:144] Setting up conv5
I0614 18:58:26.686861 13783 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0614 18:58:26.686873 13783 net.cpp:159] Memory required for data: 400351800
I0614 18:58:26.686885 13783 layer_factory.hpp:77] Creating layer relu5
I0614 18:58:26.686895 13783 net.cpp:94] Creating Layer relu5
I0614 18:58:26.686901 13783 net.cpp:435] relu5 <- conv5
I0614 18:58:26.686939 13783 net.cpp:409] relu5 -> relu5
I0614 18:58:26.686969 13783 net.cpp:144] Setting up relu5
I0614 18:58:26.686975 13783 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0614 18:58:26.686981 13783 net.cpp:159] Memory required for data: 409004600
I0614 18:58:26.686986 13783 layer_factory.hpp:77] Creating layer pool5
I0614 18:58:26.686997 13783 net.cpp:94] Creating Layer pool5
I0614 18:58:26.687002 13783 net.cpp:435] pool5 <- relu5
I0614 18:58:26.687009 13783 net.cpp:409] pool5 -> pool5
I0614 18:58:26.687059 13783 net.cpp:144] Setting up pool5
I0614 18:58:26.687065 13783 net.cpp:151] Top shape: 50 256 6 6 (460800)
I0614 18:58:26.687072 13783 net.cpp:159] Memory required for data: 410847800
I0614 18:58:26.687077 13783 layer_factory.hpp:77] Creating layer fc6
I0614 18:58:26.687086 13783 net.cpp:94] Creating Layer fc6
I0614 18:58:26.687114 13783 net.cpp:435] fc6 <- pool5
I0614 18:58:26.687124 13783 net.cpp:409] fc6 -> fc6
I0614 18:58:27.050818 13783 net.cpp:144] Setting up fc6
I0614 18:58:27.050841 13783 net.cpp:151] Top shape: 50 4096 (204800)
I0614 18:58:27.051246 13783 net.cpp:159] Memory required for data: 411667000
I0614 18:58:27.051255 13783 layer_factory.hpp:77] Creating layer relu6
I0614 18:58:27.051280 13783 net.cpp:94] Creating Layer relu6
I0614 18:58:27.051285 13783 net.cpp:435] relu6 <- fc6
I0614 18:58:27.051292 13783 net.cpp:409] relu6 -> relu6
I0614 18:58:27.051314 13783 net.cpp:144] Setting up relu6
I0614 18:58:27.051317 13783 net.cpp:151] Top shape: 50 4096 (204800)
I0614 18:58:27.051322 13783 net.cpp:159] Memory required for data: 412486200
I0614 18:58:27.051326 13783 layer_factory.hpp:77] Creating layer drop6
I0614 18:58:27.051332 13783 net.cpp:94] Creating Layer drop6
I0614 18:58:27.051335 13783 net.cpp:435] drop6 <- relu6
I0614 18:58:27.051342 13783 net.cpp:409] drop6 -> drop6
I0614 18:58:27.051360 13783 net.cpp:144] Setting up drop6
I0614 18:58:27.051363 13783 net.cpp:151] Top shape: 50 4096 (204800)
I0614 18:58:27.051367 13783 net.cpp:159] Memory required for data: 413305400
I0614 18:58:27.051371 13783 layer_factory.hpp:77] Creating layer fc7
I0614 18:58:27.051378 13783 net.cpp:94] Creating Layer fc7
I0614 18:58:27.051381 13783 net.cpp:435] fc7 <- drop6
I0614 18:58:27.051386 13783 net.cpp:409] fc7 -> fc7
I0614 18:58:27.208436 13783 net.cpp:144] Setting up fc7
I0614 18:58:27.208462 13783 net.cpp:151] Top shape: 50 4096 (204800)
I0614 18:58:27.208470 13783 net.cpp:159] Memory required for data: 414124600
I0614 18:58:27.208479 13783 layer_factory.hpp:77] Creating layer bn7
I0614 18:58:27.208488 13783 net.cpp:94] Creating Layer bn7
I0614 18:58:27.208493 13783 net.cpp:435] bn7 <- fc7
I0614 18:58:27.208500 13783 net.cpp:409] bn7 -> bn7
I0614 18:58:27.208799 13783 net.cpp:144] Setting up bn7
I0614 18:58:27.208806 13783 net.cpp:151] Top shape: 50 4096 (204800)
I0614 18:58:27.208810 13783 net.cpp:159] Memory required for data: 414943800
I0614 18:58:27.208817 13783 layer_factory.hpp:77] Creating layer relu7
I0614 18:58:27.208822 13783 net.cpp:94] Creating Layer relu7
I0614 18:58:27.208825 13783 net.cpp:435] relu7 <- bn7
I0614 18:58:27.208829 13783 net.cpp:409] relu7 -> relu7
I0614 18:58:27.208843 13783 net.cpp:144] Setting up relu7
I0614 18:58:27.208846 13783 net.cpp:151] Top shape: 50 4096 (204800)
I0614 18:58:27.208866 13783 net.cpp:159] Memory required for data: 415763000
I0614 18:58:27.208870 13783 layer_factory.hpp:77] Creating layer drop7
I0614 18:58:27.208875 13783 net.cpp:94] Creating Layer drop7
I0614 18:58:27.208879 13783 net.cpp:435] drop7 <- relu7
I0614 18:58:27.208884 13783 net.cpp:409] drop7 -> drop7
I0614 18:58:27.208900 13783 net.cpp:144] Setting up drop7
I0614 18:58:27.208904 13783 net.cpp:151] Top shape: 50 4096 (204800)
I0614 18:58:27.208909 13783 net.cpp:159] Memory required for data: 416582200
I0614 18:58:27.208911 13783 layer_factory.hpp:77] Creating layer fc8
I0614 18:58:27.208920 13783 net.cpp:94] Creating Layer fc8
I0614 18:58:27.208922 13783 net.cpp:435] fc8 <- drop7
I0614 18:58:27.208927 13783 net.cpp:409] fc8 -> fc8
I0614 18:58:27.209074 13783 net.cpp:144] Setting up fc8
I0614 18:58:27.209077 13783 net.cpp:151] Top shape: 50 2 (100)
I0614 18:58:27.209082 13783 net.cpp:159] Memory required for data: 416582600
I0614 18:58:27.209087 13783 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0614 18:58:27.209093 13783 net.cpp:94] Creating Layer fc8_fc8_0_split
I0614 18:58:27.209097 13783 net.cpp:435] fc8_fc8_0_split <- fc8
I0614 18:58:27.209101 13783 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0614 18:58:27.209108 13783 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0614 18:58:27.209113 13783 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_2
I0614 18:58:27.209136 13783 net.cpp:144] Setting up fc8_fc8_0_split
I0614 18:58:27.209141 13783 net.cpp:151] Top shape: 50 2 (100)
I0614 18:58:27.209144 13783 net.cpp:151] Top shape: 50 2 (100)
I0614 18:58:27.209149 13783 net.cpp:151] Top shape: 50 2 (100)
I0614 18:58:27.209153 13783 net.cpp:159] Memory required for data: 416583800
I0614 18:58:27.209156 13783 layer_factory.hpp:77] Creating layer accuracy
I0614 18:58:27.209163 13783 net.cpp:94] Creating Layer accuracy
I0614 18:58:27.209547 13783 net.cpp:435] accuracy <- fc8_fc8_0_split_0
I0614 18:58:27.209578 13783 net.cpp:435] accuracy <- label_data_1_split_0
I0614 18:58:27.209599 13783 net.cpp:409] accuracy -> accuracy
I0614 18:58:27.209633 13783 net.cpp:144] Setting up accuracy
I0614 18:58:27.209645 13783 net.cpp:151] Top shape: (1)
I0614 18:58:27.209661 13783 net.cpp:159] Memory required for data: 416583804
I0614 18:58:27.209672 13783 layer_factory.hpp:77] Creating layer loss
I0614 18:58:27.209692 13783 net.cpp:94] Creating Layer loss
I0614 18:58:27.209704 13783 net.cpp:435] loss <- fc8_fc8_0_split_1
I0614 18:58:27.209718 13783 net.cpp:435] loss <- label_data_1_split_1
I0614 18:58:27.209743 13783 net.cpp:409] loss -> loss
I0614 18:58:27.209769 13783 layer_factory.hpp:77] Creating layer loss
I0614 18:58:27.209959 13783 net.cpp:144] Setting up loss
I0614 18:58:27.209973 13783 net.cpp:151] Top shape: (1)
I0614 18:58:27.209988 13783 net.cpp:154]     with loss weight 1
I0614 18:58:27.210016 13783 net.cpp:159] Memory required for data: 416583808
I0614 18:58:27.210027 13783 layer_factory.hpp:77] Creating layer accuracy-top1
I0614 18:58:27.210050 13783 net.cpp:94] Creating Layer accuracy-top1
I0614 18:58:27.210063 13783 net.cpp:435] accuracy-top1 <- fc8_fc8_0_split_2
I0614 18:58:27.210078 13783 net.cpp:435] accuracy-top1 <- label_data_1_split_2
I0614 18:58:27.210094 13783 net.cpp:409] accuracy-top1 -> top-1
I0614 18:58:27.210114 13783 net.cpp:144] Setting up accuracy-top1
I0614 18:58:27.210125 13783 net.cpp:151] Top shape: (1)
I0614 18:58:27.210139 13783 net.cpp:159] Memory required for data: 416583812
I0614 18:58:27.210151 13783 net.cpp:222] accuracy-top1 does not need backward computation.
I0614 18:58:27.210165 13783 net.cpp:220] loss needs backward computation.
I0614 18:58:27.210180 13783 net.cpp:222] accuracy does not need backward computation.
I0614 18:58:27.210193 13783 net.cpp:220] fc8_fc8_0_split needs backward computation.
I0614 18:58:27.210206 13783 net.cpp:220] fc8 needs backward computation.
I0614 18:58:27.210219 13783 net.cpp:220] drop7 needs backward computation.
I0614 18:58:27.210232 13783 net.cpp:220] relu7 needs backward computation.
I0614 18:58:27.210243 13783 net.cpp:220] bn7 needs backward computation.
I0614 18:58:27.210255 13783 net.cpp:220] fc7 needs backward computation.
I0614 18:58:27.210268 13783 net.cpp:220] drop6 needs backward computation.
I0614 18:58:27.210281 13783 net.cpp:220] relu6 needs backward computation.
I0614 18:58:27.210294 13783 net.cpp:220] fc6 needs backward computation.
I0614 18:58:27.210305 13783 net.cpp:220] pool5 needs backward computation.
I0614 18:58:27.210317 13783 net.cpp:220] relu5 needs backward computation.
I0614 18:58:27.210330 13783 net.cpp:220] conv5 needs backward computation.
I0614 18:58:27.210343 13783 net.cpp:220] relu4 needs backward computation.
I0614 18:58:27.210355 13783 net.cpp:220] conv4 needs backward computation.
I0614 18:58:27.210368 13783 net.cpp:220] relu3 needs backward computation.
I0614 18:58:27.210381 13783 net.cpp:220] conv3 needs backward computation.
I0614 18:58:27.210393 13783 net.cpp:220] pool2 needs backward computation.
I0614 18:58:27.210413 13783 net.cpp:220] relu2 needs backward computation.
I0614 18:58:27.210426 13783 net.cpp:220] bn2 needs backward computation.
I0614 18:58:27.210438 13783 net.cpp:220] conv2 needs backward computation.
I0614 18:58:27.210451 13783 net.cpp:220] pool1 needs backward computation.
I0614 18:58:27.210464 13783 net.cpp:220] relu1 needs backward computation.
I0614 18:58:27.210475 13783 net.cpp:220] bn1 needs backward computation.
I0614 18:58:27.210489 13783 net.cpp:220] conv1 needs backward computation.
I0614 18:58:27.210503 13783 net.cpp:222] label_data_1_split does not need backward computation.
I0614 18:58:27.210518 13783 net.cpp:222] data does not need backward computation.
I0614 18:58:27.210530 13783 net.cpp:264] This network produces output accuracy
I0614 18:58:27.210542 13783 net.cpp:264] This network produces output loss
I0614 18:58:27.210554 13783 net.cpp:264] This network produces output top-1
I0614 18:58:27.210942 13783 net.cpp:284] Network initialization done.
I0614 18:58:27.211107 13783 solver.cpp:63] Solver scaffolding done.
I0614 18:58:27.213057 13783 caffe_interface.cpp:139] Finetuning from pruning/alexnetBNnoLRN/regular_rate_0.7/sparse.caffemodel
I0614 18:58:29.637634 13783 caffe_interface.cpp:573] Starting Optimization
I0614 18:58:29.637655 13783 solver.cpp:341] Solving 
I0614 18:58:29.637658 13783 solver.cpp:342] Learning Rate Policy: step
I0614 18:58:29.638892 13783 solver.cpp:424] Iteration 0, Testing net (#0)
I0614 18:58:31.106966 13783 solver.cpp:523]     Test net output #0: accuracy = 0.95775
I0614 18:58:31.106995 13783 solver.cpp:523]     Test net output #1: loss = 0.239479 (* 1 = 0.239479 loss)
I0614 18:58:31.107000 13783 solver.cpp:523]     Test net output #2: top-1 = 0.95775
I0614 18:58:31.356684 13783 solver.cpp:270] Iteration 0 (0 iter/s, 1.71893s/50 iter), loss = 0.0288547, remaining 333333 hours and 20 minutes
I0614 18:58:31.356714 13783 solver.cpp:291]     Train net output #0: loss = 0.0288547 (* 1 = 0.0288547 loss)
I0614 18:58:31.356727 13783 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0614 18:58:43.552845 13783 solver.cpp:270] Iteration 50 (4.09982 iter/s, 12.1957s/50 iter), loss = 0.0827821, remaining 0 hours and 48 minutes
I0614 18:58:43.552877 13783 solver.cpp:291]     Train net output #0: loss = 0.0827821 (* 1 = 0.0827821 loss)
I0614 18:58:43.552884 13783 sgd_solver.cpp:106] Iteration 50, lr = 0.001
I0614 18:58:55.791718 13783 solver.cpp:270] Iteration 100 (4.08551 iter/s, 12.2384s/50 iter), loss = 0.128307, remaining 0 hours and 48 minutes
I0614 18:58:55.791980 13783 solver.cpp:291]     Train net output #0: loss = 0.128307 (* 1 = 0.128307 loss)
I0614 18:58:55.792003 13783 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I0614 18:59:08.089658 13783 solver.cpp:270] Iteration 150 (4.06596 iter/s, 12.2972s/50 iter), loss = 0.0481923, remaining 0 hours and 48 minutes
I0614 18:59:08.089690 13783 solver.cpp:291]     Train net output #0: loss = 0.0481923 (* 1 = 0.0481923 loss)
I0614 18:59:08.089699 13783 sgd_solver.cpp:106] Iteration 150, lr = 0.001
I0614 18:59:20.546612 13783 solver.cpp:270] Iteration 200 (4.01398 iter/s, 12.4565s/50 iter), loss = 0.0741521, remaining 0 hours and 48 minutes
I0614 18:59:20.546641 13783 solver.cpp:291]     Train net output #0: loss = 0.0741521 (* 1 = 0.0741521 loss)
I0614 18:59:20.546648 13783 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I0614 18:59:33.106356 13783 solver.cpp:270] Iteration 250 (3.98111 iter/s, 12.5593s/50 iter), loss = 0.11981, remaining 0 hours and 48 minutes
I0614 18:59:33.106637 13783 solver.cpp:291]     Train net output #0: loss = 0.11981 (* 1 = 0.11981 loss)
I0614 18:59:33.106659 13783 sgd_solver.cpp:106] Iteration 250, lr = 0.001
I0614 18:59:45.694411 13783 solver.cpp:270] Iteration 300 (3.97223 iter/s, 12.5874s/50 iter), loss = 0.0666035, remaining 0 hours and 49 minutes
I0614 18:59:45.694445 13783 solver.cpp:291]     Train net output #0: loss = 0.0666035 (* 1 = 0.0666035 loss)
I0614 18:59:45.694468 13783 sgd_solver.cpp:106] Iteration 300, lr = 0.001
I0614 18:59:58.265280 13783 solver.cpp:270] Iteration 350 (3.97759 iter/s, 12.5704s/50 iter), loss = 0.039158, remaining 0 hours and 48 minutes
I0614 18:59:58.265311 13783 solver.cpp:291]     Train net output #0: loss = 0.039158 (* 1 = 0.039158 loss)
I0614 18:59:58.265318 13783 sgd_solver.cpp:106] Iteration 350, lr = 0.001
I0614 19:00:10.857985 13783 solver.cpp:270] Iteration 400 (3.97069 iter/s, 12.5923s/50 iter), loss = 0.0651504, remaining 0 hours and 48 minutes
I0614 19:00:10.858247 13783 solver.cpp:291]     Train net output #0: loss = 0.0651504 (* 1 = 0.0651504 loss)
I0614 19:00:10.858254 13783 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I0614 19:00:23.405073 13783 solver.cpp:270] Iteration 450 (3.9852 iter/s, 12.5464s/50 iter), loss = 0.0544588, remaining 0 hours and 48 minutes
I0614 19:00:23.405103 13783 solver.cpp:291]     Train net output #0: loss = 0.0544588 (* 1 = 0.0544588 loss)
I0614 19:00:23.405110 13783 sgd_solver.cpp:106] Iteration 450, lr = 0.001
I0614 19:00:35.973889 13783 solver.cpp:270] Iteration 500 (3.97824 iter/s, 12.5684s/50 iter), loss = 0.0549145, remaining 0 hours and 48 minutes
I0614 19:00:35.973922 13783 solver.cpp:291]     Train net output #0: loss = 0.0549145 (* 1 = 0.0549145 loss)
I0614 19:00:35.973928 13783 sgd_solver.cpp:106] Iteration 500, lr = 0.001
I0614 19:00:48.545039 13783 solver.cpp:270] Iteration 550 (3.9775 iter/s, 12.5707s/50 iter), loss = 0.0842939, remaining 0 hours and 47 minutes
I0614 19:00:48.545382 13783 solver.cpp:291]     Train net output #0: loss = 0.0842939 (* 1 = 0.0842939 loss)
I0614 19:00:48.545389 13783 sgd_solver.cpp:106] Iteration 550, lr = 0.001
I0614 19:01:01.107256 13783 solver.cpp:270] Iteration 600 (3.98043 iter/s, 12.5615s/50 iter), loss = 0.078846, remaining 0 hours and 47 minutes
I0614 19:01:01.107287 13783 solver.cpp:291]     Train net output #0: loss = 0.078846 (* 1 = 0.078846 loss)
I0614 19:01:01.107311 13783 sgd_solver.cpp:106] Iteration 600, lr = 0.001
I0614 19:01:13.673501 13783 solver.cpp:270] Iteration 650 (3.97905 iter/s, 12.5658s/50 iter), loss = 0.0636222, remaining 0 hours and 47 minutes
I0614 19:01:13.673532 13783 solver.cpp:291]     Train net output #0: loss = 0.0636222 (* 1 = 0.0636222 loss)
I0614 19:01:13.673539 13783 sgd_solver.cpp:106] Iteration 650, lr = 0.001
I0614 19:01:26.224408 13783 solver.cpp:270] Iteration 700 (3.98391 iter/s, 12.5505s/50 iter), loss = 0.0659923, remaining 0 hours and 47 minutes
I0614 19:01:26.224673 13783 solver.cpp:291]     Train net output #0: loss = 0.0659923 (* 1 = 0.0659923 loss)
I0614 19:01:26.224697 13783 sgd_solver.cpp:106] Iteration 700, lr = 0.001
I0614 19:01:38.785243 13783 solver.cpp:270] Iteration 750 (3.98084 iter/s, 12.5602s/50 iter), loss = 0.0939607, remaining 0 hours and 46 minutes
I0614 19:01:38.785276 13783 solver.cpp:291]     Train net output #0: loss = 0.0939607 (* 1 = 0.0939607 loss)
I0614 19:01:38.785284 13783 sgd_solver.cpp:106] Iteration 750, lr = 0.001
I0614 19:01:51.356832 13783 solver.cpp:270] Iteration 800 (3.97736 iter/s, 12.5711s/50 iter), loss = 0.0577255, remaining 0 hours and 46 minutes
I0614 19:01:51.356863 13783 solver.cpp:291]     Train net output #0: loss = 0.0577255 (* 1 = 0.0577255 loss)
I0614 19:01:51.356869 13783 sgd_solver.cpp:106] Iteration 800, lr = 0.001
I0614 19:02:03.937249 13783 solver.cpp:270] Iteration 850 (3.97457 iter/s, 12.58s/50 iter), loss = 0.060061, remaining 0 hours and 46 minutes
I0614 19:02:03.937479 13783 solver.cpp:291]     Train net output #0: loss = 0.060061 (* 1 = 0.060061 loss)
I0614 19:02:03.937485 13783 sgd_solver.cpp:106] Iteration 850, lr = 0.001
I0614 19:02:16.501897 13783 solver.cpp:270] Iteration 900 (3.97962 iter/s, 12.564s/50 iter), loss = 0.0743361, remaining 0 hours and 46 minutes
I0614 19:02:16.501928 13783 solver.cpp:291]     Train net output #0: loss = 0.0743361 (* 1 = 0.0743361 loss)
I0614 19:02:16.501935 13783 sgd_solver.cpp:106] Iteration 900, lr = 0.001
I0614 19:02:29.075373 13783 solver.cpp:270] Iteration 950 (3.97676 iter/s, 12.573s/50 iter), loss = 0.0762729, remaining 0 hours and 46 minutes
I0614 19:02:29.075403 13783 solver.cpp:291]     Train net output #0: loss = 0.0762729 (* 1 = 0.0762729 loss)
I0614 19:02:29.075412 13783 sgd_solver.cpp:106] Iteration 950, lr = 0.001
I0614 19:02:41.393554 13783 solver.cpp:424] Iteration 1000, Testing net (#0)
I0614 19:02:42.853101 13783 solver.cpp:523]     Test net output #0: accuracy = 0.871
I0614 19:02:42.853130 13783 solver.cpp:523]     Test net output #1: loss = 0.399955 (* 1 = 0.399955 loss)
I0614 19:02:42.853134 13783 solver.cpp:523]     Test net output #2: top-1 = 0.871
I0614 19:02:43.099081 13783 solver.cpp:270] Iteration 1000 (3.56551 iter/s, 14.0232s/50 iter), loss = 0.0450886, remaining 0 hours and 51 minutes
I0614 19:02:43.099110 13783 solver.cpp:291]     Train net output #0: loss = 0.0450886 (* 1 = 0.0450886 loss)
I0614 19:02:43.099118 13783 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I0614 19:02:55.650789 13783 solver.cpp:270] Iteration 1050 (3.98366 iter/s, 12.5513s/50 iter), loss = 0.0496722, remaining 0 hours and 45 minutes
I0614 19:02:55.650822 13783 solver.cpp:291]     Train net output #0: loss = 0.0496722 (* 1 = 0.0496722 loss)
I0614 19:02:55.650830 13783 sgd_solver.cpp:106] Iteration 1050, lr = 0.001
I0614 19:03:08.207832 13783 solver.cpp:270] Iteration 1100 (3.98197 iter/s, 12.5566s/50 iter), loss = 0.0741505, remaining 0 hours and 45 minutes
I0614 19:03:08.207863 13783 solver.cpp:291]     Train net output #0: loss = 0.0741505 (* 1 = 0.0741505 loss)
I0614 19:03:08.207871 13783 sgd_solver.cpp:106] Iteration 1100, lr = 0.001
I0614 19:03:20.800323 13783 solver.cpp:270] Iteration 1150 (3.97076 iter/s, 12.5921s/50 iter), loss = 0.0552948, remaining 0 hours and 45 minutes
I0614 19:03:20.800642 13783 solver.cpp:291]     Train net output #0: loss = 0.0552948 (* 1 = 0.0552948 loss)
I0614 19:03:20.800652 13783 sgd_solver.cpp:106] Iteration 1150, lr = 0.001
I0614 19:03:33.373021 13783 solver.cpp:270] Iteration 1200 (3.9771 iter/s, 12.572s/50 iter), loss = 0.0533789, remaining 0 hours and 45 minutes
I0614 19:03:33.373051 13783 solver.cpp:291]     Train net output #0: loss = 0.0533789 (* 1 = 0.0533789 loss)
I0614 19:03:33.373059 13783 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I0614 19:03:45.937388 13783 solver.cpp:270] Iteration 1250 (3.97965 iter/s, 12.5639s/50 iter), loss = 0.0912521, remaining 0 hours and 44 minutes
I0614 19:03:45.937420 13783 solver.cpp:291]     Train net output #0: loss = 0.0912521 (* 1 = 0.0912521 loss)
I0614 19:03:45.937427 13783 sgd_solver.cpp:106] Iteration 1250, lr = 0.001
I0614 19:03:58.524170 13783 solver.cpp:270] Iteration 1300 (3.97256 iter/s, 12.5863s/50 iter), loss = 0.129865, remaining 0 hours and 44 minutes
I0614 19:03:58.524436 13783 solver.cpp:291]     Train net output #0: loss = 0.129865 (* 1 = 0.129865 loss)
I0614 19:03:58.524444 13783 sgd_solver.cpp:106] Iteration 1300, lr = 0.001
I0614 19:04:11.108006 13783 solver.cpp:270] Iteration 1350 (3.97356 iter/s, 12.5832s/50 iter), loss = 0.0903146, remaining 0 hours and 44 minutes
I0614 19:04:11.108038 13783 solver.cpp:291]     Train net output #0: loss = 0.0903146 (* 1 = 0.0903146 loss)
I0614 19:04:11.108047 13783 sgd_solver.cpp:106] Iteration 1350, lr = 0.001
I0614 19:04:23.703189 13783 solver.cpp:270] Iteration 1400 (3.96991 iter/s, 12.5947s/50 iter), loss = 0.0265285, remaining 0 hours and 44 minutes
I0614 19:04:23.703222 13783 solver.cpp:291]     Train net output #0: loss = 0.0265285 (* 1 = 0.0265285 loss)
I0614 19:04:23.703228 13783 sgd_solver.cpp:106] Iteration 1400, lr = 0.001
I0614 19:04:36.286639 13783 solver.cpp:270] Iteration 1450 (3.97361 iter/s, 12.583s/50 iter), loss = 0.0488447, remaining 0 hours and 44 minutes
I0614 19:04:36.286854 13783 solver.cpp:291]     Train net output #0: loss = 0.0488447 (* 1 = 0.0488447 loss)
I0614 19:04:36.286877 13783 sgd_solver.cpp:106] Iteration 1450, lr = 0.001
I0614 19:04:48.884766 13783 solver.cpp:270] Iteration 1500 (3.96904 iter/s, 12.5975s/50 iter), loss = 0.0459525, remaining 0 hours and 44 minutes
I0614 19:04:48.884796 13783 solver.cpp:291]     Train net output #0: loss = 0.0459524 (* 1 = 0.0459524 loss)
I0614 19:04:48.884804 13783 sgd_solver.cpp:106] Iteration 1500, lr = 0.001
I0614 19:05:01.488834 13783 solver.cpp:270] Iteration 1550 (3.96711 iter/s, 12.6036s/50 iter), loss = 0.103609, remaining 0 hours and 43 minutes
I0614 19:05:01.488865 13783 solver.cpp:291]     Train net output #0: loss = 0.103609 (* 1 = 0.103609 loss)
I0614 19:05:01.488873 13783 sgd_solver.cpp:106] Iteration 1550, lr = 0.001
I0614 19:05:14.076130 13783 solver.cpp:270] Iteration 1600 (3.9724 iter/s, 12.5869s/50 iter), loss = 0.0430111, remaining 0 hours and 43 minutes
I0614 19:05:14.076400 13783 solver.cpp:291]     Train net output #0: loss = 0.043011 (* 1 = 0.043011 loss)
I0614 19:05:14.076423 13783 sgd_solver.cpp:106] Iteration 1600, lr = 0.001
I0614 19:05:26.679059 13783 solver.cpp:270] Iteration 1650 (3.96754 iter/s, 12.6023s/50 iter), loss = 0.0537922, remaining 0 hours and 43 minutes
I0614 19:05:26.679091 13783 solver.cpp:291]     Train net output #0: loss = 0.0537921 (* 1 = 0.0537921 loss)
I0614 19:05:26.679098 13783 sgd_solver.cpp:106] Iteration 1650, lr = 0.001
I0614 19:05:39.230944 13783 solver.cpp:270] Iteration 1700 (3.9836 iter/s, 12.5514s/50 iter), loss = 0.0757229, remaining 0 hours and 42 minutes
I0614 19:05:39.230976 13783 solver.cpp:291]     Train net output #0: loss = 0.0757229 (* 1 = 0.0757229 loss)
I0614 19:05:39.230984 13783 sgd_solver.cpp:106] Iteration 1700, lr = 0.001
I0614 19:05:51.795693 13783 solver.cpp:270] Iteration 1750 (3.97953 iter/s, 12.5643s/50 iter), loss = 0.0616463, remaining 0 hours and 42 minutes
I0614 19:05:51.796015 13783 solver.cpp:291]     Train net output #0: loss = 0.0616463 (* 1 = 0.0616463 loss)
I0614 19:05:51.796023 13783 sgd_solver.cpp:106] Iteration 1750, lr = 0.001
I0614 19:06:04.379465 13783 solver.cpp:270] Iteration 1800 (3.9736 iter/s, 12.583s/50 iter), loss = 0.0651878, remaining 0 hours and 42 minutes
I0614 19:06:04.379495 13783 solver.cpp:291]     Train net output #0: loss = 0.0651878 (* 1 = 0.0651878 loss)
I0614 19:06:04.379518 13783 sgd_solver.cpp:106] Iteration 1800, lr = 0.001
I0614 19:06:16.945142 13783 solver.cpp:270] Iteration 1850 (3.97923 iter/s, 12.5652s/50 iter), loss = 0.0770405, remaining 0 hours and 42 minutes
I0614 19:06:16.945173 13783 solver.cpp:291]     Train net output #0: loss = 0.0770405 (* 1 = 0.0770405 loss)
I0614 19:06:16.945196 13783 sgd_solver.cpp:106] Iteration 1850, lr = 0.001
I0614 19:06:29.507333 13783 solver.cpp:270] Iteration 1900 (3.98034 iter/s, 12.5618s/50 iter), loss = 0.0846085, remaining 0 hours and 42 minutes
I0614 19:06:29.507601 13783 solver.cpp:291]     Train net output #0: loss = 0.0846084 (* 1 = 0.0846084 loss)
I0614 19:06:29.507611 13783 sgd_solver.cpp:106] Iteration 1900, lr = 0.001
I0614 19:06:42.065737 13783 solver.cpp:270] Iteration 1950 (3.98161 iter/s, 12.5577s/50 iter), loss = 0.0442852, remaining 0 hours and 41 minutes
I0614 19:06:42.065769 13783 solver.cpp:291]     Train net output #0: loss = 0.0442852 (* 1 = 0.0442852 loss)
I0614 19:06:42.065776 13783 sgd_solver.cpp:106] Iteration 1950, lr = 0.001
I0614 19:06:54.366632 13783 solver.cpp:424] Iteration 2000, Testing net (#0)
I0614 19:06:55.832353 13783 solver.cpp:523]     Test net output #0: accuracy = 0.9265
I0614 19:06:55.832382 13783 solver.cpp:523]     Test net output #1: loss = 0.304776 (* 1 = 0.304776 loss)
I0614 19:06:55.832386 13783 solver.cpp:523]     Test net output #2: top-1 = 0.9265
I0614 19:06:56.078647 13783 solver.cpp:270] Iteration 2000 (3.56826 iter/s, 14.0124s/50 iter), loss = 0.0568509, remaining 0 hours and 46 minutes
I0614 19:06:56.078676 13783 solver.cpp:291]     Train net output #0: loss = 0.0568509 (* 1 = 0.0568509 loss)
I0614 19:06:56.078684 13783 sgd_solver.cpp:106] Iteration 2000, lr = 0.001
I0614 19:07:08.637580 13783 solver.cpp:270] Iteration 2050 (3.98137 iter/s, 12.5585s/50 iter), loss = 0.0530326, remaining 0 hours and 41 minutes
I0614 19:07:08.637853 13783 solver.cpp:291]     Train net output #0: loss = 0.0530325 (* 1 = 0.0530325 loss)
I0614 19:07:08.637862 13783 sgd_solver.cpp:106] Iteration 2050, lr = 0.001
I0614 19:07:21.205320 13783 solver.cpp:270] Iteration 2100 (3.97865 iter/s, 12.5671s/50 iter), loss = 0.0488781, remaining 0 hours and 41 minutes
I0614 19:07:21.205350 13783 solver.cpp:291]     Train net output #0: loss = 0.0488781 (* 1 = 0.0488781 loss)
I0614 19:07:21.205358 13783 sgd_solver.cpp:106] Iteration 2100, lr = 0.001
I0614 19:07:33.765853 13783 solver.cpp:270] Iteration 2150 (3.98086 iter/s, 12.5601s/50 iter), loss = 0.076507, remaining 0 hours and 41 minutes
I0614 19:07:33.765883 13783 solver.cpp:291]     Train net output #0: loss = 0.0765069 (* 1 = 0.0765069 loss)
I0614 19:07:33.765890 13783 sgd_solver.cpp:106] Iteration 2150, lr = 0.001
I0614 19:07:46.323482 13783 solver.cpp:270] Iteration 2200 (3.98178 iter/s, 12.5572s/50 iter), loss = 0.0801245, remaining 0 hours and 40 minutes
I0614 19:07:46.323803 13783 solver.cpp:291]     Train net output #0: loss = 0.0801244 (* 1 = 0.0801244 loss)
I0614 19:07:46.323827 13783 sgd_solver.cpp:106] Iteration 2200, lr = 0.001
I0614 19:07:58.889665 13783 solver.cpp:270] Iteration 2250 (3.97916 iter/s, 12.5655s/50 iter), loss = 0.0455963, remaining 0 hours and 40 minutes
I0614 19:07:58.889694 13783 solver.cpp:291]     Train net output #0: loss = 0.0455963 (* 1 = 0.0455963 loss)
I0614 19:07:58.889701 13783 sgd_solver.cpp:106] Iteration 2250, lr = 0.001
I0614 19:08:11.451758 13783 solver.cpp:270] Iteration 2300 (3.98037 iter/s, 12.5617s/50 iter), loss = 0.0653217, remaining 0 hours and 40 minutes
I0614 19:08:11.451789 13783 solver.cpp:291]     Train net output #0: loss = 0.0653216 (* 1 = 0.0653216 loss)
I0614 19:08:11.451797 13783 sgd_solver.cpp:106] Iteration 2300, lr = 0.001
I0614 19:08:24.012920 13783 solver.cpp:270] Iteration 2350 (3.98066 iter/s, 12.5607s/50 iter), loss = 0.079349, remaining 0 hours and 40 minutes
I0614 19:08:24.013172 13783 solver.cpp:291]     Train net output #0: loss = 0.079349 (* 1 = 0.079349 loss)
I0614 19:08:24.013180 13783 sgd_solver.cpp:106] Iteration 2350, lr = 0.001
I0614 19:08:36.599099 13783 solver.cpp:270] Iteration 2400 (3.97282 iter/s, 12.5855s/50 iter), loss = 0.0738861, remaining 0 hours and 40 minutes
I0614 19:08:36.599130 13783 solver.cpp:291]     Train net output #0: loss = 0.073886 (* 1 = 0.073886 loss)
I0614 19:08:36.599138 13783 sgd_solver.cpp:106] Iteration 2400, lr = 0.001
I0614 19:08:49.189128 13783 solver.cpp:270] Iteration 2450 (3.97153 iter/s, 12.5896s/50 iter), loss = 0.0463919, remaining 0 hours and 40 minutes
I0614 19:08:49.189159 13783 solver.cpp:291]     Train net output #0: loss = 0.0463918 (* 1 = 0.0463918 loss)
I0614 19:08:49.189167 13783 sgd_solver.cpp:106] Iteration 2450, lr = 0.001
I0614 19:09:01.753011 13783 solver.cpp:270] Iteration 2500 (3.9798 iter/s, 12.5634s/50 iter), loss = 0.0975098, remaining 0 hours and 39 minutes
I0614 19:09:01.753273 13783 solver.cpp:291]     Train net output #0: loss = 0.0975098 (* 1 = 0.0975098 loss)
I0614 19:09:01.753280 13783 sgd_solver.cpp:106] Iteration 2500, lr = 0.0001
I0614 19:09:14.314496 13783 solver.cpp:270] Iteration 2550 (3.98063 iter/s, 12.5608s/50 iter), loss = 0.0834387, remaining 0 hours and 39 minutes
I0614 19:09:14.314527 13783 solver.cpp:291]     Train net output #0: loss = 0.0834387 (* 1 = 0.0834387 loss)
I0614 19:09:14.314545 13783 sgd_solver.cpp:106] Iteration 2550, lr = 0.0001
I0614 19:09:26.907790 13783 solver.cpp:270] Iteration 2600 (3.9705 iter/s, 12.5929s/50 iter), loss = 0.0379925, remaining 0 hours and 39 minutes
I0614 19:09:26.907832 13783 solver.cpp:291]     Train net output #0: loss = 0.0379925 (* 1 = 0.0379925 loss)
I0614 19:09:26.907840 13783 sgd_solver.cpp:106] Iteration 2600, lr = 0.0001
I0614 19:09:39.506487 13783 solver.cpp:270] Iteration 2650 (3.96881 iter/s, 12.5982s/50 iter), loss = 0.0229104, remaining 0 hours and 39 minutes
I0614 19:09:39.506683 13783 solver.cpp:291]     Train net output #0: loss = 0.0229104 (* 1 = 0.0229104 loss)
I0614 19:09:39.506691 13783 sgd_solver.cpp:106] Iteration 2650, lr = 0.0001
I0614 19:09:52.095137 13783 solver.cpp:270] Iteration 2700 (3.97202 iter/s, 12.588s/50 iter), loss = 0.031997, remaining 0 hours and 39 minutes
I0614 19:09:52.095171 13783 solver.cpp:291]     Train net output #0: loss = 0.031997 (* 1 = 0.031997 loss)
I0614 19:09:52.095178 13783 sgd_solver.cpp:106] Iteration 2700, lr = 0.0001
I0614 19:10:04.684124 13783 solver.cpp:270] Iteration 2750 (3.97186 iter/s, 12.5885s/50 iter), loss = 0.0456279, remaining 0 hours and 38 minutes
I0614 19:10:04.684156 13783 solver.cpp:291]     Train net output #0: loss = 0.0456278 (* 1 = 0.0456278 loss)
I0614 19:10:04.684165 13783 sgd_solver.cpp:106] Iteration 2750, lr = 0.0001
I0614 19:10:17.261847 13783 solver.cpp:270] Iteration 2800 (3.97542 iter/s, 12.5773s/50 iter), loss = 0.0218226, remaining 0 hours and 38 minutes
I0614 19:10:17.262116 13783 solver.cpp:291]     Train net output #0: loss = 0.0218226 (* 1 = 0.0218226 loss)
I0614 19:10:17.262123 13783 sgd_solver.cpp:106] Iteration 2800, lr = 0.0001
I0614 19:10:29.820034 13783 solver.cpp:270] Iteration 2850 (3.98168 iter/s, 12.5575s/50 iter), loss = 0.0205998, remaining 0 hours and 38 minutes
I0614 19:10:29.820065 13783 solver.cpp:291]     Train net output #0: loss = 0.0205998 (* 1 = 0.0205998 loss)
I0614 19:10:29.820072 13783 sgd_solver.cpp:106] Iteration 2850, lr = 0.0001
I0614 19:10:42.384861 13783 solver.cpp:270] Iteration 2900 (3.9795 iter/s, 12.5644s/50 iter), loss = 0.0123921, remaining 0 hours and 37 minutes
I0614 19:10:42.384892 13783 solver.cpp:291]     Train net output #0: loss = 0.0123921 (* 1 = 0.0123921 loss)
I0614 19:10:42.384917 13783 sgd_solver.cpp:106] Iteration 2900, lr = 0.0001
I0614 19:10:54.990620 13783 solver.cpp:270] Iteration 2950 (3.96658 iter/s, 12.6053s/50 iter), loss = 0.0102236, remaining 0 hours and 37 minutes
I0614 19:10:54.990972 13783 solver.cpp:291]     Train net output #0: loss = 0.0102236 (* 1 = 0.0102236 loss)
I0614 19:10:54.990996 13783 sgd_solver.cpp:106] Iteration 2950, lr = 0.0001
I0614 19:11:07.308984 13783 solver.cpp:424] Iteration 3000, Testing net (#0)
I0614 19:11:08.773043 13783 solver.cpp:523]     Test net output #0: accuracy = 0.9535
I0614 19:11:08.773072 13783 solver.cpp:523]     Test net output #1: loss = 0.11621 (* 1 = 0.11621 loss)
I0614 19:11:08.773077 13783 solver.cpp:523]     Test net output #2: top-1 = 0.9535
I0614 19:11:09.019078 13783 solver.cpp:270] Iteration 3000 (3.56439 iter/s, 14.0277s/50 iter), loss = 0.0305077, remaining 0 hours and 42 minutes
I0614 19:11:09.019109 13783 solver.cpp:291]     Train net output #0: loss = 0.0305077 (* 1 = 0.0305077 loss)
I0614 19:11:09.019116 13783 sgd_solver.cpp:106] Iteration 3000, lr = 0.0001
I0614 19:11:21.598242 13783 solver.cpp:270] Iteration 3050 (3.97496 iter/s, 12.5787s/50 iter), loss = 0.0778147, remaining 0 hours and 37 minutes
I0614 19:11:21.598274 13783 solver.cpp:291]     Train net output #0: loss = 0.0778147 (* 1 = 0.0778147 loss)
I0614 19:11:21.598281 13783 sgd_solver.cpp:106] Iteration 3050, lr = 0.0001
I0614 19:11:34.191908 13783 solver.cpp:270] Iteration 3100 (3.97039 iter/s, 12.5932s/50 iter), loss = 0.016912, remaining 0 hours and 37 minutes
I0614 19:11:34.192186 13783 solver.cpp:291]     Train net output #0: loss = 0.016912 (* 1 = 0.016912 loss)
I0614 19:11:34.192194 13783 sgd_solver.cpp:106] Iteration 3100, lr = 0.0001
I0614 19:11:46.763697 13783 solver.cpp:270] Iteration 3150 (3.97737 iter/s, 12.5711s/50 iter), loss = 0.0673857, remaining 0 hours and 36 minutes
I0614 19:11:46.763728 13783 solver.cpp:291]     Train net output #0: loss = 0.0673856 (* 1 = 0.0673856 loss)
I0614 19:11:46.763736 13783 sgd_solver.cpp:106] Iteration 3150, lr = 0.0001
I0614 19:11:59.301108 13783 solver.cpp:270] Iteration 3200 (3.9882 iter/s, 12.537s/50 iter), loss = 0.014301, remaining 0 hours and 36 minutes
I0614 19:11:59.301138 13783 solver.cpp:291]     Train net output #0: loss = 0.014301 (* 1 = 0.014301 loss)
I0614 19:11:59.301146 13783 sgd_solver.cpp:106] Iteration 3200, lr = 0.0001
I0614 19:12:11.848351 13783 solver.cpp:270] Iteration 3250 (3.98508 iter/s, 12.5468s/50 iter), loss = 0.0318179, remaining 0 hours and 36 minutes
I0614 19:12:11.848619 13783 solver.cpp:291]     Train net output #0: loss = 0.0318179 (* 1 = 0.0318179 loss)
I0614 19:12:11.848644 13783 sgd_solver.cpp:106] Iteration 3250, lr = 0.0001
I0614 19:12:24.424710 13783 solver.cpp:270] Iteration 3300 (3.97593 iter/s, 12.5757s/50 iter), loss = 0.0259557, remaining 0 hours and 36 minutes
I0614 19:12:24.424741 13783 solver.cpp:291]     Train net output #0: loss = 0.0259557 (* 1 = 0.0259557 loss)
I0614 19:12:24.424764 13783 sgd_solver.cpp:106] Iteration 3300, lr = 0.0001
I0614 19:12:37.001680 13783 solver.cpp:270] Iteration 3350 (3.97566 iter/s, 12.5765s/50 iter), loss = 0.015452, remaining 0 hours and 36 minutes
I0614 19:12:37.001713 13783 solver.cpp:291]     Train net output #0: loss = 0.0154519 (* 1 = 0.0154519 loss)
I0614 19:12:37.001720 13783 sgd_solver.cpp:106] Iteration 3350, lr = 0.0001
I0614 19:12:49.565492 13783 solver.cpp:270] Iteration 3400 (3.97982 iter/s, 12.5634s/50 iter), loss = 0.0420885, remaining 0 hours and 35 minutes
I0614 19:12:49.565841 13783 solver.cpp:291]     Train net output #0: loss = 0.0420884 (* 1 = 0.0420884 loss)
I0614 19:12:49.565865 13783 sgd_solver.cpp:106] Iteration 3400, lr = 0.0001
I0614 19:13:02.174333 13783 solver.cpp:270] Iteration 3450 (3.96571 iter/s, 12.6081s/50 iter), loss = 0.0315944, remaining 0 hours and 35 minutes
I0614 19:13:02.174365 13783 solver.cpp:291]     Train net output #0: loss = 0.0315944 (* 1 = 0.0315944 loss)
I0614 19:13:02.174372 13783 sgd_solver.cpp:106] Iteration 3450, lr = 0.0001
I0614 19:13:14.754563 13783 solver.cpp:270] Iteration 3500 (3.97463 iter/s, 12.5798s/50 iter), loss = 0.0356168, remaining 0 hours and 35 minutes
I0614 19:13:14.754595 13783 solver.cpp:291]     Train net output #0: loss = 0.0356168 (* 1 = 0.0356168 loss)
I0614 19:13:14.754601 13783 sgd_solver.cpp:106] Iteration 3500, lr = 0.0001
I0614 19:13:27.339929 13783 solver.cpp:270] Iteration 3550 (3.97301 iter/s, 12.5849s/50 iter), loss = 0.0389233, remaining 0 hours and 35 minutes
I0614 19:13:27.340178 13783 solver.cpp:291]     Train net output #0: loss = 0.0389232 (* 1 = 0.0389232 loss)
I0614 19:13:27.340186 13783 sgd_solver.cpp:106] Iteration 3550, lr = 0.0001
I0614 19:13:39.928814 13783 solver.cpp:270] Iteration 3600 (3.97196 iter/s, 12.5882s/50 iter), loss = 0.01941, remaining 0 hours and 35 minutes
I0614 19:13:39.928846 13783 solver.cpp:291]     Train net output #0: loss = 0.01941 (* 1 = 0.01941 loss)
I0614 19:13:39.928869 13783 sgd_solver.cpp:106] Iteration 3600, lr = 0.0001
I0614 19:13:52.482033 13783 solver.cpp:270] Iteration 3650 (3.98318 iter/s, 12.5528s/50 iter), loss = 0.0119621, remaining 0 hours and 34 minutes
I0614 19:13:52.482065 13783 solver.cpp:291]     Train net output #0: loss = 0.0119621 (* 1 = 0.0119621 loss)
I0614 19:13:52.482072 13783 sgd_solver.cpp:106] Iteration 3650, lr = 0.0001
I0614 19:14:05.077204 13783 solver.cpp:270] Iteration 3700 (3.96991 iter/s, 12.5947s/50 iter), loss = 0.00690619, remaining 0 hours and 34 minutes
I0614 19:14:05.077503 13783 solver.cpp:291]     Train net output #0: loss = 0.00690617 (* 1 = 0.00690617 loss)
I0614 19:14:05.077512 13783 sgd_solver.cpp:106] Iteration 3700, lr = 0.0001
I0614 19:14:17.647013 13783 solver.cpp:270] Iteration 3750 (3.97801 iter/s, 12.5691s/50 iter), loss = 0.0143113, remaining 0 hours and 34 minutes
I0614 19:14:17.647043 13783 solver.cpp:291]     Train net output #0: loss = 0.0143113 (* 1 = 0.0143113 loss)
I0614 19:14:17.647050 13783 sgd_solver.cpp:106] Iteration 3750, lr = 0.0001
I0614 19:14:30.194949 13783 solver.cpp:270] Iteration 3800 (3.98486 iter/s, 12.5475s/50 iter), loss = 0.0314418, remaining 0 hours and 34 minutes
I0614 19:14:30.194980 13783 solver.cpp:291]     Train net output #0: loss = 0.0314417 (* 1 = 0.0314417 loss)
I0614 19:14:30.194988 13783 sgd_solver.cpp:106] Iteration 3800, lr = 0.0001
I0614 19:14:42.763808 13783 solver.cpp:270] Iteration 3850 (3.97822 iter/s, 12.5684s/50 iter), loss = 0.0254394, remaining 0 hours and 33 minutes
I0614 19:14:42.764086 13783 solver.cpp:291]     Train net output #0: loss = 0.0254394 (* 1 = 0.0254394 loss)
I0614 19:14:42.764093 13783 sgd_solver.cpp:106] Iteration 3850, lr = 0.0001
I0614 19:14:55.319182 13783 solver.cpp:270] Iteration 3900 (3.98257 iter/s, 12.5547s/50 iter), loss = 0.00939269, remaining 0 hours and 33 minutes
I0614 19:14:55.319213 13783 solver.cpp:291]     Train net output #0: loss = 0.00939269 (* 1 = 0.00939269 loss)
I0614 19:14:55.319221 13783 sgd_solver.cpp:106] Iteration 3900, lr = 0.0001
I0614 19:15:07.892792 13783 solver.cpp:270] Iteration 3950 (3.97672 iter/s, 12.5732s/50 iter), loss = 0.0106926, remaining 0 hours and 33 minutes
I0614 19:15:07.892822 13783 solver.cpp:291]     Train net output #0: loss = 0.0106926 (* 1 = 0.0106926 loss)
I0614 19:15:07.892830 13783 sgd_solver.cpp:106] Iteration 3950, lr = 0.0001
I0614 19:15:20.198020 13783 solver.cpp:424] Iteration 4000, Testing net (#0)
I0614 19:15:21.684227 13783 solver.cpp:523]     Test net output #0: accuracy = 0.9555
I0614 19:15:21.684255 13783 solver.cpp:523]     Test net output #1: loss = 0.111769 (* 1 = 0.111769 loss)
I0614 19:15:21.684259 13783 solver.cpp:523]     Test net output #2: top-1 = 0.9555
I0614 19:15:21.930467 13783 solver.cpp:270] Iteration 4000 (3.56197 iter/s, 14.0372s/50 iter), loss = 0.00556406, remaining 0 hours and 37 minutes
I0614 19:15:21.930497 13783 solver.cpp:291]     Train net output #0: loss = 0.00556405 (* 1 = 0.00556405 loss)
I0614 19:15:21.930505 13783 sgd_solver.cpp:106] Iteration 4000, lr = 0.0001
I0614 19:15:34.494302 13783 solver.cpp:270] Iteration 4050 (3.97982 iter/s, 12.5634s/50 iter), loss = 0.00959399, remaining 0 hours and 33 minutes
I0614 19:15:34.494334 13783 solver.cpp:291]     Train net output #0: loss = 0.00959399 (* 1 = 0.00959399 loss)
I0614 19:15:34.494341 13783 sgd_solver.cpp:106] Iteration 4050, lr = 0.0001
I0614 19:15:47.073143 13783 solver.cpp:270] Iteration 4100 (3.97507 iter/s, 12.5784s/50 iter), loss = 0.0138821, remaining 0 hours and 32 minutes
I0614 19:15:47.073174 13783 solver.cpp:291]     Train net output #0: loss = 0.0138821 (* 1 = 0.0138821 loss)
I0614 19:15:47.073182 13783 sgd_solver.cpp:106] Iteration 4100, lr = 0.0001
I0614 19:15:59.651021 13783 solver.cpp:270] Iteration 4150 (3.97537 iter/s, 12.5774s/50 iter), loss = 0.028402, remaining 0 hours and 32 minutes
I0614 19:15:59.651340 13783 solver.cpp:291]     Train net output #0: loss = 0.028402 (* 1 = 0.028402 loss)
I0614 19:15:59.651347 13783 sgd_solver.cpp:106] Iteration 4150, lr = 0.0001
I0614 19:16:12.235370 13783 solver.cpp:270] Iteration 4200 (3.97342 iter/s, 12.5836s/50 iter), loss = 0.00860482, remaining 0 hours and 32 minutes
I0614 19:16:12.235400 13783 solver.cpp:291]     Train net output #0: loss = 0.00860482 (* 1 = 0.00860482 loss)
I0614 19:16:12.235407 13783 sgd_solver.cpp:106] Iteration 4200, lr = 0.0001
I0614 19:16:24.796084 13783 solver.cpp:270] Iteration 4250 (3.9808 iter/s, 12.5603s/50 iter), loss = 0.0118196, remaining 0 hours and 32 minutes
I0614 19:16:24.796115 13783 solver.cpp:291]     Train net output #0: loss = 0.0118196 (* 1 = 0.0118196 loss)
I0614 19:16:24.796123 13783 sgd_solver.cpp:106] Iteration 4250, lr = 0.0001
I0614 19:16:37.357579 13783 solver.cpp:270] Iteration 4300 (3.98056 iter/s, 12.5611s/50 iter), loss = 0.0172066, remaining 0 hours and 32 minutes
I0614 19:16:37.357829 13783 solver.cpp:291]     Train net output #0: loss = 0.0172066 (* 1 = 0.0172066 loss)
I0614 19:16:37.357837 13783 sgd_solver.cpp:106] Iteration 4300, lr = 0.0001
I0614 19:16:49.946059 13783 solver.cpp:270] Iteration 4350 (3.97209 iter/s, 12.5878s/50 iter), loss = 0.0266835, remaining 0 hours and 31 minutes
I0614 19:16:49.946090 13783 solver.cpp:291]     Train net output #0: loss = 0.0266835 (* 1 = 0.0266835 loss)
I0614 19:16:49.946097 13783 sgd_solver.cpp:106] Iteration 4350, lr = 0.0001
I0614 19:17:02.514708 13783 solver.cpp:270] Iteration 4400 (3.97829 iter/s, 12.5682s/50 iter), loss = 0.0199924, remaining 0 hours and 31 minutes
I0614 19:17:02.514737 13783 solver.cpp:291]     Train net output #0: loss = 0.0199924 (* 1 = 0.0199924 loss)
I0614 19:17:02.514744 13783 sgd_solver.cpp:106] Iteration 4400, lr = 0.0001
I0614 19:17:15.091667 13783 solver.cpp:270] Iteration 4450 (3.97566 iter/s, 12.5765s/50 iter), loss = 0.00968894, remaining 0 hours and 31 minutes
I0614 19:17:15.091902 13783 solver.cpp:291]     Train net output #0: loss = 0.00968894 (* 1 = 0.00968894 loss)
I0614 19:17:15.091909 13783 sgd_solver.cpp:106] Iteration 4450, lr = 0.0001
I0614 19:17:27.674160 13783 solver.cpp:270] Iteration 4500 (3.97398 iter/s, 12.5819s/50 iter), loss = 0.0110105, remaining 0 hours and 31 minutes
I0614 19:17:27.674191 13783 solver.cpp:291]     Train net output #0: loss = 0.0110105 (* 1 = 0.0110105 loss)
I0614 19:17:27.674199 13783 sgd_solver.cpp:106] Iteration 4500, lr = 0.0001
I0614 19:17:40.256500 13783 solver.cpp:270] Iteration 4550 (3.97396 iter/s, 12.5819s/50 iter), loss = 0.0156045, remaining 0 hours and 31 minutes
I0614 19:17:40.256531 13783 solver.cpp:291]     Train net output #0: loss = 0.0156045 (* 1 = 0.0156045 loss)
I0614 19:17:40.256538 13783 sgd_solver.cpp:106] Iteration 4550, lr = 0.0001
I0614 19:17:52.839015 13783 solver.cpp:270] Iteration 4600 (3.97391 iter/s, 12.5821s/50 iter), loss = 0.00844541, remaining 0 hours and 30 minutes
I0614 19:17:52.839360 13783 solver.cpp:291]     Train net output #0: loss = 0.00844542 (* 1 = 0.00844542 loss)
I0614 19:17:52.839368 13783 sgd_solver.cpp:106] Iteration 4600, lr = 0.0001
I0614 19:18:05.426082 13783 solver.cpp:270] Iteration 4650 (3.97257 iter/s, 12.5863s/50 iter), loss = 0.0231746, remaining 0 hours and 30 minutes
I0614 19:18:05.426113 13783 solver.cpp:291]     Train net output #0: loss = 0.0231746 (* 1 = 0.0231746 loss)
I0614 19:18:05.426120 13783 sgd_solver.cpp:106] Iteration 4650, lr = 0.0001
I0614 19:18:18.004209 13783 solver.cpp:270] Iteration 4700 (3.97529 iter/s, 12.5777s/50 iter), loss = 0.0161537, remaining 0 hours and 30 minutes
I0614 19:18:18.004241 13783 solver.cpp:291]     Train net output #0: loss = 0.0161537 (* 1 = 0.0161537 loss)
I0614 19:18:18.004248 13783 sgd_solver.cpp:106] Iteration 4700, lr = 0.0001
I0614 19:18:30.580992 13783 solver.cpp:270] Iteration 4750 (3.97572 iter/s, 12.5763s/50 iter), loss = 0.0204974, remaining 0 hours and 30 minutes
I0614 19:18:30.581249 13783 solver.cpp:291]     Train net output #0: loss = 0.0204974 (* 1 = 0.0204974 loss)
I0614 19:18:30.581257 13783 sgd_solver.cpp:106] Iteration 4750, lr = 0.0001
I0614 19:18:43.170353 13783 solver.cpp:270] Iteration 4800 (3.97182 iter/s, 12.5887s/50 iter), loss = 0.00829948, remaining 0 hours and 30 minutes
I0614 19:18:43.170383 13783 solver.cpp:291]     Train net output #0: loss = 0.00829948 (* 1 = 0.00829948 loss)
I0614 19:18:43.170392 13783 sgd_solver.cpp:106] Iteration 4800, lr = 0.0001
I0614 19:18:55.738669 13783 solver.cpp:270] Iteration 4850 (3.9784 iter/s, 12.5679s/50 iter), loss = 0.0166561, remaining 0 hours and 29 minutes
I0614 19:18:55.738700 13783 solver.cpp:291]     Train net output #0: loss = 0.0166561 (* 1 = 0.0166561 loss)
I0614 19:18:55.738708 13783 sgd_solver.cpp:106] Iteration 4850, lr = 0.0001
I0614 19:19:08.337496 13783 solver.cpp:270] Iteration 4900 (3.96876 iter/s, 12.5984s/50 iter), loss = 0.00245234, remaining 0 hours and 29 minutes
I0614 19:19:08.337762 13783 solver.cpp:291]     Train net output #0: loss = 0.00245234 (* 1 = 0.00245234 loss)
I0614 19:19:08.337770 13783 sgd_solver.cpp:106] Iteration 4900, lr = 0.0001
I0614 19:19:20.924304 13783 solver.cpp:270] Iteration 4950 (3.97262 iter/s, 12.5861s/50 iter), loss = 0.0184523, remaining 0 hours and 29 minutes
I0614 19:19:20.924335 13783 solver.cpp:291]     Train net output #0: loss = 0.0184523 (* 1 = 0.0184523 loss)
I0614 19:19:20.924340 13783 sgd_solver.cpp:106] Iteration 4950, lr = 0.0001
I0614 19:19:33.249115 13783 solver.cpp:424] Iteration 5000, Testing net (#0)
I0614 19:19:34.754978 13783 solver.cpp:523]     Test net output #0: accuracy = 0.96025
I0614 19:19:34.755005 13783 solver.cpp:523]     Test net output #1: loss = 0.128135 (* 1 = 0.128135 loss)
I0614 19:19:34.755010 13783 solver.cpp:523]     Test net output #2: top-1 = 0.96025
I0614 19:19:35.001264 13783 solver.cpp:270] Iteration 5000 (3.55203 iter/s, 14.0765s/50 iter), loss = 0.0214357, remaining 0 hours and 32 minutes
I0614 19:19:35.001296 13783 solver.cpp:291]     Train net output #0: loss = 0.0214357 (* 1 = 0.0214357 loss)
I0614 19:19:35.001303 13783 sgd_solver.cpp:106] Iteration 5000, lr = 1e-05
I0614 19:19:47.577140 13783 solver.cpp:270] Iteration 5050 (3.976 iter/s, 12.5754s/50 iter), loss = 0.0365492, remaining 0 hours and 28 minutes
I0614 19:19:47.577432 13783 solver.cpp:291]     Train net output #0: loss = 0.0365492 (* 1 = 0.0365492 loss)
I0614 19:19:47.577456 13783 sgd_solver.cpp:106] Iteration 5050, lr = 1e-05
I0614 19:20:00.140754 13783 solver.cpp:270] Iteration 5100 (3.97997 iter/s, 12.5629s/50 iter), loss = 0.0116397, remaining 0 hours and 28 minutes
I0614 19:20:00.140785 13783 solver.cpp:291]     Train net output #0: loss = 0.0116397 (* 1 = 0.0116397 loss)
I0614 19:20:00.140808 13783 sgd_solver.cpp:106] Iteration 5100, lr = 1e-05
I0614 19:20:12.727768 13783 solver.cpp:270] Iteration 5150 (3.97249 iter/s, 12.5866s/50 iter), loss = 0.0103509, remaining 0 hours and 28 minutes
I0614 19:20:12.727799 13783 solver.cpp:291]     Train net output #0: loss = 0.0103509 (* 1 = 0.0103509 loss)
I0614 19:20:12.727807 13783 sgd_solver.cpp:106] Iteration 5150, lr = 1e-05
I0614 19:20:25.303001 13783 solver.cpp:270] Iteration 5200 (3.97621 iter/s, 12.5748s/50 iter), loss = 0.00898715, remaining 0 hours and 28 minutes
I0614 19:20:25.303328 13783 solver.cpp:291]     Train net output #0: loss = 0.00898716 (* 1 = 0.00898716 loss)
I0614 19:20:25.303352 13783 sgd_solver.cpp:106] Iteration 5200, lr = 1e-05
I0614 19:20:37.885727 13783 solver.cpp:270] Iteration 5250 (3.97393 iter/s, 12.582s/50 iter), loss = 0.00209295, remaining 0 hours and 28 minutes
I0614 19:20:37.885759 13783 solver.cpp:291]     Train net output #0: loss = 0.00209296 (* 1 = 0.00209296 loss)
I0614 19:20:37.885766 13783 sgd_solver.cpp:106] Iteration 5250, lr = 1e-05
I0614 19:20:50.434828 13783 solver.cpp:270] Iteration 5300 (3.98449 iter/s, 12.5487s/50 iter), loss = 0.0101464, remaining 0 hours and 27 minutes
I0614 19:20:50.434859 13783 solver.cpp:291]     Train net output #0: loss = 0.0101464 (* 1 = 0.0101464 loss)
I0614 19:20:50.434865 13783 sgd_solver.cpp:106] Iteration 5300, lr = 1e-05
I0614 19:21:03.015450 13783 solver.cpp:270] Iteration 5350 (3.9745 iter/s, 12.5802s/50 iter), loss = 0.00424982, remaining 0 hours and 27 minutes
I0614 19:21:03.015727 13783 solver.cpp:291]     Train net output #0: loss = 0.00424983 (* 1 = 0.00424983 loss)
I0614 19:21:03.015735 13783 sgd_solver.cpp:106] Iteration 5350, lr = 1e-05
I0614 19:21:15.566537 13783 solver.cpp:270] Iteration 5400 (3.98393 iter/s, 12.5504s/50 iter), loss = 0.019788, remaining 0 hours and 27 minutes
I0614 19:21:15.566568 13783 solver.cpp:291]     Train net output #0: loss = 0.019788 (* 1 = 0.019788 loss)
I0614 19:21:15.566576 13783 sgd_solver.cpp:106] Iteration 5400, lr = 1e-05
I0614 19:21:28.130147 13783 solver.cpp:270] Iteration 5450 (3.97989 iter/s, 12.5632s/50 iter), loss = 0.0134762, remaining 0 hours and 27 minutes
I0614 19:21:28.130178 13783 solver.cpp:291]     Train net output #0: loss = 0.0134762 (* 1 = 0.0134762 loss)
I0614 19:21:28.130187 13783 sgd_solver.cpp:106] Iteration 5450, lr = 1e-05
I0614 19:21:40.684779 13783 solver.cpp:270] Iteration 5500 (3.98273 iter/s, 12.5542s/50 iter), loss = 0.020664, remaining 0 hours and 27 minutes
I0614 19:21:40.685004 13783 solver.cpp:291]     Train net output #0: loss = 0.0206641 (* 1 = 0.0206641 loss)
I0614 19:21:40.685012 13783 sgd_solver.cpp:106] Iteration 5500, lr = 1e-05
I0614 19:21:53.273121 13783 solver.cpp:270] Iteration 5550 (3.97213 iter/s, 12.5877s/50 iter), loss = 0.0198708, remaining 0 hours and 26 minutes
I0614 19:21:53.273154 13783 solver.cpp:291]     Train net output #0: loss = 0.0198708 (* 1 = 0.0198708 loss)
I0614 19:21:53.273160 13783 sgd_solver.cpp:106] Iteration 5550, lr = 1e-05
I0614 19:22:05.847503 13783 solver.cpp:270] Iteration 5600 (3.97648 iter/s, 12.5739s/50 iter), loss = 0.0263771, remaining 0 hours and 26 minutes
I0614 19:22:05.847534 13783 solver.cpp:291]     Train net output #0: loss = 0.0263771 (* 1 = 0.0263771 loss)
I0614 19:22:05.847541 13783 sgd_solver.cpp:106] Iteration 5600, lr = 1e-05
I0614 19:22:18.399246 13783 solver.cpp:270] Iteration 5650 (3.98365 iter/s, 12.5513s/50 iter), loss = 0.0126227, remaining 0 hours and 26 minutes
I0614 19:22:18.399515 13783 solver.cpp:291]     Train net output #0: loss = 0.0126227 (* 1 = 0.0126227 loss)
I0614 19:22:18.399538 13783 sgd_solver.cpp:106] Iteration 5650, lr = 1e-05
I0614 19:22:30.956992 13783 solver.cpp:270] Iteration 5700 (3.98182 iter/s, 12.5571s/50 iter), loss = 0.00420635, remaining 0 hours and 26 minutes
I0614 19:22:30.957022 13783 solver.cpp:291]     Train net output #0: loss = 0.00420636 (* 1 = 0.00420636 loss)
I0614 19:22:30.957029 13783 sgd_solver.cpp:106] Iteration 5700, lr = 1e-05
I0614 19:22:43.532287 13783 solver.cpp:270] Iteration 5750 (3.97619 iter/s, 12.5749s/50 iter), loss = 0.0427075, remaining 0 hours and 26 minutes
I0614 19:22:43.532320 13783 solver.cpp:291]     Train net output #0: loss = 0.0427076 (* 1 = 0.0427076 loss)
I0614 19:22:43.532342 13783 sgd_solver.cpp:106] Iteration 5750, lr = 1e-05
I0614 19:22:56.118973 13783 solver.cpp:270] Iteration 5800 (3.97259 iter/s, 12.5862s/50 iter), loss = 0.00873414, remaining 0 hours and 25 minutes
I0614 19:22:56.119278 13783 solver.cpp:291]     Train net output #0: loss = 0.00873416 (* 1 = 0.00873416 loss)
I0614 19:22:56.119302 13783 sgd_solver.cpp:106] Iteration 5800, lr = 1e-05
I0614 19:23:08.702239 13783 solver.cpp:270] Iteration 5850 (3.97376 iter/s, 12.5826s/50 iter), loss = 0.00272682, remaining 0 hours and 25 minutes
I0614 19:23:08.702271 13783 solver.cpp:291]     Train net output #0: loss = 0.00272683 (* 1 = 0.00272683 loss)
I0614 19:23:08.702279 13783 sgd_solver.cpp:106] Iteration 5850, lr = 1e-05
I0614 19:23:21.253437 13783 solver.cpp:270] Iteration 5900 (3.98382 iter/s, 12.5508s/50 iter), loss = 0.000621755, remaining 0 hours and 25 minutes
I0614 19:23:21.253466 13783 solver.cpp:291]     Train net output #0: loss = 0.000621772 (* 1 = 0.000621772 loss)
I0614 19:23:21.253474 13783 sgd_solver.cpp:106] Iteration 5900, lr = 1e-05
I0614 19:23:33.818840 13783 solver.cpp:270] Iteration 5950 (3.97932 iter/s, 12.565s/50 iter), loss = 0.00935577, remaining 0 hours and 25 minutes
I0614 19:23:33.819113 13783 solver.cpp:291]     Train net output #0: loss = 0.00935579 (* 1 = 0.00935579 loss)
I0614 19:23:33.819137 13783 sgd_solver.cpp:106] Iteration 5950, lr = 1e-05
I0614 19:23:46.134137 13783 solver.cpp:935] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.7/snapshots/_iter_6000.caffemodel
I0614 19:23:51.989320 13783 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.7/snapshots/_iter_6000.solverstate
I0614 19:23:55.503440 13783 solver.cpp:424] Iteration 6000, Testing net (#0)
I0614 19:23:56.912540 13783 solver.cpp:523]     Test net output #0: accuracy = 0.96175
I0614 19:23:56.912571 13783 solver.cpp:523]     Test net output #1: loss = 0.14002 (* 1 = 0.14002 loss)
I0614 19:23:56.912576 13783 solver.cpp:523]     Test net output #2: top-1 = 0.96175
I0614 19:23:57.145334 13783 solver.cpp:270] Iteration 6000 (2.14358 iter/s, 23.3255s/50 iter), loss = 0.00384473, remaining 0 hours and 46 minutes
I0614 19:23:57.145364 13783 solver.cpp:291]     Train net output #0: loss = 0.00384475 (* 1 = 0.00384475 loss)
I0614 19:23:57.145372 13783 sgd_solver.cpp:106] Iteration 6000, lr = 1e-05
I0614 19:24:09.458328 13783 solver.cpp:270] Iteration 6050 (4.06089 iter/s, 12.3126s/50 iter), loss = 0.0122863, remaining 0 hours and 24 minutes
I0614 19:24:09.458580 13783 solver.cpp:291]     Train net output #0: loss = 0.0122864 (* 1 = 0.0122864 loss)
I0614 19:24:09.458604 13783 sgd_solver.cpp:106] Iteration 6050, lr = 1e-05
I0614 19:24:21.825165 13783 solver.cpp:270] Iteration 6100 (4.04328 iter/s, 12.3662s/50 iter), loss = 0.000680896, remaining 0 hours and 24 minutes
I0614 19:24:21.825197 13783 solver.cpp:291]     Train net output #0: loss = 0.000680915 (* 1 = 0.000680915 loss)
I0614 19:24:21.825204 13783 sgd_solver.cpp:106] Iteration 6100, lr = 1e-05
I0614 19:24:34.316845 13783 solver.cpp:270] Iteration 6150 (4.0028 iter/s, 12.4912s/50 iter), loss = 0.0127811, remaining 0 hours and 24 minutes
I0614 19:24:34.316874 13783 solver.cpp:291]     Train net output #0: loss = 0.0127811 (* 1 = 0.0127811 loss)
I0614 19:24:34.316882 13783 sgd_solver.cpp:106] Iteration 6150, lr = 1e-05
I0614 19:24:46.825583 13783 solver.cpp:270] Iteration 6200 (3.99734 iter/s, 12.5083s/50 iter), loss = 0.00261522, remaining 0 hours and 24 minutes
I0614 19:24:46.825856 13783 solver.cpp:291]     Train net output #0: loss = 0.00261524 (* 1 = 0.00261524 loss)
I0614 19:24:46.825865 13783 sgd_solver.cpp:106] Iteration 6200, lr = 1e-05
I0614 19:24:59.400739 13783 solver.cpp:270] Iteration 6250 (3.97631 iter/s, 12.5745s/50 iter), loss = 0.00080378, remaining 0 hours and 23 minutes
I0614 19:24:59.400771 13783 solver.cpp:291]     Train net output #0: loss = 0.000803799 (* 1 = 0.000803799 loss)
I0614 19:24:59.400779 13783 sgd_solver.cpp:106] Iteration 6250, lr = 1e-05
I0614 19:25:11.966390 13783 solver.cpp:270] Iteration 6300 (3.97924 iter/s, 12.5652s/50 iter), loss = 0.0124443, remaining 0 hours and 23 minutes
I0614 19:25:11.966421 13783 solver.cpp:291]     Train net output #0: loss = 0.0124443 (* 1 = 0.0124443 loss)
I0614 19:25:11.966429 13783 sgd_solver.cpp:106] Iteration 6300, lr = 1e-05
I0614 19:25:24.547730 13783 solver.cpp:270] Iteration 6350 (3.97428 iter/s, 12.5809s/50 iter), loss = 0.0138356, remaining 0 hours and 23 minutes
I0614 19:25:24.548071 13783 solver.cpp:291]     Train net output #0: loss = 0.0138356 (* 1 = 0.0138356 loss)
I0614 19:25:24.548079 13783 sgd_solver.cpp:106] Iteration 6350, lr = 1e-05
I0614 19:25:37.126497 13783 solver.cpp:270] Iteration 6400 (3.97519 iter/s, 12.578s/50 iter), loss = 0.000311721, remaining 0 hours and 23 minutes
I0614 19:25:37.126528 13783 solver.cpp:291]     Train net output #0: loss = 0.000311735 (* 1 = 0.000311735 loss)
I0614 19:25:37.126551 13783 sgd_solver.cpp:106] Iteration 6400, lr = 1e-05
I0614 19:25:49.704177 13783 solver.cpp:270] Iteration 6450 (3.97543 iter/s, 12.5772s/50 iter), loss = 0.00238775, remaining 0 hours and 23 minutes
I0614 19:25:49.704210 13783 solver.cpp:291]     Train net output #0: loss = 0.00238777 (* 1 = 0.00238777 loss)
I0614 19:25:49.704218 13783 sgd_solver.cpp:106] Iteration 6450, lr = 1e-05
I0614 19:26:02.267374 13783 solver.cpp:270] Iteration 6500 (3.98002 iter/s, 12.5628s/50 iter), loss = 0.00578884, remaining 0 hours and 22 minutes
I0614 19:26:02.267642 13783 solver.cpp:291]     Train net output #0: loss = 0.00578885 (* 1 = 0.00578885 loss)
I0614 19:26:02.267649 13783 sgd_solver.cpp:106] Iteration 6500, lr = 1e-05
I0614 19:26:14.846839 13783 solver.cpp:270] Iteration 6550 (3.97494 iter/s, 12.5788s/50 iter), loss = 0.0215455, remaining 0 hours and 22 minutes
I0614 19:26:14.846871 13783 solver.cpp:291]     Train net output #0: loss = 0.0215455 (* 1 = 0.0215455 loss)
I0614 19:26:14.846879 13783 sgd_solver.cpp:106] Iteration 6550, lr = 1e-05
I0614 19:26:27.426218 13783 solver.cpp:270] Iteration 6600 (3.9749 iter/s, 12.5789s/50 iter), loss = 0.00559046, remaining 0 hours and 22 minutes
I0614 19:26:27.426249 13783 solver.cpp:291]     Train net output #0: loss = 0.00559048 (* 1 = 0.00559048 loss)
I0614 19:26:27.426255 13783 sgd_solver.cpp:106] Iteration 6600, lr = 1e-05
I0614 19:26:39.986672 13783 solver.cpp:270] Iteration 6650 (3.98089 iter/s, 12.56s/50 iter), loss = 0.0018526, remaining 0 hours and 22 minutes
I0614 19:26:39.986923 13783 solver.cpp:291]     Train net output #0: loss = 0.00185262 (* 1 = 0.00185262 loss)
I0614 19:26:39.986932 13783 sgd_solver.cpp:106] Iteration 6650, lr = 1e-05
I0614 19:26:52.567521 13783 solver.cpp:270] Iteration 6700 (3.9745 iter/s, 12.5802s/50 iter), loss = 0.00369629, remaining 0 hours and 22 minutes
I0614 19:26:52.567553 13783 solver.cpp:291]     Train net output #0: loss = 0.00369631 (* 1 = 0.00369631 loss)
I0614 19:26:52.567560 13783 sgd_solver.cpp:106] Iteration 6700, lr = 1e-05
I0614 19:27:05.172737 13783 solver.cpp:270] Iteration 6750 (3.96675 iter/s, 12.6048s/50 iter), loss = 0.00725529, remaining 0 hours and 21 minutes
I0614 19:27:05.172767 13783 solver.cpp:291]     Train net output #0: loss = 0.00725531 (* 1 = 0.00725531 loss)
I0614 19:27:05.172775 13783 sgd_solver.cpp:106] Iteration 6750, lr = 1e-05
I0614 19:27:17.760354 13783 solver.cpp:270] Iteration 6800 (3.9723 iter/s, 12.5872s/50 iter), loss = 0.0151255, remaining 0 hours and 21 minutes
I0614 19:27:17.760591 13783 solver.cpp:291]     Train net output #0: loss = 0.0151255 (* 1 = 0.0151255 loss)
I0614 19:27:17.760614 13783 sgd_solver.cpp:106] Iteration 6800, lr = 1e-05
I0614 19:27:30.340085 13783 solver.cpp:270] Iteration 6850 (3.97485 iter/s, 12.5791s/50 iter), loss = 0.00184358, remaining 0 hours and 21 minutes
I0614 19:27:30.340114 13783 solver.cpp:291]     Train net output #0: loss = 0.0018436 (* 1 = 0.0018436 loss)
I0614 19:27:30.340121 13783 sgd_solver.cpp:106] Iteration 6850, lr = 1e-05
I0614 19:27:42.930552 13783 solver.cpp:270] Iteration 6900 (3.9714 iter/s, 12.59s/50 iter), loss = 0.00554818, remaining 0 hours and 21 minutes
I0614 19:27:42.930584 13783 solver.cpp:291]     Train net output #0: loss = 0.0055482 (* 1 = 0.0055482 loss)
I0614 19:27:42.930593 13783 sgd_solver.cpp:106] Iteration 6900, lr = 1e-05
I0614 19:27:55.481941 13783 solver.cpp:270] Iteration 6950 (3.98376 iter/s, 12.551s/50 iter), loss = 0.00408363, remaining 0 hours and 21 minutes
I0614 19:27:55.482225 13783 solver.cpp:291]     Train net output #0: loss = 0.00408365 (* 1 = 0.00408365 loss)
I0614 19:27:55.482249 13783 sgd_solver.cpp:106] Iteration 6950, lr = 1e-05
I0614 19:28:07.828820 13783 solver.cpp:424] Iteration 7000, Testing net (#0)
I0614 19:28:09.284940 13783 solver.cpp:523]     Test net output #0: accuracy = 0.96025
I0614 19:28:09.284969 13783 solver.cpp:523]     Test net output #1: loss = 0.159227 (* 1 = 0.159227 loss)
I0614 19:28:09.284973 13783 solver.cpp:523]     Test net output #2: top-1 = 0.96025
I0614 19:28:09.531098 13783 solver.cpp:270] Iteration 7000 (3.55912 iter/s, 14.0484s/50 iter), loss = 0.0133403, remaining 0 hours and 23 minutes
I0614 19:28:09.531128 13783 solver.cpp:291]     Train net output #0: loss = 0.0133403 (* 1 = 0.0133403 loss)
I0614 19:28:09.531136 13783 sgd_solver.cpp:106] Iteration 7000, lr = 1e-05
I0614 19:28:22.078191 13783 solver.cpp:270] Iteration 7050 (3.98512 iter/s, 12.5467s/50 iter), loss = 0.0132553, remaining 0 hours and 20 minutes
I0614 19:28:22.078224 13783 solver.cpp:291]     Train net output #0: loss = 0.0132553 (* 1 = 0.0132553 loss)
I0614 19:28:22.078233 13783 sgd_solver.cpp:106] Iteration 7050, lr = 1e-05
I0614 19:28:34.640107 13783 solver.cpp:270] Iteration 7100 (3.98042 iter/s, 12.5615s/50 iter), loss = 0.00102062, remaining 0 hours and 20 minutes
I0614 19:28:34.640237 13783 solver.cpp:291]     Train net output #0: loss = 0.00102064 (* 1 = 0.00102064 loss)
I0614 19:28:34.640246 13783 sgd_solver.cpp:106] Iteration 7100, lr = 1e-05
I0614 19:28:47.198413 13783 solver.cpp:270] Iteration 7150 (3.9816 iter/s, 12.5578s/50 iter), loss = 0.030608, remaining 0 hours and 20 minutes
I0614 19:28:47.198446 13783 solver.cpp:291]     Train net output #0: loss = 0.030608 (* 1 = 0.030608 loss)
I0614 19:28:47.198452 13783 sgd_solver.cpp:106] Iteration 7150, lr = 1e-05
I0614 19:28:59.765492 13783 solver.cpp:270] Iteration 7200 (3.97879 iter/s, 12.5666s/50 iter), loss = 0.0138538, remaining 0 hours and 20 minutes
I0614 19:28:59.765522 13783 solver.cpp:291]     Train net output #0: loss = 0.0138538 (* 1 = 0.0138538 loss)
I0614 19:28:59.765530 13783 sgd_solver.cpp:106] Iteration 7200, lr = 1e-05
I0614 19:29:12.362375 13783 solver.cpp:270] Iteration 7250 (3.96937 iter/s, 12.5964s/50 iter), loss = 0.00734829, remaining 0 hours and 19 minutes
I0614 19:29:12.362643 13783 solver.cpp:291]     Train net output #0: loss = 0.00734829 (* 1 = 0.00734829 loss)
I0614 19:29:12.362668 13783 sgd_solver.cpp:106] Iteration 7250, lr = 1e-05
I0614 19:29:24.912328 13783 solver.cpp:270] Iteration 7300 (3.98429 iter/s, 12.5493s/50 iter), loss = 0.00108879, remaining 0 hours and 19 minutes
I0614 19:29:24.912358 13783 solver.cpp:291]     Train net output #0: loss = 0.0010888 (* 1 = 0.0010888 loss)
I0614 19:29:24.912381 13783 sgd_solver.cpp:106] Iteration 7300, lr = 1e-05
I0614 19:29:37.503450 13783 solver.cpp:270] Iteration 7350 (3.97119 iter/s, 12.5907s/50 iter), loss = 0.0263327, remaining 0 hours and 19 minutes
I0614 19:29:37.503480 13783 solver.cpp:291]     Train net output #0: loss = 0.0263327 (* 1 = 0.0263327 loss)
I0614 19:29:37.503490 13783 sgd_solver.cpp:106] Iteration 7350, lr = 1e-05
I0614 19:29:50.066296 13783 solver.cpp:270] Iteration 7400 (3.98013 iter/s, 12.5624s/50 iter), loss = 0.00801352, remaining 0 hours and 19 minutes
I0614 19:29:50.066561 13783 solver.cpp:291]     Train net output #0: loss = 0.00801352 (* 1 = 0.00801352 loss)
I0614 19:29:50.066570 13783 sgd_solver.cpp:106] Iteration 7400, lr = 1e-05
I0614 19:30:02.627055 13783 solver.cpp:270] Iteration 7450 (3.98086 iter/s, 12.5601s/50 iter), loss = 0.00660824, remaining 0 hours and 18 minutes
I0614 19:30:02.627086 13783 solver.cpp:291]     Train net output #0: loss = 0.00660824 (* 1 = 0.00660824 loss)
I0614 19:30:02.627094 13783 sgd_solver.cpp:106] Iteration 7450, lr = 1e-05
I0614 19:30:15.197695 13783 solver.cpp:270] Iteration 7500 (3.97766 iter/s, 12.5702s/50 iter), loss = 0.0137919, remaining 0 hours and 18 minutes
I0614 19:30:15.197726 13783 solver.cpp:291]     Train net output #0: loss = 0.0137919 (* 1 = 0.0137919 loss)
I0614 19:30:15.197750 13783 sgd_solver.cpp:106] Iteration 7500, lr = 1e-06
I0614 19:30:27.752296 13783 solver.cpp:270] Iteration 7550 (3.98274 iter/s, 12.5542s/50 iter), loss = 0.00407725, remaining 0 hours and 18 minutes
I0614 19:30:27.752643 13783 solver.cpp:291]     Train net output #0: loss = 0.00407725 (* 1 = 0.00407725 loss)
I0614 19:30:27.752652 13783 sgd_solver.cpp:106] Iteration 7550, lr = 1e-06
I0614 19:30:40.337282 13783 solver.cpp:270] Iteration 7600 (3.97323 iter/s, 12.5842s/50 iter), loss = 0.00261582, remaining 0 hours and 18 minutes
I0614 19:30:40.337312 13783 solver.cpp:291]     Train net output #0: loss = 0.00261582 (* 1 = 0.00261582 loss)
I0614 19:30:40.337319 13783 sgd_solver.cpp:106] Iteration 7600, lr = 1e-06
I0614 19:30:52.905474 13783 solver.cpp:270] Iteration 7650 (3.97843 iter/s, 12.5678s/50 iter), loss = 0.00397584, remaining 0 hours and 18 minutes
I0614 19:30:52.905508 13783 solver.cpp:291]     Train net output #0: loss = 0.00397584 (* 1 = 0.00397584 loss)
I0614 19:30:52.905515 13783 sgd_solver.cpp:106] Iteration 7650, lr = 1e-06
I0614 19:31:05.474741 13783 solver.cpp:270] Iteration 7700 (3.9781 iter/s, 12.5688s/50 iter), loss = 0.0100226, remaining 0 hours and 17 minutes
I0614 19:31:05.474972 13783 solver.cpp:291]     Train net output #0: loss = 0.0100226 (* 1 = 0.0100226 loss)
I0614 19:31:05.474995 13783 sgd_solver.cpp:106] Iteration 7700, lr = 1e-06
I0614 19:31:18.062537 13783 solver.cpp:270] Iteration 7750 (3.9723 iter/s, 12.5872s/50 iter), loss = 0.00321328, remaining 0 hours and 17 minutes
I0614 19:31:18.062568 13783 solver.cpp:291]     Train net output #0: loss = 0.00321329 (* 1 = 0.00321329 loss)
I0614 19:31:18.062577 13783 sgd_solver.cpp:106] Iteration 7750, lr = 1e-06
I0614 19:31:30.647692 13783 solver.cpp:270] Iteration 7800 (3.97307 iter/s, 12.5847s/50 iter), loss = 0.00172935, remaining 0 hours and 17 minutes
I0614 19:31:30.647724 13783 solver.cpp:291]     Train net output #0: loss = 0.00172936 (* 1 = 0.00172936 loss)
I0614 19:31:30.647732 13783 sgd_solver.cpp:106] Iteration 7800, lr = 1e-06
I0614 19:31:43.242511 13783 solver.cpp:270] Iteration 7850 (3.97003 iter/s, 12.5944s/50 iter), loss = 0.0261215, remaining 0 hours and 17 minutes
I0614 19:31:43.242776 13783 solver.cpp:291]     Train net output #0: loss = 0.0261215 (* 1 = 0.0261215 loss)
I0614 19:31:43.242802 13783 sgd_solver.cpp:106] Iteration 7850, lr = 1e-06
I0614 19:31:55.797493 13783 solver.cpp:270] Iteration 7900 (3.9827 iter/s, 12.5543s/50 iter), loss = 0.00128614, remaining 0 hours and 17 minutes
I0614 19:31:55.797526 13783 solver.cpp:291]     Train net output #0: loss = 0.00128615 (* 1 = 0.00128615 loss)
I0614 19:31:55.797550 13783 sgd_solver.cpp:106] Iteration 7900, lr = 1e-06
I0614 19:32:08.345808 13783 solver.cpp:270] Iteration 7950 (3.98474 iter/s, 12.5479s/50 iter), loss = 0.00583399, remaining 0 hours and 16 minutes
I0614 19:32:08.345839 13783 solver.cpp:291]     Train net output #0: loss = 0.005834 (* 1 = 0.005834 loss)
I0614 19:32:08.345847 13783 sgd_solver.cpp:106] Iteration 7950, lr = 1e-06
I0614 19:32:20.651046 13783 solver.cpp:424] Iteration 8000, Testing net (#0)
I0614 19:32:22.155333 13783 solver.cpp:523]     Test net output #0: accuracy = 0.961
I0614 19:32:22.155360 13783 solver.cpp:523]     Test net output #1: loss = 0.179762 (* 1 = 0.179762 loss)
I0614 19:32:22.155364 13783 solver.cpp:523]     Test net output #2: top-1 = 0.961
I0614 19:32:22.401243 13783 solver.cpp:270] Iteration 8000 (3.55747 iter/s, 14.055s/50 iter), loss = 0.00350539, remaining 0 hours and 18 minutes
I0614 19:32:22.401273 13783 solver.cpp:291]     Train net output #0: loss = 0.0035054 (* 1 = 0.0035054 loss)
I0614 19:32:22.401283 13783 sgd_solver.cpp:106] Iteration 8000, lr = 1e-06
I0614 19:32:34.964702 13783 solver.cpp:270] Iteration 8050 (3.97993 iter/s, 12.563s/50 iter), loss = 0.0143638, remaining 0 hours and 16 minutes
I0614 19:32:34.964735 13783 solver.cpp:291]     Train net output #0: loss = 0.0143638 (* 1 = 0.0143638 loss)
I0614 19:32:34.964757 13783 sgd_solver.cpp:106] Iteration 8050, lr = 1e-06
I0614 19:32:47.533182 13783 solver.cpp:270] Iteration 8100 (3.97834 iter/s, 12.568s/50 iter), loss = 0.0064469, remaining 0 hours and 16 minutes
I0614 19:32:47.533212 13783 solver.cpp:291]     Train net output #0: loss = 0.00644691 (* 1 = 0.00644691 loss)
I0614 19:32:47.533221 13783 sgd_solver.cpp:106] Iteration 8100, lr = 1e-06
I0614 19:33:00.120695 13783 solver.cpp:270] Iteration 8150 (3.97233 iter/s, 12.5871s/50 iter), loss = 0.00943444, remaining 0 hours and 16 minutes
I0614 19:33:00.121043 13783 solver.cpp:291]     Train net output #0: loss = 0.00943445 (* 1 = 0.00943445 loss)
I0614 19:33:00.121068 13783 sgd_solver.cpp:106] Iteration 8150, lr = 1e-06
I0614 19:33:12.669517 13783 solver.cpp:270] Iteration 8200 (3.98468 iter/s, 12.5481s/50 iter), loss = 0.00150304, remaining 0 hours and 15 minutes
I0614 19:33:12.669548 13783 solver.cpp:291]     Train net output #0: loss = 0.00150305 (* 1 = 0.00150305 loss)
I0614 19:33:12.669556 13783 sgd_solver.cpp:106] Iteration 8200, lr = 1e-06
I0614 19:33:25.248651 13783 solver.cpp:270] Iteration 8250 (3.97497 iter/s, 12.5787s/50 iter), loss = 0.00411872, remaining 0 hours and 15 minutes
I0614 19:33:25.248682 13783 solver.cpp:291]     Train net output #0: loss = 0.00411873 (* 1 = 0.00411873 loss)
I0614 19:33:25.248690 13783 sgd_solver.cpp:106] Iteration 8250, lr = 1e-06
I0614 19:33:37.826714 13783 solver.cpp:270] Iteration 8300 (3.97531 iter/s, 12.5776s/50 iter), loss = 0.00287273, remaining 0 hours and 15 minutes
I0614 19:33:37.826962 13783 solver.cpp:291]     Train net output #0: loss = 0.00287273 (* 1 = 0.00287273 loss)
I0614 19:33:37.826972 13783 sgd_solver.cpp:106] Iteration 8300, lr = 1e-06
I0614 19:33:50.397329 13783 solver.cpp:270] Iteration 8350 (3.97774 iter/s, 12.57s/50 iter), loss = 0.0136176, remaining 0 hours and 15 minutes
I0614 19:33:50.397361 13783 solver.cpp:291]     Train net output #0: loss = 0.0136176 (* 1 = 0.0136176 loss)
I0614 19:33:50.397369 13783 sgd_solver.cpp:106] Iteration 8350, lr = 1e-06
I0614 19:34:02.976593 13783 solver.cpp:270] Iteration 8400 (3.97493 iter/s, 12.5788s/50 iter), loss = 0.00715247, remaining 0 hours and 15 minutes
I0614 19:34:02.976624 13783 solver.cpp:291]     Train net output #0: loss = 0.00715247 (* 1 = 0.00715247 loss)
I0614 19:34:02.976632 13783 sgd_solver.cpp:106] Iteration 8400, lr = 1e-06
I0614 19:34:15.567236 13783 solver.cpp:270] Iteration 8450 (3.97134 iter/s, 12.5902s/50 iter), loss = 0.00231572, remaining 0 hours and 14 minutes
I0614 19:34:15.567502 13783 solver.cpp:291]     Train net output #0: loss = 0.00231572 (* 1 = 0.00231572 loss)
I0614 19:34:15.567512 13783 sgd_solver.cpp:106] Iteration 8450, lr = 1e-06
I0614 19:34:28.129647 13783 solver.cpp:270] Iteration 8500 (3.98034 iter/s, 12.5617s/50 iter), loss = 0.00134747, remaining 0 hours and 14 minutes
I0614 19:34:28.129679 13783 solver.cpp:291]     Train net output #0: loss = 0.00134748 (* 1 = 0.00134748 loss)
I0614 19:34:28.129688 13783 sgd_solver.cpp:106] Iteration 8500, lr = 1e-06
I0614 19:34:40.703436 13783 solver.cpp:270] Iteration 8550 (3.97666 iter/s, 12.5734s/50 iter), loss = 0.0119407, remaining 0 hours and 14 minutes
I0614 19:34:40.703467 13783 solver.cpp:291]     Train net output #0: loss = 0.0119407 (* 1 = 0.0119407 loss)
I0614 19:34:40.703491 13783 sgd_solver.cpp:106] Iteration 8550, lr = 1e-06
I0614 19:34:53.280933 13783 solver.cpp:270] Iteration 8600 (3.97549 iter/s, 12.5771s/50 iter), loss = 0.00140593, remaining 0 hours and 14 minutes
I0614 19:34:53.281224 13783 solver.cpp:291]     Train net output #0: loss = 0.00140594 (* 1 = 0.00140594 loss)
I0614 19:34:53.281232 13783 sgd_solver.cpp:106] Iteration 8600, lr = 1e-06
I0614 19:35:05.867821 13783 solver.cpp:270] Iteration 8650 (3.97261 iter/s, 12.5862s/50 iter), loss = 0.000450421, remaining 0 hours and 13 minutes
I0614 19:35:05.867853 13783 solver.cpp:291]     Train net output #0: loss = 0.000450436 (* 1 = 0.000450436 loss)
I0614 19:35:05.867877 13783 sgd_solver.cpp:106] Iteration 8650, lr = 1e-06
I0614 19:35:18.464898 13783 solver.cpp:270] Iteration 8700 (3.96931 iter/s, 12.5966s/50 iter), loss = 0.0131946, remaining 0 hours and 13 minutes
I0614 19:35:18.464928 13783 solver.cpp:291]     Train net output #0: loss = 0.0131946 (* 1 = 0.0131946 loss)
I0614 19:35:18.464952 13783 sgd_solver.cpp:106] Iteration 8700, lr = 1e-06
I0614 19:35:31.042896 13783 solver.cpp:270] Iteration 8750 (3.97533 iter/s, 12.5776s/50 iter), loss = 0.0233781, remaining 0 hours and 13 minutes
I0614 19:35:31.043185 13783 solver.cpp:291]     Train net output #0: loss = 0.0233782 (* 1 = 0.0233782 loss)
I0614 19:35:31.043210 13783 sgd_solver.cpp:106] Iteration 8750, lr = 1e-06
I0614 19:35:43.585352 13783 solver.cpp:270] Iteration 8800 (3.98668 iter/s, 12.5418s/50 iter), loss = 0.0033025, remaining 0 hours and 13 minutes
I0614 19:35:43.585383 13783 solver.cpp:291]     Train net output #0: loss = 0.00330251 (* 1 = 0.00330251 loss)
I0614 19:35:43.585391 13783 sgd_solver.cpp:106] Iteration 8800, lr = 1e-06
I0614 19:35:56.156216 13783 solver.cpp:270] Iteration 8850 (3.97759 iter/s, 12.5704s/50 iter), loss = 0.00566654, remaining 0 hours and 13 minutes
I0614 19:35:56.156246 13783 solver.cpp:291]     Train net output #0: loss = 0.00566655 (* 1 = 0.00566655 loss)
I0614 19:35:56.156255 13783 sgd_solver.cpp:106] Iteration 8850, lr = 1e-06
I0614 19:36:08.717510 13783 solver.cpp:270] Iteration 8900 (3.98062 iter/s, 12.5609s/50 iter), loss = 0.00511854, remaining 0 hours and 12 minutes
I0614 19:36:08.717782 13783 solver.cpp:291]     Train net output #0: loss = 0.00511856 (* 1 = 0.00511856 loss)
I0614 19:36:08.717808 13783 sgd_solver.cpp:106] Iteration 8900, lr = 1e-06
I0614 19:36:21.275555 13783 solver.cpp:270] Iteration 8950 (3.98173 iter/s, 12.5574s/50 iter), loss = 0.00556404, remaining 0 hours and 12 minutes
I0614 19:36:21.275586 13783 solver.cpp:291]     Train net output #0: loss = 0.00556406 (* 1 = 0.00556406 loss)
I0614 19:36:21.275594 13783 sgd_solver.cpp:106] Iteration 8950, lr = 1e-06
I0614 19:36:33.579407 13783 solver.cpp:424] Iteration 9000, Testing net (#0)
I0614 19:36:35.084235 13783 solver.cpp:523]     Test net output #0: accuracy = 0.96
I0614 19:36:35.084264 13783 solver.cpp:523]     Test net output #1: loss = 0.195031 (* 1 = 0.195031 loss)
I0614 19:36:35.084270 13783 solver.cpp:523]     Test net output #2: top-1 = 0.96
I0614 19:36:35.330407 13783 solver.cpp:270] Iteration 9000 (3.55761 iter/s, 14.0544s/50 iter), loss = 0.0328044, remaining 0 hours and 14 minutes
I0614 19:36:35.330439 13783 solver.cpp:291]     Train net output #0: loss = 0.0328044 (* 1 = 0.0328044 loss)
I0614 19:36:35.330463 13783 sgd_solver.cpp:106] Iteration 9000, lr = 1e-06
I0614 19:36:47.900650 13783 solver.cpp:270] Iteration 9050 (3.97779 iter/s, 12.5698s/50 iter), loss = 0.00295208, remaining 0 hours and 12 minutes
I0614 19:36:47.900897 13783 solver.cpp:291]     Train net output #0: loss = 0.0029521 (* 1 = 0.0029521 loss)
I0614 19:36:47.900907 13783 sgd_solver.cpp:106] Iteration 9050, lr = 1e-06
I0614 19:37:00.475092 13783 solver.cpp:270] Iteration 9100 (3.97653 iter/s, 12.5738s/50 iter), loss = 0.00236777, remaining 0 hours and 12 minutes
I0614 19:37:00.475126 13783 solver.cpp:291]     Train net output #0: loss = 0.00236779 (* 1 = 0.00236779 loss)
I0614 19:37:00.475134 13783 sgd_solver.cpp:106] Iteration 9100, lr = 1e-06
I0614 19:37:13.040355 13783 solver.cpp:270] Iteration 9150 (3.97936 iter/s, 12.5648s/50 iter), loss = 0.00830539, remaining 0 hours and 11 minutes
I0614 19:37:13.040386 13783 solver.cpp:291]     Train net output #0: loss = 0.00830541 (* 1 = 0.00830541 loss)
I0614 19:37:13.040393 13783 sgd_solver.cpp:106] Iteration 9150, lr = 1e-06
I0614 19:37:25.619717 13783 solver.cpp:270] Iteration 9200 (3.9749 iter/s, 12.5789s/50 iter), loss = 0.00116417, remaining 0 hours and 11 minutes
I0614 19:37:25.620071 13783 solver.cpp:291]     Train net output #0: loss = 0.00116419 (* 1 = 0.00116419 loss)
I0614 19:37:25.620096 13783 sgd_solver.cpp:106] Iteration 9200, lr = 1e-06
I0614 19:37:38.220176 13783 solver.cpp:270] Iteration 9250 (3.96835 iter/s, 12.5997s/50 iter), loss = 0.00423828, remaining 0 hours and 11 minutes
I0614 19:37:38.220208 13783 solver.cpp:291]     Train net output #0: loss = 0.0042383 (* 1 = 0.0042383 loss)
I0614 19:37:38.220216 13783 sgd_solver.cpp:106] Iteration 9250, lr = 1e-06
I0614 19:37:50.798820 13783 solver.cpp:270] Iteration 9300 (3.97513 iter/s, 12.5782s/50 iter), loss = 0.0348824, remaining 0 hours and 11 minutes
I0614 19:37:50.798851 13783 solver.cpp:291]     Train net output #0: loss = 0.0348825 (* 1 = 0.0348825 loss)
I0614 19:37:50.798859 13783 sgd_solver.cpp:106] Iteration 9300, lr = 1e-06
I0614 19:38:03.397207 13783 solver.cpp:270] Iteration 9350 (3.9689 iter/s, 12.598s/50 iter), loss = 0.00773212, remaining 0 hours and 11 minutes
I0614 19:38:03.397464 13783 solver.cpp:291]     Train net output #0: loss = 0.00773214 (* 1 = 0.00773214 loss)
I0614 19:38:03.397487 13783 sgd_solver.cpp:106] Iteration 9350, lr = 1e-06
I0614 19:38:15.943444 13783 solver.cpp:270] Iteration 9400 (3.98547 iter/s, 12.5456s/50 iter), loss = 0.00432868, remaining 0 hours and 10 minutes
I0614 19:38:15.943478 13783 solver.cpp:291]     Train net output #0: loss = 0.0043287 (* 1 = 0.0043287 loss)
I0614 19:38:15.943486 13783 sgd_solver.cpp:106] Iteration 9400, lr = 1e-06
I0614 19:38:28.516558 13783 solver.cpp:270] Iteration 9450 (3.97688 iter/s, 12.5727s/50 iter), loss = 0.00423473, remaining 0 hours and 10 minutes
I0614 19:38:28.516589 13783 solver.cpp:291]     Train net output #0: loss = 0.00423476 (* 1 = 0.00423476 loss)
I0614 19:38:28.516597 13783 sgd_solver.cpp:106] Iteration 9450, lr = 1e-06
I0614 19:38:41.123171 13783 solver.cpp:270] Iteration 9500 (3.96631 iter/s, 12.6062s/50 iter), loss = 0.00878493, remaining 0 hours and 10 minutes
I0614 19:38:41.123409 13783 solver.cpp:291]     Train net output #0: loss = 0.00878495 (* 1 = 0.00878495 loss)
I0614 19:38:41.123433 13783 sgd_solver.cpp:106] Iteration 9500, lr = 1e-06
I0614 19:38:53.696645 13783 solver.cpp:270] Iteration 9550 (3.97683 iter/s, 12.5728s/50 iter), loss = 0.00147328, remaining 0 hours and 10 minutes
I0614 19:38:53.696676 13783 solver.cpp:291]     Train net output #0: loss = 0.00147329 (* 1 = 0.00147329 loss)
I0614 19:38:53.696700 13783 sgd_solver.cpp:106] Iteration 9550, lr = 1e-06
I0614 19:39:06.298115 13783 solver.cpp:270] Iteration 9600 (3.96793 iter/s, 12.601s/50 iter), loss = 0.000298264, remaining 0 hours and 10 minutes
I0614 19:39:06.298148 13783 solver.cpp:291]     Train net output #0: loss = 0.000298282 (* 1 = 0.000298282 loss)
I0614 19:39:06.298156 13783 sgd_solver.cpp:106] Iteration 9600, lr = 1e-06
I0614 19:39:18.864369 13783 solver.cpp:270] Iteration 9650 (3.97905 iter/s, 12.5658s/50 iter), loss = 0.00114881, remaining 0 hours and 9 minutes
I0614 19:39:18.864593 13783 solver.cpp:291]     Train net output #0: loss = 0.00114883 (* 1 = 0.00114883 loss)
I0614 19:39:18.864603 13783 sgd_solver.cpp:106] Iteration 9650, lr = 1e-06
I0614 19:39:31.436885 13783 solver.cpp:270] Iteration 9700 (3.97713 iter/s, 12.5719s/50 iter), loss = 0.00603599, remaining 0 hours and 9 minutes
I0614 19:39:31.436916 13783 solver.cpp:291]     Train net output #0: loss = 0.00603601 (* 1 = 0.00603601 loss)
I0614 19:39:31.436923 13783 sgd_solver.cpp:106] Iteration 9700, lr = 1e-06
I0614 19:39:44.013301 13783 solver.cpp:270] Iteration 9750 (3.97583 iter/s, 12.576s/50 iter), loss = 0.006972, remaining 0 hours and 9 minutes
I0614 19:39:44.013332 13783 solver.cpp:291]     Train net output #0: loss = 0.00697202 (* 1 = 0.00697202 loss)
I0614 19:39:44.013340 13783 sgd_solver.cpp:106] Iteration 9750, lr = 1e-06
I0614 19:39:56.604892 13783 solver.cpp:270] Iteration 9800 (3.97104 iter/s, 12.5912s/50 iter), loss = 0.00306253, remaining 0 hours and 9 minutes
I0614 19:39:56.605087 13783 solver.cpp:291]     Train net output #0: loss = 0.00306255 (* 1 = 0.00306255 loss)
I0614 19:39:56.605095 13783 sgd_solver.cpp:106] Iteration 9800, lr = 1e-06
I0614 19:40:09.207983 13783 solver.cpp:270] Iteration 9850 (3.96747 iter/s, 12.6025s/50 iter), loss = 0.0258988, remaining 0 hours and 8 minutes
I0614 19:40:09.208014 13783 solver.cpp:291]     Train net output #0: loss = 0.0258989 (* 1 = 0.0258989 loss)
I0614 19:40:09.208022 13783 sgd_solver.cpp:106] Iteration 9850, lr = 1e-06
I0614 19:40:21.778952 13783 solver.cpp:270] Iteration 9900 (3.97756 iter/s, 12.5705s/50 iter), loss = 0.00398055, remaining 0 hours and 8 minutes
I0614 19:40:21.778982 13783 solver.cpp:291]     Train net output #0: loss = 0.00398057 (* 1 = 0.00398057 loss)
I0614 19:40:21.778991 13783 sgd_solver.cpp:106] Iteration 9900, lr = 1e-06
I0614 19:40:34.366600 13783 solver.cpp:270] Iteration 9950 (3.97229 iter/s, 12.5872s/50 iter), loss = 0.00294591, remaining 0 hours and 8 minutes
I0614 19:40:34.366937 13783 solver.cpp:291]     Train net output #0: loss = 0.00294593 (* 1 = 0.00294593 loss)
I0614 19:40:34.366962 13783 sgd_solver.cpp:106] Iteration 9950, lr = 1e-06
I0614 19:40:46.683409 13783 solver.cpp:424] Iteration 10000, Testing net (#0)
I0614 19:40:48.165892 13783 solver.cpp:523]     Test net output #0: accuracy = 0.96
I0614 19:40:48.165920 13783 solver.cpp:523]     Test net output #1: loss = 0.202412 (* 1 = 0.202412 loss)
I0614 19:40:48.165925 13783 solver.cpp:523]     Test net output #2: top-1 = 0.96
I0614 19:40:48.411944 13783 solver.cpp:270] Iteration 10000 (3.5601 iter/s, 14.0446s/50 iter), loss = 0.00213192, remaining 0 hours and 9 minutes
I0614 19:40:48.411974 13783 solver.cpp:291]     Train net output #0: loss = 0.00213194 (* 1 = 0.00213194 loss)
I0614 19:40:48.411983 13783 sgd_solver.cpp:106] Iteration 10000, lr = 1e-07
I0614 19:41:00.998194 13783 solver.cpp:270] Iteration 10050 (3.97273 iter/s, 12.5858s/50 iter), loss = 0.0143212, remaining 0 hours and 8 minutes
I0614 19:41:00.998225 13783 solver.cpp:291]     Train net output #0: loss = 0.0143212 (* 1 = 0.0143212 loss)
I0614 19:41:00.998234 13783 sgd_solver.cpp:106] Iteration 10050, lr = 1e-07
I0614 19:41:13.556241 13783 solver.cpp:270] Iteration 10100 (3.98165 iter/s, 12.5576s/50 iter), loss = 0.0140709, remaining 0 hours and 7 minutes
I0614 19:41:13.556510 13783 solver.cpp:291]     Train net output #0: loss = 0.014071 (* 1 = 0.014071 loss)
I0614 19:41:13.556519 13783 sgd_solver.cpp:106] Iteration 10100, lr = 1e-07
I0614 19:41:26.124004 13783 solver.cpp:270] Iteration 10150 (3.97865 iter/s, 12.5671s/50 iter), loss = 0.000988403, remaining 0 hours and 7 minutes
I0614 19:41:26.124035 13783 solver.cpp:291]     Train net output #0: loss = 0.000988432 (* 1 = 0.000988432 loss)
I0614 19:41:26.124059 13783 sgd_solver.cpp:106] Iteration 10150, lr = 1e-07
I0614 19:41:38.670293 13783 solver.cpp:270] Iteration 10200 (3.98538 iter/s, 12.5459s/50 iter), loss = 0.0016469, remaining 0 hours and 7 minutes
I0614 19:41:38.670325 13783 solver.cpp:291]     Train net output #0: loss = 0.00164693 (* 1 = 0.00164693 loss)
I0614 19:41:38.670332 13783 sgd_solver.cpp:106] Iteration 10200, lr = 1e-07
I0614 19:41:51.243084 13783 solver.cpp:270] Iteration 10250 (3.97698 iter/s, 12.5724s/50 iter), loss = 0.00111137, remaining 0 hours and 7 minutes
I0614 19:41:51.243284 13783 solver.cpp:291]     Train net output #0: loss = 0.0011114 (* 1 = 0.0011114 loss)
I0614 19:41:51.243292 13783 sgd_solver.cpp:106] Iteration 10250, lr = 1e-07
I0614 19:42:03.822438 13783 solver.cpp:270] Iteration 10300 (3.97496 iter/s, 12.5787s/50 iter), loss = 0.0140849, remaining 0 hours and 7 minutes
I0614 19:42:03.822470 13783 solver.cpp:291]     Train net output #0: loss = 0.0140849 (* 1 = 0.0140849 loss)
I0614 19:42:03.822479 13783 sgd_solver.cpp:106] Iteration 10300, lr = 1e-07
I0614 19:42:16.395885 13783 solver.cpp:270] Iteration 10350 (3.97677 iter/s, 12.573s/50 iter), loss = 0.00209781, remaining 0 hours and 6 minutes
I0614 19:42:16.395917 13783 solver.cpp:291]     Train net output #0: loss = 0.00209784 (* 1 = 0.00209784 loss)
I0614 19:42:16.395925 13783 sgd_solver.cpp:106] Iteration 10350, lr = 1e-07
I0614 19:42:28.972503 13783 solver.cpp:270] Iteration 10400 (3.97577 iter/s, 12.5762s/50 iter), loss = 0.000266309, remaining 0 hours and 6 minutes
I0614 19:42:28.972821 13783 solver.cpp:291]     Train net output #0: loss = 0.000266341 (* 1 = 0.000266341 loss)
I0614 19:42:28.972831 13783 sgd_solver.cpp:106] Iteration 10400, lr = 1e-07
I0614 19:42:41.544139 13783 solver.cpp:270] Iteration 10450 (3.97744 iter/s, 12.5709s/50 iter), loss = 0.00249932, remaining 0 hours and 6 minutes
I0614 19:42:41.544169 13783 solver.cpp:291]     Train net output #0: loss = 0.00249936 (* 1 = 0.00249936 loss)
I0614 19:42:41.544178 13783 sgd_solver.cpp:106] Iteration 10450, lr = 1e-07
I0614 19:42:54.098943 13783 solver.cpp:270] Iteration 10500 (3.98268 iter/s, 12.5544s/50 iter), loss = 0.00294103, remaining 0 hours and 6 minutes
I0614 19:42:54.098974 13783 solver.cpp:291]     Train net output #0: loss = 0.00294106 (* 1 = 0.00294106 loss)
I0614 19:42:54.098982 13783 sgd_solver.cpp:106] Iteration 10500, lr = 1e-07
I0614 19:43:06.692576 13783 solver.cpp:270] Iteration 10550 (3.9704 iter/s, 12.5932s/50 iter), loss = 0.014868, remaining 0 hours and 6 minutes
I0614 19:43:06.692847 13783 solver.cpp:291]     Train net output #0: loss = 0.014868 (* 1 = 0.014868 loss)
I0614 19:43:06.692871 13783 sgd_solver.cpp:106] Iteration 10550, lr = 1e-07
I0614 19:43:19.280826 13783 solver.cpp:270] Iteration 10600 (3.97217 iter/s, 12.5876s/50 iter), loss = 0.00215816, remaining 0 hours and 5 minutes
I0614 19:43:19.280855 13783 solver.cpp:291]     Train net output #0: loss = 0.0021582 (* 1 = 0.0021582 loss)
I0614 19:43:19.280864 13783 sgd_solver.cpp:106] Iteration 10600, lr = 1e-07
I0614 19:43:31.840636 13783 solver.cpp:270] Iteration 10650 (3.98109 iter/s, 12.5594s/50 iter), loss = 0.00616713, remaining 0 hours and 5 minutes
I0614 19:43:31.840667 13783 solver.cpp:291]     Train net output #0: loss = 0.00616717 (* 1 = 0.00616717 loss)
I0614 19:43:31.840673 13783 sgd_solver.cpp:106] Iteration 10650, lr = 1e-07
I0614 19:43:44.399489 13783 solver.cpp:270] Iteration 10700 (3.98139 iter/s, 12.5584s/50 iter), loss = 0.0050773, remaining 0 hours and 5 minutes
I0614 19:43:44.399739 13783 solver.cpp:291]     Train net output #0: loss = 0.00507734 (* 1 = 0.00507734 loss)
I0614 19:43:44.399762 13783 sgd_solver.cpp:106] Iteration 10700, lr = 1e-07
I0614 19:43:56.980020 13783 solver.cpp:270] Iteration 10750 (3.9746 iter/s, 12.5799s/50 iter), loss = 0.0136159, remaining 0 hours and 5 minutes
I0614 19:43:56.980052 13783 solver.cpp:291]     Train net output #0: loss = 0.013616 (* 1 = 0.013616 loss)
I0614 19:43:56.980060 13783 sgd_solver.cpp:106] Iteration 10750, lr = 1e-07
I0614 19:44:09.557757 13783 solver.cpp:270] Iteration 10800 (3.97542 iter/s, 12.5773s/50 iter), loss = 0.00376661, remaining 0 hours and 5 minutes
I0614 19:44:09.557788 13783 solver.cpp:291]     Train net output #0: loss = 0.00376664 (* 1 = 0.00376664 loss)
I0614 19:44:09.557797 13783 sgd_solver.cpp:106] Iteration 10800, lr = 1e-07
I0614 19:44:22.126991 13783 solver.cpp:270] Iteration 10850 (3.97811 iter/s, 12.5688s/50 iter), loss = 0.019747, remaining 0 hours and 4 minutes
I0614 19:44:22.127264 13783 solver.cpp:291]     Train net output #0: loss = 0.019747 (* 1 = 0.019747 loss)
I0614 19:44:22.127271 13783 sgd_solver.cpp:106] Iteration 10850, lr = 1e-07
I0614 19:44:34.709079 13783 solver.cpp:270] Iteration 10900 (3.97412 iter/s, 12.5814s/50 iter), loss = 0.0139822, remaining 0 hours and 4 minutes
I0614 19:44:34.709110 13783 solver.cpp:291]     Train net output #0: loss = 0.0139823 (* 1 = 0.0139823 loss)
I0614 19:44:34.709134 13783 sgd_solver.cpp:106] Iteration 10900, lr = 1e-07
I0614 19:44:47.305063 13783 solver.cpp:270] Iteration 10950 (3.96966 iter/s, 12.5955s/50 iter), loss = 0.0113242, remaining 0 hours and 4 minutes
I0614 19:44:47.305092 13783 solver.cpp:291]     Train net output #0: loss = 0.0113242 (* 1 = 0.0113242 loss)
I0614 19:44:47.305100 13783 sgd_solver.cpp:106] Iteration 10950, lr = 1e-07
I0614 19:44:59.616184 13783 solver.cpp:424] Iteration 11000, Testing net (#0)
I0614 19:45:01.111073 13783 solver.cpp:523]     Test net output #0: accuracy = 0.96025
I0614 19:45:01.111104 13783 solver.cpp:523]     Test net output #1: loss = 0.206671 (* 1 = 0.206671 loss)
I0614 19:45:01.111107 13783 solver.cpp:523]     Test net output #2: top-1 = 0.96025
I0614 19:45:01.357103 13783 solver.cpp:270] Iteration 11000 (3.55832 iter/s, 14.0516s/50 iter), loss = 0.000758999, remaining 0 hours and 4 minutes
I0614 19:45:01.357133 13783 solver.cpp:291]     Train net output #0: loss = 0.00075903 (* 1 = 0.00075903 loss)
I0614 19:45:01.357142 13783 sgd_solver.cpp:106] Iteration 11000, lr = 1e-07
I0614 19:45:13.952263 13783 solver.cpp:270] Iteration 11050 (3.96992 iter/s, 12.5947s/50 iter), loss = 0.0073191, remaining 0 hours and 3 minutes
I0614 19:45:13.952293 13783 solver.cpp:291]     Train net output #0: loss = 0.00731913 (* 1 = 0.00731913 loss)
I0614 19:45:13.952317 13783 sgd_solver.cpp:106] Iteration 11050, lr = 1e-07
I0614 19:45:26.539707 13783 solver.cpp:270] Iteration 11100 (3.97235 iter/s, 12.587s/50 iter), loss = 0.0103083, remaining 0 hours and 3 minutes
I0614 19:45:26.539739 13783 solver.cpp:291]     Train net output #0: loss = 0.0103083 (* 1 = 0.0103083 loss)
I0614 19:45:26.539762 13783 sgd_solver.cpp:106] Iteration 11100, lr = 1e-07
I0614 19:45:39.118013 13783 solver.cpp:270] Iteration 11150 (3.97524 iter/s, 12.5779s/50 iter), loss = 0.00100423, remaining 0 hours and 3 minutes
I0614 19:45:39.118355 13783 solver.cpp:291]     Train net output #0: loss = 0.00100426 (* 1 = 0.00100426 loss)
I0614 19:45:39.118364 13783 sgd_solver.cpp:106] Iteration 11150, lr = 1e-07
I0614 19:45:51.675354 13783 solver.cpp:270] Iteration 11200 (3.98197 iter/s, 12.5566s/50 iter), loss = 0.00646387, remaining 0 hours and 3 minutes
I0614 19:45:51.675386 13783 solver.cpp:291]     Train net output #0: loss = 0.0064639 (* 1 = 0.0064639 loss)
I0614 19:45:51.675395 13783 sgd_solver.cpp:106] Iteration 11200, lr = 1e-07
I0614 19:46:04.267279 13783 solver.cpp:270] Iteration 11250 (3.97094 iter/s, 12.5915s/50 iter), loss = 0.00209842, remaining 0 hours and 3 minutes
I0614 19:46:04.267313 13783 solver.cpp:291]     Train net output #0: loss = 0.00209845 (* 1 = 0.00209845 loss)
I0614 19:46:04.267320 13783 sgd_solver.cpp:106] Iteration 11250, lr = 1e-07
I0614 19:46:16.840297 13783 solver.cpp:270] Iteration 11300 (3.97691 iter/s, 12.5726s/50 iter), loss = 0.00328712, remaining 0 hours and 2 minutes
I0614 19:46:16.840544 13783 solver.cpp:291]     Train net output #0: loss = 0.00328715 (* 1 = 0.00328715 loss)
I0614 19:46:16.840552 13783 sgd_solver.cpp:106] Iteration 11300, lr = 1e-07
I0614 19:46:29.410846 13783 solver.cpp:270] Iteration 11350 (3.97776 iter/s, 12.5699s/50 iter), loss = 0.00170944, remaining 0 hours and 2 minutes
I0614 19:46:29.410878 13783 solver.cpp:291]     Train net output #0: loss = 0.00170948 (* 1 = 0.00170948 loss)
I0614 19:46:29.410887 13783 sgd_solver.cpp:106] Iteration 11350, lr = 1e-07
I0614 19:46:41.976019 13783 solver.cpp:270] Iteration 11400 (3.97939 iter/s, 12.5647s/50 iter), loss = 0.00635484, remaining 0 hours and 2 minutes
I0614 19:46:41.976051 13783 solver.cpp:291]     Train net output #0: loss = 0.00635488 (* 1 = 0.00635488 loss)
I0614 19:46:41.976060 13783 sgd_solver.cpp:106] Iteration 11400, lr = 1e-07
I0614 19:46:54.566478 13783 solver.cpp:270] Iteration 11450 (3.9714 iter/s, 12.59s/50 iter), loss = 0.00641233, remaining 0 hours and 2 minutes
I0614 19:46:54.566727 13783 solver.cpp:291]     Train net output #0: loss = 0.00641238 (* 1 = 0.00641238 loss)
I0614 19:46:54.566735 13783 sgd_solver.cpp:106] Iteration 11450, lr = 1e-07
I0614 19:47:07.156296 13783 solver.cpp:270] Iteration 11500 (3.97167 iter/s, 12.5892s/50 iter), loss = 0.00103742, remaining 0 hours and 2 minutes
I0614 19:47:07.156327 13783 solver.cpp:291]     Train net output #0: loss = 0.00103746 (* 1 = 0.00103746 loss)
I0614 19:47:07.156350 13783 sgd_solver.cpp:106] Iteration 11500, lr = 1e-07
I0614 19:47:19.733846 13783 solver.cpp:270] Iteration 11550 (3.97547 iter/s, 12.5771s/50 iter), loss = 0.00872528, remaining 0 hours and 1 minutes
I0614 19:47:19.733877 13783 solver.cpp:291]     Train net output #0: loss = 0.00872532 (* 1 = 0.00872532 loss)
I0614 19:47:19.733886 13783 sgd_solver.cpp:106] Iteration 11550, lr = 1e-07
I0614 19:47:32.301270 13783 solver.cpp:270] Iteration 11600 (3.97868 iter/s, 12.567s/50 iter), loss = 0.00170836, remaining 0 hours and 1 minutes
I0614 19:47:32.301628 13783 solver.cpp:291]     Train net output #0: loss = 0.00170839 (* 1 = 0.00170839 loss)
I0614 19:47:32.301652 13783 sgd_solver.cpp:106] Iteration 11600, lr = 1e-07
I0614 19:47:44.866696 13783 solver.cpp:270] Iteration 11650 (3.97941 iter/s, 12.5647s/50 iter), loss = 0.00375727, remaining 0 hours and 1 minutes
I0614 19:47:44.866727 13783 solver.cpp:291]     Train net output #0: loss = 0.0037573 (* 1 = 0.0037573 loss)
I0614 19:47:44.866750 13783 sgd_solver.cpp:106] Iteration 11650, lr = 1e-07
I0614 19:47:57.458899 13783 solver.cpp:270] Iteration 11700 (3.97085 iter/s, 12.5918s/50 iter), loss = 0.00127855, remaining 0 hours and 1 minutes
I0614 19:47:57.458928 13783 solver.cpp:291]     Train net output #0: loss = 0.00127858 (* 1 = 0.00127858 loss)
I0614 19:47:57.458935 13783 sgd_solver.cpp:106] Iteration 11700, lr = 1e-07
I0614 19:48:10.048831 13783 solver.cpp:270] Iteration 11750 (3.97156 iter/s, 12.5895s/50 iter), loss = 0.00488203, remaining 0 hours and 1 minutes
I0614 19:48:10.049106 13783 solver.cpp:291]     Train net output #0: loss = 0.00488206 (* 1 = 0.00488206 loss)
I0614 19:48:10.049115 13783 sgd_solver.cpp:106] Iteration 11750, lr = 1e-07
I0614 19:48:22.609508 13783 solver.cpp:270] Iteration 11800 (3.98089 iter/s, 12.56s/50 iter), loss = 0.0396312, remaining 0 hours and 0 minutes
I0614 19:48:22.609540 13783 solver.cpp:291]     Train net output #0: loss = 0.0396312 (* 1 = 0.0396312 loss)
I0614 19:48:22.609548 13783 sgd_solver.cpp:106] Iteration 11800, lr = 1e-07
I0614 19:48:35.176277 13783 solver.cpp:270] Iteration 11850 (3.97889 iter/s, 12.5663s/50 iter), loss = 0.00179585, remaining 0 hours and 0 minutes
I0614 19:48:35.176308 13783 solver.cpp:291]     Train net output #0: loss = 0.00179587 (* 1 = 0.00179587 loss)
I0614 19:48:35.176319 13783 sgd_solver.cpp:106] Iteration 11850, lr = 1e-07
I0614 19:48:47.733319 13783 solver.cpp:270] Iteration 11900 (3.98197 iter/s, 12.5566s/50 iter), loss = 0.0202453, remaining 0 hours and 0 minutes
I0614 19:48:47.733592 13783 solver.cpp:291]     Train net output #0: loss = 0.0202453 (* 1 = 0.0202453 loss)
I0614 19:48:47.733601 13783 sgd_solver.cpp:106] Iteration 11900, lr = 1e-07
I0614 19:49:00.295141 13783 solver.cpp:270] Iteration 11950 (3.98053 iter/s, 12.5611s/50 iter), loss = 0.0238978, remaining 0 hours and 0 minutes
I0614 19:49:00.295172 13783 solver.cpp:291]     Train net output #0: loss = 0.0238979 (* 1 = 0.0238979 loss)
I0614 19:49:00.295181 13783 sgd_solver.cpp:106] Iteration 11950, lr = 1e-07
I0614 19:49:12.616930 13783 solver.cpp:935] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.7/snapshots/_iter_12000.caffemodel
I0614 19:49:18.409978 13783 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.7/snapshots/_iter_12000.solverstate
I0614 19:49:22.101275 13783 solver.cpp:384] Iteration 12000, loss = 0.00531495
I0614 19:49:22.101300 13783 solver.cpp:424] Iteration 12000, Testing net (#0)
I0614 19:49:23.506779 13783 solver.cpp:523]     Test net output #0: accuracy = 0.96125
I0614 19:49:23.506809 13783 solver.cpp:523]     Test net output #1: loss = 0.208588 (* 1 = 0.208588 loss)
I0614 19:49:23.506814 13783 solver.cpp:523]     Test net output #2: top-1 = 0.96125
I0614 19:49:23.506819 13783 solver.cpp:392] Optimization Done (3.9597 iter/s).
I0614 19:49:23.506822 13783 caffe_interface.cpp:576] Optimization Done.
(c) Copyright 2016â2019 Xilinx, Inc. All rights reserved.

I0614 19:49:28.925551 13880 gpu_memory.cpp:53] GPUMemory::Manager initialized with Plain CUDA GPU Allocator
I0614 19:49:28.925753 13880 caffe_interface.cpp:121] Use CPU.
W0614 19:49:29.775578 13880 utils.cpp:207] BVLC BatchNormLayer without ScaleLayer detected: 3, it will be converted to NVCaffe Format.
W0614 19:49:29.775880 13880 utils.cpp:207] BVLC BatchNormLayer without ScaleLayer detected: 7, it will be converted to NVCaffe Format.
W0614 19:49:29.775918 13880 utils.cpp:207] BVLC BatchNormLayer without ScaleLayer detected: 21, it will be converted to NVCaffe Format.
I0614 19:49:29.776080 13880 net.cpp:323] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0614 19:49:29.776115 13880 net.cpp:52] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_value: 106
    mean_value: 116
    mean_value: 124
  }
  data_param {
    source: "input/lmdb/valid_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 0
    kernel_size: 8
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "bn1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "bn2"
  top: "relu2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "relu6"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "drop6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn7"
  type: "BatchNorm"
  bottom: "fc7"
  top: "bn7"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "bn7"
  top: "relu7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "relu7"
  top: "drop7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "drop7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy-top1"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "top-1"
  include {
    phase: TEST
  }
}
I0614 19:49:29.776692 13880 layer_factory.hpp:77] Creating layer data
I0614 19:49:29.778393 13880 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0614 19:49:29.778865 13880 net.cpp:94] Creating Layer data
I0614 19:49:29.778885 13880 net.cpp:409] data -> data
I0614 19:49:29.778903 13880 net.cpp:409] data -> label
I0614 19:49:29.782229 13913 db_lmdb.cpp:35] Opened lmdb input/lmdb/valid_lmdb
I0614 19:49:29.782260 13913 db_lmdb.cpp:38] Items count: 4000
I0614 19:49:29.782292 13913 data_reader.cpp:124] TEST: reading data using 1 channel(s)
I0614 19:49:29.782625 13880 data_layer.cpp:78] ReshapePrefetch 50, 3, 227, 227
I0614 19:49:29.782671 13880 data_layer.cpp:83] output data size: 50,3,227,227
I0614 19:49:29.903793 13880 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0614 19:49:29.903905 13880 net.cpp:144] Setting up data
I0614 19:49:29.903910 13880 net.cpp:151] Top shape: 50 3 227 227 (7729350)
I0614 19:49:29.903935 13880 net.cpp:151] Top shape: 50 (50)
I0614 19:49:29.903940 13880 net.cpp:159] Memory required for data: 30917600
I0614 19:49:29.903945 13880 layer_factory.hpp:77] Creating layer label_data_1_split
I0614 19:49:29.903955 13880 net.cpp:94] Creating Layer label_data_1_split
I0614 19:49:29.903959 13880 net.cpp:435] label_data_1_split <- label
I0614 19:49:29.903966 13880 net.cpp:409] label_data_1_split -> label_data_1_split_0
I0614 19:49:29.903975 13880 net.cpp:409] label_data_1_split -> label_data_1_split_1
I0614 19:49:29.903981 13880 net.cpp:409] label_data_1_split -> label_data_1_split_2
I0614 19:49:29.903993 13880 net.cpp:144] Setting up label_data_1_split
I0614 19:49:29.903996 13880 net.cpp:151] Top shape: 50 (50)
I0614 19:49:29.904001 13880 net.cpp:151] Top shape: 50 (50)
I0614 19:49:29.904006 13880 net.cpp:151] Top shape: 50 (50)
I0614 19:49:29.904009 13880 net.cpp:159] Memory required for data: 30918200
I0614 19:49:29.904012 13880 layer_factory.hpp:77] Creating layer conv1
I0614 19:49:29.904023 13880 net.cpp:94] Creating Layer conv1
I0614 19:49:29.904047 13880 net.cpp:435] conv1 <- data
I0614 19:49:29.904052 13880 net.cpp:409] conv1 -> conv1
I0614 19:49:29.904316 13880 net.cpp:144] Setting up conv1
I0614 19:49:29.904323 13880 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0614 19:49:29.904331 13880 net.cpp:159] Memory required for data: 88998200
I0614 19:49:29.904342 13880 layer_factory.hpp:77] Creating layer bn1
I0614 19:49:29.904350 13880 net.cpp:94] Creating Layer bn1
I0614 19:49:29.904354 13880 net.cpp:435] bn1 <- conv1
I0614 19:49:29.904361 13880 net.cpp:409] bn1 -> bn1
I0614 19:49:29.904390 13880 net.cpp:144] Setting up bn1
I0614 19:49:29.904394 13880 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0614 19:49:29.904400 13880 net.cpp:159] Memory required for data: 147078200
I0614 19:49:29.904412 13880 layer_factory.hpp:77] Creating layer relu1
I0614 19:49:29.904421 13880 net.cpp:94] Creating Layer relu1
I0614 19:49:29.904426 13880 net.cpp:435] relu1 <- bn1
I0614 19:49:29.904433 13880 net.cpp:409] relu1 -> relu1
I0614 19:49:29.904443 13880 net.cpp:144] Setting up relu1
I0614 19:49:29.904445 13880 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0614 19:49:29.904453 13880 net.cpp:159] Memory required for data: 205158200
I0614 19:49:29.904457 13880 layer_factory.hpp:77] Creating layer pool1
I0614 19:49:29.904462 13880 net.cpp:94] Creating Layer pool1
I0614 19:49:29.904466 13880 net.cpp:435] pool1 <- relu1
I0614 19:49:29.904471 13880 net.cpp:409] pool1 -> pool1
I0614 19:49:29.904486 13880 net.cpp:144] Setting up pool1
I0614 19:49:29.904490 13880 net.cpp:151] Top shape: 50 96 27 27 (3499200)
I0614 19:49:29.904495 13880 net.cpp:159] Memory required for data: 219155000
I0614 19:49:29.904498 13880 layer_factory.hpp:77] Creating layer conv2
I0614 19:49:29.904506 13880 net.cpp:94] Creating Layer conv2
I0614 19:49:29.904510 13880 net.cpp:435] conv2 <- pool1
I0614 19:49:29.904515 13880 net.cpp:409] conv2 -> conv2
I0614 19:49:29.911608 13880 net.cpp:144] Setting up conv2
I0614 19:49:29.911621 13880 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0614 19:49:29.911628 13880 net.cpp:159] Memory required for data: 256479800
I0614 19:49:29.911636 13880 layer_factory.hpp:77] Creating layer bn2
I0614 19:49:29.911644 13880 net.cpp:94] Creating Layer bn2
I0614 19:49:29.911648 13880 net.cpp:435] bn2 <- conv2
I0614 19:49:29.911654 13880 net.cpp:409] bn2 -> bn2
I0614 19:49:29.911681 13880 net.cpp:144] Setting up bn2
I0614 19:49:29.911684 13880 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0614 19:49:29.911705 13880 net.cpp:159] Memory required for data: 293804600
I0614 19:49:29.911711 13880 layer_factory.hpp:77] Creating layer relu2
I0614 19:49:29.911717 13880 net.cpp:94] Creating Layer relu2
I0614 19:49:29.911721 13880 net.cpp:435] relu2 <- bn2
I0614 19:49:29.911727 13880 net.cpp:409] relu2 -> relu2
I0614 19:49:29.911733 13880 net.cpp:144] Setting up relu2
I0614 19:49:29.911737 13880 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0614 19:49:29.911741 13880 net.cpp:159] Memory required for data: 331129400
I0614 19:49:29.911746 13880 layer_factory.hpp:77] Creating layer pool2
I0614 19:49:29.911751 13880 net.cpp:94] Creating Layer pool2
I0614 19:49:29.911753 13880 net.cpp:435] pool2 <- relu2
I0614 19:49:29.911758 13880 net.cpp:409] pool2 -> pool2
I0614 19:49:29.911765 13880 net.cpp:144] Setting up pool2
I0614 19:49:29.911769 13880 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0614 19:49:29.911773 13880 net.cpp:159] Memory required for data: 339782200
I0614 19:49:29.911777 13880 layer_factory.hpp:77] Creating layer conv3
I0614 19:49:29.911783 13880 net.cpp:94] Creating Layer conv3
I0614 19:49:29.911787 13880 net.cpp:435] conv3 <- pool2
I0614 19:49:29.911792 13880 net.cpp:409] conv3 -> conv3
I0614 19:49:29.921406 13880 net.cpp:144] Setting up conv3
I0614 19:49:29.921417 13880 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0614 19:49:29.921423 13880 net.cpp:159] Memory required for data: 352761400
I0614 19:49:29.921430 13880 layer_factory.hpp:77] Creating layer relu3
I0614 19:49:29.921451 13880 net.cpp:94] Creating Layer relu3
I0614 19:49:29.921455 13880 net.cpp:435] relu3 <- conv3
I0614 19:49:29.921473 13880 net.cpp:409] relu3 -> relu3
I0614 19:49:29.921481 13880 net.cpp:144] Setting up relu3
I0614 19:49:29.921484 13880 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0614 19:49:29.921489 13880 net.cpp:159] Memory required for data: 365740600
I0614 19:49:29.921494 13880 layer_factory.hpp:77] Creating layer conv4
I0614 19:49:29.921501 13880 net.cpp:94] Creating Layer conv4
I0614 19:49:29.921504 13880 net.cpp:435] conv4 <- relu3
I0614 19:49:29.921509 13880 net.cpp:409] conv4 -> conv4
I0614 19:49:29.935585 13880 net.cpp:144] Setting up conv4
I0614 19:49:29.935597 13880 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0614 19:49:29.935604 13880 net.cpp:159] Memory required for data: 378719800
I0614 19:49:29.935614 13880 layer_factory.hpp:77] Creating layer relu4
I0614 19:49:29.935619 13880 net.cpp:94] Creating Layer relu4
I0614 19:49:29.935623 13880 net.cpp:435] relu4 <- conv4
I0614 19:49:29.935628 13880 net.cpp:409] relu4 -> relu4
I0614 19:49:29.935637 13880 net.cpp:144] Setting up relu4
I0614 19:49:29.935640 13880 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0614 19:49:29.935644 13880 net.cpp:159] Memory required for data: 391699000
I0614 19:49:29.935647 13880 layer_factory.hpp:77] Creating layer conv5
I0614 19:49:29.935654 13880 net.cpp:94] Creating Layer conv5
I0614 19:49:29.935657 13880 net.cpp:435] conv5 <- relu4
I0614 19:49:29.935662 13880 net.cpp:409] conv5 -> conv5
I0614 19:49:29.945133 13880 net.cpp:144] Setting up conv5
I0614 19:49:29.945147 13880 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0614 19:49:29.945152 13880 net.cpp:159] Memory required for data: 400351800
I0614 19:49:29.945158 13880 layer_factory.hpp:77] Creating layer relu5
I0614 19:49:29.945164 13880 net.cpp:94] Creating Layer relu5
I0614 19:49:29.945168 13880 net.cpp:435] relu5 <- conv5
I0614 19:49:29.945173 13880 net.cpp:409] relu5 -> relu5
I0614 19:49:29.945179 13880 net.cpp:144] Setting up relu5
I0614 19:49:29.945183 13880 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0614 19:49:29.945186 13880 net.cpp:159] Memory required for data: 409004600
I0614 19:49:29.945189 13880 layer_factory.hpp:77] Creating layer pool5
I0614 19:49:29.945196 13880 net.cpp:94] Creating Layer pool5
I0614 19:49:29.945200 13880 net.cpp:435] pool5 <- relu5
I0614 19:49:29.945204 13880 net.cpp:409] pool5 -> pool5
I0614 19:49:29.945210 13880 net.cpp:144] Setting up pool5
I0614 19:49:29.945214 13880 net.cpp:151] Top shape: 50 256 6 6 (460800)
I0614 19:49:29.945219 13880 net.cpp:159] Memory required for data: 410847800
I0614 19:49:29.945221 13880 layer_factory.hpp:77] Creating layer fc6
I0614 19:49:29.945226 13880 net.cpp:94] Creating Layer fc6
I0614 19:49:29.945230 13880 net.cpp:435] fc6 <- pool5
I0614 19:49:29.945235 13880 net.cpp:409] fc6 -> fc6
I0614 19:49:30.326278 13880 net.cpp:144] Setting up fc6
I0614 19:49:30.326304 13880 net.cpp:151] Top shape: 50 4096 (204800)
I0614 19:49:30.326313 13880 net.cpp:159] Memory required for data: 411667000
I0614 19:49:30.326323 13880 layer_factory.hpp:77] Creating layer relu6
I0614 19:49:30.326330 13880 net.cpp:94] Creating Layer relu6
I0614 19:49:30.326335 13880 net.cpp:435] relu6 <- fc6
I0614 19:49:30.326341 13880 net.cpp:409] relu6 -> relu6
I0614 19:49:30.326354 13880 net.cpp:144] Setting up relu6
I0614 19:49:30.326356 13880 net.cpp:151] Top shape: 50 4096 (204800)
I0614 19:49:30.326360 13880 net.cpp:159] Memory required for data: 412486200
I0614 19:49:30.326364 13880 layer_factory.hpp:77] Creating layer drop6
I0614 19:49:30.326370 13880 net.cpp:94] Creating Layer drop6
I0614 19:49:30.326372 13880 net.cpp:435] drop6 <- relu6
I0614 19:49:30.326378 13880 net.cpp:409] drop6 -> drop6
I0614 19:49:30.326385 13880 net.cpp:144] Setting up drop6
I0614 19:49:30.326387 13880 net.cpp:151] Top shape: 50 4096 (204800)
I0614 19:49:30.326391 13880 net.cpp:159] Memory required for data: 413305400
I0614 19:49:30.326395 13880 layer_factory.hpp:77] Creating layer fc7
I0614 19:49:30.326400 13880 net.cpp:94] Creating Layer fc7
I0614 19:49:30.326403 13880 net.cpp:435] fc7 <- drop6
I0614 19:49:30.326408 13880 net.cpp:409] fc7 -> fc7
I0614 19:49:30.495751 13880 net.cpp:144] Setting up fc7
I0614 19:49:30.495779 13880 net.cpp:151] Top shape: 50 4096 (204800)
I0614 19:49:30.495788 13880 net.cpp:159] Memory required for data: 414124600
I0614 19:49:30.495796 13880 layer_factory.hpp:77] Creating layer bn7
I0614 19:49:30.495806 13880 net.cpp:94] Creating Layer bn7
I0614 19:49:30.495811 13880 net.cpp:435] bn7 <- fc7
I0614 19:49:30.495817 13880 net.cpp:409] bn7 -> bn7
I0614 19:49:30.495918 13880 net.cpp:144] Setting up bn7
I0614 19:49:30.495923 13880 net.cpp:151] Top shape: 50 4096 (204800)
I0614 19:49:30.495926 13880 net.cpp:159] Memory required for data: 414943800
I0614 19:49:30.495932 13880 layer_factory.hpp:77] Creating layer relu7
I0614 19:49:30.495937 13880 net.cpp:94] Creating Layer relu7
I0614 19:49:30.495940 13880 net.cpp:435] relu7 <- bn7
I0614 19:49:30.495945 13880 net.cpp:409] relu7 -> relu7
I0614 19:49:30.495951 13880 net.cpp:144] Setting up relu7
I0614 19:49:30.495954 13880 net.cpp:151] Top shape: 50 4096 (204800)
I0614 19:49:30.495959 13880 net.cpp:159] Memory required for data: 415763000
I0614 19:49:30.495961 13880 layer_factory.hpp:77] Creating layer drop7
I0614 19:49:30.495968 13880 net.cpp:94] Creating Layer drop7
I0614 19:49:30.495972 13880 net.cpp:435] drop7 <- relu7
I0614 19:49:30.495976 13880 net.cpp:409] drop7 -> drop7
I0614 19:49:30.495981 13880 net.cpp:144] Setting up drop7
I0614 19:49:30.495985 13880 net.cpp:151] Top shape: 50 4096 (204800)
I0614 19:49:30.495988 13880 net.cpp:159] Memory required for data: 416582200
I0614 19:49:30.495991 13880 layer_factory.hpp:77] Creating layer fc8
I0614 19:49:30.495998 13880 net.cpp:94] Creating Layer fc8
I0614 19:49:30.496001 13880 net.cpp:435] fc8 <- drop7
I0614 19:49:30.496006 13880 net.cpp:409] fc8 -> fc8
I0614 19:49:30.496124 13880 net.cpp:144] Setting up fc8
I0614 19:49:30.496126 13880 net.cpp:151] Top shape: 50 2 (100)
I0614 19:49:30.496131 13880 net.cpp:159] Memory required for data: 416582600
I0614 19:49:30.496136 13880 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0614 19:49:30.496143 13880 net.cpp:94] Creating Layer fc8_fc8_0_split
I0614 19:49:30.496146 13880 net.cpp:435] fc8_fc8_0_split <- fc8
I0614 19:49:30.496151 13880 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0614 19:49:30.496157 13880 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0614 19:49:30.496163 13880 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_2
I0614 19:49:30.496170 13880 net.cpp:144] Setting up fc8_fc8_0_split
I0614 19:49:30.496173 13880 net.cpp:151] Top shape: 50 2 (100)
I0614 19:49:30.496177 13880 net.cpp:151] Top shape: 50 2 (100)
I0614 19:49:30.496181 13880 net.cpp:151] Top shape: 50 2 (100)
I0614 19:49:30.496186 13880 net.cpp:159] Memory required for data: 416583800
I0614 19:49:30.496189 13880 layer_factory.hpp:77] Creating layer accuracy
I0614 19:49:30.496201 13880 net.cpp:94] Creating Layer accuracy
I0614 19:49:30.496204 13880 net.cpp:435] accuracy <- fc8_fc8_0_split_0
I0614 19:49:30.496208 13880 net.cpp:435] accuracy <- label_data_1_split_0
I0614 19:49:30.496213 13880 net.cpp:409] accuracy -> accuracy
I0614 19:49:30.496220 13880 net.cpp:144] Setting up accuracy
I0614 19:49:30.496223 13880 net.cpp:151] Top shape: (1)
I0614 19:49:30.496243 13880 net.cpp:159] Memory required for data: 416583804
I0614 19:49:30.496248 13880 layer_factory.hpp:77] Creating layer loss
I0614 19:49:30.496253 13880 net.cpp:94] Creating Layer loss
I0614 19:49:30.496256 13880 net.cpp:435] loss <- fc8_fc8_0_split_1
I0614 19:49:30.496260 13880 net.cpp:435] loss <- label_data_1_split_1
I0614 19:49:30.496265 13880 net.cpp:409] loss -> loss
I0614 19:49:30.496275 13880 layer_factory.hpp:77] Creating layer loss
I0614 19:49:30.496291 13880 net.cpp:144] Setting up loss
I0614 19:49:30.496295 13880 net.cpp:151] Top shape: (1)
I0614 19:49:30.496300 13880 net.cpp:154]     with loss weight 1
I0614 19:49:30.496335 13880 net.cpp:159] Memory required for data: 416583808
I0614 19:49:30.496340 13880 layer_factory.hpp:77] Creating layer accuracy-top1
I0614 19:49:30.496345 13880 net.cpp:94] Creating Layer accuracy-top1
I0614 19:49:30.496367 13880 net.cpp:435] accuracy-top1 <- fc8_fc8_0_split_2
I0614 19:49:30.496372 13880 net.cpp:435] accuracy-top1 <- label_data_1_split_2
I0614 19:49:30.496378 13880 net.cpp:409] accuracy-top1 -> top-1
I0614 19:49:30.496387 13880 net.cpp:144] Setting up accuracy-top1
I0614 19:49:30.496390 13880 net.cpp:151] Top shape: (1)
I0614 19:49:30.496394 13880 net.cpp:159] Memory required for data: 416583812
I0614 19:49:30.496398 13880 net.cpp:222] accuracy-top1 does not need backward computation.
I0614 19:49:30.496403 13880 net.cpp:220] loss needs backward computation.
I0614 19:49:30.496407 13880 net.cpp:222] accuracy does not need backward computation.
I0614 19:49:30.496412 13880 net.cpp:220] fc8_fc8_0_split needs backward computation.
I0614 19:49:30.496416 13880 net.cpp:220] fc8 needs backward computation.
I0614 19:49:30.496420 13880 net.cpp:220] drop7 needs backward computation.
I0614 19:49:30.496423 13880 net.cpp:220] relu7 needs backward computation.
I0614 19:49:30.496428 13880 net.cpp:220] bn7 needs backward computation.
I0614 19:49:30.496431 13880 net.cpp:220] fc7 needs backward computation.
I0614 19:49:30.496435 13880 net.cpp:220] drop6 needs backward computation.
I0614 19:49:30.496439 13880 net.cpp:220] relu6 needs backward computation.
I0614 19:49:30.496444 13880 net.cpp:220] fc6 needs backward computation.
I0614 19:49:30.496448 13880 net.cpp:220] pool5 needs backward computation.
I0614 19:49:30.496452 13880 net.cpp:220] relu5 needs backward computation.
I0614 19:49:30.496456 13880 net.cpp:220] conv5 needs backward computation.
I0614 19:49:30.496460 13880 net.cpp:220] relu4 needs backward computation.
I0614 19:49:30.496464 13880 net.cpp:220] conv4 needs backward computation.
I0614 19:49:30.496469 13880 net.cpp:220] relu3 needs backward computation.
I0614 19:49:30.496472 13880 net.cpp:220] conv3 needs backward computation.
I0614 19:49:30.496476 13880 net.cpp:220] pool2 needs backward computation.
I0614 19:49:30.496480 13880 net.cpp:220] relu2 needs backward computation.
I0614 19:49:30.496485 13880 net.cpp:220] bn2 needs backward computation.
I0614 19:49:30.496490 13880 net.cpp:220] conv2 needs backward computation.
I0614 19:49:30.496493 13880 net.cpp:220] pool1 needs backward computation.
I0614 19:49:30.496497 13880 net.cpp:220] relu1 needs backward computation.
I0614 19:49:30.496501 13880 net.cpp:220] bn1 needs backward computation.
I0614 19:49:30.496505 13880 net.cpp:220] conv1 needs backward computation.
I0614 19:49:30.496510 13880 net.cpp:222] label_data_1_split does not need backward computation.
I0614 19:49:30.496515 13880 net.cpp:222] data does not need backward computation.
I0614 19:49:30.496520 13880 net.cpp:264] This network produces output accuracy
I0614 19:49:30.496523 13880 net.cpp:264] This network produces output loss
I0614 19:49:30.496527 13880 net.cpp:264] This network produces output top-1
I0614 19:49:30.496553 13880 net.cpp:284] Network initialization done.
I0614 19:49:30.572492 13880 model_transformer.cpp:126] layer: data
I0614 19:49:30.572516 13880 model_transformer.cpp:126] layer: conv1
I0614 19:49:30.572793 13880 model_transformer.cpp:126] layer: bn1
I0614 19:49:30.572815 13880 model_transformer.cpp:126] layer: relu1
I0614 19:49:30.572820 13880 model_transformer.cpp:126] layer: pool1
I0614 19:49:30.572826 13880 model_transformer.cpp:126] layer: conv2
I0614 19:49:30.577260 13880 model_transformer.cpp:126] layer: bn2
I0614 19:49:30.577301 13880 model_transformer.cpp:126] layer: relu2
I0614 19:49:30.577306 13880 model_transformer.cpp:126] layer: pool2
I0614 19:49:30.577312 13880 model_transformer.cpp:126] layer: conv3
I0614 19:49:30.579317 13880 model_transformer.cpp:126] layer: relu3
I0614 19:49:30.579332 13880 model_transformer.cpp:126] layer: conv4
I0614 19:49:30.583600 13880 model_transformer.cpp:126] layer: relu4
I0614 19:49:30.583613 13880 model_transformer.cpp:126] layer: conv5
I0614 19:49:30.585419 13880 model_transformer.cpp:126] layer: relu5
I0614 19:49:30.585433 13880 model_transformer.cpp:126] layer: pool5
I0614 19:49:30.585439 13880 model_transformer.cpp:126] layer: fc6
I0614 19:49:32.572193 13880 model_transformer.cpp:126] layer: relu6
I0614 19:49:32.572242 13880 model_transformer.cpp:126] layer: drop6
I0614 19:49:32.572248 13880 model_transformer.cpp:126] layer: fc7
I0614 19:49:32.853279 13880 model_transformer.cpp:126] layer: bn7
I0614 19:49:32.853432 13880 model_transformer.cpp:126] layer: relu7
I0614 19:49:32.853441 13880 model_transformer.cpp:126] layer: drop7
I0614 19:49:32.853447 13880 model_transformer.cpp:126] layer: fc8
I0614 19:49:32.853538 13880 model_transformer.cpp:126] layer: loss
Output transformed caffemodel: transformed.caffemodel
(c) Copyright 2016â2019 Xilinx, Inc. All rights reserved.

I0614 19:49:34.787127 13916 net.cpp:323] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0614 19:49:34.787367 13916 net.cpp:52] Initializing net from parameters: 
name: "alexnetBNnoLRN m2 (as m3 but less DROP and less BN)"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_value: 106
    mean_value: 116
    mean_value: 124
  }
  data_param {
    source: "input/lmdb/valid_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 0
    kernel_size: 8
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "bn1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "bn2"
  top: "relu2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "relu6"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "drop6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn7"
  type: "BatchNorm"
  bottom: "fc7"
  top: "bn7"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "bn7"
  top: "relu7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "relu7"
  top: "drop7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "drop7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy-top1"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "top-1"
  include {
    phase: TEST
  }
}
I0614 19:49:34.787616 13916 layer_factory.hpp:77] Creating layer data
I0614 19:49:34.788470 13916 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0614 19:49:34.788770 13916 net.cpp:94] Creating Layer data
I0614 19:49:34.788781 13916 net.cpp:409] data -> data
I0614 19:49:34.788796 13916 net.cpp:409] data -> label
I0614 19:49:34.792239 13949 db_lmdb.cpp:35] Opened lmdb input/lmdb/valid_lmdb
I0614 19:49:34.792268 13949 db_lmdb.cpp:38] Items count: 4000
I0614 19:49:34.792299 13949 data_reader.cpp:124] TEST: reading data using 1 channel(s)
I0614 19:49:34.792683 13916 data_layer.cpp:78] ReshapePrefetch 50, 3, 227, 227
I0614 19:49:34.792706 13916 data_layer.cpp:83] output data size: 50,3,227,227
I0614 19:49:34.900267 13916 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0614 19:49:34.900395 13916 net.cpp:144] Setting up data
I0614 19:49:34.900400 13916 net.cpp:151] Top shape: 50 3 227 227 (7729350)
I0614 19:49:34.900409 13916 net.cpp:151] Top shape: 50 (50)
I0614 19:49:34.900413 13916 net.cpp:159] Memory required for data: 30917600
I0614 19:49:34.900418 13916 layer_factory.hpp:77] Creating layer label_data_1_split
I0614 19:49:34.900427 13916 net.cpp:94] Creating Layer label_data_1_split
I0614 19:49:34.900431 13916 net.cpp:435] label_data_1_split <- label
I0614 19:49:34.900437 13916 net.cpp:409] label_data_1_split -> label_data_1_split_0
I0614 19:49:34.900445 13916 net.cpp:409] label_data_1_split -> label_data_1_split_1
I0614 19:49:34.900450 13916 net.cpp:409] label_data_1_split -> label_data_1_split_2
I0614 19:49:34.900458 13916 net.cpp:144] Setting up label_data_1_split
I0614 19:49:34.900461 13916 net.cpp:151] Top shape: 50 (50)
I0614 19:49:34.900465 13916 net.cpp:151] Top shape: 50 (50)
I0614 19:49:34.900468 13916 net.cpp:151] Top shape: 50 (50)
I0614 19:49:34.900471 13916 net.cpp:159] Memory required for data: 30918200
I0614 19:49:34.900475 13916 layer_factory.hpp:77] Creating layer conv1
I0614 19:49:34.900483 13916 net.cpp:94] Creating Layer conv1
I0614 19:49:34.900486 13916 net.cpp:435] conv1 <- data
I0614 19:49:34.900490 13916 net.cpp:409] conv1 -> conv1
I0614 19:49:34.900735 13916 net.cpp:144] Setting up conv1
I0614 19:49:34.900739 13916 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0614 19:49:34.900744 13916 net.cpp:159] Memory required for data: 88998200
I0614 19:49:34.900754 13916 layer_factory.hpp:77] Creating layer bn1
I0614 19:49:34.900761 13916 net.cpp:94] Creating Layer bn1
I0614 19:49:34.900764 13916 net.cpp:435] bn1 <- conv1
I0614 19:49:34.900769 13916 net.cpp:409] bn1 -> bn1
I0614 19:49:34.900815 13916 net.cpp:144] Setting up bn1
I0614 19:49:34.900820 13916 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0614 19:49:34.900825 13916 net.cpp:159] Memory required for data: 147078200
I0614 19:49:34.900833 13916 layer_factory.hpp:77] Creating layer relu1
I0614 19:49:34.900840 13916 net.cpp:94] Creating Layer relu1
I0614 19:49:34.900842 13916 net.cpp:435] relu1 <- bn1
I0614 19:49:34.900847 13916 net.cpp:409] relu1 -> relu1
I0614 19:49:34.900854 13916 net.cpp:144] Setting up relu1
I0614 19:49:34.900857 13916 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0614 19:49:34.900862 13916 net.cpp:159] Memory required for data: 205158200
I0614 19:49:34.900866 13916 layer_factory.hpp:77] Creating layer pool1
I0614 19:49:34.900871 13916 net.cpp:94] Creating Layer pool1
I0614 19:49:34.900874 13916 net.cpp:435] pool1 <- relu1
I0614 19:49:34.900879 13916 net.cpp:409] pool1 -> pool1
I0614 19:49:34.900889 13916 net.cpp:144] Setting up pool1
I0614 19:49:34.900893 13916 net.cpp:151] Top shape: 50 96 27 27 (3499200)
I0614 19:49:34.900898 13916 net.cpp:159] Memory required for data: 219155000
I0614 19:49:34.900902 13916 layer_factory.hpp:77] Creating layer conv2
I0614 19:49:34.900907 13916 net.cpp:94] Creating Layer conv2
I0614 19:49:34.900911 13916 net.cpp:435] conv2 <- pool1
I0614 19:49:34.900916 13916 net.cpp:409] conv2 -> conv2
I0614 19:49:34.907840 13916 net.cpp:144] Setting up conv2
I0614 19:49:34.907852 13916 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0614 19:49:34.907858 13916 net.cpp:159] Memory required for data: 256479800
I0614 19:49:34.907867 13916 layer_factory.hpp:77] Creating layer bn2
I0614 19:49:34.907874 13916 net.cpp:94] Creating Layer bn2
I0614 19:49:34.907878 13916 net.cpp:435] bn2 <- conv2
I0614 19:49:34.907884 13916 net.cpp:409] bn2 -> bn2
I0614 19:49:34.907909 13916 net.cpp:144] Setting up bn2
I0614 19:49:34.907912 13916 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0614 19:49:34.907917 13916 net.cpp:159] Memory required for data: 293804600
I0614 19:49:34.907924 13916 layer_factory.hpp:77] Creating layer relu2
I0614 19:49:34.907929 13916 net.cpp:94] Creating Layer relu2
I0614 19:49:34.907932 13916 net.cpp:435] relu2 <- bn2
I0614 19:49:34.907938 13916 net.cpp:409] relu2 -> relu2
I0614 19:49:34.907943 13916 net.cpp:144] Setting up relu2
I0614 19:49:34.907946 13916 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0614 19:49:34.907950 13916 net.cpp:159] Memory required for data: 331129400
I0614 19:49:34.907954 13916 layer_factory.hpp:77] Creating layer pool2
I0614 19:49:34.907958 13916 net.cpp:94] Creating Layer pool2
I0614 19:49:34.907963 13916 net.cpp:435] pool2 <- relu2
I0614 19:49:34.907966 13916 net.cpp:409] pool2 -> pool2
I0614 19:49:34.907972 13916 net.cpp:144] Setting up pool2
I0614 19:49:34.907975 13916 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0614 19:49:34.907980 13916 net.cpp:159] Memory required for data: 339782200
I0614 19:49:34.907984 13916 layer_factory.hpp:77] Creating layer conv3
I0614 19:49:34.907989 13916 net.cpp:94] Creating Layer conv3
I0614 19:49:34.907992 13916 net.cpp:435] conv3 <- pool2
I0614 19:49:34.907997 13916 net.cpp:409] conv3 -> conv3
I0614 19:49:34.918202 13916 net.cpp:144] Setting up conv3
I0614 19:49:34.918215 13916 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0614 19:49:34.918221 13916 net.cpp:159] Memory required for data: 352761400
I0614 19:49:34.918228 13916 layer_factory.hpp:77] Creating layer relu3
I0614 19:49:34.918234 13916 net.cpp:94] Creating Layer relu3
I0614 19:49:34.918238 13916 net.cpp:435] relu3 <- conv3
I0614 19:49:34.918243 13916 net.cpp:409] relu3 -> relu3
I0614 19:49:34.918251 13916 net.cpp:144] Setting up relu3
I0614 19:49:34.918254 13916 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0614 19:49:34.918258 13916 net.cpp:159] Memory required for data: 365740600
I0614 19:49:34.918262 13916 layer_factory.hpp:77] Creating layer conv4
I0614 19:49:34.918268 13916 net.cpp:94] Creating Layer conv4
I0614 19:49:34.918272 13916 net.cpp:435] conv4 <- relu3
I0614 19:49:34.918277 13916 net.cpp:409] conv4 -> conv4
I0614 19:49:34.933468 13916 net.cpp:144] Setting up conv4
I0614 19:49:34.933494 13916 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0614 19:49:34.933502 13916 net.cpp:159] Memory required for data: 378719800
I0614 19:49:34.933511 13916 layer_factory.hpp:77] Creating layer relu4
I0614 19:49:34.933516 13916 net.cpp:94] Creating Layer relu4
I0614 19:49:34.933521 13916 net.cpp:435] relu4 <- conv4
I0614 19:49:34.933526 13916 net.cpp:409] relu4 -> relu4
I0614 19:49:34.933534 13916 net.cpp:144] Setting up relu4
I0614 19:49:34.933537 13916 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0614 19:49:34.933542 13916 net.cpp:159] Memory required for data: 391699000
I0614 19:49:34.933545 13916 layer_factory.hpp:77] Creating layer conv5
I0614 19:49:34.933552 13916 net.cpp:94] Creating Layer conv5
I0614 19:49:34.933555 13916 net.cpp:435] conv5 <- relu4
I0614 19:49:34.933560 13916 net.cpp:409] conv5 -> conv5
I0614 19:49:34.943759 13916 net.cpp:144] Setting up conv5
I0614 19:49:34.943773 13916 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0614 19:49:34.943778 13916 net.cpp:159] Memory required for data: 400351800
I0614 19:49:34.943785 13916 layer_factory.hpp:77] Creating layer relu5
I0614 19:49:34.943791 13916 net.cpp:94] Creating Layer relu5
I0614 19:49:34.943795 13916 net.cpp:435] relu5 <- conv5
I0614 19:49:34.943800 13916 net.cpp:409] relu5 -> relu5
I0614 19:49:34.943809 13916 net.cpp:144] Setting up relu5
I0614 19:49:34.943811 13916 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0614 19:49:34.943815 13916 net.cpp:159] Memory required for data: 409004600
I0614 19:49:34.943819 13916 layer_factory.hpp:77] Creating layer pool5
I0614 19:49:34.943825 13916 net.cpp:94] Creating Layer pool5
I0614 19:49:34.943830 13916 net.cpp:435] pool5 <- relu5
I0614 19:49:34.943833 13916 net.cpp:409] pool5 -> pool5
I0614 19:49:34.943840 13916 net.cpp:144] Setting up pool5
I0614 19:49:34.943845 13916 net.cpp:151] Top shape: 50 256 6 6 (460800)
I0614 19:49:34.943848 13916 net.cpp:159] Memory required for data: 410847800
I0614 19:49:34.943852 13916 layer_factory.hpp:77] Creating layer fc6
I0614 19:49:34.943859 13916 net.cpp:94] Creating Layer fc6
I0614 19:49:34.943862 13916 net.cpp:435] fc6 <- pool5
I0614 19:49:34.943867 13916 net.cpp:409] fc6 -> fc6
I0614 19:49:35.336122 13916 net.cpp:144] Setting up fc6
I0614 19:49:35.336148 13916 net.cpp:151] Top shape: 50 4096 (204800)
I0614 19:49:35.336155 13916 net.cpp:159] Memory required for data: 411667000
I0614 19:49:35.336164 13916 layer_factory.hpp:77] Creating layer relu6
I0614 19:49:35.336171 13916 net.cpp:94] Creating Layer relu6
I0614 19:49:35.336175 13916 net.cpp:435] relu6 <- fc6
I0614 19:49:35.336181 13916 net.cpp:409] relu6 -> relu6
I0614 19:49:35.336192 13916 net.cpp:144] Setting up relu6
I0614 19:49:35.336195 13916 net.cpp:151] Top shape: 50 4096 (204800)
I0614 19:49:35.336198 13916 net.cpp:159] Memory required for data: 412486200
I0614 19:49:35.336201 13916 layer_factory.hpp:77] Creating layer drop6
I0614 19:49:35.336207 13916 net.cpp:94] Creating Layer drop6
I0614 19:49:35.336210 13916 net.cpp:435] drop6 <- relu6
I0614 19:49:35.336215 13916 net.cpp:409] drop6 -> drop6
I0614 19:49:35.336220 13916 net.cpp:144] Setting up drop6
I0614 19:49:35.336223 13916 net.cpp:151] Top shape: 50 4096 (204800)
I0614 19:49:35.336227 13916 net.cpp:159] Memory required for data: 413305400
I0614 19:49:35.336230 13916 layer_factory.hpp:77] Creating layer fc7
I0614 19:49:35.336236 13916 net.cpp:94] Creating Layer fc7
I0614 19:49:35.336239 13916 net.cpp:435] fc7 <- drop6
I0614 19:49:35.336243 13916 net.cpp:409] fc7 -> fc7
I0614 19:49:35.503237 13916 net.cpp:144] Setting up fc7
I0614 19:49:35.503258 13916 net.cpp:151] Top shape: 50 4096 (204800)
I0614 19:49:35.503266 13916 net.cpp:159] Memory required for data: 414124600
I0614 19:49:35.503291 13916 layer_factory.hpp:77] Creating layer bn7
I0614 19:49:35.503300 13916 net.cpp:94] Creating Layer bn7
I0614 19:49:35.503304 13916 net.cpp:435] bn7 <- fc7
I0614 19:49:35.503310 13916 net.cpp:409] bn7 -> bn7
I0614 19:49:35.503363 13916 net.cpp:144] Setting up bn7
I0614 19:49:35.503366 13916 net.cpp:151] Top shape: 50 4096 (204800)
I0614 19:49:35.503389 13916 net.cpp:159] Memory required for data: 414943800
I0614 19:49:35.503396 13916 layer_factory.hpp:77] Creating layer relu7
I0614 19:49:35.503401 13916 net.cpp:94] Creating Layer relu7
I0614 19:49:35.503403 13916 net.cpp:435] relu7 <- bn7
I0614 19:49:35.503407 13916 net.cpp:409] relu7 -> relu7
I0614 19:49:35.503414 13916 net.cpp:144] Setting up relu7
I0614 19:49:35.503417 13916 net.cpp:151] Top shape: 50 4096 (204800)
I0614 19:49:35.503420 13916 net.cpp:159] Memory required for data: 415763000
I0614 19:49:35.503423 13916 layer_factory.hpp:77] Creating layer drop7
I0614 19:49:35.503428 13916 net.cpp:94] Creating Layer drop7
I0614 19:49:35.503432 13916 net.cpp:435] drop7 <- relu7
I0614 19:49:35.503435 13916 net.cpp:409] drop7 -> drop7
I0614 19:49:35.503440 13916 net.cpp:144] Setting up drop7
I0614 19:49:35.503443 13916 net.cpp:151] Top shape: 50 4096 (204800)
I0614 19:49:35.503448 13916 net.cpp:159] Memory required for data: 416582200
I0614 19:49:35.503450 13916 layer_factory.hpp:77] Creating layer fc8
I0614 19:49:35.503455 13916 net.cpp:94] Creating Layer fc8
I0614 19:49:35.503458 13916 net.cpp:435] fc8 <- drop7
I0614 19:49:35.503463 13916 net.cpp:409] fc8 -> fc8
I0614 19:49:35.503556 13916 net.cpp:144] Setting up fc8
I0614 19:49:35.503559 13916 net.cpp:151] Top shape: 50 2 (100)
I0614 19:49:35.503563 13916 net.cpp:159] Memory required for data: 416582600
I0614 19:49:35.503568 13916 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0614 19:49:35.503573 13916 net.cpp:94] Creating Layer fc8_fc8_0_split
I0614 19:49:35.503577 13916 net.cpp:435] fc8_fc8_0_split <- fc8
I0614 19:49:35.503582 13916 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0614 19:49:35.503587 13916 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0614 19:49:35.503592 13916 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_2
I0614 19:49:35.503599 13916 net.cpp:144] Setting up fc8_fc8_0_split
I0614 19:49:35.503602 13916 net.cpp:151] Top shape: 50 2 (100)
I0614 19:49:35.503607 13916 net.cpp:151] Top shape: 50 2 (100)
I0614 19:49:35.503610 13916 net.cpp:151] Top shape: 50 2 (100)
I0614 19:49:35.503614 13916 net.cpp:159] Memory required for data: 416583800
I0614 19:49:35.503618 13916 layer_factory.hpp:77] Creating layer accuracy
I0614 19:49:35.503623 13916 net.cpp:94] Creating Layer accuracy
I0614 19:49:35.503626 13916 net.cpp:435] accuracy <- fc8_fc8_0_split_0
I0614 19:49:35.503630 13916 net.cpp:435] accuracy <- label_data_1_split_0
I0614 19:49:35.503635 13916 net.cpp:409] accuracy -> accuracy
I0614 19:49:35.503641 13916 net.cpp:144] Setting up accuracy
I0614 19:49:35.503644 13916 net.cpp:151] Top shape: (1)
I0614 19:49:35.503648 13916 net.cpp:159] Memory required for data: 416583804
I0614 19:49:35.503652 13916 layer_factory.hpp:77] Creating layer loss
I0614 19:49:35.503656 13916 net.cpp:94] Creating Layer loss
I0614 19:49:35.503660 13916 net.cpp:435] loss <- fc8_fc8_0_split_1
I0614 19:49:35.503664 13916 net.cpp:435] loss <- label_data_1_split_1
I0614 19:49:35.503669 13916 net.cpp:409] loss -> loss
I0614 19:49:35.503676 13916 layer_factory.hpp:77] Creating layer loss
I0614 19:49:35.503693 13916 net.cpp:144] Setting up loss
I0614 19:49:35.503697 13916 net.cpp:151] Top shape: (1)
I0614 19:49:35.503701 13916 net.cpp:154]     with loss weight 1
I0614 19:49:35.503732 13916 net.cpp:159] Memory required for data: 416583808
I0614 19:49:35.503736 13916 layer_factory.hpp:77] Creating layer accuracy-top1
I0614 19:49:35.503741 13916 net.cpp:94] Creating Layer accuracy-top1
I0614 19:49:35.503743 13916 net.cpp:435] accuracy-top1 <- fc8_fc8_0_split_2
I0614 19:49:35.503747 13916 net.cpp:435] accuracy-top1 <- label_data_1_split_2
I0614 19:49:35.503752 13916 net.cpp:409] accuracy-top1 -> top-1
I0614 19:49:35.503757 13916 net.cpp:144] Setting up accuracy-top1
I0614 19:49:35.503760 13916 net.cpp:151] Top shape: (1)
I0614 19:49:35.503764 13916 net.cpp:159] Memory required for data: 416583812
I0614 19:49:35.503767 13916 net.cpp:222] accuracy-top1 does not need backward computation.
I0614 19:49:35.503772 13916 net.cpp:220] loss needs backward computation.
I0614 19:49:35.503782 13916 net.cpp:222] accuracy does not need backward computation.
I0614 19:49:35.503785 13916 net.cpp:220] fc8_fc8_0_split needs backward computation.
I0614 19:49:35.503788 13916 net.cpp:220] fc8 needs backward computation.
I0614 19:49:35.503793 13916 net.cpp:220] drop7 needs backward computation.
I0614 19:49:35.503795 13916 net.cpp:220] relu7 needs backward computation.
I0614 19:49:35.503799 13916 net.cpp:220] bn7 needs backward computation.
I0614 19:49:35.503803 13916 net.cpp:220] fc7 needs backward computation.
I0614 19:49:35.503806 13916 net.cpp:220] drop6 needs backward computation.
I0614 19:49:35.503810 13916 net.cpp:220] relu6 needs backward computation.
I0614 19:49:35.503814 13916 net.cpp:220] fc6 needs backward computation.
I0614 19:49:35.503818 13916 net.cpp:220] pool5 needs backward computation.
I0614 19:49:35.503821 13916 net.cpp:220] relu5 needs backward computation.
I0614 19:49:35.503825 13916 net.cpp:220] conv5 needs backward computation.
I0614 19:49:35.503844 13916 net.cpp:220] relu4 needs backward computation.
I0614 19:49:35.503849 13916 net.cpp:220] conv4 needs backward computation.
I0614 19:49:35.503852 13916 net.cpp:220] relu3 needs backward computation.
I0614 19:49:35.503856 13916 net.cpp:220] conv3 needs backward computation.
I0614 19:49:35.503860 13916 net.cpp:220] pool2 needs backward computation.
I0614 19:49:35.503865 13916 net.cpp:220] relu2 needs backward computation.
I0614 19:49:35.503868 13916 net.cpp:220] bn2 needs backward computation.
I0614 19:49:35.503872 13916 net.cpp:220] conv2 needs backward computation.
I0614 19:49:35.503876 13916 net.cpp:220] pool1 needs backward computation.
I0614 19:49:35.503880 13916 net.cpp:220] relu1 needs backward computation.
I0614 19:49:35.503885 13916 net.cpp:220] bn1 needs backward computation.
I0614 19:49:35.503888 13916 net.cpp:220] conv1 needs backward computation.
I0614 19:49:35.503892 13916 net.cpp:222] label_data_1_split does not need backward computation.
I0614 19:49:35.503897 13916 net.cpp:222] data does not need backward computation.
I0614 19:49:35.503901 13916 net.cpp:264] This network produces output accuracy
I0614 19:49:35.503904 13916 net.cpp:264] This network produces output loss
I0614 19:49:35.503908 13916 net.cpp:264] This network produces output top-1
I0614 19:49:35.503931 13916 net.cpp:284] Network initialization done.
I0614 19:49:35.504009 13916 net_counter.cpp:104] Convolution layer conv1 ops: 111804000
I0614 19:49:35.504014 13916 net_counter.cpp:108] Convolution layer conv1 params: 18528
I0614 19:49:35.504017 13916 net_counter.cpp:108] BatchNorm layer bn1 params: 385
I0614 19:49:35.504021 13916 net_counter.cpp:104] Convolution layer conv2 ops: 895981824
I0614 19:49:35.504025 13916 net_counter.cpp:108] Convolution layer conv2 params: 614656
I0614 19:49:35.504029 13916 net_counter.cpp:108] BatchNorm layer bn2 params: 1025
I0614 19:49:35.504034 13916 net_counter.cpp:104] Convolution layer conv3 ops: 299105664
I0614 19:49:35.504036 13916 net_counter.cpp:108] Convolution layer conv3 params: 885120
I0614 19:49:35.504040 13916 net_counter.cpp:104] Convolution layer conv4 ops: 448626048
I0614 19:49:35.504045 13916 net_counter.cpp:108] Convolution layer conv4 params: 1327488
I0614 19:49:35.504048 13916 net_counter.cpp:104] Convolution layer conv5 ops: 299084032
I0614 19:49:35.504051 13916 net_counter.cpp:108] Convolution layer conv5 params: 884992
I0614 19:49:35.504055 13916 net_counter.cpp:108] BatchNorm layer bn7 params: 16385
I0614 19:49:35.504060 13916 net_counter.cpp:114] Total operations: 2054601568
I0614 19:49:35.504062 13916 net_counter.cpp:115] Total params: 3748579
(c) Copyright 2016â2019 Xilinx, Inc. All rights reserved.

I0614 19:49:36.637374 13952 net.cpp:323] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0614 19:49:36.637624 13952 net.cpp:52] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_value: 106
    mean_value: 116
    mean_value: 124
  }
  data_param {
    source: "input/lmdb/valid_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 78
    pad: 0
    kernel_size: 8
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "bn1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 180
    pad: 2
    kernel_size: 5
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "bn2"
  top: "relu2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 40
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 40
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 26
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "relu6"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "drop6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn7"
  type: "BatchNorm"
  bottom: "fc7"
  top: "bn7"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "bn7"
  top: "relu7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "relu7"
  top: "drop7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "drop7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy-top1"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "top-1"
  include {
    phase: TEST
  }
}
I0614 19:49:36.637877 13952 layer_factory.hpp:77] Creating layer data
I0614 19:49:36.638754 13952 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0614 19:49:36.639032 13952 net.cpp:94] Creating Layer data
I0614 19:49:36.639042 13952 net.cpp:409] data -> data
I0614 19:49:36.639053 13952 net.cpp:409] data -> label
I0614 19:49:36.642335 13985 db_lmdb.cpp:35] Opened lmdb input/lmdb/valid_lmdb
I0614 19:49:36.642369 13985 db_lmdb.cpp:38] Items count: 4000
I0614 19:49:36.642410 13985 data_reader.cpp:124] TEST: reading data using 1 channel(s)
I0614 19:49:36.642751 13952 data_layer.cpp:78] ReshapePrefetch 50, 3, 227, 227
I0614 19:49:36.642762 13952 data_layer.cpp:83] output data size: 50,3,227,227
I0614 19:49:36.754844 13952 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0614 19:49:36.754966 13952 net.cpp:144] Setting up data
I0614 19:49:36.754976 13952 net.cpp:151] Top shape: 50 3 227 227 (7729350)
I0614 19:49:36.754985 13952 net.cpp:151] Top shape: 50 (50)
I0614 19:49:36.754990 13952 net.cpp:159] Memory required for data: 30917600
I0614 19:49:36.754995 13952 layer_factory.hpp:77] Creating layer label_data_1_split
I0614 19:49:36.755005 13952 net.cpp:94] Creating Layer label_data_1_split
I0614 19:49:36.755009 13952 net.cpp:435] label_data_1_split <- label
I0614 19:49:36.755015 13952 net.cpp:409] label_data_1_split -> label_data_1_split_0
I0614 19:49:36.755024 13952 net.cpp:409] label_data_1_split -> label_data_1_split_1
I0614 19:49:36.755029 13952 net.cpp:409] label_data_1_split -> label_data_1_split_2
I0614 19:49:36.755038 13952 net.cpp:144] Setting up label_data_1_split
I0614 19:49:36.755041 13952 net.cpp:151] Top shape: 50 (50)
I0614 19:49:36.755045 13952 net.cpp:151] Top shape: 50 (50)
I0614 19:49:36.755048 13952 net.cpp:151] Top shape: 50 (50)
I0614 19:49:36.755053 13952 net.cpp:159] Memory required for data: 30918200
I0614 19:49:36.755056 13952 layer_factory.hpp:77] Creating layer conv1
I0614 19:49:36.755065 13952 net.cpp:94] Creating Layer conv1
I0614 19:49:36.755069 13952 net.cpp:435] conv1 <- data
I0614 19:49:36.755074 13952 net.cpp:409] conv1 -> conv1
I0614 19:49:36.755270 13952 net.cpp:144] Setting up conv1
I0614 19:49:36.755273 13952 net.cpp:151] Top shape: 50 78 55 55 (11797500)
I0614 19:49:36.755278 13952 net.cpp:159] Memory required for data: 78108200
I0614 19:49:36.755288 13952 layer_factory.hpp:77] Creating layer bn1
I0614 19:49:36.755295 13952 net.cpp:94] Creating Layer bn1
I0614 19:49:36.755298 13952 net.cpp:435] bn1 <- conv1
I0614 19:49:36.755302 13952 net.cpp:409] bn1 -> bn1
I0614 19:49:36.755331 13952 net.cpp:144] Setting up bn1
I0614 19:49:36.755352 13952 net.cpp:151] Top shape: 50 78 55 55 (11797500)
I0614 19:49:36.755357 13952 net.cpp:159] Memory required for data: 125298200
I0614 19:49:36.755367 13952 layer_factory.hpp:77] Creating layer relu1
I0614 19:49:36.755373 13952 net.cpp:94] Creating Layer relu1
I0614 19:49:36.755375 13952 net.cpp:435] relu1 <- bn1
I0614 19:49:36.755380 13952 net.cpp:409] relu1 -> relu1
I0614 19:49:36.755386 13952 net.cpp:144] Setting up relu1
I0614 19:49:36.755390 13952 net.cpp:151] Top shape: 50 78 55 55 (11797500)
I0614 19:49:36.755395 13952 net.cpp:159] Memory required for data: 172488200
I0614 19:49:36.755398 13952 layer_factory.hpp:77] Creating layer pool1
I0614 19:49:36.755403 13952 net.cpp:94] Creating Layer pool1
I0614 19:49:36.755407 13952 net.cpp:435] pool1 <- relu1
I0614 19:49:36.755411 13952 net.cpp:409] pool1 -> pool1
I0614 19:49:36.755421 13952 net.cpp:144] Setting up pool1
I0614 19:49:36.755425 13952 net.cpp:151] Top shape: 50 78 27 27 (2843100)
I0614 19:49:36.755429 13952 net.cpp:159] Memory required for data: 183860600
I0614 19:49:36.755434 13952 layer_factory.hpp:77] Creating layer conv2
I0614 19:49:36.755439 13952 net.cpp:94] Creating Layer conv2
I0614 19:49:36.755443 13952 net.cpp:435] conv2 <- pool1
I0614 19:49:36.755448 13952 net.cpp:409] conv2 -> conv2
I0614 19:49:36.759459 13952 net.cpp:144] Setting up conv2
I0614 19:49:36.759470 13952 net.cpp:151] Top shape: 50 180 27 27 (6561000)
I0614 19:49:36.759476 13952 net.cpp:159] Memory required for data: 210104600
I0614 19:49:36.759485 13952 layer_factory.hpp:77] Creating layer bn2
I0614 19:49:36.759493 13952 net.cpp:94] Creating Layer bn2
I0614 19:49:36.759497 13952 net.cpp:435] bn2 <- conv2
I0614 19:49:36.759502 13952 net.cpp:409] bn2 -> bn2
I0614 19:49:36.759531 13952 net.cpp:144] Setting up bn2
I0614 19:49:36.759533 13952 net.cpp:151] Top shape: 50 180 27 27 (6561000)
I0614 19:49:36.759538 13952 net.cpp:159] Memory required for data: 236348600
I0614 19:49:36.759544 13952 layer_factory.hpp:77] Creating layer relu2
I0614 19:49:36.759549 13952 net.cpp:94] Creating Layer relu2
I0614 19:49:36.759553 13952 net.cpp:435] relu2 <- bn2
I0614 19:49:36.759558 13952 net.cpp:409] relu2 -> relu2
I0614 19:49:36.759564 13952 net.cpp:144] Setting up relu2
I0614 19:49:36.759568 13952 net.cpp:151] Top shape: 50 180 27 27 (6561000)
I0614 19:49:36.759589 13952 net.cpp:159] Memory required for data: 262592600
I0614 19:49:36.759593 13952 layer_factory.hpp:77] Creating layer pool2
I0614 19:49:36.759598 13952 net.cpp:94] Creating Layer pool2
I0614 19:49:36.759600 13952 net.cpp:435] pool2 <- relu2
I0614 19:49:36.759605 13952 net.cpp:409] pool2 -> pool2
I0614 19:49:36.759613 13952 net.cpp:144] Setting up pool2
I0614 19:49:36.759615 13952 net.cpp:151] Top shape: 50 180 13 13 (1521000)
I0614 19:49:36.759620 13952 net.cpp:159] Memory required for data: 268676600
I0614 19:49:36.759624 13952 layer_factory.hpp:77] Creating layer conv3
I0614 19:49:36.759630 13952 net.cpp:94] Creating Layer conv3
I0614 19:49:36.759634 13952 net.cpp:435] conv3 <- pool2
I0614 19:49:36.759639 13952 net.cpp:409] conv3 -> conv3
I0614 19:49:36.760447 13952 net.cpp:144] Setting up conv3
I0614 19:49:36.760452 13952 net.cpp:151] Top shape: 50 40 13 13 (338000)
I0614 19:49:36.760458 13952 net.cpp:159] Memory required for data: 270028600
I0614 19:49:36.760463 13952 layer_factory.hpp:77] Creating layer relu3
I0614 19:49:36.760468 13952 net.cpp:94] Creating Layer relu3
I0614 19:49:36.760471 13952 net.cpp:435] relu3 <- conv3
I0614 19:49:36.760476 13952 net.cpp:409] relu3 -> relu3
I0614 19:49:36.760483 13952 net.cpp:144] Setting up relu3
I0614 19:49:36.760485 13952 net.cpp:151] Top shape: 50 40 13 13 (338000)
I0614 19:49:36.760490 13952 net.cpp:159] Memory required for data: 271380600
I0614 19:49:36.760493 13952 layer_factory.hpp:77] Creating layer conv4
I0614 19:49:36.760500 13952 net.cpp:94] Creating Layer conv4
I0614 19:49:36.760504 13952 net.cpp:435] conv4 <- relu3
I0614 19:49:36.760509 13952 net.cpp:409] conv4 -> conv4
I0614 19:49:36.760704 13952 net.cpp:144] Setting up conv4
I0614 19:49:36.760707 13952 net.cpp:151] Top shape: 50 40 13 13 (338000)
I0614 19:49:36.760722 13952 net.cpp:159] Memory required for data: 272732600
I0614 19:49:36.760728 13952 layer_factory.hpp:77] Creating layer relu4
I0614 19:49:36.760733 13952 net.cpp:94] Creating Layer relu4
I0614 19:49:36.760737 13952 net.cpp:435] relu4 <- conv4
I0614 19:49:36.760741 13952 net.cpp:409] relu4 -> relu4
I0614 19:49:36.760748 13952 net.cpp:144] Setting up relu4
I0614 19:49:36.760754 13952 net.cpp:151] Top shape: 50 40 13 13 (338000)
I0614 19:49:36.760759 13952 net.cpp:159] Memory required for data: 274084600
I0614 19:49:36.760763 13952 layer_factory.hpp:77] Creating layer conv5
I0614 19:49:36.760768 13952 net.cpp:94] Creating Layer conv5
I0614 19:49:36.760772 13952 net.cpp:435] conv5 <- relu4
I0614 19:49:36.760777 13952 net.cpp:409] conv5 -> conv5
I0614 19:49:36.760910 13952 net.cpp:144] Setting up conv5
I0614 19:49:36.760913 13952 net.cpp:151] Top shape: 50 26 13 13 (219700)
I0614 19:49:36.760918 13952 net.cpp:159] Memory required for data: 274963400
I0614 19:49:36.760922 13952 layer_factory.hpp:77] Creating layer relu5
I0614 19:49:36.760927 13952 net.cpp:94] Creating Layer relu5
I0614 19:49:36.760931 13952 net.cpp:435] relu5 <- conv5
I0614 19:49:36.760936 13952 net.cpp:409] relu5 -> relu5
I0614 19:49:36.760941 13952 net.cpp:144] Setting up relu5
I0614 19:49:36.760946 13952 net.cpp:151] Top shape: 50 26 13 13 (219700)
I0614 19:49:36.760949 13952 net.cpp:159] Memory required for data: 275842200
I0614 19:49:36.760953 13952 layer_factory.hpp:77] Creating layer pool5
I0614 19:49:36.760957 13952 net.cpp:94] Creating Layer pool5
I0614 19:49:36.760962 13952 net.cpp:435] pool5 <- relu5
I0614 19:49:36.760965 13952 net.cpp:409] pool5 -> pool5
I0614 19:49:36.760972 13952 net.cpp:144] Setting up pool5
I0614 19:49:36.760977 13952 net.cpp:151] Top shape: 50 26 6 6 (46800)
I0614 19:49:36.760980 13952 net.cpp:159] Memory required for data: 276029400
I0614 19:49:36.760984 13952 layer_factory.hpp:77] Creating layer fc6
I0614 19:49:36.760990 13952 net.cpp:94] Creating Layer fc6
I0614 19:49:36.760993 13952 net.cpp:435] fc6 <- pool5
I0614 19:49:36.760998 13952 net.cpp:409] fc6 -> fc6
I0614 19:49:36.801414 13952 net.cpp:144] Setting up fc6
I0614 19:49:36.801429 13952 net.cpp:151] Top shape: 50 4096 (204800)
I0614 19:49:36.801436 13952 net.cpp:159] Memory required for data: 276848600
I0614 19:49:36.801443 13952 layer_factory.hpp:77] Creating layer relu6
I0614 19:49:36.801450 13952 net.cpp:94] Creating Layer relu6
I0614 19:49:36.801455 13952 net.cpp:435] relu6 <- fc6
I0614 19:49:36.801460 13952 net.cpp:409] relu6 -> relu6
I0614 19:49:36.801470 13952 net.cpp:144] Setting up relu6
I0614 19:49:36.801473 13952 net.cpp:151] Top shape: 50 4096 (204800)
I0614 19:49:36.801478 13952 net.cpp:159] Memory required for data: 277667800
I0614 19:49:36.801481 13952 layer_factory.hpp:77] Creating layer drop6
I0614 19:49:36.801487 13952 net.cpp:94] Creating Layer drop6
I0614 19:49:36.801491 13952 net.cpp:435] drop6 <- relu6
I0614 19:49:36.801496 13952 net.cpp:409] drop6 -> drop6
I0614 19:49:36.801501 13952 net.cpp:144] Setting up drop6
I0614 19:49:36.801504 13952 net.cpp:151] Top shape: 50 4096 (204800)
I0614 19:49:36.801509 13952 net.cpp:159] Memory required for data: 278487000
I0614 19:49:36.801512 13952 layer_factory.hpp:77] Creating layer fc7
I0614 19:49:36.801518 13952 net.cpp:94] Creating Layer fc7
I0614 19:49:36.801522 13952 net.cpp:435] fc7 <- drop6
I0614 19:49:36.801527 13952 net.cpp:409] fc7 -> fc7
I0614 19:49:36.971494 13952 net.cpp:144] Setting up fc7
I0614 19:49:36.971519 13952 net.cpp:151] Top shape: 50 4096 (204800)
I0614 19:49:36.971527 13952 net.cpp:159] Memory required for data: 279306200
I0614 19:49:36.971535 13952 layer_factory.hpp:77] Creating layer bn7
I0614 19:49:36.971544 13952 net.cpp:94] Creating Layer bn7
I0614 19:49:36.971547 13952 net.cpp:435] bn7 <- fc7
I0614 19:49:36.971555 13952 net.cpp:409] bn7 -> bn7
I0614 19:49:36.971678 13952 net.cpp:144] Setting up bn7
I0614 19:49:36.971683 13952 net.cpp:151] Top shape: 50 4096 (204800)
I0614 19:49:36.971686 13952 net.cpp:159] Memory required for data: 280125400
I0614 19:49:36.971711 13952 layer_factory.hpp:77] Creating layer relu7
I0614 19:49:36.971717 13952 net.cpp:94] Creating Layer relu7
I0614 19:49:36.971720 13952 net.cpp:435] relu7 <- bn7
I0614 19:49:36.971725 13952 net.cpp:409] relu7 -> relu7
I0614 19:49:36.971732 13952 net.cpp:144] Setting up relu7
I0614 19:49:36.971735 13952 net.cpp:151] Top shape: 50 4096 (204800)
I0614 19:49:36.971740 13952 net.cpp:159] Memory required for data: 280944600
I0614 19:49:36.971743 13952 layer_factory.hpp:77] Creating layer drop7
I0614 19:49:36.971750 13952 net.cpp:94] Creating Layer drop7
I0614 19:49:36.971752 13952 net.cpp:435] drop7 <- relu7
I0614 19:49:36.971756 13952 net.cpp:409] drop7 -> drop7
I0614 19:49:36.971763 13952 net.cpp:144] Setting up drop7
I0614 19:49:36.971766 13952 net.cpp:151] Top shape: 50 4096 (204800)
I0614 19:49:36.971771 13952 net.cpp:159] Memory required for data: 281763800
I0614 19:49:36.971773 13952 layer_factory.hpp:77] Creating layer fc8
I0614 19:49:36.971779 13952 net.cpp:94] Creating Layer fc8
I0614 19:49:36.971783 13952 net.cpp:435] fc8 <- drop7
I0614 19:49:36.971789 13952 net.cpp:409] fc8 -> fc8
I0614 19:49:36.971915 13952 net.cpp:144] Setting up fc8
I0614 19:49:36.971920 13952 net.cpp:151] Top shape: 50 2 (100)
I0614 19:49:36.971923 13952 net.cpp:159] Memory required for data: 281764200
I0614 19:49:36.971928 13952 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0614 19:49:36.971935 13952 net.cpp:94] Creating Layer fc8_fc8_0_split
I0614 19:49:36.971938 13952 net.cpp:435] fc8_fc8_0_split <- fc8
I0614 19:49:36.971944 13952 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0614 19:49:36.971951 13952 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0614 19:49:36.971956 13952 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_2
I0614 19:49:36.971962 13952 net.cpp:144] Setting up fc8_fc8_0_split
I0614 19:49:36.971966 13952 net.cpp:151] Top shape: 50 2 (100)
I0614 19:49:36.971971 13952 net.cpp:151] Top shape: 50 2 (100)
I0614 19:49:36.971974 13952 net.cpp:151] Top shape: 50 2 (100)
I0614 19:49:36.971978 13952 net.cpp:159] Memory required for data: 281765400
I0614 19:49:36.971982 13952 layer_factory.hpp:77] Creating layer accuracy
I0614 19:49:36.971992 13952 net.cpp:94] Creating Layer accuracy
I0614 19:49:36.971995 13952 net.cpp:435] accuracy <- fc8_fc8_0_split_0
I0614 19:49:36.972000 13952 net.cpp:435] accuracy <- label_data_1_split_0
I0614 19:49:36.972007 13952 net.cpp:409] accuracy -> accuracy
I0614 19:49:36.972013 13952 net.cpp:144] Setting up accuracy
I0614 19:49:36.972016 13952 net.cpp:151] Top shape: (1)
I0614 19:49:36.972020 13952 net.cpp:159] Memory required for data: 281765404
I0614 19:49:36.972024 13952 layer_factory.hpp:77] Creating layer loss
I0614 19:49:36.972029 13952 net.cpp:94] Creating Layer loss
I0614 19:49:36.972033 13952 net.cpp:435] loss <- fc8_fc8_0_split_1
I0614 19:49:36.972038 13952 net.cpp:435] loss <- label_data_1_split_1
I0614 19:49:36.972043 13952 net.cpp:409] loss -> loss
I0614 19:49:36.972051 13952 layer_factory.hpp:77] Creating layer loss
I0614 19:49:36.972067 13952 net.cpp:144] Setting up loss
I0614 19:49:36.972071 13952 net.cpp:151] Top shape: (1)
I0614 19:49:36.972075 13952 net.cpp:154]     with loss weight 1
I0614 19:49:36.972108 13952 net.cpp:159] Memory required for data: 281765408
I0614 19:49:36.972112 13952 layer_factory.hpp:77] Creating layer accuracy-top1
I0614 19:49:36.972117 13952 net.cpp:94] Creating Layer accuracy-top1
I0614 19:49:36.972121 13952 net.cpp:435] accuracy-top1 <- fc8_fc8_0_split_2
I0614 19:49:36.972126 13952 net.cpp:435] accuracy-top1 <- label_data_1_split_2
I0614 19:49:36.972129 13952 net.cpp:409] accuracy-top1 -> top-1
I0614 19:49:36.972136 13952 net.cpp:144] Setting up accuracy-top1
I0614 19:49:36.972138 13952 net.cpp:151] Top shape: (1)
I0614 19:49:36.972142 13952 net.cpp:159] Memory required for data: 281765412
I0614 19:49:36.972146 13952 net.cpp:222] accuracy-top1 does not need backward computation.
I0614 19:49:36.972152 13952 net.cpp:220] loss needs backward computation.
I0614 19:49:36.972157 13952 net.cpp:222] accuracy does not need backward computation.
I0614 19:49:36.972167 13952 net.cpp:220] fc8_fc8_0_split needs backward computation.
I0614 19:49:36.972172 13952 net.cpp:220] fc8 needs backward computation.
I0614 19:49:36.972175 13952 net.cpp:220] drop7 needs backward computation.
I0614 19:49:36.972179 13952 net.cpp:220] relu7 needs backward computation.
I0614 19:49:36.972182 13952 net.cpp:220] bn7 needs backward computation.
I0614 19:49:36.972187 13952 net.cpp:220] fc7 needs backward computation.
I0614 19:49:36.972190 13952 net.cpp:220] drop6 needs backward computation.
I0614 19:49:36.972194 13952 net.cpp:220] relu6 needs backward computation.
I0614 19:49:36.972198 13952 net.cpp:220] fc6 needs backward computation.
I0614 19:49:36.972203 13952 net.cpp:220] pool5 needs backward computation.
I0614 19:49:36.972206 13952 net.cpp:220] relu5 needs backward computation.
I0614 19:49:36.972210 13952 net.cpp:220] conv5 needs backward computation.
I0614 19:49:36.972214 13952 net.cpp:220] relu4 needs backward computation.
I0614 19:49:36.972218 13952 net.cpp:220] conv4 needs backward computation.
I0614 19:49:36.972221 13952 net.cpp:220] relu3 needs backward computation.
I0614 19:49:36.972225 13952 net.cpp:220] conv3 needs backward computation.
I0614 19:49:36.972229 13952 net.cpp:220] pool2 needs backward computation.
I0614 19:49:36.972234 13952 net.cpp:220] relu2 needs backward computation.
I0614 19:49:36.972237 13952 net.cpp:220] bn2 needs backward computation.
I0614 19:49:36.972241 13952 net.cpp:220] conv2 needs backward computation.
I0614 19:49:36.972245 13952 net.cpp:220] pool1 needs backward computation.
I0614 19:49:36.972249 13952 net.cpp:220] relu1 needs backward computation.
I0614 19:49:36.972252 13952 net.cpp:220] bn1 needs backward computation.
I0614 19:49:36.972256 13952 net.cpp:220] conv1 needs backward computation.
I0614 19:49:36.972261 13952 net.cpp:222] label_data_1_split does not need backward computation.
I0614 19:49:36.972265 13952 net.cpp:222] data does not need backward computation.
I0614 19:49:36.972270 13952 net.cpp:264] This network produces output accuracy
I0614 19:49:36.972272 13952 net.cpp:264] This network produces output loss
I0614 19:49:36.972276 13952 net.cpp:264] This network produces output top-1
I0614 19:49:36.972302 13952 net.cpp:284] Network initialization done.
I0614 19:49:36.972388 13952 net_counter.cpp:104] Convolution layer conv1 ops: 90840750
I0614 19:49:36.972391 13952 net_counter.cpp:108] Convolution layer conv1 params: 15054
I0614 19:49:36.972395 13952 net_counter.cpp:108] BatchNorm layer bn1 params: 313
I0614 19:49:36.972399 13952 net_counter.cpp:104] Convolution layer conv2 ops: 511889220
I0614 19:49:36.972404 13952 net_counter.cpp:108] Convolution layer conv2 params: 351180
I0614 19:49:36.972406 13952 net_counter.cpp:108] BatchNorm layer bn2 params: 721
I0614 19:49:36.972410 13952 net_counter.cpp:104] Convolution layer conv3 ops: 21909160
I0614 19:49:36.972414 13952 net_counter.cpp:108] Convolution layer conv3 params: 64840
I0614 19:49:36.972419 13952 net_counter.cpp:104] Convolution layer conv4 ops: 4873960
I0614 19:49:36.972421 13952 net_counter.cpp:108] Convolution layer conv4 params: 14440
I0614 19:49:36.972425 13952 net_counter.cpp:104] Convolution layer conv5 ops: 3168074
I0614 19:49:36.972429 13952 net_counter.cpp:108] Convolution layer conv5 params: 9386
I0614 19:49:36.972434 13952 net_counter.cpp:108] BatchNorm layer bn7 params: 16385
I0614 19:49:36.972438 13952 net_counter.cpp:114] Total operations: 632681164
I0614 19:49:36.972441 13952 net_counter.cpp:115] Total params: 472319
mv: '/workspace/TUTORIALS/VAI2.0bash-Caffe-ML-CATSvsDOGS/files/pruning/alexnetBNnoLRN/transformed.caffemodel' and '/workspace/TUTORIALS/VAI2.0bash-Caffe-ML-CATSvsDOGS/files/pruning/alexnetBNnoLRN/transformed.caffemodel' are the same file
Requirement already satisfied: lmdb==0.98 in /opt/vitis_ai/conda/envs/vitis-ai-caffe/lib/python3.6/site-packages (0.98)
project ML_DIR is /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files
CAFFE_TOOLS_DIR is /workspace/VAI2.0/tutorials/caffe-xilinx
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0614 19:49:42.930713 14053 gpu_memory.cpp:53] GPUMemory::Manager initialized with Caching (CUB) GPU Allocator
I0614 19:49:42.930786 14053 gpu_memory.cpp:55] Total memory: 25635127296, Free: 24822874112, dev_info[0]: total=25635127296 free=24822874112
I0614 19:49:42.931118 14053 vai_q.cpp:260] Using GPUs 0
I0614 19:49:42.931365 14053 vai_q.cpp:265] GPU 0: Quadro P6000
I0614 19:49:45.165089 14053 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0614 19:49:45.165115 14053 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0614 19:49:45.165118 14053 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy-top1
I0614 19:49:45.165138 14053 net.cpp:52] Initializing net from parameters: 
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    crop_size: 227
    mean_value: 106
    mean_value: 116
    mean_value: 124
  }
  image_data_param {
    source: "deploy/alexnetBNnoLRN/pruned/data/calib/calibration.txt"
    batch_size: 10
    shuffle: true
    root_folder: "deploy/alexnetBNnoLRN/pruned/data/calib/"
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 78
    pad: 0
    kernel_size: 8
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "bn1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 180
    pad: 2
    kernel_size: 5
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "bn2"
  top: "relu2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 40
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 40
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 26
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "relu6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn7"
  type: "BatchNorm"
  bottom: "fc7"
  top: "bn7"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "bn7"
  top: "relu7"
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "relu7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0614 19:49:45.165372 14053 layer_factory.hpp:77] Creating layer data
I0614 19:49:45.165868 14053 net.cpp:94] Creating Layer data
I0614 19:49:45.165879 14053 net.cpp:409] data -> data
I0614 19:49:45.165894 14053 net.cpp:409] data -> label
I0614 19:49:45.166783 14053 image_data_layer.cpp:41] Opening file deploy/alexnetBNnoLRN/pruned/data/calib/calibration.txt
I0614 19:49:45.167733 14053 image_data_layer.cpp:51] Shuffling data
I0614 19:49:45.167752 14053 image_data_layer.cpp:56] A total of 200 images.
I0614 19:49:45.172610 14053 image_data_layer.cpp:84] output data size: 10,3,227,227
I0614 19:49:45.195580 14053 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0614 19:49:45.195657 14053 net.cpp:144] Setting up data
I0614 19:49:45.195660 14053 net.cpp:151] Top shape: 10 3 227 227 (1545870)
I0614 19:49:45.195668 14053 net.cpp:151] Top shape: 10 (10)
I0614 19:49:45.195672 14053 net.cpp:159] Memory required for data: 6183520
I0614 19:49:45.195677 14053 layer_factory.hpp:77] Creating layer conv1
I0614 19:49:45.195696 14053 net.cpp:94] Creating Layer conv1
I0614 19:49:45.195700 14053 net.cpp:435] conv1 <- data
I0614 19:49:45.195706 14053 net.cpp:409] conv1 -> conv1
I0614 19:49:45.196995 14053 net.cpp:144] Setting up conv1
I0614 19:49:45.197005 14053 net.cpp:151] Top shape: 10 78 55 55 (2359500)
I0614 19:49:45.197010 14053 net.cpp:159] Memory required for data: 15621520
I0614 19:49:45.197031 14053 layer_factory.hpp:77] Creating layer bn1
I0614 19:49:45.197044 14053 net.cpp:94] Creating Layer bn1
I0614 19:49:45.197048 14053 net.cpp:435] bn1 <- conv1
I0614 19:49:45.197053 14053 net.cpp:409] bn1 -> bn1
I0614 19:49:45.197623 14053 net.cpp:144] Setting up bn1
I0614 19:49:45.197629 14053 net.cpp:151] Top shape: 10 78 55 55 (2359500)
I0614 19:49:45.197635 14053 net.cpp:159] Memory required for data: 25059520
I0614 19:49:45.197644 14053 layer_factory.hpp:77] Creating layer relu1
I0614 19:49:45.197649 14053 net.cpp:94] Creating Layer relu1
I0614 19:49:45.197654 14053 net.cpp:435] relu1 <- bn1
I0614 19:49:45.197657 14053 net.cpp:409] relu1 -> relu1
I0614 19:49:45.197698 14053 net.cpp:144] Setting up relu1
I0614 19:49:45.197701 14053 net.cpp:151] Top shape: 10 78 55 55 (2359500)
I0614 19:49:45.197705 14053 net.cpp:159] Memory required for data: 34497520
I0614 19:49:45.197708 14053 layer_factory.hpp:77] Creating layer pool1
I0614 19:49:45.197715 14053 net.cpp:94] Creating Layer pool1
I0614 19:49:45.197717 14053 net.cpp:435] pool1 <- relu1
I0614 19:49:45.197721 14053 net.cpp:409] pool1 -> pool1
I0614 19:49:45.197757 14053 net.cpp:144] Setting up pool1
I0614 19:49:45.197759 14053 net.cpp:151] Top shape: 10 78 27 27 (568620)
I0614 19:49:45.197764 14053 net.cpp:159] Memory required for data: 36772000
I0614 19:49:45.197768 14053 layer_factory.hpp:77] Creating layer conv2
I0614 19:49:45.197778 14053 net.cpp:94] Creating Layer conv2
I0614 19:49:45.197783 14053 net.cpp:435] conv2 <- pool1
I0614 19:49:45.197788 14053 net.cpp:409] conv2 -> conv2
I0614 19:49:45.201357 14053 net.cpp:144] Setting up conv2
I0614 19:49:45.201368 14053 net.cpp:151] Top shape: 10 180 27 27 (1312200)
I0614 19:49:45.201375 14053 net.cpp:159] Memory required for data: 42020800
I0614 19:49:45.201388 14053 layer_factory.hpp:77] Creating layer bn2
I0614 19:49:45.201396 14053 net.cpp:94] Creating Layer bn2
I0614 19:49:45.201400 14053 net.cpp:435] bn2 <- conv2
I0614 19:49:45.201404 14053 net.cpp:409] bn2 -> bn2
I0614 19:49:45.201712 14053 net.cpp:144] Setting up bn2
I0614 19:49:45.201719 14053 net.cpp:151] Top shape: 10 180 27 27 (1312200)
I0614 19:49:45.201725 14053 net.cpp:159] Memory required for data: 47269600
I0614 19:49:45.201733 14053 layer_factory.hpp:77] Creating layer relu2
I0614 19:49:45.201740 14053 net.cpp:94] Creating Layer relu2
I0614 19:49:45.201745 14053 net.cpp:435] relu2 <- bn2
I0614 19:49:45.201750 14053 net.cpp:409] relu2 -> relu2
I0614 19:49:45.201762 14053 net.cpp:144] Setting up relu2
I0614 19:49:45.201766 14053 net.cpp:151] Top shape: 10 180 27 27 (1312200)
I0614 19:49:45.201769 14053 net.cpp:159] Memory required for data: 52518400
I0614 19:49:45.201772 14053 layer_factory.hpp:77] Creating layer pool2
I0614 19:49:45.201778 14053 net.cpp:94] Creating Layer pool2
I0614 19:49:45.201781 14053 net.cpp:435] pool2 <- relu2
I0614 19:49:45.201786 14053 net.cpp:409] pool2 -> pool2
I0614 19:49:45.201798 14053 net.cpp:144] Setting up pool2
I0614 19:49:45.201802 14053 net.cpp:151] Top shape: 10 180 13 13 (304200)
I0614 19:49:45.201805 14053 net.cpp:159] Memory required for data: 53735200
I0614 19:49:45.201808 14053 layer_factory.hpp:77] Creating layer conv3
I0614 19:49:45.201815 14053 net.cpp:94] Creating Layer conv3
I0614 19:49:45.201818 14053 net.cpp:435] conv3 <- pool2
I0614 19:49:45.201822 14053 net.cpp:409] conv3 -> conv3
I0614 19:49:45.202474 14053 net.cpp:144] Setting up conv3
I0614 19:49:45.202482 14053 net.cpp:151] Top shape: 10 40 13 13 (67600)
I0614 19:49:45.202487 14053 net.cpp:159] Memory required for data: 54005600
I0614 19:49:45.202492 14053 layer_factory.hpp:77] Creating layer relu3
I0614 19:49:45.202497 14053 net.cpp:94] Creating Layer relu3
I0614 19:49:45.202500 14053 net.cpp:435] relu3 <- conv3
I0614 19:49:45.202505 14053 net.cpp:409] relu3 -> relu3
I0614 19:49:45.202515 14053 net.cpp:144] Setting up relu3
I0614 19:49:45.202518 14053 net.cpp:151] Top shape: 10 40 13 13 (67600)
I0614 19:49:45.202522 14053 net.cpp:159] Memory required for data: 54276000
I0614 19:49:45.202524 14053 layer_factory.hpp:77] Creating layer conv4
I0614 19:49:45.202530 14053 net.cpp:94] Creating Layer conv4
I0614 19:49:45.202533 14053 net.cpp:435] conv4 <- relu3
I0614 19:49:45.202538 14053 net.cpp:409] conv4 -> conv4
I0614 19:49:45.202772 14053 net.cpp:144] Setting up conv4
I0614 19:49:45.202778 14053 net.cpp:151] Top shape: 10 40 13 13 (67600)
I0614 19:49:45.202785 14053 net.cpp:159] Memory required for data: 54546400
I0614 19:49:45.202790 14053 layer_factory.hpp:77] Creating layer relu4
I0614 19:49:45.202795 14053 net.cpp:94] Creating Layer relu4
I0614 19:49:45.202797 14053 net.cpp:435] relu4 <- conv4
I0614 19:49:45.202801 14053 net.cpp:409] relu4 -> relu4
I0614 19:49:45.202811 14053 net.cpp:144] Setting up relu4
I0614 19:49:45.202814 14053 net.cpp:151] Top shape: 10 40 13 13 (67600)
I0614 19:49:45.202818 14053 net.cpp:159] Memory required for data: 54816800
I0614 19:49:45.202821 14053 layer_factory.hpp:77] Creating layer conv5
I0614 19:49:45.202827 14053 net.cpp:94] Creating Layer conv5
I0614 19:49:45.202831 14053 net.cpp:435] conv5 <- relu4
I0614 19:49:45.202834 14053 net.cpp:409] conv5 -> conv5
I0614 19:49:45.203022 14053 net.cpp:144] Setting up conv5
I0614 19:49:45.203027 14053 net.cpp:151] Top shape: 10 26 13 13 (43940)
I0614 19:49:45.203032 14053 net.cpp:159] Memory required for data: 54992560
I0614 19:49:45.203040 14053 layer_factory.hpp:77] Creating layer relu5
I0614 19:49:45.203044 14053 net.cpp:94] Creating Layer relu5
I0614 19:49:45.203047 14053 net.cpp:435] relu5 <- conv5
I0614 19:49:45.203052 14053 net.cpp:409] relu5 -> relu5
I0614 19:49:45.203063 14053 net.cpp:144] Setting up relu5
I0614 19:49:45.203065 14053 net.cpp:151] Top shape: 10 26 13 13 (43940)
I0614 19:49:45.203069 14053 net.cpp:159] Memory required for data: 55168320
I0614 19:49:45.203073 14053 layer_factory.hpp:77] Creating layer pool5
I0614 19:49:45.203078 14053 net.cpp:94] Creating Layer pool5
I0614 19:49:45.203080 14053 net.cpp:435] pool5 <- relu5
I0614 19:49:45.203083 14053 net.cpp:409] pool5 -> pool5
I0614 19:49:45.203099 14053 net.cpp:144] Setting up pool5
I0614 19:49:45.203101 14053 net.cpp:151] Top shape: 10 26 6 6 (9360)
I0614 19:49:45.203105 14053 net.cpp:159] Memory required for data: 55205760
I0614 19:49:45.203109 14053 layer_factory.hpp:77] Creating layer fc6
I0614 19:49:45.203378 14053 net.cpp:94] Creating Layer fc6
I0614 19:49:45.203385 14053 net.cpp:435] fc6 <- pool5
I0614 19:49:45.203390 14053 net.cpp:409] fc6 -> fc6
I0614 19:49:45.240401 14053 net.cpp:144] Setting up fc6
I0614 19:49:45.240422 14053 net.cpp:151] Top shape: 10 4096 (40960)
I0614 19:49:45.240429 14053 net.cpp:159] Memory required for data: 55369600
I0614 19:49:45.240439 14053 layer_factory.hpp:77] Creating layer relu6
I0614 19:49:45.240448 14053 net.cpp:94] Creating Layer relu6
I0614 19:49:45.240453 14053 net.cpp:435] relu6 <- fc6
I0614 19:49:45.240458 14053 net.cpp:409] relu6 -> relu6
I0614 19:49:45.240479 14053 net.cpp:144] Setting up relu6
I0614 19:49:45.240482 14053 net.cpp:151] Top shape: 10 4096 (40960)
I0614 19:49:45.240485 14053 net.cpp:159] Memory required for data: 55533440
I0614 19:49:45.240489 14053 layer_factory.hpp:77] Creating layer fc7
I0614 19:49:45.240495 14053 net.cpp:94] Creating Layer fc7
I0614 19:49:45.240499 14053 net.cpp:435] fc7 <- relu6
I0614 19:49:45.240502 14053 net.cpp:409] fc7 -> fc7
I0614 19:49:45.399355 14053 net.cpp:144] Setting up fc7
I0614 19:49:45.399376 14053 net.cpp:151] Top shape: 10 4096 (40960)
I0614 19:49:45.399382 14053 net.cpp:159] Memory required for data: 55697280
I0614 19:49:45.399394 14053 layer_factory.hpp:77] Creating layer bn7
I0614 19:49:45.399405 14053 net.cpp:94] Creating Layer bn7
I0614 19:49:45.399410 14053 net.cpp:435] bn7 <- fc7
I0614 19:49:45.399415 14053 net.cpp:409] bn7 -> bn7
I0614 19:49:45.399698 14053 net.cpp:144] Setting up bn7
I0614 19:49:45.399701 14053 net.cpp:151] Top shape: 10 4096 (40960)
I0614 19:49:45.399705 14053 net.cpp:159] Memory required for data: 55861120
I0614 19:49:45.399711 14053 layer_factory.hpp:77] Creating layer relu7
I0614 19:49:45.399716 14053 net.cpp:94] Creating Layer relu7
I0614 19:49:45.399719 14053 net.cpp:435] relu7 <- bn7
I0614 19:49:45.399724 14053 net.cpp:409] relu7 -> relu7
I0614 19:49:45.399734 14053 net.cpp:144] Setting up relu7
I0614 19:49:45.399737 14053 net.cpp:151] Top shape: 10 4096 (40960)
I0614 19:49:45.399740 14053 net.cpp:159] Memory required for data: 56024960
I0614 19:49:45.399744 14053 layer_factory.hpp:77] Creating layer fc8
I0614 19:49:45.399750 14053 net.cpp:94] Creating Layer fc8
I0614 19:49:45.399755 14053 net.cpp:435] fc8 <- relu7
I0614 19:49:45.399760 14053 net.cpp:409] fc8 -> fc8
I0614 19:49:45.399906 14053 net.cpp:144] Setting up fc8
I0614 19:49:45.399912 14053 net.cpp:151] Top shape: 10 2 (20)
I0614 19:49:45.399917 14053 net.cpp:159] Memory required for data: 56025040
I0614 19:49:45.399924 14053 layer_factory.hpp:77] Creating layer loss
I0614 19:49:45.401674 14053 net.cpp:94] Creating Layer loss
I0614 19:49:45.401680 14053 net.cpp:435] loss <- fc8
I0614 19:49:45.401684 14053 net.cpp:435] loss <- label
I0614 19:49:45.401690 14053 net.cpp:409] loss -> loss
I0614 19:49:45.401697 14053 layer_factory.hpp:77] Creating layer loss
I0614 19:49:45.401746 14053 net.cpp:144] Setting up loss
I0614 19:49:45.401749 14053 net.cpp:151] Top shape: (1)
I0614 19:49:45.401752 14053 net.cpp:154]     with loss weight 1
I0614 19:49:45.401777 14053 net.cpp:159] Memory required for data: 56025044
I0614 19:49:45.401779 14053 net.cpp:220] loss needs backward computation.
I0614 19:49:45.401783 14053 net.cpp:220] fc8 needs backward computation.
I0614 19:49:45.401787 14053 net.cpp:220] relu7 needs backward computation.
I0614 19:49:45.401789 14053 net.cpp:220] bn7 needs backward computation.
I0614 19:49:45.401791 14053 net.cpp:220] fc7 needs backward computation.
I0614 19:49:45.401795 14053 net.cpp:220] relu6 needs backward computation.
I0614 19:49:45.401798 14053 net.cpp:220] fc6 needs backward computation.
I0614 19:49:45.401801 14053 net.cpp:220] pool5 needs backward computation.
I0614 19:49:45.401804 14053 net.cpp:220] relu5 needs backward computation.
I0614 19:49:45.401808 14053 net.cpp:220] conv5 needs backward computation.
I0614 19:49:45.401810 14053 net.cpp:220] relu4 needs backward computation.
I0614 19:49:45.401813 14053 net.cpp:220] conv4 needs backward computation.
I0614 19:49:45.401816 14053 net.cpp:220] relu3 needs backward computation.
I0614 19:49:45.401819 14053 net.cpp:220] conv3 needs backward computation.
I0614 19:49:45.401839 14053 net.cpp:220] pool2 needs backward computation.
I0614 19:49:45.401841 14053 net.cpp:220] relu2 needs backward computation.
I0614 19:49:45.401845 14053 net.cpp:220] bn2 needs backward computation.
I0614 19:49:45.401849 14053 net.cpp:220] conv2 needs backward computation.
I0614 19:49:45.401851 14053 net.cpp:220] pool1 needs backward computation.
I0614 19:49:45.401854 14053 net.cpp:220] relu1 needs backward computation.
I0614 19:49:45.401857 14053 net.cpp:220] bn1 needs backward computation.
I0614 19:49:45.401860 14053 net.cpp:220] conv1 needs backward computation.
I0614 19:49:45.401863 14053 net.cpp:222] data does not need backward computation.
I0614 19:49:45.401866 14053 net.cpp:264] This network produces output loss
I0614 19:49:45.401881 14053 net.cpp:284] Network initialization done.
W0614 19:49:45.402091 14053 net.cpp:860] Force copying param 0 weights from layer 'bn1'; shape mismatch.  Source param shape is 78 (78); target param shape is 1 78 1 1 (78).
W0614 19:49:45.402177 14053 net.cpp:860] Force copying param 1 weights from layer 'bn1'; shape mismatch.  Source param shape is 78 (78); target param shape is 1 78 1 1 (78).
W0614 19:49:45.402256 14053 net.cpp:860] Force copying param 2 weights from layer 'bn1'; shape mismatch.  Source param shape is 78 (78); target param shape is 1 78 1 1 (78).
W0614 19:49:45.402324 14053 net.cpp:860] Force copying param 3 weights from layer 'bn1'; shape mismatch.  Source param shape is 78 (78); target param shape is 1 78 1 1 (78).
W0614 19:49:45.402412 14053 net.cpp:860] Force copying param 4 weights from layer 'bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0614 19:49:45.402736 14053 net.cpp:860] Force copying param 0 weights from layer 'bn2'; shape mismatch.  Source param shape is 180 (180); target param shape is 1 180 1 1 (180).
W0614 19:49:45.402812 14053 net.cpp:860] Force copying param 1 weights from layer 'bn2'; shape mismatch.  Source param shape is 180 (180); target param shape is 1 180 1 1 (180).
W0614 19:49:45.402887 14053 net.cpp:860] Force copying param 2 weights from layer 'bn2'; shape mismatch.  Source param shape is 180 (180); target param shape is 1 180 1 1 (180).
W0614 19:49:45.402953 14053 net.cpp:860] Force copying param 3 weights from layer 'bn2'; shape mismatch.  Source param shape is 180 (180); target param shape is 1 180 1 1 (180).
W0614 19:49:45.403029 14053 net.cpp:860] Force copying param 4 weights from layer 'bn2'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0614 19:49:45.414691 14053 net.cpp:860] Force copying param 0 weights from layer 'bn7'; shape mismatch.  Source param shape is 4096 (4096); target param shape is 1 4096 1 1 (4096).
W0614 19:49:45.414781 14053 net.cpp:860] Force copying param 1 weights from layer 'bn7'; shape mismatch.  Source param shape is 4096 (4096); target param shape is 1 4096 1 1 (4096).
W0614 19:49:45.414875 14053 net.cpp:860] Force copying param 2 weights from layer 'bn7'; shape mismatch.  Source param shape is 4096 (4096); target param shape is 1 4096 1 1 (4096).
W0614 19:49:45.414963 14053 net.cpp:860] Force copying param 3 weights from layer 'bn7'; shape mismatch.  Source param shape is 4096 (4096); target param shape is 1 4096 1 1 (4096).
W0614 19:49:45.415041 14053 net.cpp:860] Force copying param 4 weights from layer 'bn7'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
I0614 19:49:45.466100 14053 convert_proto.cpp:184] Opening file deploy/alexnetBNnoLRN/pruned/data/calib/calibration.txt
I0614 19:49:45.466706 14053 convert_proto.cpp:195] A total of 200 images.
I0614 19:49:45.532982 14053 convert_proto.cpp:2712]  Merge InnerProductBatchNorm -> InnerProduct: fc7 + bn7
I0614 19:49:45.616495 14053 convert_proto.cpp:2712]  Merge InnerProductBatchNorm -> InnerProduct: fc7 + bn7
I0614 19:49:45.847373 14053 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0614 19:49:45.847395 14053 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0614 19:49:45.847398 14053 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy-top1
I0614 19:49:45.847401 14053 net.cpp:52] Initializing net from parameters: 
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    crop_size: 227
    mean_value: 106
    mean_value: 116
    mean_value: 124
  }
  image_data_param {
    source: "deploy/alexnetBNnoLRN/pruned/data/calib/calibration.txt"
    batch_size: 10
    shuffle: true
    root_folder: "deploy/alexnetBNnoLRN/pruned/data/calib/"
  }
}
layer {
  name: "data_fixed"
  type: "FixedNeuron"
  bottom: "data"
  top: "data"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: OVER_FLOW
    bit_width: 8
    follow_data_layer: true
  }
}
layer {
  name: "conv1"
  type: "ConvolutionFixed"
  bottom: "data"
  top: "bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  convolution_param {
    num_output: 78
    bias_term: true
    pad: 0
    kernel_size: 8
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "bn1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "pool1_fixed"
  type: "FixedNeuron"
  bottom: "pool1"
  top: "pool1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "conv2"
  type: "ConvolutionFixed"
  bottom: "pool1"
  top: "bn2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  convolution_param {
    num_output: 180
    bias_term: true
    pad: 2
    kernel_size: 5
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "bn2"
  top: "relu2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "pool2_fixed"
  type: "FixedNeuron"
  bottom: "pool2"
  top: "pool2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "conv3"
  type: "ConvolutionFixed"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 40
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "relu3_fixed"
  type: "FixedNeuron"
  bottom: "relu3"
  top: "relu3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "conv4"
  type: "ConvolutionFixed"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 40
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "relu4_fixed"
  type: "FixedNeuron"
  bottom: "relu4"
  top: "relu4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "conv5"
  type: "ConvolutionFixed"
  bottom: "relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 26
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "pool5_fixed"
  type: "FixedNeuron"
  bottom: "pool5"
  top: "pool5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "fc6"
  type: "InnerProductFixed"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "relu6_fixed"
  type: "FixedNeuron"
  bottom: "relu6"
  top: "relu6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "fc7"
  type: "InnerProductFixed"
  bottom: "relu6"
  top: "bn7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    bias_term: true
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "bn7"
  top: "relu7"
}
layer {
  name: "relu7_fixed"
  type: "FixedNeuron"
  bottom: "relu7"
  top: "relu7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "fc8"
  type: "InnerProductFixed"
  bottom: "relu7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "fc8_fixed"
  type: "FixedNeuron"
  bottom: "fc8"
  top: "fc8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0614 19:49:45.847563 14053 layer_factory.hpp:77] Creating layer data
I0614 19:49:45.847582 14053 net.cpp:94] Creating Layer data
I0614 19:49:45.847586 14053 net.cpp:409] data -> data
I0614 19:49:45.847594 14053 net.cpp:409] data -> label
I0614 19:49:45.847602 14053 image_data_layer.cpp:41] Opening file deploy/alexnetBNnoLRN/pruned/data/calib/calibration.txt
I0614 19:49:45.848206 14053 image_data_layer.cpp:51] Shuffling data
I0614 19:49:45.848223 14053 image_data_layer.cpp:56] A total of 200 images.
I0614 19:49:45.850840 14053 image_data_layer.cpp:84] output data size: 10,3,227,227
I0614 19:49:45.873731 14053 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0614 19:49:45.873807 14053 net.cpp:144] Setting up data
I0614 19:49:45.873812 14053 net.cpp:151] Top shape: 10 3 227 227 (1545870)
I0614 19:49:45.873821 14053 net.cpp:151] Top shape: 10 (10)
I0614 19:49:45.873826 14053 net.cpp:159] Memory required for data: 6183520
I0614 19:49:45.873829 14053 layer_factory.hpp:77] Creating layer data_fixed
I0614 19:49:45.875543 14053 net.cpp:94] Creating Layer data_fixed
I0614 19:49:45.875551 14053 net.cpp:435] data_fixed <- data
I0614 19:49:45.875559 14053 net.cpp:396] data_fixed -> data (in-place)
I0614 19:49:45.875598 14053 net.cpp:144] Setting up data_fixed
I0614 19:49:45.875602 14053 net.cpp:151] Top shape: 10 3 227 227 (1545870)
I0614 19:49:45.875605 14053 net.cpp:159] Memory required for data: 12367000
I0614 19:49:45.875613 14053 layer_factory.hpp:77] Creating layer conv1
I0614 19:49:45.875623 14053 net.cpp:94] Creating Layer conv1
I0614 19:49:45.875627 14053 net.cpp:435] conv1 <- data
I0614 19:49:45.875630 14053 net.cpp:409] conv1 -> bn1
I0614 19:49:45.875844 14053 layer_factory.hpp:77] Creating layer conv1
I0614 19:49:45.876140 14053 net.cpp:144] Setting up conv1
I0614 19:49:45.876148 14053 net.cpp:151] Top shape: 10 78 55 55 (2359500)
I0614 19:49:45.876153 14053 net.cpp:159] Memory required for data: 21805000
I0614 19:49:45.876160 14053 layer_factory.hpp:77] Creating layer relu1
I0614 19:49:45.876165 14053 net.cpp:94] Creating Layer relu1
I0614 19:49:45.876168 14053 net.cpp:435] relu1 <- bn1
I0614 19:49:45.876173 14053 net.cpp:409] relu1 -> relu1
I0614 19:49:45.876185 14053 net.cpp:144] Setting up relu1
I0614 19:49:45.876188 14053 net.cpp:151] Top shape: 10 78 55 55 (2359500)
I0614 19:49:45.876192 14053 net.cpp:159] Memory required for data: 31243000
I0614 19:49:45.876195 14053 layer_factory.hpp:77] Creating layer pool1
I0614 19:49:45.876200 14053 net.cpp:94] Creating Layer pool1
I0614 19:49:45.876204 14053 net.cpp:435] pool1 <- relu1
I0614 19:49:45.876207 14053 net.cpp:409] pool1 -> pool1
I0614 19:49:45.876222 14053 net.cpp:144] Setting up pool1
I0614 19:49:45.876225 14053 net.cpp:151] Top shape: 10 78 27 27 (568620)
I0614 19:49:45.876230 14053 net.cpp:159] Memory required for data: 33517480
I0614 19:49:45.876232 14053 layer_factory.hpp:77] Creating layer pool1_fixed
I0614 19:49:45.876237 14053 net.cpp:94] Creating Layer pool1_fixed
I0614 19:49:45.876240 14053 net.cpp:435] pool1_fixed <- pool1
I0614 19:49:45.876245 14053 net.cpp:396] pool1_fixed -> pool1 (in-place)
I0614 19:49:45.876257 14053 net.cpp:144] Setting up pool1_fixed
I0614 19:49:45.876260 14053 net.cpp:151] Top shape: 10 78 27 27 (568620)
I0614 19:49:45.876263 14053 net.cpp:159] Memory required for data: 35791960
I0614 19:49:45.876267 14053 layer_factory.hpp:77] Creating layer conv2
I0614 19:49:45.876276 14053 net.cpp:94] Creating Layer conv2
I0614 19:49:45.876279 14053 net.cpp:435] conv2 <- pool1
I0614 19:49:45.876286 14053 net.cpp:409] conv2 -> bn2
I0614 19:49:45.879748 14053 layer_factory.hpp:77] Creating layer conv2
I0614 19:49:45.883868 14053 net.cpp:144] Setting up conv2
I0614 19:49:45.883882 14053 net.cpp:151] Top shape: 10 180 27 27 (1312200)
I0614 19:49:45.883889 14053 net.cpp:159] Memory required for data: 41040760
I0614 19:49:45.883898 14053 layer_factory.hpp:77] Creating layer relu2
I0614 19:49:45.883904 14053 net.cpp:94] Creating Layer relu2
I0614 19:49:45.883908 14053 net.cpp:435] relu2 <- bn2
I0614 19:49:45.883913 14053 net.cpp:409] relu2 -> relu2
I0614 19:49:45.883924 14053 net.cpp:144] Setting up relu2
I0614 19:49:45.883926 14053 net.cpp:151] Top shape: 10 180 27 27 (1312200)
I0614 19:49:45.883930 14053 net.cpp:159] Memory required for data: 46289560
I0614 19:49:45.883934 14053 layer_factory.hpp:77] Creating layer pool2
I0614 19:49:45.883939 14053 net.cpp:94] Creating Layer pool2
I0614 19:49:45.883941 14053 net.cpp:435] pool2 <- relu2
I0614 19:49:45.883945 14053 net.cpp:409] pool2 -> pool2
I0614 19:49:45.883960 14053 net.cpp:144] Setting up pool2
I0614 19:49:45.883961 14053 net.cpp:151] Top shape: 10 180 13 13 (304200)
I0614 19:49:45.883965 14053 net.cpp:159] Memory required for data: 47506360
I0614 19:49:45.883968 14053 layer_factory.hpp:77] Creating layer pool2_fixed
I0614 19:49:45.883973 14053 net.cpp:94] Creating Layer pool2_fixed
I0614 19:49:45.883976 14053 net.cpp:435] pool2_fixed <- pool2
I0614 19:49:45.883980 14053 net.cpp:396] pool2_fixed -> pool2 (in-place)
I0614 19:49:45.883992 14053 net.cpp:144] Setting up pool2_fixed
I0614 19:49:45.883996 14053 net.cpp:151] Top shape: 10 180 13 13 (304200)
I0614 19:49:45.883999 14053 net.cpp:159] Memory required for data: 48723160
I0614 19:49:45.884002 14053 layer_factory.hpp:77] Creating layer conv3
I0614 19:49:45.884009 14053 net.cpp:94] Creating Layer conv3
I0614 19:49:45.884012 14053 net.cpp:435] conv3 <- pool2
I0614 19:49:45.884016 14053 net.cpp:409] conv3 -> conv3
I0614 19:49:45.884660 14053 layer_factory.hpp:77] Creating layer conv3
I0614 19:49:45.885336 14053 net.cpp:144] Setting up conv3
I0614 19:49:45.885345 14053 net.cpp:151] Top shape: 10 40 13 13 (67600)
I0614 19:49:45.885351 14053 net.cpp:159] Memory required for data: 48993560
I0614 19:49:45.885358 14053 layer_factory.hpp:77] Creating layer relu3
I0614 19:49:45.885363 14053 net.cpp:94] Creating Layer relu3
I0614 19:49:45.885366 14053 net.cpp:435] relu3 <- conv3
I0614 19:49:45.885371 14053 net.cpp:409] relu3 -> relu3
I0614 19:49:45.885388 14053 net.cpp:144] Setting up relu3
I0614 19:49:45.885392 14053 net.cpp:151] Top shape: 10 40 13 13 (67600)
I0614 19:49:45.885396 14053 net.cpp:159] Memory required for data: 49263960
I0614 19:49:45.885399 14053 layer_factory.hpp:77] Creating layer relu3_fixed
I0614 19:49:45.885404 14053 net.cpp:94] Creating Layer relu3_fixed
I0614 19:49:45.885406 14053 net.cpp:435] relu3_fixed <- relu3
I0614 19:49:45.885411 14053 net.cpp:396] relu3_fixed -> relu3 (in-place)
I0614 19:49:45.885423 14053 net.cpp:144] Setting up relu3_fixed
I0614 19:49:45.885426 14053 net.cpp:151] Top shape: 10 40 13 13 (67600)
I0614 19:49:45.885430 14053 net.cpp:159] Memory required for data: 49534360
I0614 19:49:45.885434 14053 layer_factory.hpp:77] Creating layer conv4
I0614 19:49:45.885440 14053 net.cpp:94] Creating Layer conv4
I0614 19:49:45.885443 14053 net.cpp:435] conv4 <- relu3
I0614 19:49:45.885447 14053 net.cpp:409] conv4 -> conv4
I0614 19:49:45.885654 14053 layer_factory.hpp:77] Creating layer conv4
I0614 19:49:45.885906 14053 net.cpp:144] Setting up conv4
I0614 19:49:45.885913 14053 net.cpp:151] Top shape: 10 40 13 13 (67600)
I0614 19:49:45.885918 14053 net.cpp:159] Memory required for data: 49804760
I0614 19:49:45.885923 14053 layer_factory.hpp:77] Creating layer relu4
I0614 19:49:45.885927 14053 net.cpp:94] Creating Layer relu4
I0614 19:49:45.885931 14053 net.cpp:435] relu4 <- conv4
I0614 19:49:45.885934 14053 net.cpp:409] relu4 -> relu4
I0614 19:49:45.885944 14053 net.cpp:144] Setting up relu4
I0614 19:49:45.885947 14053 net.cpp:151] Top shape: 10 40 13 13 (67600)
I0614 19:49:45.885951 14053 net.cpp:159] Memory required for data: 50075160
I0614 19:49:45.885953 14053 layer_factory.hpp:77] Creating layer relu4_fixed
I0614 19:49:45.885958 14053 net.cpp:94] Creating Layer relu4_fixed
I0614 19:49:45.885962 14053 net.cpp:435] relu4_fixed <- relu4
I0614 19:49:45.885965 14053 net.cpp:396] relu4_fixed -> relu4 (in-place)
I0614 19:49:45.885977 14053 net.cpp:144] Setting up relu4_fixed
I0614 19:49:45.885980 14053 net.cpp:151] Top shape: 10 40 13 13 (67600)
I0614 19:49:45.885984 14053 net.cpp:159] Memory required for data: 50345560
I0614 19:49:45.885988 14053 layer_factory.hpp:77] Creating layer conv5
I0614 19:49:45.885994 14053 net.cpp:94] Creating Layer conv5
I0614 19:49:45.885998 14053 net.cpp:435] conv5 <- relu4
I0614 19:49:45.886001 14053 net.cpp:409] conv5 -> conv5
I0614 19:49:45.886159 14053 layer_factory.hpp:77] Creating layer conv5
I0614 19:49:45.886368 14053 net.cpp:144] Setting up conv5
I0614 19:49:45.886374 14053 net.cpp:151] Top shape: 10 26 13 13 (43940)
I0614 19:49:45.886379 14053 net.cpp:159] Memory required for data: 50521320
I0614 19:49:45.886384 14053 layer_factory.hpp:77] Creating layer relu5
I0614 19:49:45.886387 14053 net.cpp:94] Creating Layer relu5
I0614 19:49:45.886391 14053 net.cpp:435] relu5 <- conv5
I0614 19:49:45.886395 14053 net.cpp:409] relu5 -> relu5
I0614 19:49:45.886407 14053 net.cpp:144] Setting up relu5
I0614 19:49:45.886411 14053 net.cpp:151] Top shape: 10 26 13 13 (43940)
I0614 19:49:45.886418 14053 net.cpp:159] Memory required for data: 50697080
I0614 19:49:45.886422 14053 layer_factory.hpp:77] Creating layer pool5
I0614 19:49:45.886426 14053 net.cpp:94] Creating Layer pool5
I0614 19:49:45.886430 14053 net.cpp:435] pool5 <- relu5
I0614 19:49:45.886433 14053 net.cpp:409] pool5 -> pool5
I0614 19:49:45.886448 14053 net.cpp:144] Setting up pool5
I0614 19:49:45.886451 14053 net.cpp:151] Top shape: 10 26 6 6 (9360)
I0614 19:49:45.886456 14053 net.cpp:159] Memory required for data: 50734520
I0614 19:49:45.886458 14053 layer_factory.hpp:77] Creating layer pool5_fixed
I0614 19:49:45.886463 14053 net.cpp:94] Creating Layer pool5_fixed
I0614 19:49:45.886466 14053 net.cpp:435] pool5_fixed <- pool5
I0614 19:49:45.886469 14053 net.cpp:396] pool5_fixed -> pool5 (in-place)
I0614 19:49:45.886482 14053 net.cpp:144] Setting up pool5_fixed
I0614 19:49:45.886485 14053 net.cpp:151] Top shape: 10 26 6 6 (9360)
I0614 19:49:45.886490 14053 net.cpp:159] Memory required for data: 50771960
I0614 19:49:45.886495 14053 layer_factory.hpp:77] Creating layer fc6
I0614 19:49:45.886504 14053 net.cpp:94] Creating Layer fc6
I0614 19:49:45.886508 14053 net.cpp:435] fc6 <- pool5
I0614 19:49:45.886513 14053 net.cpp:409] fc6 -> fc6
I0614 19:49:45.923547 14053 layer_factory.hpp:77] Creating layer fc6
I0614 19:49:45.960563 14053 net.cpp:144] Setting up fc6
I0614 19:49:45.960582 14053 net.cpp:151] Top shape: 10 4096 (40960)
I0614 19:49:45.960589 14053 net.cpp:159] Memory required for data: 50935800
I0614 19:49:45.960601 14053 layer_factory.hpp:77] Creating layer relu6
I0614 19:49:45.960609 14053 net.cpp:94] Creating Layer relu6
I0614 19:49:45.960613 14053 net.cpp:435] relu6 <- fc6
I0614 19:49:45.960619 14053 net.cpp:409] relu6 -> relu6
I0614 19:49:45.960637 14053 net.cpp:144] Setting up relu6
I0614 19:49:45.960640 14053 net.cpp:151] Top shape: 10 4096 (40960)
I0614 19:49:45.960644 14053 net.cpp:159] Memory required for data: 51099640
I0614 19:49:45.960646 14053 layer_factory.hpp:77] Creating layer relu6_fixed
I0614 19:49:45.960654 14053 net.cpp:94] Creating Layer relu6_fixed
I0614 19:49:45.960656 14053 net.cpp:435] relu6_fixed <- relu6
I0614 19:49:45.960660 14053 net.cpp:396] relu6_fixed -> relu6 (in-place)
I0614 19:49:45.960675 14053 net.cpp:144] Setting up relu6_fixed
I0614 19:49:45.960676 14053 net.cpp:151] Top shape: 10 4096 (40960)
I0614 19:49:45.960680 14053 net.cpp:159] Memory required for data: 51263480
I0614 19:49:45.960683 14053 layer_factory.hpp:77] Creating layer fc7
I0614 19:49:45.960690 14053 net.cpp:94] Creating Layer fc7
I0614 19:49:45.960692 14053 net.cpp:435] fc7 <- relu6
I0614 19:49:45.960696 14053 net.cpp:409] fc7 -> bn7
I0614 19:49:46.104620 14053 layer_factory.hpp:77] Creating layer fc7
I0614 19:49:46.248054 14053 net.cpp:144] Setting up fc7
I0614 19:49:46.248077 14053 net.cpp:151] Top shape: 10 4096 (40960)
I0614 19:49:46.248083 14053 net.cpp:159] Memory required for data: 51427320
I0614 19:49:46.248108 14053 layer_factory.hpp:77] Creating layer relu7
I0614 19:49:46.248117 14053 net.cpp:94] Creating Layer relu7
I0614 19:49:46.248121 14053 net.cpp:435] relu7 <- bn7
I0614 19:49:46.248128 14053 net.cpp:409] relu7 -> relu7
I0614 19:49:46.248143 14053 net.cpp:144] Setting up relu7
I0614 19:49:46.248145 14053 net.cpp:151] Top shape: 10 4096 (40960)
I0614 19:49:46.248148 14053 net.cpp:159] Memory required for data: 51591160
I0614 19:49:46.248152 14053 layer_factory.hpp:77] Creating layer relu7_fixed
I0614 19:49:46.248157 14053 net.cpp:94] Creating Layer relu7_fixed
I0614 19:49:46.248160 14053 net.cpp:435] relu7_fixed <- relu7
I0614 19:49:46.248163 14053 net.cpp:396] relu7_fixed -> relu7 (in-place)
I0614 19:49:46.248176 14053 net.cpp:144] Setting up relu7_fixed
I0614 19:49:46.248178 14053 net.cpp:151] Top shape: 10 4096 (40960)
I0614 19:49:46.248181 14053 net.cpp:159] Memory required for data: 51755000
I0614 19:49:46.248184 14053 layer_factory.hpp:77] Creating layer fc8
I0614 19:49:46.248191 14053 net.cpp:94] Creating Layer fc8
I0614 19:49:46.248193 14053 net.cpp:435] fc8 <- relu7
I0614 19:49:46.248198 14053 net.cpp:409] fc8 -> fc8
I0614 19:49:46.248286 14053 layer_factory.hpp:77] Creating layer fc8
I0614 19:49:46.248425 14053 net.cpp:144] Setting up fc8
I0614 19:49:46.248430 14053 net.cpp:151] Top shape: 10 2 (20)
I0614 19:49:46.248433 14053 net.cpp:159] Memory required for data: 51755080
I0614 19:49:46.248437 14053 layer_factory.hpp:77] Creating layer fc8_fixed
I0614 19:49:46.248442 14053 net.cpp:94] Creating Layer fc8_fixed
I0614 19:49:46.248445 14053 net.cpp:435] fc8_fixed <- fc8
I0614 19:49:46.248450 14053 net.cpp:396] fc8_fixed -> fc8 (in-place)
I0614 19:49:46.248462 14053 net.cpp:144] Setting up fc8_fixed
I0614 19:49:46.248466 14053 net.cpp:151] Top shape: 10 2 (20)
I0614 19:49:46.248468 14053 net.cpp:159] Memory required for data: 51755160
I0614 19:49:46.248471 14053 layer_factory.hpp:77] Creating layer loss
I0614 19:49:46.248476 14053 net.cpp:94] Creating Layer loss
I0614 19:49:46.248479 14053 net.cpp:435] loss <- fc8
I0614 19:49:46.248482 14053 net.cpp:435] loss <- label
I0614 19:49:46.248486 14053 net.cpp:409] loss -> loss
I0614 19:49:46.248492 14053 layer_factory.hpp:77] Creating layer loss
I0614 19:49:46.248528 14053 net.cpp:144] Setting up loss
I0614 19:49:46.248530 14053 net.cpp:151] Top shape: (1)
I0614 19:49:46.248533 14053 net.cpp:154]     with loss weight 1
I0614 19:49:46.248544 14053 net.cpp:159] Memory required for data: 51755164
I0614 19:49:46.248548 14053 net.cpp:220] loss needs backward computation.
I0614 19:49:46.248550 14053 net.cpp:220] fc8_fixed needs backward computation.
I0614 19:49:46.248553 14053 net.cpp:220] fc8 needs backward computation.
I0614 19:49:46.248556 14053 net.cpp:220] relu7_fixed needs backward computation.
I0614 19:49:46.248558 14053 net.cpp:220] relu7 needs backward computation.
I0614 19:49:46.248577 14053 net.cpp:220] fc7 needs backward computation.
I0614 19:49:46.248580 14053 net.cpp:220] relu6_fixed needs backward computation.
I0614 19:49:46.248584 14053 net.cpp:220] relu6 needs backward computation.
I0614 19:49:46.248586 14053 net.cpp:220] fc6 needs backward computation.
I0614 19:49:46.248590 14053 net.cpp:220] pool5_fixed needs backward computation.
I0614 19:49:46.248593 14053 net.cpp:220] pool5 needs backward computation.
I0614 19:49:46.248597 14053 net.cpp:220] relu5 needs backward computation.
I0614 19:49:46.248602 14053 net.cpp:220] conv5 needs backward computation.
I0614 19:49:46.248606 14053 net.cpp:220] relu4_fixed needs backward computation.
I0614 19:49:46.248610 14053 net.cpp:220] relu4 needs backward computation.
I0614 19:49:46.248615 14053 net.cpp:220] conv4 needs backward computation.
I0614 19:49:46.248620 14053 net.cpp:220] relu3_fixed needs backward computation.
I0614 19:49:46.248625 14053 net.cpp:220] relu3 needs backward computation.
I0614 19:49:46.248631 14053 net.cpp:220] conv3 needs backward computation.
I0614 19:49:46.248634 14053 net.cpp:220] pool2_fixed needs backward computation.
I0614 19:49:46.248638 14053 net.cpp:220] pool2 needs backward computation.
I0614 19:49:46.248642 14053 net.cpp:220] relu2 needs backward computation.
I0614 19:49:46.248647 14053 net.cpp:220] conv2 needs backward computation.
I0614 19:49:46.248652 14053 net.cpp:220] pool1_fixed needs backward computation.
I0614 19:49:46.248656 14053 net.cpp:220] pool1 needs backward computation.
I0614 19:49:46.248661 14053 net.cpp:220] relu1 needs backward computation.
I0614 19:49:46.248663 14053 net.cpp:220] conv1 needs backward computation.
I0614 19:49:46.248667 14053 net.cpp:222] data_fixed does not need backward computation.
I0614 19:49:46.248670 14053 net.cpp:222] data does not need backward computation.
I0614 19:49:46.248673 14053 net.cpp:264] This network produces output loss
I0614 19:49:46.248688 14053 net.cpp:284] Network initialization done.
I0614 19:49:46.260376 14053 vai_q.cpp:182] Start Calibration
I0614 19:49:46.300220 14053 vai_q.cpp:206] Calibration iter: 1/100 ,loss: 70.7442
I0614 19:49:46.304809 14053 vai_q.cpp:206] Calibration iter: 2/100 ,loss: 78.6029
I0614 19:49:46.309316 14053 vai_q.cpp:206] Calibration iter: 3/100 ,loss: 87.3365
I0614 19:49:46.314345 14053 vai_q.cpp:206] Calibration iter: 4/100 ,loss: 63.7106
I0614 19:49:46.318812 14053 vai_q.cpp:206] Calibration iter: 5/100 ,loss: 61.1356
I0614 19:49:46.323302 14053 vai_q.cpp:206] Calibration iter: 6/100 ,loss: 87.3365
I0614 19:49:46.327781 14053 vai_q.cpp:206] Calibration iter: 7/100 ,loss: 71.4942
I0614 19:49:46.332279 14053 vai_q.cpp:206] Calibration iter: 8/100 ,loss: 69.8692
I0614 19:49:46.336786 14053 vai_q.cpp:206] Calibration iter: 9/100 ,loss: 62.8356
I0614 19:49:46.341828 14053 vai_q.cpp:206] Calibration iter: 10/100 ,loss: 71.2442
I0614 19:49:46.346344 14053 vai_q.cpp:206] Calibration iter: 11/100 ,loss: 78.6029
I0614 19:49:46.350829 14053 vai_q.cpp:206] Calibration iter: 12/100 ,loss: 79.6279
I0614 19:49:46.350842 14053 blocking_queue.cpp:50] Data layer prefetch queue empty
I0614 19:49:46.397320 14053 vai_q.cpp:206] Calibration iter: 13/100 ,loss: 69.8692
I0614 19:49:46.425598 14053 vai_q.cpp:206] Calibration iter: 14/100 ,loss: 87.3365
I0614 19:49:46.452773 14053 vai_q.cpp:206] Calibration iter: 15/100 ,loss: 52.4019
I0614 19:49:46.479089 14053 vai_q.cpp:206] Calibration iter: 16/100 ,loss: 70.6693
I0614 19:49:46.505851 14053 vai_q.cpp:206] Calibration iter: 17/100 ,loss: 78.6031
I0614 19:49:46.532253 14053 vai_q.cpp:206] Calibration iter: 18/100 ,loss: 87.3365
I0614 19:49:46.577590 14053 vai_q.cpp:206] Calibration iter: 19/100 ,loss: 69.8692
I0614 19:49:46.605839 14053 vai_q.cpp:206] Calibration iter: 20/100 ,loss: 78.6029
I0614 19:49:46.632462 14053 vai_q.cpp:206] Calibration iter: 21/100 ,loss: 69.8692
I0614 19:49:46.658573 14053 vai_q.cpp:206] Calibration iter: 22/100 ,loss: 78.6029
I0614 19:49:46.685425 14053 vai_q.cpp:206] Calibration iter: 23/100 ,loss: 87.3365
I0614 19:49:46.712103 14053 vai_q.cpp:206] Calibration iter: 24/100 ,loss: 71.3192
I0614 19:49:46.738760 14053 vai_q.cpp:206] Calibration iter: 25/100 ,loss: 54.4269
I0614 19:49:46.766304 14053 vai_q.cpp:206] Calibration iter: 26/100 ,loss: 78.6029
I0614 19:49:46.793040 14053 vai_q.cpp:206] Calibration iter: 27/100 ,loss: 87.3365
I0614 19:49:46.819447 14053 vai_q.cpp:206] Calibration iter: 28/100 ,loss: 78.6029
I0614 19:49:46.845455 14053 vai_q.cpp:206] Calibration iter: 29/100 ,loss: 87.3365
I0614 19:49:46.871850 14053 vai_q.cpp:206] Calibration iter: 30/100 ,loss: 79.2281
I0614 19:49:46.898924 14053 vai_q.cpp:206] Calibration iter: 31/100 ,loss: 52.4019
I0614 19:49:46.925689 14053 vai_q.cpp:206] Calibration iter: 32/100 ,loss: 78.6029
I0614 19:49:46.952507 14053 vai_q.cpp:206] Calibration iter: 33/100 ,loss: 80.0279
I0614 19:49:46.979075 14053 vai_q.cpp:206] Calibration iter: 34/100 ,loss: 69.8692
I0614 19:49:47.005790 14053 vai_q.cpp:206] Calibration iter: 35/100 ,loss: 79.5279
I0614 19:49:47.032814 14053 vai_q.cpp:206] Calibration iter: 36/100 ,loss: 69.8692
I0614 19:49:47.060233 14053 vai_q.cpp:206] Calibration iter: 37/100 ,loss: 80.5279
I0614 19:49:47.087255 14053 vai_q.cpp:206] Calibration iter: 38/100 ,loss: 78.6029
I0614 19:49:47.113680 14053 vai_q.cpp:206] Calibration iter: 39/100 ,loss: 78.6029
I0614 19:49:47.141618 14053 vai_q.cpp:206] Calibration iter: 40/100 ,loss: 78.6029
I0614 19:49:47.168795 14053 vai_q.cpp:206] Calibration iter: 41/100 ,loss: 70.9442
I0614 19:49:47.195112 14053 vai_q.cpp:206] Calibration iter: 42/100 ,loss: 78.6029
I0614 19:49:47.222771 14053 vai_q.cpp:206] Calibration iter: 43/100 ,loss: 61.1356
I0614 19:49:47.248736 14053 vai_q.cpp:206] Calibration iter: 44/100 ,loss: 78.6029
I0614 19:49:47.275249 14053 vai_q.cpp:206] Calibration iter: 45/100 ,loss: 78.6029
I0614 19:49:47.301826 14053 vai_q.cpp:206] Calibration iter: 46/100 ,loss: 79.4029
I0614 19:49:47.348654 14053 vai_q.cpp:206] Calibration iter: 47/100 ,loss: 87.3365
I0614 19:49:47.377792 14053 vai_q.cpp:206] Calibration iter: 48/100 ,loss: 78.6029
I0614 19:49:47.403568 14053 vai_q.cpp:206] Calibration iter: 49/100 ,loss: 78.6029
I0614 19:49:47.430033 14053 vai_q.cpp:206] Calibration iter: 50/100 ,loss: 78.6029
I0614 19:49:47.457923 14053 vai_q.cpp:206] Calibration iter: 51/100 ,loss: 54.3519
I0614 19:49:47.484673 14053 vai_q.cpp:206] Calibration iter: 52/100 ,loss: 87.3365
I0614 19:49:47.511451 14053 vai_q.cpp:206] Calibration iter: 53/100 ,loss: 63.2356
I0614 19:49:47.546126 14053 vai_q.cpp:206] Calibration iter: 54/100 ,loss: 52.4019
I0614 19:49:47.596099 14053 vai_q.cpp:206] Calibration iter: 55/100 ,loss: 87.3365
I0614 19:49:47.623936 14053 vai_q.cpp:206] Calibration iter: 56/100 ,loss: 79.5779
I0614 19:49:47.650921 14053 vai_q.cpp:206] Calibration iter: 57/100 ,loss: 72.0192
I0614 19:49:47.678879 14053 vai_q.cpp:206] Calibration iter: 58/100 ,loss: 69.8692
I0614 19:49:47.705209 14053 vai_q.cpp:206] Calibration iter: 59/100 ,loss: 87.3365
I0614 19:49:47.731647 14053 vai_q.cpp:206] Calibration iter: 60/100 ,loss: 87.3365
I0614 19:49:47.767220 14053 vai_q.cpp:206] Calibration iter: 61/100 ,loss: 87.3365
I0614 19:49:47.807116 14053 vai_q.cpp:206] Calibration iter: 62/100 ,loss: 61.9606
I0614 19:49:47.834821 14053 vai_q.cpp:206] Calibration iter: 63/100 ,loss: 87.3365
I0614 19:49:47.861078 14053 vai_q.cpp:206] Calibration iter: 64/100 ,loss: 64.4481
I0614 19:49:47.888069 14053 vai_q.cpp:206] Calibration iter: 65/100 ,loss: 52.402
I0614 19:49:47.914990 14053 vai_q.cpp:206] Calibration iter: 66/100 ,loss: 62.8606
I0614 19:49:47.942502 14053 vai_q.cpp:206] Calibration iter: 67/100 ,loss: 61.1356
I0614 19:49:47.969200 14053 vai_q.cpp:206] Calibration iter: 68/100 ,loss: 70.5943
I0614 19:49:47.996351 14053 vai_q.cpp:206] Calibration iter: 69/100 ,loss: 87.3365
I0614 19:49:48.022949 14053 vai_q.cpp:206] Calibration iter: 70/100 ,loss: 87.3365
I0614 19:49:48.049441 14053 vai_q.cpp:206] Calibration iter: 71/100 ,loss: 63.7231
I0614 19:49:48.076560 14053 vai_q.cpp:206] Calibration iter: 72/100 ,loss: 79.4779
I0614 19:49:48.103462 14053 vai_q.cpp:206] Calibration iter: 73/100 ,loss: 62.7356
I0614 19:49:48.130326 14053 vai_q.cpp:206] Calibration iter: 74/100 ,loss: 71.8192
I0614 19:49:48.157845 14053 vai_q.cpp:206] Calibration iter: 75/100 ,loss: 78.6029
I0614 19:49:48.184190 14053 vai_q.cpp:206] Calibration iter: 76/100 ,loss: 63.2856
I0614 19:49:48.212148 14053 vai_q.cpp:206] Calibration iter: 77/100 ,loss: 87.3365
I0614 19:49:48.257133 14053 vai_q.cpp:206] Calibration iter: 78/100 ,loss: 87.3365
I0614 19:49:48.286109 14053 vai_q.cpp:206] Calibration iter: 79/100 ,loss: 69.8692
I0614 19:49:48.313253 14053 vai_q.cpp:206] Calibration iter: 80/100 ,loss: 87.3365
I0614 19:49:48.340082 14053 vai_q.cpp:206] Calibration iter: 81/100 ,loss: 80.3779
I0614 19:49:48.367605 14053 vai_q.cpp:206] Calibration iter: 82/100 ,loss: 78.6029
I0614 19:49:48.394793 14053 vai_q.cpp:206] Calibration iter: 83/100 ,loss: 61.1356
I0614 19:49:48.421958 14053 vai_q.cpp:206] Calibration iter: 84/100 ,loss: 69.8692
I0614 19:49:48.448503 14053 vai_q.cpp:206] Calibration iter: 85/100 ,loss: 43.6683
I0614 19:49:48.475891 14053 vai_q.cpp:206] Calibration iter: 86/100 ,loss: 87.3365
I0614 19:49:48.501998 14053 vai_q.cpp:206] Calibration iter: 87/100 ,loss: 53.8521
I0614 19:49:48.529081 14053 vai_q.cpp:206] Calibration iter: 88/100 ,loss: 62.8856
I0614 19:49:48.555800 14053 vai_q.cpp:206] Calibration iter: 89/100 ,loss: 87.3365
I0614 19:49:48.583519 14053 vai_q.cpp:206] Calibration iter: 90/100 ,loss: 69.8692
I0614 19:49:48.609596 14053 vai_q.cpp:206] Calibration iter: 91/100 ,loss: 72.0942
I0614 19:49:48.636324 14053 vai_q.cpp:206] Calibration iter: 92/100 ,loss: 70.1504
I0614 19:49:48.663163 14053 vai_q.cpp:206] Calibration iter: 93/100 ,loss: 87.3365
I0614 19:49:48.690383 14053 vai_q.cpp:206] Calibration iter: 94/100 ,loss: 61.1356
I0614 19:49:48.733708 14053 vai_q.cpp:206] Calibration iter: 95/100 ,loss: 69.8692
I0614 19:49:48.761873 14053 vai_q.cpp:206] Calibration iter: 96/100 ,loss: 62.5856
I0614 19:49:48.788213 14053 vai_q.cpp:206] Calibration iter: 97/100 ,loss: 78.6029
I0614 19:49:48.815366 14053 vai_q.cpp:206] Calibration iter: 98/100 ,loss: 69.8692
I0614 19:49:48.842427 14053 vai_q.cpp:206] Calibration iter: 99/100 ,loss: 78.6029
I0614 19:49:48.869251 14053 vai_q.cpp:206] Calibration iter: 100/100 ,loss: 69.8692
I0614 19:49:48.869293 14053 vai_q.cpp:211] Calibration Done!
I0614 19:49:49.726009 14053 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0614 19:49:49.726063 14053 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0614 19:49:49.726071 14053 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy-top1
I0614 19:49:49.726081 14053 net.cpp:52] Initializing net from parameters: 
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    crop_size: 227
    mean_value: 106
    mean_value: 116
    mean_value: 124
  }
  image_data_param {
    source: "deploy/alexnetBNnoLRN/pruned/data/calib/calibration.txt"
    batch_size: 10
    shuffle: true
    root_folder: "deploy/alexnetBNnoLRN/pruned/data/calib/"
  }
}
layer {
  name: "data_fixed"
  type: "FixedNeuron"
  bottom: "data"
  top: "data"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: OVER_FLOW
    bit_width: 8
    follow_data_layer: true
  }
}
layer {
  name: "conv1"
  type: "ConvolutionFixed"
  bottom: "data"
  top: "bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  convolution_param {
    num_output: 78
    bias_term: true
    pad: 0
    kernel_size: 8
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "bn1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "pool1_fixed"
  type: "FixedNeuron"
  bottom: "pool1"
  top: "pool1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "conv2"
  type: "ConvolutionFixed"
  bottom: "pool1"
  top: "bn2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  convolution_param {
    num_output: 180
    bias_term: true
    pad: 2
    kernel_size: 5
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "bn2"
  top: "relu2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "pool2_fixed"
  type: "FixedNeuron"
  bottom: "pool2"
  top: "pool2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "conv3"
  type: "ConvolutionFixed"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 40
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "relu3_fixed"
  type: "FixedNeuron"
  bottom: "relu3"
  top: "relu3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "conv4"
  type: "ConvolutionFixed"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 40
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "relu4_fixed"
  type: "FixedNeuron"
  bottom: "relu4"
  top: "relu4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "conv5"
  type: "ConvolutionFixed"
  bottom: "relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 26
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "pool5_fixed"
  type: "FixedNeuron"
  bottom: "pool5"
  top: "pool5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "fc6"
  type: "InnerProductFixed"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "relu6_fixed"
  type: "FixedNeuron"
  bottom: "relu6"
  top: "relu6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "fc7"
  type: "InnerProductFixed"
  bottom: "relu6"
  top: "bn7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    bias_term: true
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "bn7"
  top: "relu7"
}
layer {
  name: "relu7_fixed"
  type: "FixedNeuron"
  bottom: "relu7"
  top: "relu7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "fc8"
  type: "InnerProductFixed"
  bottom: "relu7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "fc8_fixed"
  type: "FixedNeuron"
  bottom: "fc8"
  top: "fc8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0614 19:49:49.726574 14053 layer_factory.hpp:77] Creating layer data
I0614 19:49:49.726600 14053 net.cpp:94] Creating Layer data
I0614 19:49:49.726622 14053 net.cpp:409] data -> data
I0614 19:49:49.726655 14053 net.cpp:409] data -> label
I0614 19:49:49.726686 14053 image_data_layer.cpp:41] Opening file deploy/alexnetBNnoLRN/pruned/data/calib/calibration.txt
I0614 19:49:49.727335 14053 image_data_layer.cpp:51] Shuffling data
I0614 19:49:49.727370 14053 image_data_layer.cpp:56] A total of 200 images.
I0614 19:49:49.731266 14053 image_data_layer.cpp:84] output data size: 10,3,227,227
I0614 19:49:49.762022 14053 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0614 19:49:49.762075 14053 net.cpp:144] Setting up data
I0614 19:49:49.762080 14053 net.cpp:151] Top shape: 10 3 227 227 (1545870)
I0614 19:49:49.762090 14053 net.cpp:151] Top shape: 10 (10)
I0614 19:49:49.762094 14053 net.cpp:159] Memory required for data: 6183520
I0614 19:49:49.762099 14053 layer_factory.hpp:77] Creating layer data_fixed
I0614 19:49:49.762111 14053 net.cpp:94] Creating Layer data_fixed
I0614 19:49:49.762115 14053 net.cpp:435] data_fixed <- data
I0614 19:49:49.762121 14053 net.cpp:396] data_fixed -> data (in-place)
I0614 19:49:49.762235 14053 net.cpp:144] Setting up data_fixed
I0614 19:49:49.762239 14053 net.cpp:151] Top shape: 10 3 227 227 (1545870)
I0614 19:49:49.762245 14053 net.cpp:159] Memory required for data: 12367000
I0614 19:49:49.762255 14053 layer_factory.hpp:77] Creating layer conv1
I0614 19:49:49.762266 14053 net.cpp:94] Creating Layer conv1
I0614 19:49:49.762269 14053 net.cpp:435] conv1 <- data
I0614 19:49:49.762274 14053 net.cpp:409] conv1 -> bn1
I0614 19:49:49.762573 14053 layer_factory.hpp:77] Creating layer conv1
I0614 19:49:49.762838 14053 net.cpp:144] Setting up conv1
I0614 19:49:49.762845 14053 net.cpp:151] Top shape: 10 78 55 55 (2359500)
I0614 19:49:49.762850 14053 net.cpp:159] Memory required for data: 21805000
I0614 19:49:49.762857 14053 layer_factory.hpp:77] Creating layer relu1
I0614 19:49:49.762863 14053 net.cpp:94] Creating Layer relu1
I0614 19:49:49.762866 14053 net.cpp:435] relu1 <- bn1
I0614 19:49:49.762871 14053 net.cpp:409] relu1 -> relu1
I0614 19:49:49.762881 14053 net.cpp:144] Setting up relu1
I0614 19:49:49.762884 14053 net.cpp:151] Top shape: 10 78 55 55 (2359500)
I0614 19:49:49.762888 14053 net.cpp:159] Memory required for data: 31243000
I0614 19:49:49.762892 14053 layer_factory.hpp:77] Creating layer pool1
I0614 19:49:49.762897 14053 net.cpp:94] Creating Layer pool1
I0614 19:49:49.762900 14053 net.cpp:435] pool1 <- relu1
I0614 19:49:49.762904 14053 net.cpp:409] pool1 -> pool1
I0614 19:49:49.762919 14053 net.cpp:144] Setting up pool1
I0614 19:49:49.762923 14053 net.cpp:151] Top shape: 10 78 27 27 (568620)
I0614 19:49:49.762926 14053 net.cpp:159] Memory required for data: 33517480
I0614 19:49:49.762931 14053 layer_factory.hpp:77] Creating layer pool1_fixed
I0614 19:49:49.762938 14053 net.cpp:94] Creating Layer pool1_fixed
I0614 19:49:49.762940 14053 net.cpp:435] pool1_fixed <- pool1
I0614 19:49:49.762944 14053 net.cpp:396] pool1_fixed -> pool1 (in-place)
I0614 19:49:49.762959 14053 net.cpp:144] Setting up pool1_fixed
I0614 19:49:49.762964 14053 net.cpp:151] Top shape: 10 78 27 27 (568620)
I0614 19:49:49.762969 14053 net.cpp:159] Memory required for data: 35791960
I0614 19:49:49.762972 14053 layer_factory.hpp:77] Creating layer conv2
I0614 19:49:49.762979 14053 net.cpp:94] Creating Layer conv2
I0614 19:49:49.762981 14053 net.cpp:435] conv2 <- pool1
I0614 19:49:49.762985 14053 net.cpp:409] conv2 -> bn2
I0614 19:49:49.766552 14053 layer_factory.hpp:77] Creating layer conv2
I0614 19:49:49.770923 14053 net.cpp:144] Setting up conv2
I0614 19:49:49.770936 14053 net.cpp:151] Top shape: 10 180 27 27 (1312200)
I0614 19:49:49.770943 14053 net.cpp:159] Memory required for data: 41040760
I0614 19:49:49.770951 14053 layer_factory.hpp:77] Creating layer relu2
I0614 19:49:49.770957 14053 net.cpp:94] Creating Layer relu2
I0614 19:49:49.770961 14053 net.cpp:435] relu2 <- bn2
I0614 19:49:49.770967 14053 net.cpp:409] relu2 -> relu2
I0614 19:49:49.770978 14053 net.cpp:144] Setting up relu2
I0614 19:49:49.770982 14053 net.cpp:151] Top shape: 10 180 27 27 (1312200)
I0614 19:49:49.770985 14053 net.cpp:159] Memory required for data: 46289560
I0614 19:49:49.770988 14053 layer_factory.hpp:77] Creating layer pool2
I0614 19:49:49.770993 14053 net.cpp:94] Creating Layer pool2
I0614 19:49:49.770996 14053 net.cpp:435] pool2 <- relu2
I0614 19:49:49.771000 14053 net.cpp:409] pool2 -> pool2
I0614 19:49:49.771014 14053 net.cpp:144] Setting up pool2
I0614 19:49:49.771018 14053 net.cpp:151] Top shape: 10 180 13 13 (304200)
I0614 19:49:49.771020 14053 net.cpp:159] Memory required for data: 47506360
I0614 19:49:49.771023 14053 layer_factory.hpp:77] Creating layer pool2_fixed
I0614 19:49:49.771028 14053 net.cpp:94] Creating Layer pool2_fixed
I0614 19:49:49.771031 14053 net.cpp:435] pool2_fixed <- pool2
I0614 19:49:49.771034 14053 net.cpp:396] pool2_fixed -> pool2 (in-place)
I0614 19:49:49.771047 14053 net.cpp:144] Setting up pool2_fixed
I0614 19:49:49.771050 14053 net.cpp:151] Top shape: 10 180 13 13 (304200)
I0614 19:49:49.771054 14053 net.cpp:159] Memory required for data: 48723160
I0614 19:49:49.771057 14053 layer_factory.hpp:77] Creating layer conv3
I0614 19:49:49.771064 14053 net.cpp:94] Creating Layer conv3
I0614 19:49:49.771067 14053 net.cpp:435] conv3 <- pool2
I0614 19:49:49.771071 14053 net.cpp:409] conv3 -> conv3
I0614 19:49:49.771705 14053 layer_factory.hpp:77] Creating layer conv3
I0614 19:49:49.772384 14053 net.cpp:144] Setting up conv3
I0614 19:49:49.772392 14053 net.cpp:151] Top shape: 10 40 13 13 (67600)
I0614 19:49:49.772397 14053 net.cpp:159] Memory required for data: 48993560
I0614 19:49:49.772404 14053 layer_factory.hpp:77] Creating layer relu3
I0614 19:49:49.772409 14053 net.cpp:94] Creating Layer relu3
I0614 19:49:49.772413 14053 net.cpp:435] relu3 <- conv3
I0614 19:49:49.772418 14053 net.cpp:409] relu3 -> relu3
I0614 19:49:49.772428 14053 net.cpp:144] Setting up relu3
I0614 19:49:49.772431 14053 net.cpp:151] Top shape: 10 40 13 13 (67600)
I0614 19:49:49.772435 14053 net.cpp:159] Memory required for data: 49263960
I0614 19:49:49.772439 14053 layer_factory.hpp:77] Creating layer relu3_fixed
I0614 19:49:49.772442 14053 net.cpp:94] Creating Layer relu3_fixed
I0614 19:49:49.772445 14053 net.cpp:435] relu3_fixed <- relu3
I0614 19:49:49.772449 14053 net.cpp:396] relu3_fixed -> relu3 (in-place)
I0614 19:49:49.772462 14053 net.cpp:144] Setting up relu3_fixed
I0614 19:49:49.772465 14053 net.cpp:151] Top shape: 10 40 13 13 (67600)
I0614 19:49:49.772469 14053 net.cpp:159] Memory required for data: 49534360
I0614 19:49:49.772473 14053 layer_factory.hpp:77] Creating layer conv4
I0614 19:49:49.772480 14053 net.cpp:94] Creating Layer conv4
I0614 19:49:49.772485 14053 net.cpp:435] conv4 <- relu3
I0614 19:49:49.772490 14053 net.cpp:409] conv4 -> conv4
I0614 19:49:49.772691 14053 layer_factory.hpp:77] Creating layer conv4
I0614 19:49:49.772946 14053 net.cpp:144] Setting up conv4
I0614 19:49:49.772953 14053 net.cpp:151] Top shape: 10 40 13 13 (67600)
I0614 19:49:49.772958 14053 net.cpp:159] Memory required for data: 49804760
I0614 19:49:49.772962 14053 layer_factory.hpp:77] Creating layer relu4
I0614 19:49:49.772966 14053 net.cpp:94] Creating Layer relu4
I0614 19:49:49.772969 14053 net.cpp:435] relu4 <- conv4
I0614 19:49:49.772974 14053 net.cpp:409] relu4 -> relu4
I0614 19:49:49.772984 14053 net.cpp:144] Setting up relu4
I0614 19:49:49.772986 14053 net.cpp:151] Top shape: 10 40 13 13 (67600)
I0614 19:49:49.772990 14053 net.cpp:159] Memory required for data: 50075160
I0614 19:49:49.772992 14053 layer_factory.hpp:77] Creating layer relu4_fixed
I0614 19:49:49.772996 14053 net.cpp:94] Creating Layer relu4_fixed
I0614 19:49:49.773000 14053 net.cpp:435] relu4_fixed <- relu4
I0614 19:49:49.773003 14053 net.cpp:396] relu4_fixed -> relu4 (in-place)
I0614 19:49:49.773015 14053 net.cpp:144] Setting up relu4_fixed
I0614 19:49:49.773018 14053 net.cpp:151] Top shape: 10 40 13 13 (67600)
I0614 19:49:49.773022 14053 net.cpp:159] Memory required for data: 50345560
I0614 19:49:49.773025 14053 layer_factory.hpp:77] Creating layer conv5
I0614 19:49:49.773032 14053 net.cpp:94] Creating Layer conv5
I0614 19:49:49.773036 14053 net.cpp:435] conv5 <- relu4
I0614 19:49:49.773042 14053 net.cpp:409] conv5 -> conv5
I0614 19:49:49.773203 14053 layer_factory.hpp:77] Creating layer conv5
I0614 19:49:49.773420 14053 net.cpp:144] Setting up conv5
I0614 19:49:49.773424 14053 net.cpp:151] Top shape: 10 26 13 13 (43940)
I0614 19:49:49.773429 14053 net.cpp:159] Memory required for data: 50521320
I0614 19:49:49.773433 14053 layer_factory.hpp:77] Creating layer relu5
I0614 19:49:49.773438 14053 net.cpp:94] Creating Layer relu5
I0614 19:49:49.773442 14053 net.cpp:435] relu5 <- conv5
I0614 19:49:49.773445 14053 net.cpp:409] relu5 -> relu5
I0614 19:49:49.773458 14053 net.cpp:144] Setting up relu5
I0614 19:49:49.773460 14053 net.cpp:151] Top shape: 10 26 13 13 (43940)
I0614 19:49:49.773464 14053 net.cpp:159] Memory required for data: 50697080
I0614 19:49:49.773468 14053 layer_factory.hpp:77] Creating layer pool5
I0614 19:49:49.773473 14053 net.cpp:94] Creating Layer pool5
I0614 19:49:49.773475 14053 net.cpp:435] pool5 <- relu5
I0614 19:49:49.773478 14053 net.cpp:409] pool5 -> pool5
I0614 19:49:49.773494 14053 net.cpp:144] Setting up pool5
I0614 19:49:49.773496 14053 net.cpp:151] Top shape: 10 26 6 6 (9360)
I0614 19:49:49.773500 14053 net.cpp:159] Memory required for data: 50734520
I0614 19:49:49.773504 14053 layer_factory.hpp:77] Creating layer pool5_fixed
I0614 19:49:49.773507 14053 net.cpp:94] Creating Layer pool5_fixed
I0614 19:49:49.773510 14053 net.cpp:435] pool5_fixed <- pool5
I0614 19:49:49.773514 14053 net.cpp:396] pool5_fixed -> pool5 (in-place)
I0614 19:49:49.773530 14053 net.cpp:144] Setting up pool5_fixed
I0614 19:49:49.773532 14053 net.cpp:151] Top shape: 10 26 6 6 (9360)
I0614 19:49:49.773536 14053 net.cpp:159] Memory required for data: 50771960
I0614 19:49:49.773540 14053 layer_factory.hpp:77] Creating layer fc6
I0614 19:49:49.773546 14053 net.cpp:94] Creating Layer fc6
I0614 19:49:49.773548 14053 net.cpp:435] fc6 <- pool5
I0614 19:49:49.773555 14053 net.cpp:409] fc6 -> fc6
I0614 19:49:49.810971 14053 layer_factory.hpp:77] Creating layer fc6
I0614 19:49:49.845546 14053 net.cpp:144] Setting up fc6
I0614 19:49:49.845562 14053 net.cpp:151] Top shape: 10 4096 (40960)
I0614 19:49:49.845569 14053 net.cpp:159] Memory required for data: 50935800
I0614 19:49:49.845580 14053 layer_factory.hpp:77] Creating layer relu6
I0614 19:49:49.845588 14053 net.cpp:94] Creating Layer relu6
I0614 19:49:49.845592 14053 net.cpp:435] relu6 <- fc6
I0614 19:49:49.845598 14053 net.cpp:409] relu6 -> relu6
I0614 19:49:49.845613 14053 net.cpp:144] Setting up relu6
I0614 19:49:49.845616 14053 net.cpp:151] Top shape: 10 4096 (40960)
I0614 19:49:49.845619 14053 net.cpp:159] Memory required for data: 51099640
I0614 19:49:49.845621 14053 layer_factory.hpp:77] Creating layer relu6_fixed
I0614 19:49:49.845628 14053 net.cpp:94] Creating Layer relu6_fixed
I0614 19:49:49.845629 14053 net.cpp:435] relu6_fixed <- relu6
I0614 19:49:49.845633 14053 net.cpp:396] relu6_fixed -> relu6 (in-place)
I0614 19:49:49.845645 14053 net.cpp:144] Setting up relu6_fixed
I0614 19:49:49.845647 14053 net.cpp:151] Top shape: 10 4096 (40960)
I0614 19:49:49.845650 14053 net.cpp:159] Memory required for data: 51263480
I0614 19:49:49.845654 14053 layer_factory.hpp:77] Creating layer fc7
I0614 19:49:49.845659 14053 net.cpp:94] Creating Layer fc7
I0614 19:49:49.845662 14053 net.cpp:435] fc7 <- relu6
I0614 19:49:49.845665 14053 net.cpp:409] fc7 -> bn7
I0614 19:49:49.995951 14053 layer_factory.hpp:77] Creating layer fc7
I0614 19:49:50.143244 14053 net.cpp:144] Setting up fc7
I0614 19:49:50.143270 14053 net.cpp:151] Top shape: 10 4096 (40960)
I0614 19:49:50.143276 14053 net.cpp:159] Memory required for data: 51427320
I0614 19:49:50.143286 14053 layer_factory.hpp:77] Creating layer relu7
I0614 19:49:50.143293 14053 net.cpp:94] Creating Layer relu7
I0614 19:49:50.143297 14053 net.cpp:435] relu7 <- bn7
I0614 19:49:50.143303 14053 net.cpp:409] relu7 -> relu7
I0614 19:49:50.143318 14053 net.cpp:144] Setting up relu7
I0614 19:49:50.143321 14053 net.cpp:151] Top shape: 10 4096 (40960)
I0614 19:49:50.143323 14053 net.cpp:159] Memory required for data: 51591160
I0614 19:49:50.143327 14053 layer_factory.hpp:77] Creating layer relu7_fixed
I0614 19:49:50.143334 14053 net.cpp:94] Creating Layer relu7_fixed
I0614 19:49:50.143337 14053 net.cpp:435] relu7_fixed <- relu7
I0614 19:49:50.143340 14053 net.cpp:396] relu7_fixed -> relu7 (in-place)
I0614 19:49:50.143353 14053 net.cpp:144] Setting up relu7_fixed
I0614 19:49:50.143355 14053 net.cpp:151] Top shape: 10 4096 (40960)
I0614 19:49:50.143358 14053 net.cpp:159] Memory required for data: 51755000
I0614 19:49:50.143361 14053 layer_factory.hpp:77] Creating layer fc8
I0614 19:49:50.143368 14053 net.cpp:94] Creating Layer fc8
I0614 19:49:50.143370 14053 net.cpp:435] fc8 <- relu7
I0614 19:49:50.143374 14053 net.cpp:409] fc8 -> fc8
I0614 19:49:50.143465 14053 layer_factory.hpp:77] Creating layer fc8
I0614 19:49:50.143611 14053 net.cpp:144] Setting up fc8
I0614 19:49:50.143632 14053 net.cpp:151] Top shape: 10 2 (20)
I0614 19:49:50.143636 14053 net.cpp:159] Memory required for data: 51755080
I0614 19:49:50.143641 14053 layer_factory.hpp:77] Creating layer fc8_fixed
I0614 19:49:50.143646 14053 net.cpp:94] Creating Layer fc8_fixed
I0614 19:49:50.143649 14053 net.cpp:435] fc8_fixed <- fc8
I0614 19:49:50.143653 14053 net.cpp:396] fc8_fixed -> fc8 (in-place)
I0614 19:49:50.143667 14053 net.cpp:144] Setting up fc8_fixed
I0614 19:49:50.143671 14053 net.cpp:151] Top shape: 10 2 (20)
I0614 19:49:50.143673 14053 net.cpp:159] Memory required for data: 51755160
I0614 19:49:50.143676 14053 layer_factory.hpp:77] Creating layer loss
I0614 19:49:50.143682 14053 net.cpp:94] Creating Layer loss
I0614 19:49:50.143684 14053 net.cpp:435] loss <- fc8
I0614 19:49:50.143688 14053 net.cpp:435] loss <- label
I0614 19:49:50.143692 14053 net.cpp:409] loss -> loss
I0614 19:49:50.143698 14053 layer_factory.hpp:77] Creating layer loss
I0614 19:49:50.143739 14053 net.cpp:144] Setting up loss
I0614 19:49:50.143743 14053 net.cpp:151] Top shape: (1)
I0614 19:49:50.143746 14053 net.cpp:154]     with loss weight 1
I0614 19:49:50.143759 14053 net.cpp:159] Memory required for data: 51755164
I0614 19:49:50.143761 14053 net.cpp:220] loss needs backward computation.
I0614 19:49:50.143765 14053 net.cpp:220] fc8_fixed needs backward computation.
I0614 19:49:50.143767 14053 net.cpp:220] fc8 needs backward computation.
I0614 19:49:50.143771 14053 net.cpp:220] relu7_fixed needs backward computation.
I0614 19:49:50.143774 14053 net.cpp:220] relu7 needs backward computation.
I0614 19:49:50.143779 14053 net.cpp:220] fc7 needs backward computation.
I0614 19:49:50.143782 14053 net.cpp:220] relu6_fixed needs backward computation.
I0614 19:49:50.143786 14053 net.cpp:220] relu6 needs backward computation.
I0614 19:49:50.143790 14053 net.cpp:220] fc6 needs backward computation.
I0614 19:49:50.143792 14053 net.cpp:220] pool5_fixed needs backward computation.
I0614 19:49:50.143796 14053 net.cpp:220] pool5 needs backward computation.
I0614 19:49:50.143800 14053 net.cpp:220] relu5 needs backward computation.
I0614 19:49:50.143802 14053 net.cpp:220] conv5 needs backward computation.
I0614 19:49:50.143806 14053 net.cpp:220] relu4_fixed needs backward computation.
I0614 19:49:50.143810 14053 net.cpp:220] relu4 needs backward computation.
I0614 19:49:50.143815 14053 net.cpp:220] conv4 needs backward computation.
I0614 19:49:50.143818 14053 net.cpp:220] relu3_fixed needs backward computation.
I0614 19:49:50.143821 14053 net.cpp:220] relu3 needs backward computation.
I0614 19:49:50.143824 14053 net.cpp:220] conv3 needs backward computation.
I0614 19:49:50.143827 14053 net.cpp:220] pool2_fixed needs backward computation.
I0614 19:49:50.143831 14053 net.cpp:220] pool2 needs backward computation.
I0614 19:49:50.143834 14053 net.cpp:220] relu2 needs backward computation.
I0614 19:49:50.143837 14053 net.cpp:220] conv2 needs backward computation.
I0614 19:49:50.143841 14053 net.cpp:220] pool1_fixed needs backward computation.
I0614 19:49:50.143843 14053 net.cpp:220] pool1 needs backward computation.
I0614 19:49:50.143846 14053 net.cpp:220] relu1 needs backward computation.
I0614 19:49:50.143849 14053 net.cpp:220] conv1 needs backward computation.
I0614 19:49:50.143853 14053 net.cpp:222] data_fixed does not need backward computation.
I0614 19:49:50.143857 14053 net.cpp:222] data does not need backward computation.
I0614 19:49:50.143860 14053 net.cpp:264] This network produces output loss
I0614 19:49:50.143874 14053 net.cpp:284] Network initialization done.
I0614 19:49:50.206009 14053 net.cpp:323] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0614 19:49:50.206035 14053 net.cpp:52] Initializing net from parameters: 
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_value: 106
    mean_value: 116
    mean_value: 124
  }
  data_param {
    source: "input/lmdb/valid_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "data_fixed"
  type: "FixedNeuron"
  bottom: "data"
  top: "data"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: OVER_FLOW
    bit_width: 8
    follow_data_layer: true
  }
}
layer {
  name: "conv1"
  type: "ConvolutionFixed"
  bottom: "data"
  top: "bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  convolution_param {
    num_output: 78
    bias_term: true
    pad: 0
    kernel_size: 8
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "bn1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "pool1_fixed"
  type: "FixedNeuron"
  bottom: "pool1"
  top: "pool1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "conv2"
  type: "ConvolutionFixed"
  bottom: "pool1"
  top: "bn2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  convolution_param {
    num_output: 180
    bias_term: true
    pad: 2
    kernel_size: 5
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "bn2"
  top: "relu2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "pool2_fixed"
  type: "FixedNeuron"
  bottom: "pool2"
  top: "pool2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "conv3"
  type: "ConvolutionFixed"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 40
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "relu3_fixed"
  type: "FixedNeuron"
  bottom: "relu3"
  top: "relu3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "conv4"
  type: "ConvolutionFixed"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 40
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "relu4_fixed"
  type: "FixedNeuron"
  bottom: "relu4"
  top: "relu4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "conv5"
  type: "ConvolutionFixed"
  bottom: "relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 26
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "pool5_fixed"
  type: "FixedNeuron"
  bottom: "pool5"
  top: "pool5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "fc6"
  type: "InnerProductFixed"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "relu6_fixed"
  type: "FixedNeuron"
  bottom: "relu6"
  top: "relu6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "fc7"
  type: "InnerProductFixed"
  bottom: "relu6"
  top: "bn7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    bias_term: true
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "bn7"
  top: "relu7"
}
layer {
  name: "relu7_fixed"
  type: "FixedNeuron"
  bottom: "relu7"
  top: "relu7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "fc8"
  type: "InnerProductFixed"
  bottom: "relu7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "fc8_fixed"
  type: "FixedNeuron"
  bottom: "fc8"
  top: "fc8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy-top1"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "top-1"
  include {
    phase: TEST
  }
}
I0614 19:49:50.206477 14053 layer_factory.hpp:77] Creating layer data
I0614 19:49:50.206512 14053 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0614 19:49:50.207352 14053 net.cpp:94] Creating Layer data
I0614 19:49:50.207365 14053 net.cpp:409] data -> data
I0614 19:49:50.207374 14053 net.cpp:409] data -> label
I0614 19:49:50.209172 14087 db_lmdb.cpp:35] Opened lmdb input/lmdb/valid_lmdb
I0614 19:49:50.209199 14087 db_lmdb.cpp:38] Items count: 4000
I0614 19:49:50.209228 14087 data_reader.cpp:124] TEST: reading data using 1 channel(s)
I0614 19:49:50.209393 14053 data_layer.cpp:78] ReshapePrefetch 50, 3, 227, 227
I0614 19:49:50.209447 14053 data_layer.cpp:83] output data size: 50,3,227,227
I0614 19:49:50.324445 14053 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0614 19:49:50.324695 14053 net.cpp:144] Setting up data
I0614 19:49:50.324704 14053 net.cpp:151] Top shape: 50 3 227 227 (7729350)
I0614 19:49:50.324714 14053 net.cpp:151] Top shape: 50 (50)
I0614 19:49:50.324718 14053 net.cpp:159] Memory required for data: 30917600
I0614 19:49:50.324723 14053 layer_factory.hpp:77] Creating layer label_data_1_split
I0614 19:49:50.324736 14053 net.cpp:94] Creating Layer label_data_1_split
I0614 19:49:50.324740 14053 net.cpp:435] label_data_1_split <- label
I0614 19:49:50.324748 14053 net.cpp:409] label_data_1_split -> label_data_1_split_0
I0614 19:49:50.324774 14053 net.cpp:409] label_data_1_split -> label_data_1_split_1
I0614 19:49:50.324781 14053 net.cpp:409] label_data_1_split -> label_data_1_split_2
I0614 19:49:50.324826 14053 net.cpp:144] Setting up label_data_1_split
I0614 19:49:50.324831 14053 net.cpp:151] Top shape: 50 (50)
I0614 19:49:50.324834 14053 net.cpp:151] Top shape: 50 (50)
I0614 19:49:50.324838 14053 net.cpp:151] Top shape: 50 (50)
I0614 19:49:50.324841 14053 net.cpp:159] Memory required for data: 30918200
I0614 19:49:50.324844 14053 layer_factory.hpp:77] Creating layer data_fixed
I0614 19:49:50.324851 14053 net.cpp:94] Creating Layer data_fixed
I0614 19:49:50.324854 14053 net.cpp:435] data_fixed <- data
I0614 19:49:50.324860 14053 net.cpp:396] data_fixed -> data (in-place)
I0614 19:49:50.324879 14053 net.cpp:144] Setting up data_fixed
I0614 19:49:50.324882 14053 net.cpp:151] Top shape: 50 3 227 227 (7729350)
I0614 19:49:50.324888 14053 net.cpp:159] Memory required for data: 61835600
I0614 19:49:50.324898 14053 layer_factory.hpp:77] Creating layer conv1
I0614 19:49:50.324908 14053 net.cpp:94] Creating Layer conv1
I0614 19:49:50.324911 14053 net.cpp:435] conv1 <- data
I0614 19:49:50.324915 14053 net.cpp:409] conv1 -> bn1
I0614 19:49:50.325240 14053 layer_factory.hpp:77] Creating layer conv1
I0614 19:49:50.325531 14053 net.cpp:144] Setting up conv1
I0614 19:49:50.325538 14053 net.cpp:151] Top shape: 50 78 55 55 (11797500)
I0614 19:49:50.325544 14053 net.cpp:159] Memory required for data: 109025600
I0614 19:49:50.325551 14053 layer_factory.hpp:77] Creating layer relu1
I0614 19:49:50.325557 14053 net.cpp:94] Creating Layer relu1
I0614 19:49:50.325560 14053 net.cpp:435] relu1 <- bn1
I0614 19:49:50.325564 14053 net.cpp:409] relu1 -> relu1
I0614 19:49:50.325577 14053 net.cpp:144] Setting up relu1
I0614 19:49:50.325582 14053 net.cpp:151] Top shape: 50 78 55 55 (11797500)
I0614 19:49:50.325587 14053 net.cpp:159] Memory required for data: 156215600
I0614 19:49:50.325592 14053 layer_factory.hpp:77] Creating layer pool1
I0614 19:49:50.325598 14053 net.cpp:94] Creating Layer pool1
I0614 19:49:50.325603 14053 net.cpp:435] pool1 <- relu1
I0614 19:49:50.325608 14053 net.cpp:409] pool1 -> pool1
I0614 19:49:50.325626 14053 net.cpp:144] Setting up pool1
I0614 19:49:50.325630 14053 net.cpp:151] Top shape: 50 78 27 27 (2843100)
I0614 19:49:50.325636 14053 net.cpp:159] Memory required for data: 167588000
I0614 19:49:50.325639 14053 layer_factory.hpp:77] Creating layer pool1_fixed
I0614 19:49:50.325644 14053 net.cpp:94] Creating Layer pool1_fixed
I0614 19:49:50.325647 14053 net.cpp:435] pool1_fixed <- pool1
I0614 19:49:50.325651 14053 net.cpp:396] pool1_fixed -> pool1 (in-place)
I0614 19:49:50.325667 14053 net.cpp:144] Setting up pool1_fixed
I0614 19:49:50.325670 14053 net.cpp:151] Top shape: 50 78 27 27 (2843100)
I0614 19:49:50.325675 14053 net.cpp:159] Memory required for data: 178960400
I0614 19:49:50.325680 14053 layer_factory.hpp:77] Creating layer conv2
I0614 19:49:50.325687 14053 net.cpp:94] Creating Layer conv2
I0614 19:49:50.325692 14053 net.cpp:435] conv2 <- pool1
I0614 19:49:50.325698 14053 net.cpp:409] conv2 -> bn2
I0614 19:49:50.331473 14053 layer_factory.hpp:77] Creating layer conv2
I0614 19:49:50.335889 14053 net.cpp:144] Setting up conv2
I0614 19:49:50.335904 14053 net.cpp:151] Top shape: 50 180 27 27 (6561000)
I0614 19:49:50.335911 14053 net.cpp:159] Memory required for data: 205204400
I0614 19:49:50.335922 14053 layer_factory.hpp:77] Creating layer relu2
I0614 19:49:50.335929 14053 net.cpp:94] Creating Layer relu2
I0614 19:49:50.335933 14053 net.cpp:435] relu2 <- bn2
I0614 19:49:50.335939 14053 net.cpp:409] relu2 -> relu2
I0614 19:49:50.335952 14053 net.cpp:144] Setting up relu2
I0614 19:49:50.335955 14053 net.cpp:151] Top shape: 50 180 27 27 (6561000)
I0614 19:49:50.335959 14053 net.cpp:159] Memory required for data: 231448400
I0614 19:49:50.335963 14053 layer_factory.hpp:77] Creating layer pool2
I0614 19:49:50.335968 14053 net.cpp:94] Creating Layer pool2
I0614 19:49:50.335973 14053 net.cpp:435] pool2 <- relu2
I0614 19:49:50.335976 14053 net.cpp:409] pool2 -> pool2
I0614 19:49:50.335992 14053 net.cpp:144] Setting up pool2
I0614 19:49:50.335995 14053 net.cpp:151] Top shape: 50 180 13 13 (1521000)
I0614 19:49:50.335999 14053 net.cpp:159] Memory required for data: 237532400
I0614 19:49:50.336002 14053 layer_factory.hpp:77] Creating layer pool2_fixed
I0614 19:49:50.336009 14053 net.cpp:94] Creating Layer pool2_fixed
I0614 19:49:50.336011 14053 net.cpp:435] pool2_fixed <- pool2
I0614 19:49:50.336015 14053 net.cpp:396] pool2_fixed -> pool2 (in-place)
I0614 19:49:50.336030 14053 net.cpp:144] Setting up pool2_fixed
I0614 19:49:50.336033 14053 net.cpp:151] Top shape: 50 180 13 13 (1521000)
I0614 19:49:50.336036 14053 net.cpp:159] Memory required for data: 243616400
I0614 19:49:50.336040 14053 layer_factory.hpp:77] Creating layer conv3
I0614 19:49:50.336048 14053 net.cpp:94] Creating Layer conv3
I0614 19:49:50.336051 14053 net.cpp:435] conv3 <- pool2
I0614 19:49:50.336056 14053 net.cpp:409] conv3 -> conv3
I0614 19:49:50.336845 14053 layer_factory.hpp:77] Creating layer conv3
I0614 19:49:50.337797 14053 net.cpp:144] Setting up conv3
I0614 19:49:50.337811 14053 net.cpp:151] Top shape: 50 40 13 13 (338000)
I0614 19:49:50.337821 14053 net.cpp:159] Memory required for data: 244968400
I0614 19:49:50.337832 14053 layer_factory.hpp:77] Creating layer relu3
I0614 19:49:50.337841 14053 net.cpp:94] Creating Layer relu3
I0614 19:49:50.337846 14053 net.cpp:435] relu3 <- conv3
I0614 19:49:50.337853 14053 net.cpp:409] relu3 -> relu3
I0614 19:49:50.337872 14053 net.cpp:144] Setting up relu3
I0614 19:49:50.337877 14053 net.cpp:151] Top shape: 50 40 13 13 (338000)
I0614 19:49:50.337883 14053 net.cpp:159] Memory required for data: 246320400
I0614 19:49:50.337888 14053 layer_factory.hpp:77] Creating layer relu3_fixed
I0614 19:49:50.337895 14053 net.cpp:94] Creating Layer relu3_fixed
I0614 19:49:50.337900 14053 net.cpp:435] relu3_fixed <- relu3
I0614 19:49:50.337906 14053 net.cpp:396] relu3_fixed -> relu3 (in-place)
I0614 19:49:50.337926 14053 net.cpp:144] Setting up relu3_fixed
I0614 19:49:50.337931 14053 net.cpp:151] Top shape: 50 40 13 13 (338000)
I0614 19:49:50.337939 14053 net.cpp:159] Memory required for data: 247672400
I0614 19:49:50.337944 14053 layer_factory.hpp:77] Creating layer conv4
I0614 19:49:50.337953 14053 net.cpp:94] Creating Layer conv4
I0614 19:49:50.337956 14053 net.cpp:435] conv4 <- relu3
I0614 19:49:50.337962 14053 net.cpp:409] conv4 -> conv4
I0614 19:49:50.338238 14053 layer_factory.hpp:77] Creating layer conv4
I0614 19:49:50.338534 14053 net.cpp:144] Setting up conv4
I0614 19:49:50.338541 14053 net.cpp:151] Top shape: 50 40 13 13 (338000)
I0614 19:49:50.338547 14053 net.cpp:159] Memory required for data: 249024400
I0614 19:49:50.338552 14053 layer_factory.hpp:77] Creating layer relu4
I0614 19:49:50.338557 14053 net.cpp:94] Creating Layer relu4
I0614 19:49:50.338562 14053 net.cpp:435] relu4 <- conv4
I0614 19:49:50.338568 14053 net.cpp:409] relu4 -> relu4
I0614 19:49:50.338583 14053 net.cpp:144] Setting up relu4
I0614 19:49:50.338588 14053 net.cpp:151] Top shape: 50 40 13 13 (338000)
I0614 19:49:50.338595 14053 net.cpp:159] Memory required for data: 250376400
I0614 19:49:50.338600 14053 layer_factory.hpp:77] Creating layer relu4_fixed
I0614 19:49:50.338609 14053 net.cpp:94] Creating Layer relu4_fixed
I0614 19:49:50.338614 14053 net.cpp:435] relu4_fixed <- relu4
I0614 19:49:50.338620 14053 net.cpp:396] relu4_fixed -> relu4 (in-place)
I0614 19:49:50.338640 14053 net.cpp:144] Setting up relu4_fixed
I0614 19:49:50.338645 14053 net.cpp:151] Top shape: 50 40 13 13 (338000)
I0614 19:49:50.338651 14053 net.cpp:159] Memory required for data: 251728400
I0614 19:49:50.338657 14053 layer_factory.hpp:77] Creating layer conv5
I0614 19:49:50.338667 14053 net.cpp:94] Creating Layer conv5
I0614 19:49:50.338672 14053 net.cpp:435] conv5 <- relu4
I0614 19:49:50.338680 14053 net.cpp:409] conv5 -> conv5
I0614 19:49:50.338892 14053 layer_factory.hpp:77] Creating layer conv5
I0614 19:49:50.339166 14053 net.cpp:144] Setting up conv5
I0614 19:49:50.339174 14053 net.cpp:151] Top shape: 50 26 13 13 (219700)
I0614 19:49:50.339179 14053 net.cpp:159] Memory required for data: 252607200
I0614 19:49:50.339183 14053 layer_factory.hpp:77] Creating layer relu5
I0614 19:49:50.339188 14053 net.cpp:94] Creating Layer relu5
I0614 19:49:50.339193 14053 net.cpp:435] relu5 <- conv5
I0614 19:49:50.339200 14053 net.cpp:409] relu5 -> relu5
I0614 19:49:50.339216 14053 net.cpp:144] Setting up relu5
I0614 19:49:50.339221 14053 net.cpp:151] Top shape: 50 26 13 13 (219700)
I0614 19:49:50.339228 14053 net.cpp:159] Memory required for data: 253486000
I0614 19:49:50.339232 14053 layer_factory.hpp:77] Creating layer pool5
I0614 19:49:50.339241 14053 net.cpp:94] Creating Layer pool5
I0614 19:49:50.339246 14053 net.cpp:435] pool5 <- relu5
I0614 19:49:50.339252 14053 net.cpp:409] pool5 -> pool5
I0614 19:49:50.339274 14053 net.cpp:144] Setting up pool5
I0614 19:49:50.339278 14053 net.cpp:151] Top shape: 50 26 6 6 (46800)
I0614 19:49:50.339283 14053 net.cpp:159] Memory required for data: 253673200
I0614 19:49:50.339287 14053 layer_factory.hpp:77] Creating layer pool5_fixed
I0614 19:49:50.339294 14053 net.cpp:94] Creating Layer pool5_fixed
I0614 19:49:50.339299 14053 net.cpp:435] pool5_fixed <- pool5
I0614 19:49:50.339305 14053 net.cpp:396] pool5_fixed -> pool5 (in-place)
I0614 19:49:50.339327 14053 net.cpp:144] Setting up pool5_fixed
I0614 19:49:50.339335 14053 net.cpp:151] Top shape: 50 26 6 6 (46800)
I0614 19:49:50.339341 14053 net.cpp:159] Memory required for data: 253860400
I0614 19:49:50.339347 14053 layer_factory.hpp:77] Creating layer fc6
I0614 19:49:50.339355 14053 net.cpp:94] Creating Layer fc6
I0614 19:49:50.339360 14053 net.cpp:435] fc6 <- pool5
I0614 19:49:50.339367 14053 net.cpp:409] fc6 -> fc6
I0614 19:49:50.379976 14053 layer_factory.hpp:77] Creating layer fc6
I0614 19:49:50.417871 14053 net.cpp:144] Setting up fc6
I0614 19:49:50.417896 14053 net.cpp:151] Top shape: 50 4096 (204800)
I0614 19:49:50.417907 14053 net.cpp:159] Memory required for data: 254679600
I0614 19:49:50.417920 14053 layer_factory.hpp:77] Creating layer relu6
I0614 19:49:50.417928 14053 net.cpp:94] Creating Layer relu6
I0614 19:49:50.417933 14053 net.cpp:435] relu6 <- fc6
I0614 19:49:50.417940 14053 net.cpp:409] relu6 -> relu6
I0614 19:49:50.417958 14053 net.cpp:144] Setting up relu6
I0614 19:49:50.417960 14053 net.cpp:151] Top shape: 50 4096 (204800)
I0614 19:49:50.417964 14053 net.cpp:159] Memory required for data: 255498800
I0614 19:49:50.417968 14053 layer_factory.hpp:77] Creating layer relu6_fixed
I0614 19:49:50.417973 14053 net.cpp:94] Creating Layer relu6_fixed
I0614 19:49:50.417976 14053 net.cpp:435] relu6_fixed <- relu6
I0614 19:49:50.417980 14053 net.cpp:396] relu6_fixed -> relu6 (in-place)
I0614 19:49:50.417994 14053 net.cpp:144] Setting up relu6_fixed
I0614 19:49:50.417997 14053 net.cpp:151] Top shape: 50 4096 (204800)
I0614 19:49:50.418001 14053 net.cpp:159] Memory required for data: 256318000
I0614 19:49:50.418004 14053 layer_factory.hpp:77] Creating layer fc7
I0614 19:49:50.418011 14053 net.cpp:94] Creating Layer fc7
I0614 19:49:50.418015 14053 net.cpp:435] fc7 <- relu6
I0614 19:49:50.418020 14053 net.cpp:409] fc7 -> bn7
I0614 19:49:50.561466 14053 layer_factory.hpp:77] Creating layer fc7
I0614 19:49:50.704478 14053 net.cpp:144] Setting up fc7
I0614 19:49:50.704502 14053 net.cpp:151] Top shape: 50 4096 (204800)
I0614 19:49:50.704510 14053 net.cpp:159] Memory required for data: 257137200
I0614 19:49:50.704535 14053 layer_factory.hpp:77] Creating layer relu7
I0614 19:49:50.704545 14053 net.cpp:94] Creating Layer relu7
I0614 19:49:50.704548 14053 net.cpp:435] relu7 <- bn7
I0614 19:49:50.704555 14053 net.cpp:409] relu7 -> relu7
I0614 19:49:50.704571 14053 net.cpp:144] Setting up relu7
I0614 19:49:50.704572 14053 net.cpp:151] Top shape: 50 4096 (204800)
I0614 19:49:50.704576 14053 net.cpp:159] Memory required for data: 257956400
I0614 19:49:50.704578 14053 layer_factory.hpp:77] Creating layer relu7_fixed
I0614 19:49:50.704584 14053 net.cpp:94] Creating Layer relu7_fixed
I0614 19:49:50.704587 14053 net.cpp:435] relu7_fixed <- relu7
I0614 19:49:50.704591 14053 net.cpp:396] relu7_fixed -> relu7 (in-place)
I0614 19:49:50.704603 14053 net.cpp:144] Setting up relu7_fixed
I0614 19:49:50.704607 14053 net.cpp:151] Top shape: 50 4096 (204800)
I0614 19:49:50.704609 14053 net.cpp:159] Memory required for data: 258775600
I0614 19:49:50.704612 14053 layer_factory.hpp:77] Creating layer fc8
I0614 19:49:50.704618 14053 net.cpp:94] Creating Layer fc8
I0614 19:49:50.704620 14053 net.cpp:435] fc8 <- relu7
I0614 19:49:50.704624 14053 net.cpp:409] fc8 -> fc8
I0614 19:49:50.704716 14053 layer_factory.hpp:77] Creating layer fc8
I0614 19:49:50.704859 14053 net.cpp:144] Setting up fc8
I0614 19:49:50.704865 14053 net.cpp:151] Top shape: 50 2 (100)
I0614 19:49:50.704870 14053 net.cpp:159] Memory required for data: 258776000
I0614 19:49:50.704874 14053 layer_factory.hpp:77] Creating layer fc8_fixed
I0614 19:49:50.704879 14053 net.cpp:94] Creating Layer fc8_fixed
I0614 19:49:50.704882 14053 net.cpp:435] fc8_fixed <- fc8
I0614 19:49:50.704886 14053 net.cpp:396] fc8_fixed -> fc8 (in-place)
I0614 19:49:50.704900 14053 net.cpp:144] Setting up fc8_fixed
I0614 19:49:50.704903 14053 net.cpp:151] Top shape: 50 2 (100)
I0614 19:49:50.704906 14053 net.cpp:159] Memory required for data: 258776400
I0614 19:49:50.704910 14053 layer_factory.hpp:77] Creating layer fc8_fc8_fixed_0_split
I0614 19:49:50.704916 14053 net.cpp:94] Creating Layer fc8_fc8_fixed_0_split
I0614 19:49:50.704918 14053 net.cpp:435] fc8_fc8_fixed_0_split <- fc8
I0614 19:49:50.704921 14053 net.cpp:409] fc8_fc8_fixed_0_split -> fc8_fc8_fixed_0_split_0
I0614 19:49:50.704942 14053 net.cpp:409] fc8_fc8_fixed_0_split -> fc8_fc8_fixed_0_split_1
I0614 19:49:50.704948 14053 net.cpp:409] fc8_fc8_fixed_0_split -> fc8_fc8_fixed_0_split_2
I0614 19:49:50.704967 14053 net.cpp:144] Setting up fc8_fc8_fixed_0_split
I0614 19:49:50.704970 14053 net.cpp:151] Top shape: 50 2 (100)
I0614 19:49:50.704974 14053 net.cpp:151] Top shape: 50 2 (100)
I0614 19:49:50.704977 14053 net.cpp:151] Top shape: 50 2 (100)
I0614 19:49:50.704980 14053 net.cpp:159] Memory required for data: 258777600
I0614 19:49:50.704983 14053 layer_factory.hpp:77] Creating layer accuracy
I0614 19:49:50.704991 14053 net.cpp:94] Creating Layer accuracy
I0614 19:49:50.704994 14053 net.cpp:435] accuracy <- fc8_fc8_fixed_0_split_0
I0614 19:49:50.704998 14053 net.cpp:435] accuracy <- label_data_1_split_0
I0614 19:49:50.705003 14053 net.cpp:409] accuracy -> accuracy
I0614 19:49:50.705008 14053 net.cpp:144] Setting up accuracy
I0614 19:49:50.705010 14053 net.cpp:151] Top shape: (1)
I0614 19:49:50.705014 14053 net.cpp:159] Memory required for data: 258777604
I0614 19:49:50.705018 14053 layer_factory.hpp:77] Creating layer loss
I0614 19:49:50.705022 14053 net.cpp:94] Creating Layer loss
I0614 19:49:50.705025 14053 net.cpp:435] loss <- fc8_fc8_fixed_0_split_1
I0614 19:49:50.705029 14053 net.cpp:435] loss <- label_data_1_split_1
I0614 19:49:50.705032 14053 net.cpp:409] loss -> loss
I0614 19:49:50.705039 14053 layer_factory.hpp:77] Creating layer loss
I0614 19:49:50.705077 14053 net.cpp:144] Setting up loss
I0614 19:49:50.705081 14053 net.cpp:151] Top shape: (1)
I0614 19:49:50.705085 14053 net.cpp:154]     with loss weight 1
I0614 19:49:50.705096 14053 net.cpp:159] Memory required for data: 258777608
I0614 19:49:50.705098 14053 layer_factory.hpp:77] Creating layer accuracy-top1
I0614 19:49:50.705104 14053 net.cpp:94] Creating Layer accuracy-top1
I0614 19:49:50.705107 14053 net.cpp:435] accuracy-top1 <- fc8_fc8_fixed_0_split_2
I0614 19:49:50.705111 14053 net.cpp:435] accuracy-top1 <- label_data_1_split_2
I0614 19:49:50.705116 14053 net.cpp:409] accuracy-top1 -> top-1
I0614 19:49:50.705121 14053 net.cpp:144] Setting up accuracy-top1
I0614 19:49:50.705123 14053 net.cpp:151] Top shape: (1)
I0614 19:49:50.705127 14053 net.cpp:159] Memory required for data: 258777612
I0614 19:49:50.705130 14053 net.cpp:222] accuracy-top1 does not need backward computation.
I0614 19:49:50.705133 14053 net.cpp:220] loss needs backward computation.
I0614 19:49:50.705137 14053 net.cpp:222] accuracy does not need backward computation.
I0614 19:49:50.705140 14053 net.cpp:220] fc8_fc8_fixed_0_split needs backward computation.
I0614 19:49:50.705143 14053 net.cpp:220] fc8_fixed needs backward computation.
I0614 19:49:50.705147 14053 net.cpp:220] fc8 needs backward computation.
I0614 19:49:50.705149 14053 net.cpp:220] relu7_fixed needs backward computation.
I0614 19:49:50.705152 14053 net.cpp:220] relu7 needs backward computation.
I0614 19:49:50.705155 14053 net.cpp:220] fc7 needs backward computation.
I0614 19:49:50.705158 14053 net.cpp:220] relu6_fixed needs backward computation.
I0614 19:49:50.705163 14053 net.cpp:220] relu6 needs backward computation.
I0614 19:49:50.705165 14053 net.cpp:220] fc6 needs backward computation.
I0614 19:49:50.705168 14053 net.cpp:220] pool5_fixed needs backward computation.
I0614 19:49:50.705171 14053 net.cpp:220] pool5 needs backward computation.
I0614 19:49:50.705174 14053 net.cpp:220] relu5 needs backward computation.
I0614 19:49:50.705178 14053 net.cpp:220] conv5 needs backward computation.
I0614 19:49:50.705180 14053 net.cpp:220] relu4_fixed needs backward computation.
I0614 19:49:50.705184 14053 net.cpp:220] relu4 needs backward computation.
I0614 19:49:50.705188 14053 net.cpp:220] conv4 needs backward computation.
I0614 19:49:50.705190 14053 net.cpp:220] relu3_fixed needs backward computation.
I0614 19:49:50.705193 14053 net.cpp:220] relu3 needs backward computation.
I0614 19:49:50.705196 14053 net.cpp:220] conv3 needs backward computation.
I0614 19:49:50.705199 14053 net.cpp:220] pool2_fixed needs backward computation.
I0614 19:49:50.705202 14053 net.cpp:220] pool2 needs backward computation.
I0614 19:49:50.705205 14053 net.cpp:220] relu2 needs backward computation.
I0614 19:49:50.705209 14053 net.cpp:220] conv2 needs backward computation.
I0614 19:49:50.705211 14053 net.cpp:220] pool1_fixed needs backward computation.
I0614 19:49:50.705214 14053 net.cpp:220] pool1 needs backward computation.
I0614 19:49:50.705217 14053 net.cpp:220] relu1 needs backward computation.
I0614 19:49:50.705220 14053 net.cpp:220] conv1 needs backward computation.
I0614 19:49:50.705224 14053 net.cpp:222] data_fixed does not need backward computation.
I0614 19:49:50.705227 14053 net.cpp:222] label_data_1_split does not need backward computation.
I0614 19:49:50.705231 14053 net.cpp:222] data does not need backward computation.
I0614 19:49:50.705233 14053 net.cpp:264] This network produces output accuracy
I0614 19:49:50.705236 14053 net.cpp:264] This network produces output loss
I0614 19:49:50.705240 14053 net.cpp:264] This network produces output top-1
I0614 19:49:50.705257 14053 net.cpp:284] Network initialization done.
I0614 19:49:50.717346 14053 net_test.cpp:431] Net type: other
I0614 19:49:50.717362 14053 net_test.cpp:439] Test Start, total iterations: 50
I0614 19:49:50.717367 14053 net_test.cpp:372] Testing ...
I0614 19:49:50.760272 14053 net_test.cpp:394] Test iter: 1/50, accuracy = 0.96
I0614 19:49:50.760293 14053 net_test.cpp:394] Test iter: 1/50, loss = 0.434708
I0614 19:49:50.760298 14053 net_test.cpp:394] Test iter: 1/50, top-1 = 0.96
I0614 19:49:50.785840 14053 net_test.cpp:394] Test iter: 2/50, accuracy = 0.96
I0614 19:49:50.785861 14053 net_test.cpp:394] Test iter: 2/50, loss = 0.202706
I0614 19:49:50.785863 14053 net_test.cpp:394] Test iter: 2/50, top-1 = 0.96
I0614 19:49:50.811350 14053 net_test.cpp:394] Test iter: 3/50, accuracy = 0.98
I0614 19:49:50.811373 14053 net_test.cpp:394] Test iter: 3/50, loss = 0.0306471
I0614 19:49:50.811376 14053 net_test.cpp:394] Test iter: 3/50, top-1 = 0.98
I0614 19:49:50.836760 14053 net_test.cpp:394] Test iter: 4/50, accuracy = 0.92
I0614 19:49:50.836781 14053 net_test.cpp:394] Test iter: 4/50, loss = 0.444177
I0614 19:49:50.836786 14053 net_test.cpp:394] Test iter: 4/50, top-1 = 0.92
I0614 19:49:50.862232 14053 net_test.cpp:394] Test iter: 5/50, accuracy = 0.96
I0614 19:49:50.862254 14053 net_test.cpp:394] Test iter: 5/50, loss = 0.261496
I0614 19:49:50.862258 14053 net_test.cpp:394] Test iter: 5/50, top-1 = 0.96
I0614 19:49:50.892271 14053 net_test.cpp:394] Test iter: 6/50, accuracy = 0.96
I0614 19:49:50.892292 14053 net_test.cpp:394] Test iter: 6/50, loss = 0.215447
I0614 19:49:50.892295 14053 net_test.cpp:394] Test iter: 6/50, top-1 = 0.96
I0614 19:49:50.916779 14053 net_test.cpp:394] Test iter: 7/50, accuracy = 0.96
I0614 19:49:50.916800 14053 net_test.cpp:394] Test iter: 7/50, loss = 0.22033
I0614 19:49:50.916803 14053 net_test.cpp:394] Test iter: 7/50, top-1 = 0.96
I0614 19:49:50.940912 14053 net_test.cpp:394] Test iter: 8/50, accuracy = 0.98
I0614 19:49:50.940932 14053 net_test.cpp:394] Test iter: 8/50, loss = 0.0452796
I0614 19:49:50.940935 14053 net_test.cpp:394] Test iter: 8/50, top-1 = 0.98
I0614 19:49:50.965111 14053 net_test.cpp:394] Test iter: 9/50, accuracy = 0.98
I0614 19:49:50.965131 14053 net_test.cpp:394] Test iter: 9/50, loss = 0.0687625
I0614 19:49:50.965135 14053 net_test.cpp:394] Test iter: 9/50, top-1 = 0.98
I0614 19:49:50.989463 14053 net_test.cpp:394] Test iter: 10/50, accuracy = 0.98
I0614 19:49:50.989485 14053 net_test.cpp:394] Test iter: 10/50, loss = 0.016455
I0614 19:49:50.989490 14053 net_test.cpp:394] Test iter: 10/50, top-1 = 0.98
I0614 19:49:51.013752 14053 net_test.cpp:394] Test iter: 11/50, accuracy = 0.9
I0614 19:49:51.013774 14053 net_test.cpp:394] Test iter: 11/50, loss = 0.32995
I0614 19:49:51.013778 14053 net_test.cpp:394] Test iter: 11/50, top-1 = 0.9
I0614 19:49:51.038305 14053 net_test.cpp:394] Test iter: 12/50, accuracy = 0.98
I0614 19:49:51.038326 14053 net_test.cpp:394] Test iter: 12/50, loss = 0.160622
I0614 19:49:51.038331 14053 net_test.cpp:394] Test iter: 12/50, top-1 = 0.98
I0614 19:49:51.062520 14053 net_test.cpp:394] Test iter: 13/50, accuracy = 0.9
I0614 19:49:51.062541 14053 net_test.cpp:394] Test iter: 13/50, loss = 0.615163
I0614 19:49:51.062546 14053 net_test.cpp:394] Test iter: 13/50, top-1 = 0.9
I0614 19:49:51.086608 14053 net_test.cpp:394] Test iter: 14/50, accuracy = 0.92
I0614 19:49:51.086628 14053 net_test.cpp:394] Test iter: 14/50, loss = 0.461648
I0614 19:49:51.086632 14053 net_test.cpp:394] Test iter: 14/50, top-1 = 0.92
I0614 19:49:51.110754 14053 net_test.cpp:394] Test iter: 15/50, accuracy = 1
I0614 19:49:51.110776 14053 net_test.cpp:394] Test iter: 15/50, loss = 0.0140663
I0614 19:49:51.110780 14053 net_test.cpp:394] Test iter: 15/50, top-1 = 1
I0614 19:49:51.134894 14053 net_test.cpp:394] Test iter: 16/50, accuracy = 0.96
I0614 19:49:51.134915 14053 net_test.cpp:394] Test iter: 16/50, loss = 0.325607
I0614 19:49:51.134918 14053 net_test.cpp:394] Test iter: 16/50, top-1 = 0.96
I0614 19:49:51.158856 14053 net_test.cpp:394] Test iter: 17/50, accuracy = 0.98
I0614 19:49:51.158877 14053 net_test.cpp:394] Test iter: 17/50, loss = 0.0322541
I0614 19:49:51.158881 14053 net_test.cpp:394] Test iter: 17/50, top-1 = 0.98
I0614 19:49:51.182958 14053 net_test.cpp:394] Test iter: 18/50, accuracy = 0.96
I0614 19:49:51.182981 14053 net_test.cpp:394] Test iter: 18/50, loss = 0.277664
I0614 19:49:51.182983 14053 net_test.cpp:394] Test iter: 18/50, top-1 = 0.96
I0614 19:49:51.206987 14053 net_test.cpp:394] Test iter: 19/50, accuracy = 0.96
I0614 19:49:51.207010 14053 net_test.cpp:394] Test iter: 19/50, loss = 0.192884
I0614 19:49:51.207012 14053 net_test.cpp:394] Test iter: 19/50, top-1 = 0.96
I0614 19:49:51.231431 14053 net_test.cpp:394] Test iter: 20/50, accuracy = 0.98
I0614 19:49:51.231452 14053 net_test.cpp:394] Test iter: 20/50, loss = 0.18016
I0614 19:49:51.231456 14053 net_test.cpp:394] Test iter: 20/50, top-1 = 0.98
I0614 19:49:51.255795 14053 net_test.cpp:394] Test iter: 21/50, accuracy = 0.98
I0614 19:49:51.255817 14053 net_test.cpp:394] Test iter: 21/50, loss = 0.0516265
I0614 19:49:51.255821 14053 net_test.cpp:394] Test iter: 21/50, top-1 = 0.98
I0614 19:49:51.280237 14053 net_test.cpp:394] Test iter: 22/50, accuracy = 0.98
I0614 19:49:51.280258 14053 net_test.cpp:394] Test iter: 22/50, loss = 0.0884972
I0614 19:49:51.280262 14053 net_test.cpp:394] Test iter: 22/50, top-1 = 0.98
I0614 19:49:51.304286 14053 net_test.cpp:394] Test iter: 23/50, accuracy = 0.96
I0614 19:49:51.304308 14053 net_test.cpp:394] Test iter: 23/50, loss = 0.303314
I0614 19:49:51.304311 14053 net_test.cpp:394] Test iter: 23/50, top-1 = 0.96
I0614 19:49:51.328720 14053 net_test.cpp:394] Test iter: 24/50, accuracy = 0.96
I0614 19:49:51.328742 14053 net_test.cpp:394] Test iter: 24/50, loss = 0.178419
I0614 19:49:51.328747 14053 net_test.cpp:394] Test iter: 24/50, top-1 = 0.96
I0614 19:49:51.353125 14053 net_test.cpp:394] Test iter: 25/50, accuracy = 0.92
I0614 19:49:51.353147 14053 net_test.cpp:394] Test iter: 25/50, loss = 0.522883
I0614 19:49:51.353152 14053 net_test.cpp:394] Test iter: 25/50, top-1 = 0.92
I0614 19:49:51.377285 14053 net_test.cpp:394] Test iter: 26/50, accuracy = 0.92
I0614 19:49:51.377306 14053 net_test.cpp:394] Test iter: 26/50, loss = 0.484035
I0614 19:49:51.377310 14053 net_test.cpp:394] Test iter: 26/50, top-1 = 0.92
I0614 19:49:51.401504 14053 net_test.cpp:394] Test iter: 27/50, accuracy = 0.98
I0614 19:49:51.401525 14053 net_test.cpp:394] Test iter: 27/50, loss = 0.0349278
I0614 19:49:51.401528 14053 net_test.cpp:394] Test iter: 27/50, top-1 = 0.98
I0614 19:49:51.425599 14053 net_test.cpp:394] Test iter: 28/50, accuracy = 0.9
I0614 19:49:51.425621 14053 net_test.cpp:394] Test iter: 28/50, loss = 0.392745
I0614 19:49:51.425624 14053 net_test.cpp:394] Test iter: 28/50, top-1 = 0.9
I0614 19:49:51.449739 14053 net_test.cpp:394] Test iter: 29/50, accuracy = 0.92
I0614 19:49:51.449761 14053 net_test.cpp:394] Test iter: 29/50, loss = 0.564678
I0614 19:49:51.449765 14053 net_test.cpp:394] Test iter: 29/50, top-1 = 0.92
I0614 19:49:51.474046 14053 net_test.cpp:394] Test iter: 30/50, accuracy = 0.98
I0614 19:49:51.474067 14053 net_test.cpp:394] Test iter: 30/50, loss = 0.150425
I0614 19:49:51.474072 14053 net_test.cpp:394] Test iter: 30/50, top-1 = 0.98
I0614 19:49:51.498418 14053 net_test.cpp:394] Test iter: 31/50, accuracy = 0.9
I0614 19:49:51.498440 14053 net_test.cpp:394] Test iter: 31/50, loss = 0.313848
I0614 19:49:51.498443 14053 net_test.cpp:394] Test iter: 31/50, top-1 = 0.9
I0614 19:49:51.522598 14053 net_test.cpp:394] Test iter: 32/50, accuracy = 0.94
I0614 19:49:51.522617 14053 net_test.cpp:394] Test iter: 32/50, loss = 0.223419
I0614 19:49:51.522620 14053 net_test.cpp:394] Test iter: 32/50, top-1 = 0.94
I0614 19:49:51.546581 14053 net_test.cpp:394] Test iter: 33/50, accuracy = 0.92
I0614 19:49:51.546602 14053 net_test.cpp:394] Test iter: 33/50, loss = 0.333813
I0614 19:49:51.546605 14053 net_test.cpp:394] Test iter: 33/50, top-1 = 0.92
I0614 19:49:51.570613 14053 net_test.cpp:394] Test iter: 34/50, accuracy = 0.98
I0614 19:49:51.570634 14053 net_test.cpp:394] Test iter: 34/50, loss = 0.106199
I0614 19:49:51.570638 14053 net_test.cpp:394] Test iter: 34/50, top-1 = 0.98
I0614 19:49:51.594813 14053 net_test.cpp:394] Test iter: 35/50, accuracy = 0.96
I0614 19:49:51.594833 14053 net_test.cpp:394] Test iter: 35/50, loss = 0.227757
I0614 19:49:51.594836 14053 net_test.cpp:394] Test iter: 35/50, top-1 = 0.96
I0614 19:49:51.619170 14053 net_test.cpp:394] Test iter: 36/50, accuracy = 0.96
I0614 19:49:51.619190 14053 net_test.cpp:394] Test iter: 36/50, loss = 0.258003
I0614 19:49:51.619194 14053 net_test.cpp:394] Test iter: 36/50, top-1 = 0.96
I0614 19:49:51.643553 14053 net_test.cpp:394] Test iter: 37/50, accuracy = 0.96
I0614 19:49:51.643573 14053 net_test.cpp:394] Test iter: 37/50, loss = 0.146479
I0614 19:49:51.643577 14053 net_test.cpp:394] Test iter: 37/50, top-1 = 0.96
I0614 19:49:51.667636 14053 net_test.cpp:394] Test iter: 38/50, accuracy = 0.9
I0614 19:49:51.667659 14053 net_test.cpp:394] Test iter: 38/50, loss = 0.678815
I0614 19:49:51.667661 14053 net_test.cpp:394] Test iter: 38/50, top-1 = 0.9
I0614 19:49:51.691807 14053 net_test.cpp:394] Test iter: 39/50, accuracy = 0.94
I0614 19:49:51.691828 14053 net_test.cpp:394] Test iter: 39/50, loss = 0.519199
I0614 19:49:51.691831 14053 net_test.cpp:394] Test iter: 39/50, top-1 = 0.94
I0614 19:49:51.715880 14053 net_test.cpp:394] Test iter: 40/50, accuracy = 0.92
I0614 19:49:51.715903 14053 net_test.cpp:394] Test iter: 40/50, loss = 0.151468
I0614 19:49:51.715906 14053 net_test.cpp:394] Test iter: 40/50, top-1 = 0.92
I0614 19:49:51.740056 14053 net_test.cpp:394] Test iter: 41/50, accuracy = 0.98
I0614 19:49:51.740077 14053 net_test.cpp:394] Test iter: 41/50, loss = 0.183553
I0614 19:49:51.740082 14053 net_test.cpp:394] Test iter: 41/50, top-1 = 0.98
I0614 19:49:51.764437 14053 net_test.cpp:394] Test iter: 42/50, accuracy = 0.9
I0614 19:49:51.764461 14053 net_test.cpp:394] Test iter: 42/50, loss = 0.393049
I0614 19:49:51.764464 14053 net_test.cpp:394] Test iter: 42/50, top-1 = 0.9
I0614 19:49:51.788506 14053 net_test.cpp:394] Test iter: 43/50, accuracy = 0.96
I0614 19:49:51.788527 14053 net_test.cpp:394] Test iter: 43/50, loss = 0.345768
I0614 19:49:51.788529 14053 net_test.cpp:394] Test iter: 43/50, top-1 = 0.96
I0614 19:49:51.812815 14053 net_test.cpp:394] Test iter: 44/50, accuracy = 0.96
I0614 19:49:51.812836 14053 net_test.cpp:394] Test iter: 44/50, loss = 0.347065
I0614 19:49:51.812840 14053 net_test.cpp:394] Test iter: 44/50, top-1 = 0.96
I0614 19:49:51.837021 14053 net_test.cpp:394] Test iter: 45/50, accuracy = 0.98
I0614 19:49:51.837044 14053 net_test.cpp:394] Test iter: 45/50, loss = 0.0812084
I0614 19:49:51.837047 14053 net_test.cpp:394] Test iter: 45/50, top-1 = 0.98
I0614 19:49:51.861275 14053 net_test.cpp:394] Test iter: 46/50, accuracy = 1
I0614 19:49:51.861299 14053 net_test.cpp:394] Test iter: 46/50, loss = 0.00425687
I0614 19:49:51.861303 14053 net_test.cpp:394] Test iter: 46/50, top-1 = 1
I0614 19:49:51.885713 14053 net_test.cpp:394] Test iter: 47/50, accuracy = 0.9
I0614 19:49:51.885732 14053 net_test.cpp:394] Test iter: 47/50, loss = 0.440296
I0614 19:49:51.885736 14053 net_test.cpp:394] Test iter: 47/50, top-1 = 0.9
I0614 19:49:51.909788 14053 net_test.cpp:394] Test iter: 48/50, accuracy = 0.96
I0614 19:49:51.909811 14053 net_test.cpp:394] Test iter: 48/50, loss = 0.505611
I0614 19:49:51.909813 14053 net_test.cpp:394] Test iter: 48/50, top-1 = 0.96
I0614 19:49:51.934182 14053 net_test.cpp:394] Test iter: 49/50, accuracy = 0.98
I0614 19:49:51.934204 14053 net_test.cpp:394] Test iter: 49/50, loss = 0.146782
I0614 19:49:51.934208 14053 net_test.cpp:394] Test iter: 49/50, top-1 = 0.98
I0614 19:49:51.958295 14053 net_test.cpp:394] Test iter: 50/50, accuracy = 0.94
I0614 19:49:51.958317 14053 net_test.cpp:394] Test iter: 50/50, loss = 0.253702
I0614 19:49:51.958320 14053 net_test.cpp:394] Test iter: 50/50, top-1 = 0.94
I0614 19:49:51.958324 14053 net_test.cpp:405] Test Results: 
I0614 19:49:51.958328 14053 net_test.cpp:406] Loss: 0.259237
I0614 19:49:51.958331 14053 net_test.cpp:421] accuracy = 0.9524
I0614 19:49:51.958339 14053 net_test.cpp:421] loss = 0.259237 (* 1 = 0.259237 loss)
I0614 19:49:51.958343 14053 net_test.cpp:421] top-1 = 0.9524
I0614 19:49:51.958348 14053 net_test.cpp:450] Test Done!
I0614 19:49:52.086406 14053 vai_q.cpp:360] Start Deploy
I0614 19:49:52.401177 14053 vai_q.cpp:368] Deploy Done!
--------------------------------------------------
Output Quantized Train&Test Model:   "/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/deploy/alexnetBNnoLRN/pruned/vaiq_output/quantize_train_test.prototxt"
Output Quantized Train&Test Weights: "/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/deploy/alexnetBNnoLRN/pruned/vaiq_output/quantize_train_test.caffemodel"
Output Deploy Weights: "/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/deploy/alexnetBNnoLRN/pruned/vaiq_output/deploy.caffemodel"
Output Deploy Model:   "/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/deploy/alexnetBNnoLRN/pruned/vaiq_output/deploy.prototxt"
Compiling network: alexnetBNnoLRN for ZCU102
[INFO] Namespace(batchsize=1, inputs_shape=None, layout='NCHW', model_files=['/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/deploy/alexnetBNnoLRN/pruned/vaiq_output/deploy.caffemodel'], model_type='caffe', named_inputs_shape=None, out_filename='/tmp/alexnetBNnoLRN_org.xmodel', proto='/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/deploy/alexnetBNnoLRN/pruned/vaiq_output/deploy.prototxt')
[INFO] caffe model: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/deploy/alexnetBNnoLRN/pruned/vaiq_output/deploy.caffemodel
[INFO] caffe model: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/deploy/alexnetBNnoLRN/pruned/vaiq_output/deploy.prototxt
[INFO] parse raw model     :  0%|          | 0/29 [00:00<?, ?it/s]                           [INFO] parse raw model     : 38%|ââââ      | 11/29 [00:00<00:00, 94.86it/s]                  [INFO] parse raw model     : 72%|ââââââââ  | 21/29 [00:01<00:00, 15.52it/s]                  [INFO] parse raw model     : 90%|âââââââââ | 26/29 [00:05<00:00,  3.32it/s]                  [INFO] parse raw model     :100%|ââââââââââ| 29/29 [00:05<00:00,  5.16it/s]                  
[INFO] infer shape (NCHW)  :  0%|          | 0/29 [00:00<?, ?it/s]                           [INFO] infer shape (NCHW)  :100%|ââââââââââ| 29/29 [00:00<00:00, 9562.49it/s]                
[INFO] infer shape (NHWC)  :  0%|          | 0/29 [00:00<?, ?it/s]                           [INFO] infer shape (NHWC)  :100%|ââââââââââ| 29/29 [00:00<00:00, 737.15it/s]                 
[INFO] perform level-1 opt :  0%|          | 0/3 [00:00<?, ?it/s]                            [INFO] perform level-1 opt :100%|ââââââââââ| 3/3 [00:00<00:00, 1303.39it/s]                  
[INFO] generate xmodel     :  0%|          | 0/29 [00:00<?, ?it/s]                           [INFO] generate xmodel     : 83%|âââââââââ | 24/29 [00:00<00:00, 184.35it/s]                 [INFO] generate xmodel     :100%|ââââââââââ| 29/29 [00:00<00:00, 220.85it/s]                 
[INFO] dump xmodel ...[INFO] dump xmodel: /tmp/alexnetBNnoLRN_org.xmodel
[UNILOG][INFO] Compile mode: dpu
[UNILOG][INFO] Debug mode: function
[UNILOG][INFO] Target architecture: DPUCZDX8G_ISA0_B4096_MAX_BG2
[UNILOG][INFO] Graph name: deploy, with op num: 61
[UNILOG][INFO] Begin to compile...
[UNILOG][INFO] Total device subgraph number 3, DPU subgraph number 1
[UNILOG][INFO] Compile done.
[UNILOG][INFO] The meta json is saved to "/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/deploy/alexnetBNnoLRN/pruned/vaic_output/meta.json"
[UNILOG][INFO] The compiled xmodel is saved to "/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/deploy/alexnetBNnoLRN/pruned/vaic_output/alexnetBNnoLRN.xmodel"
[UNILOG][INFO] The compiled xmodel's md5sum is d15c4418199c6d4eb5814b8b39b1e991, and has been saved to "/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/deploy/alexnetBNnoLRN/pruned/vaic_output/md5sum.txt"
**************************************************
* VITIS_AI Compilation - Xilinx Inc.
**************************************************
 copying xmodel file into /../zcu102/baseline/model/arm64_4096 
 copying the test images to be used by the ZCU102
Compiling network: alexnetBNnoLRN for VCK190
[INFO] Namespace(batchsize=1, inputs_shape=None, layout='NCHW', model_files=['/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/deploy/alexnetBNnoLRN/pruned/vaiq_output/deploy.caffemodel'], model_type='caffe', named_inputs_shape=None, out_filename='/tmp/alexnetBNnoLRN_org.xmodel', proto='/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/deploy/alexnetBNnoLRN/pruned/vaiq_output/deploy.prototxt')
[INFO] caffe model: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/deploy/alexnetBNnoLRN/pruned/vaiq_output/deploy.caffemodel
[INFO] caffe model: /workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/deploy/alexnetBNnoLRN/pruned/vaiq_output/deploy.prototxt
[INFO] parse raw model     :  0%|          | 0/29 [00:00<?, ?it/s]                           [INFO] parse raw model     : 38%|ââââ      | 11/29 [00:00<00:00, 97.53it/s]                  [INFO] parse raw model     : 72%|ââââââââ  | 21/29 [00:01<00:00, 15.80it/s]                  [INFO] parse raw model     : 90%|âââââââââ | 26/29 [00:05<00:00,  3.33it/s]                  [INFO] parse raw model     :100%|ââââââââââ| 29/29 [00:05<00:00,  5.19it/s]                  
[INFO] infer shape (NCHW)  :  0%|          | 0/29 [00:00<?, ?it/s]                           [INFO] infer shape (NCHW)  :100%|ââââââââââ| 29/29 [00:00<00:00, 9533.26it/s]                
[INFO] infer shape (NHWC)  :  0%|          | 0/29 [00:00<?, ?it/s]                           [INFO] infer shape (NHWC)  :100%|ââââââââââ| 29/29 [00:00<00:00, 1281.99it/s]                
[INFO] perform level-1 opt :  0%|          | 0/3 [00:00<?, ?it/s]                            [INFO] perform level-1 opt :100%|ââââââââââ| 3/3 [00:00<00:00, 1293.07it/s]                  
[INFO] generate xmodel     :  0%|          | 0/29 [00:00<?, ?it/s]                           [INFO] generate xmodel     : 83%|âââââââââ | 24/29 [00:00<00:00, 186.11it/s]                 [INFO] generate xmodel     :100%|ââââââââââ| 29/29 [00:00<00:00, 222.99it/s]                 
[INFO] dump xmodel ...[INFO] dump xmodel: /tmp/alexnetBNnoLRN_org.xmodel
[UNILOG][INFO] Compile mode: dpu
[UNILOG][INFO] Debug mode: function
[UNILOG][INFO] Target architecture: DPUCVDX8G_ISA2_C32B3
[UNILOG][INFO] Graph name: deploy, with op num: 61
[UNILOG][INFO] Begin to compile...
[UNILOG][INFO] Total device subgraph number 3, DPU subgraph number 1
[UNILOG][INFO] Compile done.
[UNILOG][INFO] The meta json is saved to "/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/deploy/alexnetBNnoLRN/pruned/vaic_output/meta.json"
[UNILOG][INFO] The compiled xmodel is saved to "/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/deploy/alexnetBNnoLRN/pruned/vaic_output/alexnetBNnoLRN.xmodel"
[UNILOG][INFO] The compiled xmodel's md5sum is d62a843dac868367ee64a558705315c6, and has been saved to "/workspace/VAI2.0/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/deploy/alexnetBNnoLRN/pruned/vaic_output/md5sum.txt"
**************************************************
* VITIS_AI Compilation - Xilinx Inc.
**************************************************
 copying xmodel file into /../vck190/baseline/model/arm64_4096 


 preparing test images 
 preparing target boards archives 
