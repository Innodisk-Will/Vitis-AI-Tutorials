/**

* Â© Copyright (C) 2016-2020 Xilinx, Inc
*
* Licensed under the Apache License, Version 2.0 (the "License"). You may
* not use this file except in compliance with the License. A copy of the
* License is located at
*
*     http://www.apache.org/licenses/LICENSE-2.0
*
* Unless required by applicable law or agreed to in writing, software
* distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
* WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
* License for the specific language governing permissions and limitations
* under the License.
*/



                                                                               N/A% (0 of 20) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--                                                                                 5% (1 of 20) |#                        | Elapsed Time: 0:00:01 ETA:   0:00:32                                                                                10% (2 of 20) |##                       | Elapsed Time: 0:00:03 ETA:   0:00:30                                                                                15% (3 of 20) |###                      | Elapsed Time: 0:00:05 ETA:   0:00:28                                                                                20% (4 of 20) |#####                    | Elapsed Time: 0:00:06 ETA:   0:00:26                                                                                25% (5 of 20) |######                   | Elapsed Time: 0:00:08 ETA:   0:00:24                                                                                30% (6 of 20) |#######                  | Elapsed Time: 0:00:09 ETA:   0:00:23                                                                                35% (7 of 20) |########                 | Elapsed Time: 0:00:11 ETA:   0:00:21                                                                                40% (8 of 20) |##########               | Elapsed Time: 0:00:13 ETA:   0:00:19                                                                                45% (9 of 20) |###########              | Elapsed Time: 0:00:14 ETA:   0:00:18                                                                                50% (10 of 20) |############            | Elapsed Time: 0:00:16 ETA:   0:00:16                                                                                55% (11 of 20) |#############           | Elapsed Time: 0:00:18 ETA:   0:00:14                                                                                60% (12 of 20) |##############          | Elapsed Time: 0:00:19 ETA:   0:00:13                                                                                65% (13 of 20) |###############         | Elapsed Time: 0:00:21 ETA:   0:00:11                                                                                70% (14 of 20) |################        | Elapsed Time: 0:00:23 ETA:   0:00:09                                                                                75% (15 of 20) |##################      | Elapsed Time: 0:00:24 ETA:   0:00:08                                                                                80% (16 of 20) |###################     | Elapsed Time: 0:00:26 ETA:   0:00:06                                                                                85% (17 of 20) |####################    | Elapsed Time: 0:00:28 ETA:   0:00:04                                                                                90% (18 of 20) |#####################   | Elapsed Time: 0:00:29 ETA:   0:00:03                                                                                95% (19 of 20) |######################  | Elapsed Time: 0:00:31 ETA:   0:00:01                                                                               100% (20 of 20) |########################| Elapsed Time: 0:00:33 Time:  0:00:33
[DEPLOY WARNING] Batchnorm Node (batch_normalization_1/FusedBatchNorm_1/add + batch_normalization_1/FusedBatchNorm_1/mul) is not folded. It will be converted to a Scale node (batch_normalization_1/FusedBatchNorm_1/add) to deploy on DPU. This may cause accuracy decrease and error for DPU compiler.
[DEPLOY WARNING] Batchnorm Node (batch_normalization_5/FusedBatchNorm_1/add + batch_normalization_5/FusedBatchNorm_1/mul) is not folded. It will be converted to a Scale node (batch_normalization_5/FusedBatchNorm_1/add) to deploy on DPU. This may cause accuracy decrease and error for DPU compiler.
[DEPLOY WARNING] Batchnorm Node (batch_normalization_8/FusedBatchNorm_1/add + batch_normalization_8/FusedBatchNorm_1/mul) is not folded. It will be converted to a Scale node (batch_normalization_8/FusedBatchNorm_1/add) to deploy on DPU. This may cause accuracy decrease and error for DPU compiler.
[DEPLOY WARNING] Batchnorm Node (batch_normalization_11/FusedBatchNorm_1/add + batch_normalization_11/FusedBatchNorm_1/mul) is not folded. It will be converted to a Scale node (batch_normalization_11/FusedBatchNorm_1/add) to deploy on DPU. This may cause accuracy decrease and error for DPU compiler.
[DEPLOY WARNING] Batchnorm Node (batch_normalization_14/FusedBatchNorm_1/add + batch_normalization_14/FusedBatchNorm_1/mul) is not folded. It will be converted to a Scale node (batch_normalization_14/FusedBatchNorm_1/add) to deploy on DPU. This may cause accuracy decrease and error for DPU compiler.
[DEPLOY WARNING] Batchnorm Node (batch_normalization_17/FusedBatchNorm_1/add + batch_normalization_17/FusedBatchNorm_1/mul) is not folded. It will be converted to a Scale node (batch_normalization_17/FusedBatchNorm_1/add) to deploy on DPU. This may cause accuracy decrease and error for DPU compiler.
[DEPLOY WARNING] Batchnorm Node (batch_normalization_20/FusedBatchNorm_1/add + batch_normalization_20/FusedBatchNorm_1/mul) is not folded. It will be converted to a Scale node (batch_normalization_20/FusedBatchNorm_1/add) to deploy on DPU. This may cause accuracy decrease and error for DPU compiler.
[DEPLOY WARNING] Batchnorm Node (batch_normalization_23/FusedBatchNorm_1/add + batch_normalization_23/FusedBatchNorm_1/mul) is not folded. It will be converted to a Scale node (batch_normalization_23/FusedBatchNorm_1/add) to deploy on DPU. This may cause accuracy decrease and error for DPU compiler.
[DEPLOY WARNING] Batchnorm Node (batch_normalization_26/FusedBatchNorm_1/add + batch_normalization_26/FusedBatchNorm_1/mul) is not folded. It will be converted to a Scale node (batch_normalization_26/FusedBatchNorm_1/add) to deploy on DPU. This may cause accuracy decrease and error for DPU compiler.
[DEPLOY WARNING] Batchnorm Node (batch_normalization_29/FusedBatchNorm_1/add + batch_normalization_29/FusedBatchNorm_1/mul) is not folded. It will be converted to a Scale node (batch_normalization_29/FusedBatchNorm_1/add) to deploy on DPU. This may cause accuracy decrease and error for DPU compiler.
[DEPLOY WARNING] Batchnorm Node (batch_normalization_32/FusedBatchNorm_1/add + batch_normalization_32/FusedBatchNorm_1/mul) is not folded. It will be converted to a Scale node (batch_normalization_32/FusedBatchNorm_1/add) to deploy on DPU. This may cause accuracy decrease and error for DPU compiler.
[DEPLOY WARNING] Batchnorm Node (batch_normalization_35/FusedBatchNorm_1/add + batch_normalization_35/FusedBatchNorm_1/mul) is not folded. It will be converted to a Scale node (batch_normalization_35/FusedBatchNorm_1/add) to deploy on DPU. This may cause accuracy decrease and error for DPU compiler.
[DEPLOY WARNING] Batchnorm Node (batch_normalization_38/FusedBatchNorm_1/add + batch_normalization_38/FusedBatchNorm_1/mul) is not folded. It will be converted to a Scale node (batch_normalization_38/FusedBatchNorm_1/add) to deploy on DPU. This may cause accuracy decrease and error for DPU compiler.
[DEPLOY WARNING] Batchnorm Node (batch_normalization_41/FusedBatchNorm_1/add + batch_normalization_41/FusedBatchNorm_1/mul) is not folded. It will be converted to a Scale node (batch_normalization_41/FusedBatchNorm_1/add) to deploy on DPU. This may cause accuracy decrease and error for DPU compiler.
[DEPLOY WARNING] Batchnorm Node (batch_normalization_44/FusedBatchNorm_1/add + batch_normalization_44/FusedBatchNorm_1/mul) is not folded. It will be converted to a Scale node (batch_normalization_44/FusedBatchNorm_1/add) to deploy on DPU. This may cause accuracy decrease and error for DPU compiler.
[DEPLOY WARNING] Batchnorm Node (batch_normalization_47/FusedBatchNorm_1/add + batch_normalization_47/FusedBatchNorm_1/mul) is not folded. It will be converted to a Scale node (batch_normalization_47/FusedBatchNorm_1/add) to deploy on DPU. This may cause accuracy decrease and error for DPU compiler.
[DEPLOY WARNING] Batchnorm Node (batch_normalization_50/FusedBatchNorm_1/add + batch_normalization_50/FusedBatchNorm_1/mul) is not folded. It will be converted to a Scale node (batch_normalization_50/FusedBatchNorm_1/add) to deploy on DPU. This may cause accuracy decrease and error for DPU compiler.
[DEPLOY WARNING] Batchnorm Node (batch_normalization_53/FusedBatchNorm_1/add + batch_normalization_53/FusedBatchNorm_1/mul) is not folded. It will be converted to a Scale node (batch_normalization_53/FusedBatchNorm_1/add) to deploy on DPU. This may cause accuracy decrease and error for DPU compiler.
[DEPLOY WARNING] Batchnorm Node (batch_normalization_56/FusedBatchNorm_1/add + batch_normalization_56/FusedBatchNorm_1/mul) is not folded. It will be converted to a Scale node (batch_normalization_56/FusedBatchNorm_1/add) to deploy on DPU. This may cause accuracy decrease and error for DPU compiler.
[DEPLOY WARNING] Batchnorm Node (batch_normalization_59/FusedBatchNorm_1/add + batch_normalization_59/FusedBatchNorm_1/mul) is not folded. It will be converted to a Scale node (batch_normalization_59/FusedBatchNorm_1/add) to deploy on DPU. This may cause accuracy decrease and error for DPU compiler.
[DEPLOY WARNING] Batchnorm Node (batch_normalization_62/FusedBatchNorm_1/add + batch_normalization_62/FusedBatchNorm_1/mul) is not folded. It will be converted to a Scale node (batch_normalization_62/FusedBatchNorm_1/add) to deploy on DPU. This may cause accuracy decrease and error for DPU compiler.
[DEPLOY WARNING] Batchnorm Node (batch_normalization_65/FusedBatchNorm_1/add + batch_normalization_65/FusedBatchNorm_1/mul) is not folded. It will be converted to a Scale node (batch_normalization_65/FusedBatchNorm_1/add) to deploy on DPU. This may cause accuracy decrease and error for DPU compiler.
[DEPLOY WARNING] Batchnorm Node (batch_normalization_68/FusedBatchNorm_1/add + batch_normalization_68/FusedBatchNorm_1/mul) is not folded. It will be converted to a Scale node (batch_normalization_68/FusedBatchNorm_1/add) to deploy on DPU. This may cause accuracy decrease and error for DPU compiler.
[DEPLOY WARNING] Batchnorm Node (batch_normalization_71/FusedBatchNorm_1/add + batch_normalization_71/FusedBatchNorm_1/mul) is not folded. It will be converted to a Scale node (batch_normalization_71/FusedBatchNorm_1/add) to deploy on DPU. This may cause accuracy decrease and error for DPU compiler.
[DEPLOY WARNING] Batchnorm Node (batch_normalization_74/FusedBatchNorm_1/add + batch_normalization_74/FusedBatchNorm_1/mul) is not folded. It will be converted to a Scale node (batch_normalization_74/FusedBatchNorm_1/add) to deploy on DPU. This may cause accuracy decrease and error for DPU compiler.
[DEPLOY WARNING] Batchnorm Node (batch_normalization_77/FusedBatchNorm_1/add + batch_normalization_77/FusedBatchNorm_1/mul) is not folded. It will be converted to a Scale node (batch_normalization_77/FusedBatchNorm_1/add) to deploy on DPU. This may cause accuracy decrease and error for DPU compiler.
[DEPLOY WARNING] Batchnorm Node (batch_normalization_80/FusedBatchNorm_1/add + batch_normalization_80/FusedBatchNorm_1/mul) is not folded. It will be converted to a Scale node (batch_normalization_80/FusedBatchNorm_1/add) to deploy on DPU. This may cause accuracy decrease and error for DPU compiler.
[DEPLOY WARNING] Batchnorm Node (batch_normalization_83/FusedBatchNorm_1/add + batch_normalization_83/FusedBatchNorm_1/mul) is not folded. It will be converted to a Scale node (batch_normalization_83/FusedBatchNorm_1/add) to deploy on DPU. This may cause accuracy decrease and error for DPU compiler.
script running on folder  /workspace/VAI-KERAS-CUSTOM-GOOGLENET-RESNET/code
CALIB DIR  /workspace/VAI-KERAS-CUSTOM-GOOGLENET-RESNET/code/../dataset/fashion-mnist/calib/
INFO: Checking Float Graph...
INFO: Float Graph Check Done.
INFO: Calibrating for 20 iterations...
INFO: Calibration Done.
INFO: Generating Deploy Model...
INFO: Deploy Model Generated.
********************* Quantization Summary *********************      
INFO: Output:       
  quantize_eval_model: ../quantized_results/fmnist/miniResNet/quantize_eval_model.pb       
  deploy_model: ../quantized_results/fmnist/miniResNet/deploy_model.pb
