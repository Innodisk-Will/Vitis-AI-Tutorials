/**

* Â© Copyright (C) 2016-2020 Xilinx, Inc
*
* Licensed under the Apache License, Version 2.0 (the "License"). You may
* not use this file except in compliance with the License. A copy of the
* License is located at
*
*     http://www.apache.org/licenses/LICENSE-2.0
*
* Unless required by applicable law or agreed to in writing, software
* distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
* WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
* License for the specific language governing permissions and limitations
* under the License.
*/



2020-02-13 06:12:36.264310: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F
2020-02-13 06:12:36.377790: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Quadro P6000 major: 6 minor: 1 memoryClockRate(GHz): 1.645
pciBusID: 0000:65:00.0
totalMemory: 23.86GiB freeMemory: 22.94GiB
2020-02-13 06:12:36.377815: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-02-13 06:12:36.855281: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-02-13 06:12:36.855302: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-02-13 06:12:36.855308: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-02-13 06:12:36.855940: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22255 MB memory) -> physical GPU (device: 0, name: Quadro P6000, pci bus id: 0000:65:00.0, compute capability: 6.1)
[INFO] compiling model...
[INFO] training model...
Epoch 1/25
 - 30s - loss: 0.4852 - acc: 0.8643 - val_loss: 0.3741 - val_acc: 0.9018

Epoch 00001: val_loss improved from inf to 0.37408, saving model to keras_model/fmnist/miniVggNet/best_chkpt.hdf5
Epoch 2/25
 - 29s - loss: 0.3616 - acc: 0.9074 - val_loss: 0.3412 - val_acc: 0.9154

Epoch 00002: val_loss improved from 0.37408 to 0.34115, saving model to keras_model/fmnist/miniVggNet/best_chkpt.hdf5
Epoch 3/25
 - 29s - loss: 0.3273 - acc: 0.9192 - val_loss: 0.3168 - val_acc: 0.9232

Epoch 00003: val_loss improved from 0.34115 to 0.31681, saving model to keras_model/fmnist/miniVggNet/best_chkpt.hdf5
Epoch 4/25
 - 29s - loss: 0.3106 - acc: 0.9241 - val_loss: 0.3044 - val_acc: 0.9283

Epoch 00004: val_loss improved from 0.31681 to 0.30440, saving model to keras_model/fmnist/miniVggNet/best_chkpt.hdf5
Epoch 5/25
 - 29s - loss: 0.2952 - acc: 0.9287 - val_loss: 0.2955 - val_acc: 0.9296

Epoch 00005: val_loss improved from 0.30440 to 0.29548, saving model to keras_model/fmnist/miniVggNet/best_chkpt.hdf5
Epoch 6/25
 - 29s - loss: 0.2843 - acc: 0.9322 - val_loss: 0.3037 - val_acc: 0.9309

Epoch 00006: val_loss did not improve from 0.29548
Epoch 7/25
 - 29s - loss: 0.2775 - acc: 0.9346 - val_loss: 0.2893 - val_acc: 0.9317

Epoch 00007: val_loss improved from 0.29548 to 0.28933, saving model to keras_model/fmnist/miniVggNet/best_chkpt.hdf5
Epoch 8/25
 - 29s - loss: 0.2702 - acc: 0.9366 - val_loss: 0.2887 - val_acc: 0.9354

Epoch 00008: val_loss improved from 0.28933 to 0.28870, saving model to keras_model/fmnist/miniVggNet/best_chkpt.hdf5
Epoch 9/25
 - 29s - loss: 0.2638 - acc: 0.9391 - val_loss: 0.2898 - val_acc: 0.9332

Epoch 00009: val_loss did not improve from 0.28870
Epoch 10/25
 - 29s - loss: 0.2595 - acc: 0.9404 - val_loss: 0.2799 - val_acc: 0.9329

Epoch 00010: val_loss improved from 0.28870 to 0.27986, saving model to keras_model/fmnist/miniVggNet/best_chkpt.hdf5
Epoch 11/25
 - 29s - loss: 0.2532 - acc: 0.9425 - val_loss: 0.2820 - val_acc: 0.9336

Epoch 00011: val_loss did not improve from 0.27986
Epoch 12/25
 - 29s - loss: 0.2500 - acc: 0.9436 - val_loss: 0.2768 - val_acc: 0.9349

Epoch 00012: val_loss improved from 0.27986 to 0.27684, saving model to keras_model/fmnist/miniVggNet/best_chkpt.hdf5
Epoch 13/25
 - 29s - loss: 0.2459 - acc: 0.9448 - val_loss: 0.2754 - val_acc: 0.9358

Epoch 00013: val_loss improved from 0.27684 to 0.27544, saving model to keras_model/fmnist/miniVggNet/best_chkpt.hdf5
Epoch 14/25
 - 29s - loss: 0.2421 - acc: 0.9459 - val_loss: 0.2802 - val_acc: 0.9345

Epoch 00014: val_loss did not improve from 0.27544
Epoch 15/25
 - 29s - loss: 0.2388 - acc: 0.9468 - val_loss: 0.2746 - val_acc: 0.9363

Epoch 00015: val_loss improved from 0.27544 to 0.27457, saving model to keras_model/fmnist/miniVggNet/best_chkpt.hdf5
Epoch 16/25
 - 29s - loss: 0.2373 - acc: 0.9467 - val_loss: 0.2702 - val_acc: 0.9373

Epoch 00016: val_loss improved from 0.27457 to 0.27016, saving model to keras_model/fmnist/miniVggNet/best_chkpt.hdf5
Epoch 17/25
 - 29s - loss: 0.2344 - acc: 0.9477 - val_loss: 0.2711 - val_acc: 0.9343

Epoch 00017: val_loss did not improve from 0.27016
Epoch 18/25
 - 29s - loss: 0.2316 - acc: 0.9490 - val_loss: 0.2697 - val_acc: 0.9369

Epoch 00018: val_loss improved from 0.27016 to 0.26974, saving model to keras_model/fmnist/miniVggNet/best_chkpt.hdf5
Epoch 19/25
 - 29s - loss: 0.2303 - acc: 0.9493 - val_loss: 0.2723 - val_acc: 0.9372

Epoch 00019: val_loss did not improve from 0.26974
Epoch 20/25
 - 29s - loss: 0.2254 - acc: 0.9506 - val_loss: 0.2676 - val_acc: 0.9383

Epoch 00020: val_loss improved from 0.26974 to 0.26763, saving model to keras_model/fmnist/miniVggNet/best_chkpt.hdf5
Epoch 21/25
 - 29s - loss: 0.2248 - acc: 0.9515 - val_loss: 0.2664 - val_acc: 0.9381

Epoch 00021: val_loss improved from 0.26763 to 0.26636, saving model to keras_model/fmnist/miniVggNet/best_chkpt.hdf5
Epoch 22/25
 - 29s - loss: 0.2225 - acc: 0.9517 - val_loss: 0.2672 - val_acc: 0.9368

Epoch 00022: val_loss did not improve from 0.26636
Epoch 23/25
 - 29s - loss: 0.2207 - acc: 0.9524 - val_loss: 0.2675 - val_acc: 0.9371

Epoch 00023: val_loss did not improve from 0.26636
Epoch 24/25
 - 28s - loss: 0.2193 - acc: 0.9528 - val_loss: 0.2672 - val_acc: 0.9362

Epoch 00024: val_loss did not improve from 0.26636
Epoch 25/25
 - 29s - loss: 0.2154 - acc: 0.9539 - val_loss: 0.2608 - val_acc: 0.9402

Epoch 00025: val_loss improved from 0.26636 to 0.26080, saving model to keras_model/fmnist/miniVggNet/best_chkpt.hdf5


Elapsed time for Keras training (s):  723.469456


[INFO] evaluating network on Test and Validation datasets...

  64/5000 [..............................] - ETA: 0s
1088/5000 [=====>........................] - ETA: 0s
2112/5000 [===========>..................] - ETA: 0s
3072/5000 [=================>............] - ETA: 0s
4032/5000 [=======================>......] - ETA: 0s
4928/5000 [============================>.] - ETA: 0s
5000/5000 [==============================] - 0s 54us/step
Validation Loss: 0.265
validation Accuracy: 0.938

  64/5000 [..............................] - ETA: 0s
 960/5000 [====>.........................] - ETA: 0s
1856/5000 [==========>...................] - ETA: 0s
2752/5000 [===============>..............] - ETA: 0s
3648/5000 [====================>.........] - ETA: 0s
4544/5000 [==========================>...] - ETA: 0s
5000/5000 [==============================] - 0s 60us/step
Using TensorFlow backend.
Test Loss: 0.254
Test Accuracy: 0.943
              precision    recall  f1-score   support

         top       0.89      0.88      0.88       500
     trouser       1.00      0.99      0.99       500
    pullover       0.95      0.92      0.93       500
       dress       0.94      0.96      0.95       500
        coat       0.91      0.93      0.92       500
      sandal       0.99      0.99      0.99       500
       shirt       0.82      0.83      0.82       500
     sneaker       0.96      0.98      0.97       500
         bag       0.99      0.99      0.99       500
   ankleBoot       0.98      0.96      0.97       500

    accuracy                           0.94      5000
   macro avg       0.94      0.94      0.94      5000
weighted avg       0.94      0.94      0.94      5000


TRAINING miniVggNet FINISHED

