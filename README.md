<table class="sphinxhide">
 <tr width="100%">
    <td align="center"><img src="https://raw.githubusercontent.com/Xilinx/Image-Collateral/main/xilinx-logo.png" width="30%"/><h1>Vitis-AI™ 2.0</h1>
    <a href="https://www.xilinx.com/products/design-tools/vitis.html">See Vitis™ Development Environment on xilinx.com</br></a>
    <a href="https://www.xilinx.com/products/design-tools/vitis/vitis-ai.html">See Vitis-AI™ Development Environment on xilinx.com</a>
    </td>
 </tr>
</table>


# Tutorials

<table>
<thead>
  <tr>
    <th width="35%" align="center"><h3><b>Tutorial Name</b></hr></th>
    <th width="15%" align="center"><h3><b>Highest Version</b></hr></th>
    <th width="50%" align="center"><h3><b>Description</b></hr></th>
  </tr>
</thead>
<tbody>
  <tr>
    <td><a href="https://github.com/Xilinx/Vitis-AI-Tutorials/tree/2.0/Tutorials/caffe_cats_vs_dogs/README.md">Quantization and Pruning of AlexNet CNN trained in Caffe with Cats-vs-Dogs dataset</a></td>
    <td align="center">2.0</td>
    <td>Train, prune, and quantize a modified version of the AlexNet convolutional neural network (CNN) with the Kaggle Dogs vs. Cats dataset in order to deploy it on the Xilinx® ZCU102 board.</td>
  </tr>
  <tr>
    <td><a href="https://github.com/Xilinx/Vitis-AI-Tutorials/tree/2.0/Tutorials/Vitis-AI-on-VCK5000-ES-Board/">Vitis AI on VCK5000-ES Card</a></td>
    <td align="center">2.0</td>
    <td>Start from card installation and go through a step-by-step workflow to run the first Vitis AI sample on a <b>VCK5000 ES card</b>.</td>
  </tr>
  <tr>
    <td><a href="https://github.com/Xilinx/Vitis-AI-Tutorials/tree/2.0/Tutorials/VCK190_CUSTOM_LAMBDA_OP/">VCK190 Custom Lambda Operator</a></td>
    <td align="center">2.0</td>
    <td>The general concept behind the custom operator flow is to make Vitis AI and the DPU more extensible—both for supporting custom layers as well as framework layers that are currently unsupported in the toolchain. The custom operator flow enables you to define layers which are unsupported, and ultimately deploy those layers either on the CPU or an accelerator.</td>
  </tr>
  <tr>
    <td><a href="https://github.com/Xilinx/Vitis-AI-Tutorials/tree/2.0/Tutorials/kv260_lidar_cam_fusion/">LIDAR + Camera Fusion on KV260</a></td>
    <td align="center">2.0</td>
    <td>Shows you how to install Ubuntu on the KV260 then build ROS, bring in multiple sensors, and deploy FPGA-accelerated neural network to process the data before displaying the data using RViz. All of this is possible without ever using FPGA tools!</td>
  </tr>
  <tr>
    <td><a href="https://github.com/Xilinx/Vitis-AI-Tutorials/tree/2.0/Tutorials/Vitis-AI-Vivado-TRD/">Leveraging the Vitis AI DPU in the Vivado Workflow</a></td>
    <td align="center">2.0</td>
    <td>SShows you how to build the Vitis AI Targeted Reference Design (TRD) using the Vivado flow and walks you through the steps required to build a PetaLinux image from the ZCU102 BSP that is provided in the TRD archive.</td>
  </tr>
</tbody>
</table>



</hr>
<p class="sphinxhide" align="center"><sup>Copyright&copy; 2022 Xilinx</sup></p>
